@pytest mark django_dbdef test_vfolder_with_no_filter_rules vfolder_item {'name' 'whatever' 'priority' 4 'is_public' True 'filter_rules' ''}with pytest raises ValidationError as excinfo VirtualFolder objects create **vfolder_item assert u'Somefilteringrulemustbespecified ' in str excinfo value vfolder_item['filter_rules'] 'FOO'vf VirtualFolder objects create **vfolder_item vf filter_rules ''with pytest raises ValidationError as excinfo vf save assert u'Somefilteringrulemustbespecified ' in str excinfo value
def safe_range *args rng xrange *args if len rng > MAX_RANGE raise OverflowError 'rangetoobig maximumsizeforrangeis%d' % MAX_RANGE return rng
def safe_range *args rng xrange *args if len rng > MAX_RANGE raise OverflowError 'rangetoobig maximumsizeforrangeis%d' % MAX_RANGE return rng
def safe_range *args rng xrange *args if len rng > MAX_RANGE raise OverflowError 'rangetoobig maximumsizeforrangeis%d' % MAX_RANGE return rng
def not_allowed func def inner self *args **kwargs raise NotImplementedError '%sisnotallowedon%sinstances' % func type self __name__ return inner
def snapshot_id_to_name name snap_id strict False runas None name _sdecode name if not re match GUID_REGEX snap_id raise SaltInvocationError u'SnapshotID"{0}"isnotaGUID' format _sdecode snap_id info prlctl 'snapshot-list' [name '--id' snap_id] runas runas if not len info raise SaltInvocationError u'NosnapshotsforVM"{0}"haveID"{1}"' format name snap_id try data yaml safe_load info except yaml YAMLError as err log warning 'Couldnotinterpretsnapshotdatareturnedfromprlctl {0}' format err data {}if isinstance data dict snap_name data get 'Name' '' if snap_name is None snap_name ''else log warning u'Couldnotinterpretsnapshotdatareturnedfromprlctl dataisnotformedasadictionary {0}' format data snap_name ''if not snap_name and strict raise SaltInvocationError u'CouldnotfindasnapshotnameforsnapshotID"{0}"ofVM"{1}"' format snap_id name return _sdecode snap_name
def GetMostRecentClient client_list token None last rdfvalue RDFDatetime 0 client_urn Nonefor client in aff4 FACTORY MultiOpen client_list token token client_last client Get client Schema LAST if client_last > last last client_lastclient_urn client urnreturn client_urn
def GetMostRecentClient client_list token None last rdfvalue RDFDatetime 0 client_urn Nonefor client in aff4 FACTORY MultiOpen client_list token token client_last client Get client Schema LAST if client_last > last last client_lastclient_urn client urnreturn client_urn
def GetMostRecentClient client_list token None last rdfvalue RDFDatetime 0 client_urn Nonefor client in aff4 FACTORY MultiOpen client_list token token client_last client Get client Schema LAST if client_last > last last client_lastclient_urn client urnreturn client_urn
@register simple_tagdef static path return staticfiles_storage url path
@register simple_tagdef static path return staticfiles_storage url path
def set_mindays name days return False
def set_mindays name days return False
def getFileNamesByFilePaths pluginFilePaths fileNames []for pluginFilePath in pluginFilePaths pluginBasename os path basename pluginFilePath pluginBasename getUntilDot pluginBasename fileNames append pluginBasename return fileNames
def getFileNamesByFilePaths pluginFilePaths fileNames []for pluginFilePath in pluginFilePaths pluginBasename os path basename pluginFilePath pluginBasename getUntilDot pluginBasename fileNames append pluginBasename return fileNames
def get_task_data task_id result AsyncResult task_id state info result state result info if state 'PENDING' raise TaskNotFound task_id if 'task_name' not in info raise TaskNotFound task_id try task celery_app tasks[info['task_name']]except KeyError raise TaskNotFound task_id return task state info
def get_task_data task_id result AsyncResult task_id state info result state result info if state 'PENDING' raise TaskNotFound task_id if 'task_name' not in info raise TaskNotFound task_id try task celery_app tasks[info['task_name']]except KeyError raise TaskNotFound task_id return task state info
def get_task_data task_id result AsyncResult task_id state info result state result info if state 'PENDING' raise TaskNotFound task_id if 'task_name' not in info raise TaskNotFound task_id try task celery_app tasks[info['task_name']]except KeyError raise TaskNotFound task_id return task state info
def present name password permission ret {'name' name 'result' True 'changes' {} 'comment' ''}users __salt__['drac list_users'] if __opts__['test'] if name in users ret['comment'] '`{0}`alreadyexists' format name else ret['comment'] '`{0}`willbecreated' format name ret['changes'] {name 'willbecreated'}return retif name in users ret['comment'] '`{0}`alreadyexists' format name elif __salt__['drac create_user'] name password permission users ret['comment'] '`{0}`usercreated' format name ret['changes'] {name 'newusercreated'}else ret['comment'] 'Unabletocreateuser'ret['result'] Falsereturn ret
def present name password permission ret {'name' name 'result' True 'changes' {} 'comment' ''}users __salt__['drac list_users'] if __opts__['test'] if name in users ret['comment'] '`{0}`alreadyexists' format name else ret['comment'] '`{0}`willbecreated' format name ret['changes'] {name 'willbecreated'}return retif name in users ret['comment'] '`{0}`alreadyexists' format name elif __salt__['drac create_user'] name password permission users ret['comment'] '`{0}`usercreated' format name ret['changes'] {name 'newusercreated'}else ret['comment'] 'Unabletocreateuser'ret['result'] Falsereturn ret
def present name password permission ret {'name' name 'result' True 'changes' {} 'comment' ''}users __salt__['drac list_users'] if __opts__['test'] if name in users ret['comment'] '`{0}`alreadyexists' format name else ret['comment'] '`{0}`willbecreated' format name ret['changes'] {name 'willbecreated'}return retif name in users ret['comment'] '`{0}`alreadyexists' format name elif __salt__['drac create_user'] name password permission users ret['comment'] '`{0}`usercreated' format name ret['changes'] {name 'newusercreated'}else ret['comment'] 'Unabletocreateuser'ret['result'] Falsereturn ret
def present name password permission ret {'name' name 'result' True 'changes' {} 'comment' ''}users __salt__['drac list_users'] if __opts__['test'] if name in users ret['comment'] '`{0}`alreadyexists' format name else ret['comment'] '`{0}`willbecreated' format name ret['changes'] {name 'willbecreated'}return retif name in users ret['comment'] '`{0}`alreadyexists' format name elif __salt__['drac create_user'] name password permission users ret['comment'] '`{0}`usercreated' format name ret['changes'] {name 'newusercreated'}else ret['comment'] 'Unabletocreateuser'ret['result'] Falsereturn ret
def ext_pillar minion_id pillar command try data yaml safe_load __salt__['cmd run'] '{0}{1}' format command minion_id data data['parameters']return dataexcept Exception log critical 'YAMLdatafrom{0}failedtoparse' format command return {}
def ext_pillar minion_id pillar command try data yaml safe_load __salt__['cmd run'] '{0}{1}' format command minion_id data data['parameters']return dataexcept Exception log critical 'YAMLdatafrom{0}failedtoparse' format command return {}
def ext_pillar minion_id pillar command try data yaml safe_load __salt__['cmd run'] '{0}{1}' format command minion_id data data['parameters']return dataexcept Exception log critical 'YAMLdatafrom{0}failedtoparse' format command return {}
def get_xml_encoding source with get_xml_iterator source as iterator start tag data pos six next iterator if not start or tag u'xml' raise IOError u'InvalidXMLfile' return data get u'encoding' or u'utf-8'
def get_xml_encoding source with get_xml_iterator source as iterator start tag data pos six next iterator if not start or tag u'xml' raise IOError u'InvalidXMLfile' return data get u'encoding' or u'utf-8'
def get_xml_encoding source with get_xml_iterator source as iterator start tag data pos six next iterator if not start or tag u'xml' raise IOError u'InvalidXMLfile' return data get u'encoding' or u'utf-8'
@register filterdef bootstrap_message_classes message extra_tags Nonetry extra_tags message extra_tagsexcept AttributeError passif not extra_tags extra_tags u''classes [extra_tags]try level message levelexcept AttributeError passelse try classes append MESSAGE_LEVEL_CLASSES[level] except KeyError classes append u'alertalert-danger' return u'' join classes strip
def ToSentences paragraph include_token True s_gen SnippetGen paragraph SENTENCE_START SENTENCE_END include_token return [s for s in s_gen]
def ToSentences paragraph include_token True s_gen SnippetGen paragraph SENTENCE_START SENTENCE_END include_token return [s for s in s_gen]
def test_multi_constructor_obj try load 'a obj decimal Decimal{1}' except TypeError as e assert str e 'Receivednonstringobject 1 askeyinmapping ' passexcept Exception as e error_msg 'Gottheunexpectederror %s' % e reraise_as ValueError error_msg
def test_multi_constructor_obj try load 'a obj decimal Decimal{1}' except TypeError as e assert str e 'Receivednonstringobject 1 askeyinmapping ' passexcept Exception as e error_msg 'Gottheunexpectederror %s' % e reraise_as ValueError error_msg
def test_multi_constructor_obj try load 'a obj decimal Decimal{1}' except TypeError as e assert str e 'Receivednonstringobject 1 askeyinmapping ' passexcept Exception as e error_msg 'Gottheunexpectederror %s' % e reraise_as ValueError error_msg
def _listFriends fs sep ' ' lock True getLastMessage False p PyFred 'ch xtin skypingalfred find' False for f in fs img imgtype _getAvatar f[0] p addItem 'skypename_' + f[0] f[0] + sep f[0] + ' ' + f[1] + ' ' if f[1] else ' ' + f[2] + ' ' if f[2] else '' _getLastMessageFormated f[0] if getLastMessage else '' not lock f[0] + sep img imgtype if len p _items 0 p addItem 'skypename_notfound' 'skypeupdate' 'NoSkypefriendfound ' + tg 'Maybetryupdatingyourfriends?Hitentertodoso ' True return p toXML
def _listFriends fs sep ' ' lock True getLastMessage False p PyFred 'ch xtin skypingalfred find' False for f in fs img imgtype _getAvatar f[0] p addItem 'skypename_' + f[0] f[0] + sep f[0] + ' ' + f[1] + ' ' if f[1] else ' ' + f[2] + ' ' if f[2] else '' _getLastMessageFormated f[0] if getLastMessage else '' not lock f[0] + sep img imgtype if len p _items 0 p addItem 'skypename_notfound' 'skypeupdate' 'NoSkypefriendfound ' + tg 'Maybetryupdatingyourfriends?Hitentertodoso ' True return p toXML
def _listFriends fs sep ' ' lock True getLastMessage False p PyFred 'ch xtin skypingalfred find' False for f in fs img imgtype _getAvatar f[0] p addItem 'skypename_' + f[0] f[0] + sep f[0] + ' ' + f[1] + ' ' if f[1] else ' ' + f[2] + ' ' if f[2] else '' _getLastMessageFormated f[0] if getLastMessage else '' not lock f[0] + sep img imgtype if len p _items 0 p addItem 'skypename_notfound' 'skypeupdate' 'NoSkypefriendfound ' + tg 'Maybetryupdatingyourfriends?Hitentertodoso ' True return p toXML
def _listFriends fs sep ' ' lock True getLastMessage False p PyFred 'ch xtin skypingalfred find' False for f in fs img imgtype _getAvatar f[0] p addItem 'skypename_' + f[0] f[0] + sep f[0] + ' ' + f[1] + ' ' if f[1] else ' ' + f[2] + ' ' if f[2] else '' _getLastMessageFormated f[0] if getLastMessage else '' not lock f[0] + sep img imgtype if len p _items 0 p addItem 'skypename_notfound' 'skypeupdate' 'NoSkypefriendfound ' + tg 'Maybetryupdatingyourfriends?Hitentertodoso ' True return p toXML
def prob_quantize_cdf_old binsx binsy cdf binsx np asarray binsx binsy np asarray binsy nx len binsx - 1 ny len binsy - 1 probs np nan * np ones nx ny for xind in range 1 nx + 1 for yind in range 1 ny + 1 upper binsx[xind] binsy[yind] lower binsx[ xind - 1 ] binsy[ yind - 1 ] probs[ xind - 1 yind - 1 ] prob_bv_rectangle lower upper cdf assert not np isnan probs any return probs
def prob_quantize_cdf_old binsx binsy cdf binsx np asarray binsx binsy np asarray binsy nx len binsx - 1 ny len binsy - 1 probs np nan * np ones nx ny for xind in range 1 nx + 1 for yind in range 1 ny + 1 upper binsx[xind] binsy[yind] lower binsx[ xind - 1 ] binsy[ yind - 1 ] probs[ xind - 1 yind - 1 ] prob_bv_rectangle lower upper cdf assert not np isnan probs any return probs
def prob_quantize_cdf_old binsx binsy cdf binsx np asarray binsx binsy np asarray binsy nx len binsx - 1 ny len binsy - 1 probs np nan * np ones nx ny for xind in range 1 nx + 1 for yind in range 1 ny + 1 upper binsx[xind] binsy[yind] lower binsx[ xind - 1 ] binsy[ yind - 1 ] probs[ xind - 1 yind - 1 ] prob_bv_rectangle lower upper cdf assert not np isnan probs any return probs
def _RetainVerticalSpacingBetweenTokens cur_tok prev_tok if prev_tok is None returnif prev_tok is_string prev_lineno prev_tok lineno + prev_tok value count u'\n' elif prev_tok is_pseudo_paren if not prev_tok previous_token is_multiline_string prev_lineno prev_tok previous_token linenoelse prev_lineno prev_tok linenoelse prev_lineno prev_tok linenoif cur_tok is_comment cur_lineno cur_tok lineno - cur_tok value count u'\n' else cur_lineno cur_tok linenocur_tok AdjustNewlinesBefore cur_lineno - prev_lineno
def _RetainVerticalSpacingBetweenTokens cur_tok prev_tok if prev_tok is None returnif prev_tok is_string prev_lineno prev_tok lineno + prev_tok value count u'\n' elif prev_tok is_pseudo_paren if not prev_tok previous_token is_multiline_string prev_lineno prev_tok previous_token linenoelse prev_lineno prev_tok linenoelse prev_lineno prev_tok linenoif cur_tok is_comment cur_lineno cur_tok lineno - cur_tok value count u'\n' else cur_lineno cur_tok linenocur_tok AdjustNewlinesBefore cur_lineno - prev_lineno
def scan_multilang tokens module_elem tokenizer ruby_lexer RubyMultiLangLexer tokens parser ruby_parser Parser tokenizer 'RHTML' parse_tree parser parse parser_cix produce_elementTree_contents_cix parse_tree module_elem csl_tokens tokenizer get_csl_tokens return csl_tokens tokenizer has_ruby_code
def scan_multilang tokens module_elem tokenizer ruby_lexer RubyMultiLangLexer tokens parser ruby_parser Parser tokenizer 'RHTML' parse_tree parser parse parser_cix produce_elementTree_contents_cix parse_tree module_elem csl_tokens tokenizer get_csl_tokens return csl_tokens tokenizer has_ruby_code
def osd_discover return ceph_cfg osd_discover
def parse_ssl2 message enforce_length True try record size types Sslv2Record from_stream message if enforce_length and size len message return Nonereturn recordexcept IndexError ValueError struct error as e return None
def has_roles var roles match_all False var_roles getattr var tag 'roles' [] matches any isinstance var_role role __class__ for var_role in var_roles for role in roles return all matches if match_all else any matches
def has_roles var roles match_all False var_roles getattr var tag 'roles' [] matches any isinstance var_role role __class__ for var_role in var_roles for role in roles return all matches if match_all else any matches
def has_roles var roles match_all False var_roles getattr var tag 'roles' [] matches any isinstance var_role role __class__ for var_role in var_roles for role in roles return all matches if match_all else any matches
def has_roles var roles match_all False var_roles getattr var tag 'roles' [] matches any isinstance var_role role __class__ for var_role in var_roles for role in roles return all matches if match_all else any matches
def DrtVariableExpression variable if is_indvar variable name return DrtIndividualVariableExpression variable elif is_funcvar variable name return DrtFunctionVariableExpression variable elif is_eventvar variable name return DrtEventVariableExpression variable else return DrtConstantExpression variable
def DrtVariableExpression variable if is_indvar variable name return DrtIndividualVariableExpression variable elif is_funcvar variable name return DrtFunctionVariableExpression variable elif is_eventvar variable name return DrtEventVariableExpression variable else return DrtConstantExpression variable
def _compare_acl current desired region key keyid profile ocid _get_canonical_id region key keyid profile return __utils__['boto3 json_objs_equal'] current _acl_to_grant desired ocid
def _execute cmd_list process_input None check_exit_code True cmd '' join cmd_list logging debug _ "Executingcommand '%s'" % cmd env os environ copy obj subprocess Popen cmd shell True stdin subprocess PIPE stdout subprocess PIPE stderr subprocess PIPE env env result Noneif process_input is not None result obj communicate process_input else result obj communicate obj stdin close if obj returncode logging debug _ 'Resultwas%s' % obj returncode if check_exit_code and obj returncode 0 stdout stderr resultraise ProcessExecutionError exit_code obj returncode stdout stdout stderr stderr cmd cmd time sleep 0 1 return result
def _execute cmd_list process_input None check_exit_code True cmd '' join cmd_list logging debug _ "Executingcommand '%s'" % cmd env os environ copy obj subprocess Popen cmd shell True stdin subprocess PIPE stdout subprocess PIPE stderr subprocess PIPE env env result Noneif process_input is not None result obj communicate process_input else result obj communicate obj stdin close if obj returncode logging debug _ 'Resultwas%s' % obj returncode if check_exit_code and obj returncode 0 stdout stderr resultraise ProcessExecutionError exit_code obj returncode stdout stdout stderr stderr cmd cmd time sleep 0 1 return result
def glob obj *args **kwargs return obj __glob__ *args **kwargs
def glob obj *args **kwargs return obj __glob__ *args **kwargs
def glob obj *args **kwargs return obj __glob__ *args **kwargs
def glob obj *args **kwargs return obj __glob__ *args **kwargs
def call_fp_intrinsic builder name args mod builder moduleintr lc Function intrinsic mod name [a type for a in args] return builder call intr args
def call_fp_intrinsic builder name args mod builder moduleintr lc Function intrinsic mod name [a type for a in args] return builder call intr args
def create_verifier_for_dsa signature hash_method public_key return public_key verifier signature hash_method
def create_verifier_for_dsa signature hash_method public_key return public_key verifier signature hash_method
def create_verifier_for_dsa signature hash_method public_key return public_key verifier signature hash_method
def absent name ret {'name' name 'changes' {} 'result' True 'comment' ''}grp_info __salt__['group info'] name if grp_info if __opts__['test'] ret['result'] Noneret['comment'] 'Group{0}issetforremoval' format name return retret['result'] __salt__['group delete'] name if ret['result'] ret['changes'] {name ''}ret['comment'] 'Removedgroup{0}' format name return retelse ret['comment'] 'Failedtoremovegroup{0}' format name return retelse ret['comment'] 'Groupnotpresent'return ret
def absent name ret {'name' name 'changes' {} 'result' True 'comment' ''}grp_info __salt__['group info'] name if grp_info if __opts__['test'] ret['result'] Noneret['comment'] 'Group{0}issetforremoval' format name return retret['result'] __salt__['group delete'] name if ret['result'] ret['changes'] {name ''}ret['comment'] 'Removedgroup{0}' format name return retelse ret['comment'] 'Failedtoremovegroup{0}' format name return retelse ret['comment'] 'Groupnotpresent'return ret
def _process_caption caption tokenized_caption [FLAGS start_word]tokenized_caption extend nltk tokenize word_tokenize caption lower tokenized_caption append FLAGS end_word return tokenized_caption
def _process_caption caption tokenized_caption [FLAGS start_word]tokenized_caption extend nltk tokenize word_tokenize caption lower tokenized_caption append FLAGS end_word return tokenized_caption
def bzr_wc_version test 'bzr_wc_version'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric api import runfrom fabtools files import is_dirfrom fabtools import requireassert not is_dir wt require bazaar working_copy REMOTE_URL wt version '2' assert_wc_exists wt assert run 'bzrrevno%s' % wt '2'
def bzr_wc_version test 'bzr_wc_version'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric api import runfrom fabtools files import is_dirfrom fabtools import requireassert not is_dir wt require bazaar working_copy REMOTE_URL wt version '2' assert_wc_exists wt assert run 'bzrrevno%s' % wt '2'
def _get_template path option_key with salt utils fopen path 'r' as template_f template deserialize template_f info option_key template get 'description' '' template return info
def _get_template path option_key with salt utils fopen path 'r' as template_f template deserialize template_f info option_key template get 'description' '' template return info
def _get_template path option_key with salt utils fopen path 'r' as template_f template deserialize template_f info option_key template get 'description' '' template return info
def parse_timedelta text td_kwargs {}for match in _PARSE_TD_RE finditer text value unit match group 'value' match group 'unit' try unit_key _PARSE_TD_KW_MAP[unit]except KeyError raise ValueError 'invalidtimeunit%r expectedoneof%r' % unit _PARSE_TD_KW_MAP keys try value float value except ValueError raise ValueError 'invalidtimevalueforunit%r %r' % unit value td_kwargs[unit_key] valuereturn timedelta **td_kwargs
def test_prefix class TableA tables Table name tables Column class Meta prefix u'x'table TableA [] html table as_html build_request u'/' assert u'x' table prefix assert u'xsort name' in html class TableB tables Table last_name tables Column assert u'' TableB [] prefix assert u'x' TableB [] prefix u'x' prefix table TableB [] table prefix u'x-'html table as_html build_request u'/' assert u'x-' table prefix assert u'x-sort last_name' in html
def test_prefix class TableA tables Table name tables Column class Meta prefix u'x'table TableA [] html table as_html build_request u'/' assert u'x' table prefix assert u'xsort name' in html class TableB tables Table last_name tables Column assert u'' TableB [] prefix assert u'x' TableB [] prefix u'x' prefix table TableB [] table prefix u'x-'html table as_html build_request u'/' assert u'x-' table prefix assert u'x-sort last_name' in html
def test_prefix class TableA tables Table name tables Column class Meta prefix u'x'table TableA [] html table as_html build_request u'/' assert u'x' table prefix assert u'xsort name' in html class TableB tables Table last_name tables Column assert u'' TableB [] prefix assert u'x' TableB [] prefix u'x' prefix table TableB [] table prefix u'x-'html table as_html build_request u'/' assert u'x-' table prefix assert u'x-sort last_name' in html
def register_plugin_class base_class file_path class_name plugin_dir os path dirname os path realpath file_path _register_plugin_path plugin_dir module_name _get_plugin_module file_path if module_name is None return Nonemodule imp load_source module_name file_path klass getattr module class_name None if not klass raise Exception 'Pluginfile"%s"doesn\'texposeclassnamed"%s"' % file_path class_name _register_plugin base_class klass return klass
def register_plugin_class base_class file_path class_name plugin_dir os path dirname os path realpath file_path _register_plugin_path plugin_dir module_name _get_plugin_module file_path if module_name is None return Nonemodule imp load_source module_name file_path klass getattr module class_name None if not klass raise Exception 'Pluginfile"%s"doesn\'texposeclassnamed"%s"' % file_path class_name _register_plugin base_class klass return klass
def get_rand_pass CRYPTOR gen_rand_pass 20
def get_rand_pass CRYPTOR gen_rand_pass 20
def setup_platform hass config add_devices discovery_info None litejet_ hass data['litejet_system']devices []for i in litejet_ button_switches name litejet_ get_switch_name i if not litejet is_ignored hass name devices append LiteJetSwitch hass litejet_ i name add_devices devices
def setup_platform hass config add_devices discovery_info None litejet_ hass data['litejet_system']devices []for i in litejet_ button_switches name litejet_ get_switch_name i if not litejet is_ignored hass name devices append LiteJetSwitch hass litejet_ i name add_devices devices
def addCylinderOutputByEndStart endZ inradiusComplex outputs sides start topOverBottom 1 0 inradius Vector3 inradiusComplex real inradiusComplex imag 0 5 * abs endZ - start z cylinderOutput getGeometryOutput inradius sides topOverBottom vertexes matrix getVertexes cylinderOutput if endZ < start z for vertex in vertexes vertex z - vertex z translation Vector3 start x start y inradius z + min start z endZ euclidean translateVector3Path vertexes translation outputs append cylinderOutput
def addCylinderOutputByEndStart endZ inradiusComplex outputs sides start topOverBottom 1 0 inradius Vector3 inradiusComplex real inradiusComplex imag 0 5 * abs endZ - start z cylinderOutput getGeometryOutput inradius sides topOverBottom vertexes matrix getVertexes cylinderOutput if endZ < start z for vertex in vertexes vertex z - vertex z translation Vector3 start x start y inradius z + min start z endZ euclidean translateVector3Path vertexes translation outputs append cylinderOutput
def test_empty_lists Chart chart Chart chart add 'A' [1 2] chart add 'B' [] if not chart _dual chart x_labels 'red' 'green' 'blue' q chart render_pyquery assert len q ' legend' 2
def d3write fct path *args **kwargs formatter PyDotFormatter *args **kwargs graph formatter fct graph write_dot path
def d3write fct path *args **kwargs formatter PyDotFormatter *args **kwargs graph formatter fct graph write_dot path
def d3write fct path *args **kwargs formatter PyDotFormatter *args **kwargs graph formatter fct graph write_dot path
def _fill inst_class frequencies ctype_info inst_class get_flat_type_info inst_class cfreq_key inst_class 0 for k v in ctype_info items if v Attributes min_occurs > 0 frequencies[cfreq_key][k] 0
def process_status name with settings hide 'running' 'stdout' 'stderr' 'warnings' warn_only True res run_as_root 'supervisorctlstatus% name s' % locals if res startswith 'Nosuchprocess' return Noneelse return res split [1]
def process_status name with settings hide 'running' 'stdout' 'stderr' 'warnings' warn_only True res run_as_root 'supervisorctlstatus% name s' % locals if res startswith 'Nosuchprocess' return Noneelse return res split [1]
def get_pgraster_srid data if data is None returnreturn unpack 'i' data[106 114] [0]
def get_pgraster_srid data if data is None returnreturn unpack 'i' data[106 114] [0]
def upload_to field_path default from mezzanine conf import settingsfor k v in settings UPLOAD_TO_HANDLERS items if k lower field_path lower return import_dotted_path v return default
def is_instance_of gateway java_object java_class if isinstance java_class basestring param java_classelif isinstance java_class JavaClass param java_class _fqnelif isinstance java_class JavaObject param java_class getClass else raise Py4JError u'java_classmustbeastring aJavaClass oraJavaObject' return gateway jvm py4j reflection TypeUtil isInstanceOf param java_object
def is_instance_of gateway java_object java_class if isinstance java_class basestring param java_classelif isinstance java_class JavaClass param java_class _fqnelif isinstance java_class JavaObject param java_class getClass else raise Py4JError u'java_classmustbeastring aJavaClass oraJavaObject' return gateway jvm py4j reflection TypeUtil isInstanceOf param java_object
def get_targets ret []for each in Guid find Q 'referent 1' 'nin' ['nodefile' 'osfguidfile'] if each referent is None logger info 'GUID{}hasnoreferent ' format each _id ret append each return ret
def get_targets ret []for each in Guid find Q 'referent 1' 'nin' ['nodefile' 'osfguidfile'] if each referent is None logger info 'GUID{}hasnoreferent ' format each _id ret append each return ret
def convert_db_channel_to_json channel include_rel_score False res_json {'id' channel[0] 'dispersy_cid' channel[1] encode 'hex' 'name' channel[2] 'description' channel[3] 'votes' channel[5] 'torrents' channel[4] 'spam' channel[6] 'modified' channel[8] 'subscribed' channel[7] VOTE_SUBSCRIBE }if include_rel_score res_json['relevance_score'] channel[9]return res_json
def convert_db_channel_to_json channel include_rel_score False res_json {'id' channel[0] 'dispersy_cid' channel[1] encode 'hex' 'name' channel[2] 'description' channel[3] 'votes' channel[5] 'torrents' channel[4] 'spam' channel[6] 'modified' channel[8] 'subscribed' channel[7] VOTE_SUBSCRIBE }if include_rel_score res_json['relevance_score'] channel[9]return res_json
@lower_constant types Tuple @lower_constant types NamedTuple def unituple_constant context builder ty pyval consts [context get_constant_generic builder ty types[i] v for i v in enumerate pyval ]return ir Constant literal_struct consts
@lower_constant types Tuple @lower_constant types NamedTuple def unituple_constant context builder ty pyval consts [context get_constant_generic builder ty types[i] v for i v in enumerate pyval ]return ir Constant literal_struct consts
def validate_dictionary_string_length specs if not isinstance specs dict msg _ 'specsmustbeadictionary ' raise exception InvalidInput reason msg for key value in specs items if key is not None check_string_length key 'Key"%s"' % key min_length 1 max_length 255 if value is not None check_string_length value 'Valueforkey"%s"' % key min_length 0 max_length 255
def validate_dictionary_string_length specs if not isinstance specs dict msg _ 'specsmustbeadictionary ' raise exception InvalidInput reason msg for key value in specs items if key is not None check_string_length key 'Key"%s"' % key min_length 1 max_length 255 if value is not None check_string_length value 'Valueforkey"%s"' % key min_length 0 max_length 255
@transaction non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_finance_admindef get_exec_summary_report request course_id course_key SlashSeparatedCourseKey from_deprecated_string course_id try lms djangoapps instructor_task api submit_executive_summary_report request course_key status_response _ 'Theexecutivesummaryreportisbeingcreated Toviewthestatusofthereport seePendingTasksbelow ' except AlreadyRunningError status_response _ 'Theexecutivesummaryreportiscurrentlybeingcreated Toviewthestatusofthereport seePendingTasksbelow Youwillbeabletodownloadthereportwhenitiscomplete ' return JsonResponse {'status' status_response}
@transaction non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' @require_finance_admindef get_exec_summary_report request course_id course_key SlashSeparatedCourseKey from_deprecated_string course_id try lms djangoapps instructor_task api submit_executive_summary_report request course_key status_response _ 'Theexecutivesummaryreportisbeingcreated Toviewthestatusofthereport seePendingTasksbelow ' except AlreadyRunningError status_response _ 'Theexecutivesummaryreportiscurrentlybeingcreated Toviewthestatusofthereport seePendingTasksbelow Youwillbeabletodownloadthereportwhenitiscomplete ' return JsonResponse {'status' status_response}
def cm2deg cm monitor correctFlat False if not isinstance monitor monitors Monitor msg 'cm2degrequiresamonitors Monitorobjectasthesecondargumentbutreceived%s'raise ValueError msg % str type monitor dist monitor getDistance if dist is None msg 'Monitor%shasnoknowndistance SEEMONITORCENTER 'raise ValueError msg % monitor name if correctFlat return np arctan np radians cm / dist else return cm / dist * 0 017455
def cm2deg cm monitor correctFlat False if not isinstance monitor monitors Monitor msg 'cm2degrequiresamonitors Monitorobjectasthesecondargumentbutreceived%s'raise ValueError msg % str type monitor dist monitor getDistance if dist is None msg 'Monitor%shasnoknowndistance SEEMONITORCENTER 'raise ValueError msg % monitor name if correctFlat return np arctan np radians cm / dist else return cm / dist * 0 017455
def test_batch_normalized_mlp_allocation mlp BatchNormalizedMLP [Tanh Tanh ] [5 7 9] mlp allocate assert mlp activations[0] children[0] input_dim 7 assert mlp activations[1] children[0] input_dim 9 assert not any l use_bias for l in mlp linear_transformations
def test_batch_normalized_mlp_allocation mlp BatchNormalizedMLP [Tanh Tanh ] [5 7 9] mlp allocate assert mlp activations[0] children[0] input_dim 7 assert mlp activations[1] children[0] input_dim 9 assert not any l use_bias for l in mlp linear_transformations
def manage_changed wrapped def changed session *arg **kw session accessed int time time session changed return wrapped session *arg **kw changed __doc__ wrapped __doc__return changed
def manage_changed wrapped def changed session *arg **kw session accessed int time time session changed return wrapped session *arg **kw changed __doc__ wrapped __doc__return changed
def manage_changed wrapped def changed session *arg **kw session accessed int time time session changed return wrapped session *arg **kw changed __doc__ wrapped __doc__return changed
def _win_user_token_is_admin user_token class SID_IDENTIFIER_AUTHORITY ctypes Structure _fields_ [ 'byte0' ctypes c_byte 'byte1' ctypes c_byte 'byte2' ctypes c_byte 'byte3' ctypes c_byte 'byte4' ctypes c_byte 'byte5' ctypes c_byte ]nt_authority SID_IDENTIFIER_AUTHORITY nt_authority byte5 5SECURITY_BUILTIN_DOMAIN_RID 32DOMAIN_ALIAS_RID_ADMINS 544administrators_group ctypes c_void_p if ctypes windll advapi32 AllocateAndInitializeSid ctypes byref nt_authority 2 SECURITY_BUILTIN_DOMAIN_RID DOMAIN_ALIAS_RID_ADMINS 0 0 0 0 0 0 ctypes byref administrators_group 0 raise Exception 'AllocateAndInitializeSidfailed' try is_admin ctypes wintypes BOOL if ctypes windll advapi32 CheckTokenMembership user_token administrators_group ctypes byref is_admin 0 raise Exception 'CheckTokenMembershipfailed' return is_admin value 0 finally ctypes windll advapi32 FreeSid administrators_group
def _win_user_token_is_admin user_token class SID_IDENTIFIER_AUTHORITY ctypes Structure _fields_ [ 'byte0' ctypes c_byte 'byte1' ctypes c_byte 'byte2' ctypes c_byte 'byte3' ctypes c_byte 'byte4' ctypes c_byte 'byte5' ctypes c_byte ]nt_authority SID_IDENTIFIER_AUTHORITY nt_authority byte5 5SECURITY_BUILTIN_DOMAIN_RID 32DOMAIN_ALIAS_RID_ADMINS 544administrators_group ctypes c_void_p if ctypes windll advapi32 AllocateAndInitializeSid ctypes byref nt_authority 2 SECURITY_BUILTIN_DOMAIN_RID DOMAIN_ALIAS_RID_ADMINS 0 0 0 0 0 0 ctypes byref administrators_group 0 raise Exception 'AllocateAndInitializeSidfailed' try is_admin ctypes wintypes BOOL if ctypes windll advapi32 CheckTokenMembership user_token administrators_group ctypes byref is_admin 0 raise Exception 'CheckTokenMembershipfailed' return is_admin value 0 finally ctypes windll advapi32 FreeSid administrators_group
def get_default_cgsnapshot_type grp_type {}ctxt context get_admin_context try grp_type get_group_type_by_name ctxt DEFAULT_CGSNAPSHOT_TYPE except exception GroupTypeNotFoundByName LOG exception _LE 'Defaultcgsnapshottype%sisnotfound ' % DEFAULT_CGSNAPSHOT_TYPE return grp_type
def get_default_cgsnapshot_type grp_type {}ctxt context get_admin_context try grp_type get_group_type_by_name ctxt DEFAULT_CGSNAPSHOT_TYPE except exception GroupTypeNotFoundByName LOG exception _LE 'Defaultcgsnapshottype%sisnotfound ' % DEFAULT_CGSNAPSHOT_TYPE return grp_type
def get_property obj name old_name default None if hasattr obj old_name warnings warn 'Property%sisobsolete pleaseuse%sinstead' % old_name name stacklevel 2 return getattr obj old_name return getattr obj name default
def get_property obj name old_name default None if hasattr obj old_name warnings warn 'Property%sisobsolete pleaseuse%sinstead' % old_name name stacklevel 2 return getattr obj old_name return getattr obj name default
def ffi_callback signature name **kwargs def wrapper func if lib Cryptography_STATIC_CALLBACKS ffi def_extern name name **kwargs func callback getattr lib name else callback ffi callback signature **kwargs func return callbackreturn wrapper
def ffi_callback signature name **kwargs def wrapper func if lib Cryptography_STATIC_CALLBACKS ffi def_extern name name **kwargs func callback getattr lib name else callback ffi callback signature **kwargs func return callbackreturn wrapper
def ffi_callback signature name **kwargs def wrapper func if lib Cryptography_STATIC_CALLBACKS ffi def_extern name name **kwargs func callback getattr lib name else callback ffi callback signature **kwargs func return callbackreturn wrapper
def require_app app_name api_style False iterable inspect getmodule frame[0] for frame in inspect stack modules [module for module in iterable if module is not None ]if api_style m modules[2]else m modules[1]m _REQUIRED_APP getattr m '_REQUIRED_APP' [] m _REQUIRED_APP append app_name LOG debug 'require_app %sisrequiredby%s' app_name m __name__
def require_app app_name api_style False iterable inspect getmodule frame[0] for frame in inspect stack modules [module for module in iterable if module is not None ]if api_style m modules[2]else m modules[1]m _REQUIRED_APP getattr m '_REQUIRED_APP' [] m _REQUIRED_APP append app_name LOG debug 'require_app %sisrequiredby%s' app_name m __name__
@deprecated since u'1 3' message _DEPRECATION_MESSAGE alternative u' func `~astropy coordinates matrix_utilities rotation_matrix`' def rotation_matrix angle axis u'z' unit None return matrix_utilities rotation_matrix angle axis unit view np matrix
@deprecated since u'1 3' message _DEPRECATION_MESSAGE alternative u' func `~astropy coordinates matrix_utilities rotation_matrix`' def rotation_matrix angle axis u'z' unit None return matrix_utilities rotation_matrix angle axis unit view np matrix
def clear_lookups namespace if namespace in LOOKUP del LOOKUP[namespace]
def clear_lookups namespace if namespace in LOOKUP del LOOKUP[namespace]
def create_connection auth return sdk Connection url auth get 'url' username auth get 'username' password auth get 'password' ca_file auth get 'ca_file' None insecure auth get 'insecure' False token auth get 'token' None kerberos auth get 'kerberos' None
def create_connection auth return sdk Connection url auth get 'url' username auth get 'username' password auth get 'password' ca_file auth get 'ca_file' None insecure auth get 'insecure' False token auth get 'token' None kerberos auth get 'kerberos' None
def clean_pyc path if not os access path os W_OK warnings warn '{0}isnotwritablesocannotdeletestale*pycfiles' format path returnprint 'Cleaning*pycfiles ifwritable from {0}' format path for root __dirs files in os walk path pyc_files filter lambda filename filename endswith ' pyc' files py_files set filter lambda filename filename endswith ' py' files excess_pyc_files filter lambda pyc_filename pyc_filename[ -1 ] not in py_files pyc_files for excess_pyc_file in excess_pyc_files full_path os path join root excess_pyc_file os remove full_path
def clean_pyc path if not os access path os W_OK warnings warn '{0}isnotwritablesocannotdeletestale*pycfiles' format path returnprint 'Cleaning*pycfiles ifwritable from {0}' format path for root __dirs files in os walk path pyc_files filter lambda filename filename endswith ' pyc' files py_files set filter lambda filename filename endswith ' py' files excess_pyc_files filter lambda pyc_filename pyc_filename[ -1 ] not in py_files pyc_files for excess_pyc_file in excess_pyc_files full_path os path join root excess_pyc_file os remove full_path
def get_chost return get_var 'CHOST'
def get_chost return get_var 'CHOST'
def metadef_namespace_delete context namespace_name session None session session or get_session return metadef_namespace_api delete_cascade context namespace_name session
def metadef_namespace_delete context namespace_name session None session session or get_session return metadef_namespace_api delete_cascade context namespace_name session
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def iter_sample draws step start None trace None chain 0 tune None model None random_seed -1 sampling _iter_sample draws step start trace chain tune model random_seed for i strace in enumerate sampling yield MultiTrace [strace[ i + 1 ]]
def _changeVersionInFile old new filename replaceInFile filename {old base new base }
def _changeVersionInFile old new filename replaceInFile filename {old base new base }
def _changeVersionInFile old new filename replaceInFile filename {old base new base }
def s3_utc dt if dt if dt tzinfo is None return dt replace tzinfo dateutil tz tzutc return dt astimezone dateutil tz tzutc else return None
def s3_utc dt if dt if dt tzinfo is None return dt replace tzinfo dateutil tz tzutc return dt astimezone dateutil tz tzutc else return None
def deeper2net_conv2d teacher_w nb_filter nb_channel kh kw teacher_w shapestudent_w np zeros nb_filter nb_filter kh kw for i in xrange nb_filter student_w[ i i kh - 1 / 2 kw - 1 / 2 ] 1 0student_b np zeros nb_filter return student_w student_b
def deeper2net_conv2d teacher_w nb_filter nb_channel kh kw teacher_w shapestudent_w np zeros nb_filter nb_filter kh kw for i in xrange nb_filter student_w[ i i kh - 1 / 2 kw - 1 / 2 ] 1 0student_b np zeros nb_filter return student_w student_b
def freeze_region clip t 0 region None outside_region None mask None if region is not None x1 y1 x2 y2 regionfreeze clip fx crop *region to_ImageClip t t set_duration clip duration set_position x1 y1 return CompositeVideoClip [clip freeze] elif outside_region is not None x1 y1 x2 y2 outside_regionanimated_region clip fx crop *outside_region set_position x1 y1 freeze clip to_ImageClip t t set_duration clip duration return CompositeVideoClip [freeze animated_region] elif mask is not None freeze clip to_ImageClip t t set_duration clip duration set_mask mask return CompositeVideoClip [clip freeze]
def freeze_region clip t 0 region None outside_region None mask None if region is not None x1 y1 x2 y2 regionfreeze clip fx crop *region to_ImageClip t t set_duration clip duration set_position x1 y1 return CompositeVideoClip [clip freeze] elif outside_region is not None x1 y1 x2 y2 outside_regionanimated_region clip fx crop *outside_region set_position x1 y1 freeze clip to_ImageClip t t set_duration clip duration return CompositeVideoClip [freeze animated_region] elif mask is not None freeze clip to_ImageClip t t set_duration clip duration set_mask mask return CompositeVideoClip [clip freeze]
def copy_file_from_manifest repo ctx filename dir for changeset in reversed_upper_bounded_changelog repo ctx changeset_ctx repo changectx changeset fctx get_file_context_from_ctx changeset_ctx filename if fctx and fctx not in ['DELETED'] file_path os path join dir filename fh open file_path 'wb' fh write fctx data fh close return file_pathreturn None
def copy_file_from_manifest repo ctx filename dir for changeset in reversed_upper_bounded_changelog repo ctx changeset_ctx repo changectx changeset fctx get_file_context_from_ctx changeset_ctx filename if fctx and fctx not in ['DELETED'] file_path os path join dir filename fh open file_path 'wb' fh write fctx data fh close return file_pathreturn None
def proxy port 9999 l listen port l wait_for_connection r remote context adb_host context adb_port level 'debug' l r
def proxy port 9999 l listen port l wait_for_connection r remote context adb_host context adb_port level 'debug' l r
def remove_notifications email_notification_ids None for email_id in email_notification_ids NotificationDigest remove Q '_id' 'eq' email_id
def remove_notifications email_notification_ids None for email_id in email_notification_ids NotificationDigest remove Q '_id' 'eq' email_id
def MakeCdfFromItems items label None return Cdf dict items label label
def MakeCdfFromItems items label None return Cdf dict items label label
def gather_git_command_html_files command_list_html session get git_docs_base_url soup BeautifulSoup command_list_html text 'html parser' links soup find_all 'a' commands []for link in links href link get 'href' if '/docs/git-' in href href href replace '/docs' '' with open 'download/{} html' format link text 'wb' as outfile outfile write bytes session get '{}{}' format git_docs_base_url href text 'UTF-8'
def gather_git_command_html_files command_list_html session get git_docs_base_url soup BeautifulSoup command_list_html text 'html parser' links soup find_all 'a' commands []for link in links href link get 'href' if '/docs/git-' in href href href replace '/docs' '' with open 'download/{} html' format link text 'wb' as outfile outfile write bytes session get '{}{}' format git_docs_base_url href text 'UTF-8'
def gather_git_command_html_files command_list_html session get git_docs_base_url soup BeautifulSoup command_list_html text 'html parser' links soup find_all 'a' commands []for link in links href link get 'href' if '/docs/git-' in href href href replace '/docs' '' with open 'download/{} html' format link text 'wb' as outfile outfile write bytes session get '{}{}' format git_docs_base_url href text 'UTF-8'
def _sanitize_index data index copy False if index is None return dataif len data len index raise ValueError 'Lengthofvaluesdoesnotmatchlengthofindex' if isinstance data PeriodIndex data data asobjectelif isinstance data DatetimeIndex data data _to_embed keep_tz True if copy data data copy elif isinstance data np ndarray if data dtype kind in ['M' 'm'] data _sanitize_array data index copy copy return data
def _sanitize_index data index copy False if index is None return dataif len data len index raise ValueError 'Lengthofvaluesdoesnotmatchlengthofindex' if isinstance data PeriodIndex data data asobjectelif isinstance data DatetimeIndex data data _to_embed keep_tz True if copy data data copy elif isinstance data np ndarray if data dtype kind in ['M' 'm'] data _sanitize_array data index copy copy return data
def _sanitize_index data index copy False if index is None return dataif len data len index raise ValueError 'Lengthofvaluesdoesnotmatchlengthofindex' if isinstance data PeriodIndex data data asobjectelif isinstance data DatetimeIndex data data _to_embed keep_tz True if copy data data copy elif isinstance data np ndarray if data dtype kind in ['M' 'm'] data _sanitize_array data index copy copy return data
@set_modified_ondef save_persona_image src full_dst **kw log info '[1@None]Savingpersonaimage %s' % full_dst img ImageCheck storage open src if not img is_image log error 'Notanimage %s' % src exc_info True returnwith storage open src 'rb' as fp i Image open fp with storage open full_dst 'wb' as fp i save fp 'png' return True
@set_modified_ondef save_persona_image src full_dst **kw log info '[1@None]Savingpersonaimage %s' % full_dst img ImageCheck storage open src if not img is_image log error 'Notanimage %s' % src exc_info True returnwith storage open src 'rb' as fp i Image open fp with storage open full_dst 'wb' as fp i save fp 'png' return True
def execfile filename globals locals None if locals is None locals globalswith open filename 'rbU' as fin source fin read code compile source filename 'exec' exec code in globals locals
def execfile filename globals locals None if locals is None locals globalswith open filename 'rbU' as fin source fin read code compile source filename 'exec' exec code in globals locals
def create_modulestore_instance engine contentstore doc_store_config options i18n_service None fs_service None user_service None signal_handler None class_ load_function engine if issubclass class_ ModuleStoreDraftAndPublished options['branch_setting_func'] lambda ModuleStoreEnum Branch draft_preferred return class_ doc_store_config doc_store_config contentstore contentstore signal_handler signal_handler **options
def create_modulestore_instance engine contentstore doc_store_config options i18n_service None fs_service None user_service None signal_handler None class_ load_function engine if issubclass class_ ModuleStoreDraftAndPublished options['branch_setting_func'] lambda ModuleStoreEnum Branch draft_preferred return class_ doc_store_config doc_store_config contentstore contentstore signal_handler signal_handler **options
def Client hub None **kwargs from curl import CurlClientreturn CurlClient hub **kwargs
def Client hub None **kwargs from curl import CurlClientreturn CurlClient hub **kwargs
def connection_before_request CLIENT_POOL acquire
def connection_before_request CLIENT_POOL acquire
@requires_application def test_arrow_transform_draw if os getenv 'APPVEYOR' '' lower 'true' raise SkipTest 'AppVeyorhasunknownfailure' old_numpy LooseVersion np __version__ < '1 8' if os getenv 'TRAVIS' 'false' 'true' and sys version[ 3] '2 6' or old_numpy raise SkipTest 'TravisfailsduetoFBstackproblem' with TestingCanvas as c for arrow_type in ARROW_TYPES arrow visuals Arrow pos vertices arrow_type arrow_type arrows arrows arrow_size 10 color 'red' connect 'segments' parent c scene arrow transform transforms STTransform scale 0 5 0 75 translate -20 -20 assert_image_approved c render 'visuals/arrow_transform_type_%s png' % arrow_type arrow parent None
def partitionby func seq return map tuple pluck 1 itertools groupby seq key func
def partitionby func seq return map tuple pluck 1 itertools groupby seq key func
def partitionby func seq return map tuple pluck 1 itertools groupby seq key func
def rehash return win32gui SendMessageTimeout win32con HWND_BROADCAST win32con WM_SETTINGCHANGE 0 'Environment' 0 10000 [0] 1
def rehash return win32gui SendMessageTimeout win32con HWND_BROADCAST win32con WM_SETTINGCHANGE 0 'Environment' 0 10000 [0] 1
def rehash return win32gui SendMessageTimeout win32con HWND_BROADCAST win32con WM_SETTINGCHANGE 0 'Environment' 0 10000 [0] 1
def a1_to_rowcol label m CELL_ADDR_RE match label if m column_label m group 1 upper row int m group 2 col 0for i c in enumerate reversed column_label col + ord c - MAGIC_NUMBER * 26 ** i else raise IncorrectCellLabel label return row col
def a1_to_rowcol label m CELL_ADDR_RE match label if m column_label m group 1 upper row int m group 2 col 0for i c in enumerate reversed column_label col + ord c - MAGIC_NUMBER * 26 ** i else raise IncorrectCellLabel label return row col
def signed_permutations t return type t i for j in permutations t for i in permute_signs j
def signed_permutations t return type t i for j in permutations t for i in permute_signs j
def empty_iter yield iter [] next
def empty_iter yield iter [] next
def register func *args **kwargs global _identwith _lock ident _ident_ident + 1_handlers[ident] func args kwargs vars context return ident
def pgrep pattern user None full False procs []for proc in psutil process_iter name_match pattern in '' join _get_proc_cmdline proc if full else pattern in _get_proc_name proc user_match True if user is None else user _get_proc_username proc if name_match and user_match procs append _get_proc_pid proc return procs or None
def pgrep pattern user None full False procs []for proc in psutil process_iter name_match pattern in '' join _get_proc_cmdline proc if full else pattern in _get_proc_name proc user_match True if user is None else user _get_proc_username proc if name_match and user_match procs append _get_proc_pid proc return procs or None
def pgrep pattern user None full False procs []for proc in psutil process_iter name_match pattern in '' join _get_proc_cmdline proc if full else pattern in _get_proc_name proc user_match True if user is None else user _get_proc_username proc if name_match and user_match procs append _get_proc_pid proc return procs or None
def getComplexIfNone valueComplex if valueComplex None return complex return valueComplex
def getComplexIfNone valueComplex if valueComplex None return complex return valueComplex
def sanitise_redirect_url redirect_to is_valid Trueif not redirect_to or '' in redirect_to is_valid Falseelif '//' in redirect_to allowed_domains getattr settings 'ALLOWED_EXTERNAL_OPENID_REDIRECT_DOMAINS' [] s netloc p q f urlsplit redirect_to if netloc if netloc find ' ' -1 netloc _ netloc split ' ' 1 if netloc not in allowed_domains is_valid Falseif not is_valid redirect_to settings LOGIN_REDIRECT_URLreturn redirect_to
def sanitise_redirect_url redirect_to is_valid Trueif not redirect_to or '' in redirect_to is_valid Falseelif '//' in redirect_to allowed_domains getattr settings 'ALLOWED_EXTERNAL_OPENID_REDIRECT_DOMAINS' [] s netloc p q f urlsplit redirect_to if netloc if netloc find ' ' -1 netloc _ netloc split ' ' 1 if netloc not in allowed_domains is_valid Falseif not is_valid redirect_to settings LOGIN_REDIRECT_URLreturn redirect_to
def send_arp_reply reply_to mac src_mac None src_ip None arpp reply_to parsed find 'arp' mac EthAddr mac if src_mac is None src_mac reply_to connection eth_addrelif src_mac is True src_mac reply_to connection ports[reply_to port] hw_addrelse src_mac EthAddr src_mac r arp r opcode r REPLYr hwdst arpp hwsrcr protodst arpp protosrcr hwsrc EthAddr src_mac r protosrc IPAddr '0 0 0 0' if src_ip is None else IPAddr src_ip e ethernet type ethernet ARP_TYPE src src_mac dst r hwdst e payload rmsg of ofp_packet_out msg data e pack msg actions append of ofp_action_output port reply_to port msg in_port of OFPP_NONEreply_to connection send msg
def send_arp_reply reply_to mac src_mac None src_ip None arpp reply_to parsed find 'arp' mac EthAddr mac if src_mac is None src_mac reply_to connection eth_addrelif src_mac is True src_mac reply_to connection ports[reply_to port] hw_addrelse src_mac EthAddr src_mac r arp r opcode r REPLYr hwdst arpp hwsrcr protodst arpp protosrcr hwsrc EthAddr src_mac r protosrc IPAddr '0 0 0 0' if src_ip is None else IPAddr src_ip e ethernet type ethernet ARP_TYPE src src_mac dst r hwdst e payload rmsg of ofp_packet_out msg data e pack msg actions append of ofp_action_output port reply_to port msg in_port of OFPP_NONEreply_to connection send msg
@logic side_effect_freedef datastore_search_sql context data_dict sql _get_or_bust data_dict 'sql' if not datastore_helpers is_single_statement sql raise p toolkit ValidationError {'query' ['Queryisnotasinglestatement ']} p toolkit check_access 'datastore_search_sql' context data_dict data_dict['connection_url'] config['ckan datastore read_url']result db search_sql context data_dict result pop 'id' None result pop 'connection_url' return result
@logic side_effect_freedef datastore_search_sql context data_dict sql _get_or_bust data_dict 'sql' if not datastore_helpers is_single_statement sql raise p toolkit ValidationError {'query' ['Queryisnotasinglestatement ']} p toolkit check_access 'datastore_search_sql' context data_dict data_dict['connection_url'] config['ckan datastore read_url']result db search_sql context data_dict result pop 'id' None result pop 'connection_url' return result
def task_create_flocker_pool_file return sequence [run 'mkdir-p/var/opt/flocker' run 'truncate--size10G/var/opt/flocker/pool-vdev' run 'ZFS_MODULE_LOADING yeszpoolcreateflocker/var/opt/flocker/pool-vdev' ]
def task_create_flocker_pool_file return sequence [run 'mkdir-p/var/opt/flocker' run 'truncate--size10G/var/opt/flocker/pool-vdev' run 'ZFS_MODULE_LOADING yeszpoolcreateflocker/var/opt/flocker/pool-vdev' ]
def _parse_mime_message mime_message if isinstance mime_message email Message Message return mime_messageelif isinstance mime_message basestring return email message_from_string mime_message else return email message_from_file mime_message
def _parse_mime_message mime_message if isinstance mime_message email Message Message return mime_messageelif isinstance mime_message basestring return email message_from_string mime_message else return email message_from_file mime_message
def get_site_path url path urlparse url pathif path '' path '/'return path
def get_site_path url path urlparse url pathif path '' path '/'return path
def corpus_chrf list_of_references hypotheses min_len 1 max_len 6 beta 3 0 assert len list_of_references len hypotheses 'Thenumberofhypothesesandtheirreferencesshouldbethesame'for reference hypothesis in zip list_of_references hypotheses if type reference and type hypothesis str reference hypothesis '' join reference '' join hypothesis ref_ngrams Counter everygrams reference min_len max_len hyp_ngrams Counter everygrams hypothesis min_len max_len overlap_ngrams ref_ngrams & hyp_ngrams tp sum overlap_ngrams values tpfp sum hyp_ngrams values tffn sum ref_ngrams values precision tp / tpfp recall tp / tffn factor beta ** 2 score 1 + factor * precision * recall / factor * precision + recall return score
def corpus_chrf list_of_references hypotheses min_len 1 max_len 6 beta 3 0 assert len list_of_references len hypotheses 'Thenumberofhypothesesandtheirreferencesshouldbethesame'for reference hypothesis in zip list_of_references hypotheses if type reference and type hypothesis str reference hypothesis '' join reference '' join hypothesis ref_ngrams Counter everygrams reference min_len max_len hyp_ngrams Counter everygrams hypothesis min_len max_len overlap_ngrams ref_ngrams & hyp_ngrams tp sum overlap_ngrams values tpfp sum hyp_ngrams values tffn sum ref_ngrams values precision tp / tpfp recall tp / tffn factor beta ** 2 score 1 + factor * precision * recall / factor * precision + recall return score
def _item_to_job iterator resource return iterator client job_from_resource resource
def _item_to_job iterator resource return iterator client job_from_resource resource
def inet_pton family text if family AF_INET return dns ipv4 inet_aton text elif family AF_INET6 return dns ipv6 inet_aton text else raise NotImplementedError
def inet_pton family text if family AF_INET return dns ipv4 inet_aton text elif family AF_INET6 return dns ipv6 inet_aton text else raise NotImplementedError
def on_color clip size None color 0 0 0 pos None col_opacity None if size is None size clip sizeif pos is None pos 'center'colorclip ColorClip size color if col_opacity colorclip colorclip with_mask set_opacity col_opacity return CompositeVideoClip [colorclip clip set_pos pos ] transparent col_opacity is not None
def on_color clip size None color 0 0 0 pos None col_opacity None if size is None size clip sizeif pos is None pos 'center'colorclip ColorClip size color if col_opacity colorclip colorclip with_mask set_opacity col_opacity return CompositeVideoClip [colorclip clip set_pos pos ] transparent col_opacity is not None
def extract_gcs_tokens full_object_name bucket_name Noneobject_name Nonetokens full_object_name split '/' if len tokens < 3 logging error "MalformedGCSpath'{0}' AbortingGCSoperation " format full_object_name return bucket_name object_name bucket_name tokens[2]object_name ''for token in tokens[3 -1 ] object_name + token + '/' object_name + tokens[ -1 ]return bucket_name object_name
def extract_gcs_tokens full_object_name bucket_name Noneobject_name Nonetokens full_object_name split '/' if len tokens < 3 logging error "MalformedGCSpath'{0}' AbortingGCSoperation " format full_object_name return bucket_name object_name bucket_name tokens[2]object_name ''for token in tokens[3 -1 ] object_name + token + '/' object_name + tokens[ -1 ]return bucket_name object_name
def _isLeft a b c return b[0] - a[0] * c[1] - a[1] - b[1] - a[1] * c[0] - a[0] > 0
def GetHttpContext global _threadLocalContextreturn _threadLocalContext __dict__ setdefault 'httpCtx' dict
def GetHttpContext global _threadLocalContextreturn _threadLocalContext __dict__ setdefault 'httpCtx' dict
def _make_stim_channel trigger_chs slope threshold stim_code trigger_values if slope '+' trig_chs_bin trigger_chs > threshold elif slope '-' trig_chs_bin trigger_chs < threshold else raise ValueError "slopeneedstobe'+'or'-'" if stim_code 'binary' trigger_values 2 ** np arange len trigger_chs elif stim_code 'channel' raise ValueError "stim_codemustbe'binary'or'channel' got%s" % repr stim_code trig_chs trig_chs_bin * trigger_values[ np newaxis] return np array trig_chs sum axis 0 ndmin 2
def _make_stim_channel trigger_chs slope threshold stim_code trigger_values if slope '+' trig_chs_bin trigger_chs > threshold elif slope '-' trig_chs_bin trigger_chs < threshold else raise ValueError "slopeneedstobe'+'or'-'" if stim_code 'binary' trigger_values 2 ** np arange len trigger_chs elif stim_code 'channel' raise ValueError "stim_codemustbe'binary'or'channel' got%s" % repr stim_code trig_chs trig_chs_bin * trigger_values[ np newaxis] return np array trig_chs sum axis 0 ndmin 2
def _make_stim_channel trigger_chs slope threshold stim_code trigger_values if slope '+' trig_chs_bin trigger_chs > threshold elif slope '-' trig_chs_bin trigger_chs < threshold else raise ValueError "slopeneedstobe'+'or'-'" if stim_code 'binary' trigger_values 2 ** np arange len trigger_chs elif stim_code 'channel' raise ValueError "stim_codemustbe'binary'or'channel' got%s" % repr stim_code trig_chs trig_chs_bin * trigger_values[ np newaxis] return np array trig_chs sum axis 0 ndmin 2
@pytest fixturedef templates_project0 request templates project0 from pootle_translationproject models import TranslationProjectreturn TranslationProject objects get language templates project project0
@pytest fixturedef templates_project0 request templates project0 from pootle_translationproject models import TranslationProjectreturn TranslationProject objects get language templates project project0
def word_wrap text max_length if len text > max_length return u'\n' join wrap text max_length return text
def word_wrap text max_length if len text > max_length return u'\n' join wrap text max_length return text
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def find_split_rechunk old_chunks new_chunks graph_size_limit ndim len old_chunks chunks list old_chunks for dim in range ndim graph_size estimate_graph_size chunks new_chunks if graph_size > graph_size_limit breakif len old_chunks[dim] > len new_chunks[dim] continuemax_number int len old_chunks[dim] * graph_size_limit / graph_size c merge_to_number new_chunks[dim] max_number assert len c < max_number if len c > len old_chunks[dim] and max c < max old_chunks[dim] chunks[dim] creturn tuple chunks
def validate_file_path path _validate_path path if not _CS_FULLPATH_REGEX match path raise ValueError 'Pathshouldhaveformat/bucket/filenamebutgot%s' % path
def validate_file_path path _validate_path path if not _CS_FULLPATH_REGEX match path raise ValueError 'Pathshouldhaveformat/bucket/filenamebutgot%s' % path
def review_request_published_cb sender user review_request trivial changedesc **kwargs siteconfig SiteConfiguration objects get_current if siteconfig get u'mail_send_review_mail' and not trivial mail_review_request review_request user changedesc
def MkDirListWidget w msg Tix Message w relief Tix FLAT width 240 anchor Tix N text 'TheTixDirListwidgetgivesagraphicalrepresentationofthefilesystemdirectoryandmakesiteasyfortheusertochooseandaccessdirectories ' dirlist Tix DirList w options 'hlist padY1hlist width25hlist height16' msg pack side Tix TOP expand 1 fill Tix BOTH padx 3 pady 3 dirlist pack side Tix TOP padx 3 pady 3
def MkDirListWidget w msg Tix Message w relief Tix FLAT width 240 anchor Tix N text 'TheTixDirListwidgetgivesagraphicalrepresentationofthefilesystemdirectoryandmakesiteasyfortheusertochooseandaccessdirectories ' dirlist Tix DirList w options 'hlist padY1hlist width25hlist height16' msg pack side Tix TOP expand 1 fill Tix BOTH padx 3 pady 3 dirlist pack side Tix TOP padx 3 pady 3
def get_checkers_for lang u'python' global NOTIFICATIONS_CHECKERSreturn NOTIFICATIONS_CHECKERS get lang []
def _get_subgraph codons G subgraph {}for i in codons subgraph[i] {}for j in codons if i j subgraph[i][j] G[i][j]return subgraph
def DeletionTest f @functools wraps f def Decorator testinstance if testinstance TEST_DELETION return f testinstance else return testinstance skipTest 'Teststhatusedeletionaredisabledforthisdatastore ' return Decorator
def _count0Bits num num long num if num < 0 raise ValueError 'OnlypositiveNumbersplease %s' % num ret 0while num > 0 if num & 1 1 breaknum num >> 1 ret + 1return ret
@help BarBuilder def Bar data label None values None color None stack None group None agg 'sum' xscale 'categorical' yscale 'linear' xgrid False ygrid True continuous_range None **kw if continuous_range and not isinstance continuous_range Range1d raise ValueError 'continuous_rangemustbeaninstanceofbokeh models ranges Range1d' if label is not None and values is None kw['label_only'] Trueif agg 'sum' or agg 'mean' agg 'count'values labely_range continuous_rangekw['label'] labelkw['values'] valueskw['color'] colorkw['stack'] stackkw['group'] groupkw['agg'] aggkw['xscale'] xscalekw['yscale'] yscalekw['xgrid'] xgridkw['ygrid'] ygridkw['y_range'] y_rangechart create_and_build BarBuilder data **kw if len chart x_range factors 1 and not label chart below[0] visible Falsereturn chart
@help BarBuilder def Bar data label None values None color None stack None group None agg 'sum' xscale 'categorical' yscale 'linear' xgrid False ygrid True continuous_range None **kw if continuous_range and not isinstance continuous_range Range1d raise ValueError 'continuous_rangemustbeaninstanceofbokeh models ranges Range1d' if label is not None and values is None kw['label_only'] Trueif agg 'sum' or agg 'mean' agg 'count'values labely_range continuous_rangekw['label'] labelkw['values'] valueskw['color'] colorkw['stack'] stackkw['group'] groupkw['agg'] aggkw['xscale'] xscalekw['yscale'] yscalekw['xgrid'] xgridkw['ygrid'] ygridkw['y_range'] y_rangechart create_and_build BarBuilder data **kw if len chart x_range factors 1 and not label chart below[0] visible Falsereturn chart
def p_statement_assign p print '%s %s' % p[2] p[4]
def p_statement_assign p print '%s %s' % p[2] p[4]
def run_gdb *args **env_vars if env_vars env os environ copy env update env_vars else env Nonebase_cmd 'gdb' '--batch' '-nx' if gdb_major_version gdb_minor_version > 7 4 base_cmd + '-iex' 'add-auto-load-safe-path' + checkout_hook_path out err subprocess Popen base_cmd + args stdin subprocess PIPE stdout subprocess PIPE stderr subprocess PIPE env env communicate return out err
def _parse_global_variables user_cidr inventory user_defined_config if 'all' not in inventory inventory['all'] {}if 'vars' not in inventory['all'] inventory['all']['vars'] {}inventory['all']['vars']['container_cidr'] user_cidrif 'global_overrides' in user_defined_config if isinstance user_defined_config['global_overrides'] dict inventory['all']['vars'] update user_defined_config['global_overrides'] logger debug 'Appliedglobal_overrides' kept_vars user_defined_config['global_overrides'] keys kept_vars append 'container_cidr' for key in inventory['all']['vars'] keys if key not in kept_vars logger debug 'Deletingkey%sfrominventory' key del inventory['all']['vars'][key]
def _parse_global_variables user_cidr inventory user_defined_config if 'all' not in inventory inventory['all'] {}if 'vars' not in inventory['all'] inventory['all']['vars'] {}inventory['all']['vars']['container_cidr'] user_cidrif 'global_overrides' in user_defined_config if isinstance user_defined_config['global_overrides'] dict inventory['all']['vars'] update user_defined_config['global_overrides'] logger debug 'Appliedglobal_overrides' kept_vars user_defined_config['global_overrides'] keys kept_vars append 'container_cidr' for key in inventory['all']['vars'] keys if key not in kept_vars logger debug 'Deletingkey%sfrominventory' key del inventory['all']['vars'][key]
@preloaderStopdef SelectSearchResult listItems **kwargs return printList listItems showSelector True **kwargs
def create_superuser print "\nCreateasuperuserbelow ThesuperuserisPlayer#1 the'owner'accountoftheserver \n" django core management call_command 'createsuperuser' interactive True
def store_outcome_parameters request_params user lti_consumer result_id request_params get 'lis_result_sourcedid' None if result_id result_service request_params get 'lis_outcome_service_url' None if not result_service log warn 'OutcomeService lis_outcome_service_urlparametermissingfromscoredassignment wewillbeunabletoreturnascore Requestparameters %s' request_params returnusage_key request_params['usage_key']course_key request_params['course_key'] outcomes __ OutcomeService objects get_or_create lis_outcome_service_url result_service lti_consumer lti_consumer GradedAssignment objects get_or_create lis_result_sourcedid result_id course_key course_key usage_key usage_key user user outcome_service outcomes
def store_outcome_parameters request_params user lti_consumer result_id request_params get 'lis_result_sourcedid' None if result_id result_service request_params get 'lis_outcome_service_url' None if not result_service log warn 'OutcomeService lis_outcome_service_urlparametermissingfromscoredassignment wewillbeunabletoreturnascore Requestparameters %s' request_params returnusage_key request_params['usage_key']course_key request_params['course_key'] outcomes __ OutcomeService objects get_or_create lis_outcome_service_url result_service lti_consumer lti_consumer GradedAssignment objects get_or_create lis_result_sourcedid result_id course_key course_key usage_key usage_key user user outcome_service outcomes
def _prefix subject if email prefix return '{}{}' format email prefix subject else return subject
def _prefix subject if email prefix return '{}{}' format email prefix subject else return subject
def get_package_version base os path abspath os path dirname __file__ with open os path join base 'flower/__init__ py' as initf for line in initf m version match line strip if not m continuereturn ' ' join m groups [0] split ' '
def setup hass config None log logging getLogger __name__ log info "\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nHello andwelcometoHomeAssistant \n\nWe'llhopethatwecanmakeallyourdreamscometrue \n\nHerearesomeresourcestogetstarted \n\n-ConfiguringHomeAssistant \nhttps //home-assistant io/getting-started/configuration/\n\n-Availablecomponents \nhttps //home-assistant io/components/\n\n-Troubleshootingyourconfiguration \nhttps //home-assistant io/getting-started/troubleshooting-configuration/\n\n-Gettinghelp \nhttps //home-assistant io/help/\n\nThismessageisgeneratedbytheintroductioncomponent Youcan\ndisableitinconfiguration yaml \n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n" return True
def stack_pages pages memmap False tempdir None *args **kwargs if len pages 0 raise ValueError 'nopages' if len pages 1 return pages[0] asarray memmap memmap *args **kwargs data0 pages[0] asarray *args **kwargs shape len pages + data0 shape if memmap with tempfile NamedTemporaryFile dir tempdir as fh data numpy memmap fh dtype data0 dtype shape shape else data numpy empty shape dtype data0 dtype data[0] data0if memmap data flush del data0for i page in enumerate pages[1 ] data[ i + 1 ] page asarray *args **kwargs if memmap data flush return data
def get_bin_seeds X bin_size min_bin_freq 1 bin_sizes defaultdict int for point in X binned_point np round point / bin_size bin_sizes[tuple binned_point ] + 1bin_seeds np array [point for point freq in six iteritems bin_sizes if freq > min_bin_freq ] dtype np float32 if len bin_seeds len X warnings warn 'Binningdatafailedwithprovidedbin_size %f usingdatapointsasseeds ' % bin_size return Xbin_seeds bin_seeds * bin_size return bin_seeds
def get_bin_seeds X bin_size min_bin_freq 1 bin_sizes defaultdict int for point in X binned_point np round point / bin_size bin_sizes[tuple binned_point ] + 1bin_seeds np array [point for point freq in six iteritems bin_sizes if freq > min_bin_freq ] dtype np float32 if len bin_seeds len X warnings warn 'Binningdatafailedwithprovidedbin_size %f usingdatapointsasseeds ' % bin_size return Xbin_seeds bin_seeds * bin_size return bin_seeds
@frappe whitelist def get_desk_assets build_version data get_context {u'for_mobile' True} assets [{u'type' u'js' u'data' u''} {u'type' u'css' u'data' u''}]if build_version data[u'build_version'] for path in data[u'include_js'] with open os path join frappe local sites_path path u'r' as f assets[0][u'data'] assets[0][u'data'] + u'\n' + unicode f read u'utf-8' for path in data[u'include_css'] with open os path join frappe local sites_path path u'r' as f assets[1][u'data'] assets[1][u'data'] + u'\n' + unicode f read u'utf-8' return {u'build_version' data[u'build_version'] u'boot' data[u'boot'] u'assets' assets}
def test_multiple_rng_aliasing rng1 MRG_RandomStreams 1234 rng2 MRG_RandomStreams 2392 assert rng1 state_updates is not rng2 state_updates
def filter_docker_plays plays repo_path items set for play in plays dockerfile pathlib2 Path DOCKER_PATH_ROOT play 'Dockerfile' if dockerfile exists items add play else LOGGER warning "coveredplaybook'%s'doesnothaveDockerfile " % play return items
def filter_docker_plays plays repo_path items set for play in plays dockerfile pathlib2 Path DOCKER_PATH_ROOT play 'Dockerfile' if dockerfile exists items add play else LOGGER warning "coveredplaybook'%s'doesnothaveDockerfile " % play return items
def filter_docker_plays plays repo_path items set for play in plays dockerfile pathlib2 Path DOCKER_PATH_ROOT play 'Dockerfile' if dockerfile exists items add play else LOGGER warning "coveredplaybook'%s'doesnothaveDockerfile " % play return items
def get_external_ip try r requests get METADATA_NETWORK_INTERFACE_URL headers {'Metadata-Flavor' 'Google'} timeout 2 return r textexcept requests RequestException logging info 'Metadataservercouldnotbereached assuminglocal ' return 'localhost'
def list_repos _check_apt repos {}sources sourceslist SourcesList for source in sources list if source invalid continuerepo {}repo['file'] source filerepo['comps'] getattr source 'comps' [] repo['disabled'] source disabledrepo['dist'] source distrepo['type'] source typerepo['uri'] source uri rstrip '/' repo['line'] _strip_uri source line strip repo['architectures'] getattr source 'architectures' [] repos setdefault source uri [] append repo return repos
def windows_memory_usage from ctypes import windll Structure c_uint64 sizeof byreffrom ctypes wintypes import DWORDclass MemoryStatus Structure _fields_ [ 'dwLength' DWORD 'dwMemoryLoad' DWORD 'ullTotalPhys' c_uint64 'ullAvailPhys' c_uint64 'ullTotalPageFile' c_uint64 'ullAvailPageFile' c_uint64 'ullTotalVirtual' c_uint64 'ullAvailVirtual' c_uint64 'ullAvailExtendedVirtual' c_uint64 ]memorystatus MemoryStatus memorystatus dwLength sizeof memorystatus windll kernel32 GlobalMemoryStatusEx byref memorystatus return float memorystatus dwMemoryLoad
def toResponse stanza stanzaType None toAddr stanza getAttribute 'from' fromAddr stanza getAttribute 'to' stanzaID stanza getAttribute 'id' response domish Element None stanza name if toAddr response['to'] toAddrif fromAddr response['from'] fromAddrif stanzaID response['id'] stanzaIDif stanzaType response['type'] stanzaTypereturn response
def _make_subclasshook cls if isinstance cls __extra__ abc ABCMeta def __extrahook__ cls subclass _valid_for_check cls res cls __extra__ __subclasshook__ subclass if res is not NotImplemented return resif cls __extra__ in getattr subclass u'__mro__' return Truefor scls in cls __extra__ __subclasses__ if isinstance scls GenericMeta continueif issubclass subclass scls return Truereturn NotImplementedelse def __extrahook__ cls subclass _valid_for_check cls if cls __extra__ and issubclass subclass cls __extra__ return Truereturn NotImplementedreturn classmethod __extrahook__
def _make_subclasshook cls if isinstance cls __extra__ abc ABCMeta def __extrahook__ cls subclass _valid_for_check cls res cls __extra__ __subclasshook__ subclass if res is not NotImplemented return resif cls __extra__ in getattr subclass u'__mro__' return Truefor scls in cls __extra__ __subclasses__ if isinstance scls GenericMeta continueif issubclass subclass scls return Truereturn NotImplementedelse def __extrahook__ cls subclass _valid_for_check cls if cls __extra__ and issubclass subclass cls __extra__ return Truereturn NotImplementedreturn classmethod __extrahook__
def _make_subclasshook cls if isinstance cls __extra__ abc ABCMeta def __extrahook__ cls subclass _valid_for_check cls res cls __extra__ __subclasshook__ subclass if res is not NotImplemented return resif cls __extra__ in getattr subclass u'__mro__' return Truefor scls in cls __extra__ __subclasses__ if isinstance scls GenericMeta continueif issubclass subclass scls return Truereturn NotImplementedelse def __extrahook__ cls subclass _valid_for_check cls if cls __extra__ and issubclass subclass cls __extra__ return Truereturn NotImplementedreturn classmethod __extrahook__
def get_version if not os path exists os path join directories dataDir 'RELEASE-VERSION' try return subprocess check_output 'gitdescribe--tags--match * * *' split strip except return 'unknown'fin open os path join directories dataDir 'RELEASE-VERSION' 'rb' v fin read strip fin close return v
def Transactional _func None **kwargs if _func is not None return Transactional _func if not kwargs pop 'require_new' None kwargs setdefault 'propagation' datastore_rpc TransactionOptions ALLOWED options datastore_rpc TransactionOptions **kwargs def outer_wrapper func def inner_wrapper *args **kwds return RunInTransactionOptions options func *args **kwds return inner_wrapperreturn outer_wrapper
def tokenMap func *args def pa s l t return [func tokn *args for tokn in t]try func_name getattr func '__name__' getattr func '__class__' __name__ except Exception func_name str func pa __name__ func_namereturn pa
@utils arg 'name' metavar '<name>' help 'Nameofthenewmonitortype' @utils service_type 'monitor' def do_type_create cs args vtype cs monitor_types create args name _print_monitor_type_list [vtype]
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def test_spinner_non_unicode_console stream FakeTTY u'ascii' chars console Spinner _default_unicode_charswith console Spinner u'Reticulatingsplines' file stream chars chars as s next s
def get_pil_version try __import__ 'PIL' fromlist [str 'Image' ] return 0 except ImportError return None
def _expiry_range_all session upper_bound_func yield upper_bound_func
def run sys exit main sys argv[1 ] or 0
def run sys exit main sys argv[1 ] or 0
def _preprocess table if not len table return tablenew_domain data Domain [a for a in table domain attributes if a is_continuous] table domain class_vars table domain metas new_data data Table new_domain table new_data SklImpute new_data return new_data
def version hostname timeout 20 username None password None return __version __connect hostname timeout username password
@keras_testdef test_temporal_regression X_train y_train X_test y_test get_test_data nb_train 500 nb_test 400 input_shape 3 5 output_shape 2 classification False model Sequential model add GRU y_train shape[ -1 ] input_shape X_train shape[1] X_train shape[2] model compile loss 'hinge' optimizer 'adam' history model fit X_train y_train nb_epoch 5 batch_size 16 validation_data X_test y_test verbose 0 assert history history['val_loss'][ -1 ] < 1 0
@library filterdef urlparams url_ hash None **query url urlparse urlparse url_ fragment hash if hash is not None else url fragment q url queryquery_dict dict urlparse parse_qsl smart_str q if q else {} query_dict update k v for k v in query items query_string _urlencode [ k v for k v in query_dict items if v is not None ] new urlparse ParseResult url scheme url netloc url path url params query_string fragment return new geturl
def fixup_old_jsargs for i in range len sys argv if sys argv[i] '--build_js' print 'WARNING --build_js withunderscore isdeprecated use--build-js' sys argv[i] '--build-js'if sys argv[i] '--install_js' print 'WARNING --install_js withunderscore isdeprecated use--install-js' sys argv[i] '--install-js'
def create_suggestion exploration_id author_id exploration_version state_name description suggestion_content thread_id _create_models_for_thread_and_first_message exploration_id state_name author_id description DEFAULT_SUGGESTION_THREAD_INITIAL_MESSAGE True feedback_models SuggestionModel create exploration_id thread_id author_id exploration_version state_name description suggestion_content full_thread_id feedback_models FeedbackThreadModel generate_full_thread_id exploration_id thread_id subscription_services subscribe_to_thread author_id full_thread_id _enqueue_suggestion_email_task exploration_id thread_id
def content fid share_key None inline_data None map_data None url build_url RESOURCE id fid route 'content' params make_params share_key share_key inline_data inline_data map_data map_data return request 'get' url params params
def deserialize_count_specs text specs text splitlines specs [line split ' ' for line in specs if line strip ]return {int num slug strip lower for num slug in specs}
def safe_readline handle line handle readline if not line raise ValueError 'Unexpectedendofstream ' return line
def minimum_cut_value G s t capacity 'capacity' flow_func None **kwargs if flow_func is None if kwargs raise nx NetworkXError 'Youhavetoexplicitlysetaflow_funcifyouneedtopassparametersviakwargs ' flow_func default_flow_funcif not callable flow_func raise nx NetworkXError 'flow_funchastobecallable ' if kwargs get 'cutoff' is not None and flow_func in flow_funcs raise nx NetworkXError 'cutoffshouldnotbespecified ' R flow_func G s t capacity capacity value_only True **kwargs return R graph['flow_value']
def sp value return dpi2px value 'sp'
def serializable_property name docstring None def set obj value setattr obj '_' + name value obj _needs_serialization Truedef get obj return getattr obj '_' + name return property get set doc docstring
def tree_lookup_path lookup_obj root_sha path tree lookup_obj root_sha if not isinstance tree Tree raise NotTreeError root_sha return tree lookup_path lookup_obj path
def test_bound_logger_isolation caplog slogging configure config_string ' trace' real_log slogging getLogger bound_log_1 real_log bind key1 'value1' with caplog at_level slogging TRACE bound_log_1 info 'test1' records caplog recordsassert len records 1 assert 'test1' in records[0] msg assert 'key1 value1' in records[0] msg with caplog at_level slogging TRACE real_log info 'test2' records caplog recordsassert len records 2 assert 'test2' in records[1] msg assert 'key1 value1' not in records[1] msg
def test_bound_logger_isolation caplog slogging configure config_string ' trace' real_log slogging getLogger bound_log_1 real_log bind key1 'value1' with caplog at_level slogging TRACE bound_log_1 info 'test1' records caplog recordsassert len records 1 assert 'test1' in records[0] msg assert 'key1 value1' in records[0] msg with caplog at_level slogging TRACE real_log info 'test2' records caplog recordsassert len records 2 assert 'test2' in records[1] msg assert 'key1 value1' not in records[1] msg
def test_bound_logger_isolation caplog slogging configure config_string ' trace' real_log slogging getLogger bound_log_1 real_log bind key1 'value1' with caplog at_level slogging TRACE bound_log_1 info 'test1' records caplog recordsassert len records 1 assert 'test1' in records[0] msg assert 'key1 value1' in records[0] msg with caplog at_level slogging TRACE real_log info 'test2' records caplog recordsassert len records 2 assert 'test2' in records[1] msg assert 'key1 value1' not in records[1] msg
def test_bound_logger_isolation caplog slogging configure config_string ' trace' real_log slogging getLogger bound_log_1 real_log bind key1 'value1' with caplog at_level slogging TRACE bound_log_1 info 'test1' records caplog recordsassert len records 1 assert 'test1' in records[0] msg assert 'key1 value1' in records[0] msg with caplog at_level slogging TRACE real_log info 'test2' records caplog recordsassert len records 2 assert 'test2' in records[1] msg assert 'key1 value1' not in records[1] msg
def make_fna sff_fp output_fp use_sfftools False no_trim False if use_sfftools _fail_on_gzipped_sff sff_fp check_sffinfo if no_trim _check_call ['sffinfo' '-notrim' '-s' sff_fp] stdout open output_fp 'w' else _check_call ['sffinfo' '-s' sff_fp] stdout open output_fp 'w' else try format_binary_sff_as_fna qiime_open sff_fp 'rb' open output_fp 'w' except raise IOError 'CouldnotparseSFF%s' % sff_fp
def extract_substructure_for_test test_case substructure config try return extract_substructure config substructure except MissingConfigError as e yaml add_representer Optional lambda d x d represent_scalar u'tag yaml org 2002 str' repr x test_case skip 'Skippingtest couldnotgetconfiguration {}\n\nInordertorunthistest addensurefileat$ACCEPTANCE_YAMLhasstructurelike \n\n{}' format e message yaml dump substructure default_flow_style False
def extract_substructure_for_test test_case substructure config try return extract_substructure config substructure except MissingConfigError as e yaml add_representer Optional lambda d x d represent_scalar u'tag yaml org 2002 str' repr x test_case skip 'Skippingtest couldnotgetconfiguration {}\n\nInordertorunthistest addensurefileat$ACCEPTANCE_YAMLhasstructurelike \n\n{}' format e message yaml dump substructure default_flow_style False
def build_binary_response request data code return build_response request data code None
def get_hash f import hashlibm hashlib md5 m update f return m hexdigest
def get_user_impact_score user_id model user_models UserStatsModel get user_id strict False if model return model impact_scoreelse return 0
def get_build_results build r_url get_results_raw_url build if not r_url returnreturn convert_json_to_df r_url
def set_owner obj_name principal obj_type 'file' sid get_sid principal flags Flags new_privs set luid win32security LookupPrivilegeValue '' 'SeTakeOwnershipPrivilege' new_privs add luid win32con SE_PRIVILEGE_ENABLED luid win32security LookupPrivilegeValue '' 'SeRestorePrivilege' new_privs add luid win32con SE_PRIVILEGE_ENABLED p_handle win32api GetCurrentProcess t_handle win32security OpenProcessToken p_handle win32security TOKEN_ALL_ACCESS win32con TOKEN_ADJUST_PRIVILEGES win32security AdjustTokenPrivileges t_handle 0 new_privs try win32security SetNamedSecurityInfo obj_name flags obj_type[obj_type] flags element['owner'] sid None None None except pywintypes error as exc log debug 'Failedtomake{0}theowner {1}' format principal exc[2] raise CommandExecutionError 'Failedtosetowner {0}' format exc[2] return True
@dec skip_win32def test_find_cmd_ls path find_cmd 'ls' nt assert_true path endswith 'ls'
def pow_high p max_denom 1024 assert p > 1 p Fraction 1 / Fraction p limit_denominator max_denom if 1 / p int 1 / p return int 1 / p p 1 - p return 1 / p p 1 - p
def check_integrity models messages dict error [] warning [] for model in models validators []for name in dir model if not name startswith '_check' continueobj getattr model name if getattr obj 'validator_type' None validators append obj for func in validators messages[func validator_type] extend func for msg in sorted messages['error'] logger error 'E-%d %s %s %s' % msg for msg in sorted messages['warning'] logger warning 'W-%d %s %s %s' % msg
def path_to_file_uri abspath return path path_to_uri abspath
def path_to_file_uri abspath return path path_to_uri abspath
def survey_buildQuestionnaireFromSeries series_id complete_id None questions survey_getAllQuestionsForSeries series_id return buildQuestionsForm questions complete_id
def survey_buildQuestionnaireFromSeries series_id complete_id None questions survey_getAllQuestionsForSeries series_id return buildQuestionsForm questions complete_id
def print_results results print_report_info results print_pagination_info results print_profile_info results print_query results print_column_headers results print_totals_for_all_results results print_rows results
def print_results results print_report_info results print_pagination_info results print_profile_info results print_query results print_column_headers results print_totals_for_all_results results print_rows results
def lmbda v x if not isscalar v and isscalar x raise ValueError 'argumentsmustbescalars ' if v < 0 raise ValueError 'argumentmustbe>0 ' n int v v0 v - n if n < 1 n1 1else n1 nv1 n1 + v0 if v floor v vm vl dl specfun lamv v1 x else vm vl dl specfun lamn v1 x return vl[ n + 1 ] dl[ n + 1 ]
def lmbda v x if not isscalar v and isscalar x raise ValueError 'argumentsmustbescalars ' if v < 0 raise ValueError 'argumentmustbe>0 ' n int v v0 v - n if n < 1 n1 1else n1 nv1 n1 + v0 if v floor v vm vl dl specfun lamv v1 x else vm vl dl specfun lamn v1 x return vl[ n + 1 ] dl[ n + 1 ]
def test_huber_scaling_invariant rng np random RandomState 0 X y make_regression_with_outliers huber HuberRegressor fit_intercept False alpha 0 0 max_iter 100 huber fit X y n_outliers_mask_1 huber outliers_assert_false np all n_outliers_mask_1 huber fit X 2 0 * y n_outliers_mask_2 huber outliers_assert_array_equal n_outliers_mask_2 n_outliers_mask_1 huber fit 2 0 * X 2 0 * y n_outliers_mask_3 huber outliers_assert_array_equal n_outliers_mask_3 n_outliers_mask_1
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def _check_orphans cursor orphans cursor all '\nselectusername\nfromparticipants\nwherenotexists select*fromelsewherewhereelsewhere participant username \nandnotexists select*fromabsorptionswherearchived_as username \n' assert len orphans 0 'missingelsewheres {}' format list orphans
def providerIsAuthoritative providerID canonicalID lastbang canonicalID rindex ' ' parent canonicalID[ lastbang]return parent providerID
def iter_token_lines tokenlist line []for token c in explode_tokens tokenlist line append token c if c u'\n' yield line line [] yield line
def check_can_access node user key None api_node None if user is None return Falseif not node can_view Auth user user and api_node node if key in node private_link_keys_deleted status push_status_message 'Theview-onlylinksyouusedareexpired ' trust False raise HTTPError http FORBIDDEN data {'message_long' 'Userhasrestrictedaccesstothispage Ifthisshouldnothaveoccurredandtheissuepersists pleasereportitto<ahref "mailto support@osf io">support@osf io</a> '} return True
def isorted to_sort return sorted to_sort key lambda x x lower
@with_devicedef listdir directory '/' return list sorted AdbClient list directory
def run_shell_command cmd child sp Popen cmd shell True stdout sp PIPE stderr sp STDOUT output child communicate [0]rc child returncodereturn output rc
def testDict suffix 'Test'trim len suffix fdict dict [ fname[ - trim ] f for fname f in inspect getmembers modules[__name__] inspect isfunction if fname endswith suffix ] return fdict
@event u'forget' def forget value with Session as session log debug u'forgetcalledwith%s' value count 0field_count 0for se in session query SeenEntry filter or_ SeenEntry title value SeenEntry task value all field_count + len se fields count + 1log debug u'forgetting%s' se session delete se for sf in session query SeenField filter SeenField value value all se session query SeenEntry filter SeenEntry id sf seen_entry_id first field_count + len se fields count + 1log debug u'forgetting%s' se session delete se return count field_count
def pick_channels_regexp ch_names regexp r re compile regexp return [k for k name in enumerate ch_names if r match name ]
def pick_channels_regexp ch_names regexp r re compile regexp return [k for k name in enumerate ch_names if r match name ]
def regenerate_user_certificates student course_key course None forced_grade None template_file None insecure False xqueue XQueueCertInterface if insecure xqueue use_https Falsegenerate_pdf not has_html_certificates_enabled course_key course return xqueue regen_cert student course_key course course forced_grade forced_grade template_file template_file generate_pdf generate_pdf
@pytest mark networkdef test_git_with_non_editable_where_egg_contains_dev_string script tmpdir result script pip 'install' '%s#egg django-devserver' % local_checkout 'git+git //github com/dcramer/django-devserver git' tmpdir join 'cache' devserver_folder script site_packages / 'devserver' assert devserver_folder in result files_created str result
def directed_connected_components digr if not digr DIRECTED raise Exception '%sisnotadirectedgraph' % digr finishing_times DFS_loop digr get_transpose nodes_explored connected_components [] [] for node in finishing_times[ -1 ] component []outer_dfs digr node nodes_explored component if component nodes_explored + componentconnected_components append component return connected_components
def _esc code return '\x1b[{}m' format code
def should_ignore_paypal return settings DEBUG and 'sandbox' not in settings PAYPAL_PERMISSIONS_URL
def parse_cookie data return k v for k v in _parse_cookie data if _valid_cookie_name k
def forms if request env request_method 'GET' if auth permission format 'json' response headers['Content-Type'] 'application/json'return s3base S3MobileFormList json else error 415 'Invalidrequestformat' else error 405 'Unsupportedrequestmethod'
def dmp_deflate f u K if dmp_zero_p f u return 1 * u + 1 f F dmp_to_dict f u B [0] * u + 1 for M in F keys for i m in enumerate M B[i] igcd B[i] m for i b in enumerate B if not b B[i] 1B tuple B if all b 1 for b in B return B f H {}for A coeff in F items N [ a // b for a b in zip A B ]H[tuple N ] coeffreturn B dmp_from_dict H u K
def dmp_deflate f u K if dmp_zero_p f u return 1 * u + 1 f F dmp_to_dict f u B [0] * u + 1 for M in F keys for i m in enumerate M B[i] igcd B[i] m for i b in enumerate B if not b B[i] 1B tuple B if all b 1 for b in B return B f H {}for A coeff in F items N [ a // b for a b in zip A B ]H[tuple N ] coeffreturn B dmp_from_dict H u K
def calc_text_angle start end text_angle start + end / 2 0 shift_angles text_angle > np pi / 2 & text_angle < 3 * np pi / 2 text_angle[shift_angles] text_angle[shift_angles] + np pi return text_angle
def load_bytes value units magnitudes {'KiB' 1 'MiB' 2 'GiB' 3 'TiB' 4}if units not in magnitudes raise InvalidUnits '{}notarecognizedunit' format units return int value * 1024 ** magnitudes[units]
def aggregate_raters data n_cat None data np asarray data n_rows data shape[0]if n_cat is None cat_uni cat_int np unique data ravel return_inverse True n_cat len cat_uni data_ cat_int reshape data shape else cat_uni np arange n_cat data_ datatt np zeros n_rows n_cat int for idx row in enumerate data_ ro np bincount row tt[idx len ro ] roreturn tt cat_uni
def aggregate_raters data n_cat None data np asarray data n_rows data shape[0]if n_cat is None cat_uni cat_int np unique data ravel return_inverse True n_cat len cat_uni data_ cat_int reshape data shape else cat_uni np arange n_cat data_ datatt np zeros n_rows n_cat int for idx row in enumerate data_ ro np bincount row tt[idx len ro ] roreturn tt cat_uni
def get_coursetalk_course_key course_key return u'{0 org}_{0 course}' format course_key
def get_long_description path if path with open path 'rt' as fp return fp read return None
def _get_vispy_font_filename face bold italic name face + '-' name + 'Regular' if not bold and not italic else '' name + 'Bold' if bold else '' name + 'Italic' if italic else '' name + ' ttf'return load_data_file 'fonts/%s' % name
def finger hash_type None if hash_type is None hash_type __opts__['hash_type']return salt utils pem_finger os path join __opts__['pki_dir'] 'minion pub' sum_type hash_type
def remove_callable dic for key value in dic items if callable value del dic[key]return dic
@frappe whitelist def get doctype name None filters None if filters and not name name frappe db get_value doctype json loads filters if not name raise Exception u'Nodocumentfoundforgivenfilters'doc frappe get_doc doctype name if not doc has_permission u'read' raise frappe PermissionErrorreturn frappe get_doc doctype name as_dict
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
def make_model_tuple model try if isinstance model tuple model_tuple modelelif isinstance model str app_label model_name model split ' ' model_tuple app_label model_name lower else model_tuple model _meta app_label model _meta model_name assert len model_tuple 2 return model_tupleexcept ValueError AssertionError raise ValueError "Invalidmodelreference'%s' Stringmodelreferencesmustbeoftheform'app_label ModelName' " % model
def _preflight_check desired fromrepo **kwargs if 'pkg check_db' not in __salt__ return {}ret {'suggest' {} 'no_suggest' []}pkginfo __salt__['pkg check_db'] fromrepo fromrepo *list desired keys **kwargs for pkgname in pkginfo if pkginfo[pkgname]['found'] is False if pkginfo[pkgname]['suggestions'] ret['suggest'][pkgname] pkginfo[pkgname]['suggestions']else ret['no_suggest'] append pkgname return ret
def TimeFromTicks ticks return Time *time localtime ticks [3 6]
def parse_html_list dictionary prefix '' ret {}regex re compile '^%s\\[ [0-9]+ \\] * $' % re escape prefix for field value in dictionary items match regex match field if not match continue index key match groups index int index if not key ret[index] valueelif isinstance ret get index dict ret[index][key] valueelse ret[index] MultiValueDict {key [value]} return [ret[item] for item in sorted ret keys ]
def atomic fn @functools wraps fn @writedef inner *args **kwargs cursor connection cursor cursor execute 'SETTRANSACTIONISOLATIONLEVELSERIALIZABLE' with transaction atomic return fn *args **kwargs inner non_atomic fnreturn inner
def update_module conn module remote_module conn modules[module __name__]local_file inspect getsourcefile module remote_file inspect getsourcefile remote_module upload_file conn local_filem remote_file reload remote_module
def _changed filename filename_cache filename + ' md5' try md5_cached open filename_cache 'rb' read except IOError md5_cached '0'with open filename 'rb' as f md5_new _md5sum f with open filename_cache 'wb' as cf cf write md5_new encode 'utf-8' return md5_cached md5_new encode 'utf-8'
def setClosedAttribute revolutions xmlElement xmlElement attributeDictionary['closed'] str evaluate getEvaluatedBooleanDefault revolutions < 1 'closed' xmlElement lower
def _pre_startup _setup_logging if _options verbose logging getLogger setLevel logging DEBUG if _options enable_openflow pox openflow launch
def notify context publisher_id event_type priority payload if priority not in log_levels raise BadPriorityException _ '%snotinvalidpriorities' % priority payload jsonutils to_primitive payload convert_instances True msg dict message_id str uuid uuid4 publisher_id publisher_id event_type event_type priority priority payload payload timestamp str timeutils utcnow for driver in _get_drivers try driver notify context msg except Exception as e LOG exception _ "Problem'% e s'attemptingtosendtonotificationsystem Payload % payload s" % dict e e payload payload
def notify context publisher_id event_type priority payload if priority not in log_levels raise BadPriorityException _ '%snotinvalidpriorities' % priority payload jsonutils to_primitive payload convert_instances True msg dict message_id str uuid uuid4 publisher_id publisher_id event_type event_type priority priority payload payload timestamp str timeutils utcnow for driver in _get_drivers try driver notify context msg except Exception as e LOG exception _ "Problem'% e s'attemptingtosendtonotificationsystem Payload % payload s" % dict e e payload payload
def click_component_from_menu category component_type is_advanced if is_advanced world retry_on_exception _click_advanced ignored_exceptions AssertionError link world retry_on_exception lambda _find_matching_button category component_type ignored_exceptions AssertionError world retry_on_exception lambda link click
def test_gnb_pfit_wrong_nb_features clf GaussianNB clf fit X y assert_raises ValueError clf partial_fit np hstack X X y
def get_config profiles {}curr Nonecmd ['netsh' 'advfirewall' 'show' 'allprofiles']for line in __salt__['cmd run'] cmd python_shell False splitlines if not curr tmp re search ' * ProfileSettings ' line if tmp curr tmp group 1 elif line startswith 'State' profiles[curr] line split [1] 'ON' curr Nonereturn profiles
def suppress_output fn save_stdout sys stdouttry sys stdout DummyFile fn finally sys stdout save_stdout
def create_oebbook log path_or_stream opts reader None encoding 'utf-8' populate True for_regex_wizard False specialize None from calibre ebooks oeb base import OEBBookhtml_preprocessor HTMLPreProcessor log opts regex_wizard_callback regex_wizard_callback if not encoding encoding Noneoeb OEBBook log html_preprocessor pretty_print opts pretty_print input_encoding encoding if not populate return oebif specialize is not None oeb specialize oeb or oeb log 'Parsingallcontent ' if reader is None from calibre ebooks oeb reader import OEBReaderreader OEBReaderreader oeb path_or_stream return oeb
def set_permissions vhost user conf ' *' write ' *' read ' *' runas None if runas is None and not salt utils is_windows runas salt utils get_user res __salt__['cmd run_all'] [__context__['rabbitmqctl'] 'set_permissions' '-p' vhost user conf write read] runas runas python_shell False msg 'PermissionsSet'return _format_response res msg
def catalogue_pre_save instance sender **kwargs record Nonetry catalogue get_catalogue record catalogue get_record instance uuid except EnvironmentError as err msg 'Couldnotconnecttocataloguetosaveinformationforlayer"%s"' % instance name LOGGER warn msg err raise errif record is None return
def yaml_encode data yrepr yaml representer SafeRepresenter ynode yrepr represent_data data if not isinstance ynode yaml ScalarNode raise TypeError 'yaml_encode onlyworkswithYAMLscalardata failedfor{0}' format type data tag ynode tag rsplit ' ' 1 [ -1 ]ret ynode valueif tag 'str' ret yaml_dquote ynode value return ret
def yaml_encode data yrepr yaml representer SafeRepresenter ynode yrepr represent_data data if not isinstance ynode yaml ScalarNode raise TypeError 'yaml_encode onlyworkswithYAMLscalardata failedfor{0}' format type data tag ynode tag rsplit ' ' 1 [ -1 ]ret ynode valueif tag 'str' ret yaml_dquote ynode value return ret
def set_proxy proxy user None password '' from nltk import compatif proxy is None try proxy getproxies ['http']except KeyError raise ValueError 'Couldnotdetectdefaultproxysettings' proxy_handler ProxyHandler {'http' proxy} opener build_opener proxy_handler if user is not None password_manager HTTPPasswordMgrWithDefaultRealm password_manager add_password realm None uri proxy user user passwd password opener add_handler ProxyBasicAuthHandler password_manager opener add_handler ProxyDigestAuthHandler password_manager install_opener opener
@register simple_tagdef bootstrap_css rendered_urls [render_link_tag bootstrap_css_url ]if bootstrap_theme_url rendered_urls append render_link_tag bootstrap_theme_url return mark_safe u'' join [url for url in rendered_urls]
def GetFieldInDocument document field_name for f in document field_list if f name field_name return freturn None
def prompt_and_delete_repo repo_dir no_input False if no_input ok_to_delete Trueelse question u"You'vecloned{}before Isitokaytodeleteandre-cloneit?" format repo_dir ok_to_delete read_user_yes_no question u'yes' if ok_to_delete rmtree repo_dir else sys exit
def resources_from_path instance path if ' ' in path path path split ' ' else path [path]seen set nextlevel set [instance] first_time Truewhile nextlevel thislevel nextlevelnextlevel set if path relation path pop 0 else relation Nonefor resource in thislevel if resource in seen continueif first_time first_time Falseelse yield resource seen add resource if relation is not None if is_like_list resource relation update nextlevel updateelse update nextlevel addupdate getattr resource relation
def resources_from_path instance path if ' ' in path path path split ' ' else path [path]seen set nextlevel set [instance] first_time Truewhile nextlevel thislevel nextlevelnextlevel set if path relation path pop 0 else relation Nonefor resource in thislevel if resource in seen continueif first_time first_time Falseelse yield resource seen add resource if relation is not None if is_like_list resource relation update nextlevel updateelse update nextlevel addupdate getattr resource relation
def pearson_score list1 list2 size len list1 sum1 sum list1 sum2 sum list2 sum_sq1 sum [pow l 2 for l in list1] sum_sq2 sum [pow l 2 for l in list2] prod_sum sum [ list1[i] * list2[i] for i in range size ] num prod_sum - sum1 * sum2 / float size den sqrt sum_sq1 - pow sum1 2 0 / size * sum_sq2 - pow sum2 2 0 / size return num / den
def translate s tex tex_greek_dictionary get s if tex return texelif s lower in greek_letters_set return '\\' + s lower elif s in other_symbols return '\\' + s else for key in sorted modifier_dict keys key lambda k len k reverse True if s lower endswith key and len s > len key return modifier_dict[key] translate s[ - len key ] return s
def dots_to_camel_case dots def return_upper match return match groups [0] upper return str DOTS sub return_upper dots
def dots_to_camel_case dots def return_upper match return match groups [0] upper return str DOTS sub return_upper dots
def dots_to_camel_case dots def return_upper match return match groups [0] upper return str DOTS sub return_upper dots
@conf commands registerdef dyndns_del nameserver name type 'ALL' ttl 10 zone name[ name find ' ' + 1 ]r sr1 IP dst nameserver / UDP / DNS opcode 5 qd [DNSQR qname zone qtype 'SOA' ] ns [DNSRR rrname name type type rclass 'ANY' ttl 0 rdata '' ] verbose 0 timeout 5 if r and r haslayer DNS return r getlayer DNS rcodeelse return -1
def _get_conn opts profile None if profile is None profile opts get 'etcd returner' path opts get 'etcd returner_root' '/salt/return' return salt utils etcd_util get_conn opts profile path
def _estimate_gaussian_covariances_tied resp X nk means reg_covar avg_X2 np dot X T X avg_means2 np dot nk * means T means covariance avg_X2 - avg_means2 covariance / nk sum covariance flat[ len covariance + 1 ] + reg_covarreturn covariance
def getManipulatedPaths close elementNode loop prefix sideLength if len loop < 2 return [loop]derivation OutlineDerivation elementNode prefix sideLength loopComplex euclidean getComplexPath loop if derivation isClosed loopComplexes intercircle getAroundsFromLoop loopComplex derivation radius else loopComplexes intercircle getAroundsFromPath loopComplex derivation radius return euclidean getVector3Paths loopComplexes loop[0] z
def setup_platform hass config add_devices discovery_info None dev_id config get CONF_ID devname config get CONF_NAME add_devices [EnOceanSwitch dev_id devname ]
def get_request_ip request return request META get 'HTTP_X_FORWARDED_FOR' or request META get 'REMOTE_ADDR' or request META get 'HTTP_X_REAL_IP'
def update_repository repo ctx_rev None commands update get_configured_ui repo rev ctx_rev
def DBSubjectLockTest f @functools wraps f def Decorator testinstance if testinstance TEST_DBSUBJECTLOCKS return f testinstance else return testinstance skipTest 'Teststhatuselocksaredisabledforthisdatastore ' return Decorator
def validate_setup_for_nested_quota_use ctxt resources nested_quota_driver fix_allocated_quotas False try project_roots get_all_root_project_ids ctxt for root in project_roots root_proj get_project_hierarchy ctxt root subtree_as_ids True nested_quota_driver validate_nested_setup ctxt resources {root_proj id root_proj subtree} fix_allocated_quotas fix_allocated_quotas except exceptions VersionNotAvailable msg _ 'Keystoneversion3orgreatermustbeusedtogetnestedquotasupport ' raise exception CinderException message msg except exceptions Forbidden msg _ 'MustrunthiscommandascloudadminusingaKeystonepolicy jsonwhichallowscloudadmintolistandgetanyproject ' raise exception CinderException message msg
def validate_setup_for_nested_quota_use ctxt resources nested_quota_driver fix_allocated_quotas False try project_roots get_all_root_project_ids ctxt for root in project_roots root_proj get_project_hierarchy ctxt root subtree_as_ids True nested_quota_driver validate_nested_setup ctxt resources {root_proj id root_proj subtree} fix_allocated_quotas fix_allocated_quotas except exceptions VersionNotAvailable msg _ 'Keystoneversion3orgreatermustbeusedtogetnestedquotasupport ' raise exception CinderException message msg except exceptions Forbidden msg _ 'MustrunthiscommandascloudadminusingaKeystonepolicy jsonwhichallowscloudadmintolistandgetanyproject ' raise exception CinderException message msg
def get_known_settings return _KNOWN_SETTINGS values
def test_sparse_oneclasssvm X_blobs _ make_blobs n_samples 100 centers 10 random_state 0 X_blobs sparse csr_matrix X_blobs datasets [[X_sp None T] [X2_sp None T2] [X_blobs[ 80] None X_blobs[80 ]] [iris data None iris data]]kernels ['linear' 'poly' 'rbf' 'sigmoid']for dataset in datasets for kernel in kernels clf svm OneClassSVM kernel kernel random_state 0 sp_clf svm OneClassSVM kernel kernel random_state 0 check_svm_model_equal clf sp_clf *dataset
def test_sparse_oneclasssvm X_blobs _ make_blobs n_samples 100 centers 10 random_state 0 X_blobs sparse csr_matrix X_blobs datasets [[X_sp None T] [X2_sp None T2] [X_blobs[ 80] None X_blobs[80 ]] [iris data None iris data]]kernels ['linear' 'poly' 'rbf' 'sigmoid']for dataset in datasets for kernel in kernels clf svm OneClassSVM kernel kernel random_state 0 sp_clf svm OneClassSVM kernel kernel random_state 0 check_svm_model_equal clf sp_clf *dataset
def update_subnet subnet name profile None conn _auth profile return conn update_subnet subnet name
def get_module_cache dirname init_args None global _module_cacheif init_args is None init_args {}if _module_cache is None _module_cache ModuleCache dirname **init_args atexit register _module_cache _on_atexit elif init_args _logger warning 'Ignoringinitargumentsformodulecachebecauseitwascreatedpriortothiscall' if _module_cache dirname dirname _logger warning 'Returningmodulecacheinstancewithdifferentdirname %s thanyourequested %s ' _module_cache dirname dirname return _module_cache
def get_module_cache dirname init_args None global _module_cacheif init_args is None init_args {}if _module_cache is None _module_cache ModuleCache dirname **init_args atexit register _module_cache _on_atexit elif init_args _logger warning 'Ignoringinitargumentsformodulecachebecauseitwascreatedpriortothiscall' if _module_cache dirname dirname _logger warning 'Returningmodulecacheinstancewithdifferentdirname %s thanyourequested %s ' _module_cache dirname dirname return _module_cache
def user_registered_cb user **kwargs siteconfig SiteConfiguration objects get_current if siteconfig get u'mail_send_new_user_mail' mail_new_user user
def get_readme_path file_path dir os path dirname file_path readme os path join REPO_ROOT dir 'README md' return readme
def root_mean_square_error y_real y_pred y_real y_pred check_arrays y_real y_pred return np sqrt np sum y_pred - y_real ** 2 / y_real shape[0]
def require_open func def wrapper self *args **kwargs if self closed raise IOError errno EBADF 'I/Ooperationonclosedfile' return func self *args **kwargs return wrapper
def addrow row1 row2 K return [ element1 + element2 for element1 element2 in zip row1 row2 ]
def reset_indent TokenClass def callback lexer match context text match group context indent_stack []context indent -1 context next_indent 0context block_scalar_indent None yield match start TokenClass text context pos match end return callback
def get_reader identity global FORMAT_READERSif FORMAT_READERS is None _import_readers return FORMAT_READERS get identity None
def has_change_path_cmd sql return u'setsearch_path' in sql lower
def has_change_path_cmd sql return u'setsearch_path' in sql lower
def has_change_path_cmd sql return u'setsearch_path' in sql lower
def test_feature_max_length_on_feature_name feature Feature from_string FEATURE3 assert_equals feature max_length 78
def _latest_common_snapshot some others others_set set others for snapshot in reversed some if snapshot in others_set return snapshotreturn None
def scatter input target_gpus def scatter_map obj if isinstance obj Variable return Scatter target_gpus obj return tuple zip *map scatter_map obj return scatter_map input
def list_repos basedir None basedirs _normalize_basedir basedir repos {}log debug 'Searchingforreposin%s' basedirs for bdir in basedirs if not os path exists bdir continuefor repofile in os listdir bdir repopath '{0}/{1}' format bdir repofile if not repofile endswith ' repo' continuefilerepos _parse_repo_file repopath [1]for reponame in filerepos keys repo filerepos[reponame]repo['file'] repopathrepos[reponame] reporeturn repos
def get_thread exploration_id thread_id model feedback_models FeedbackThreadModel get_by_exp_and_thread_id exploration_id thread_id return _get_thread_from_model model
def py_default type_name return {'double' '123 0' 'long' '123' 'integer' '123' 'string' "'string'" 'blob' "b'bytes'" 'boolean' 'True False' 'list' '[ ]' 'map' '{ }' 'structure' '{ }' 'timestamp' 'datetime 2015 1 1 '} get type_name ' '
def rm_host ip alias if not has_pair ip alias return Truehfn _get_or_create_hostfile with salt utils fopen hfn as fp_ lines fp_ readlines for ind in range len lines tmpline lines[ind] strip if not tmpline continueif tmpline startswith '#' continuecomps tmpline split if comps[0] ip newline '{0} DCTB DCTB ' format comps[0] for existing in comps[1 ] if existing alias continuenewline + '{0}' format existing if newline strip ip lines[ind] ''else lines[ind] newline + os linesep with salt utils fopen hfn 'w+' as ofile ofile writelines lines return True
def rm_host ip alias if not has_pair ip alias return Truehfn _get_or_create_hostfile with salt utils fopen hfn as fp_ lines fp_ readlines for ind in range len lines tmpline lines[ind] strip if not tmpline continueif tmpline startswith '#' continuecomps tmpline split if comps[0] ip newline '{0} DCTB DCTB ' format comps[0] for existing in comps[1 ] if existing alias continuenewline + '{0}' format existing if newline strip ip lines[ind] ''else lines[ind] newline + os linesep with salt utils fopen hfn 'w+' as ofile ofile writelines lines return True
def reject_spurious_dots *items for list in items for tok in list if tok ' ' and type tok HySymbol raise LexException 'Malformeddottedlist' tok start_line tok start_column
def parse_set_header value on_update None if not value return HeaderSet None on_update return HeaderSet parse_list_header value on_update
def _to_report name if name in _REPORTS return nameraise UsageError 'Unrecognizedreport{} {}' format name _to_report coerceDoc
def auto_kwargs function supported introspect arguments function @wraps function def call_function *args **kwargs return function *args **{key value for key value in kwargs items if key in supported } return call_function
def auto_kwargs function supported introspect arguments function @wraps function def call_function *args **kwargs return function *args **{key value for key value in kwargs items if key in supported } return call_function
def discretize_center_2D model x_range y_range x np arange *x_range y np arange *y_range x y np meshgrid x y return model x y
def test_invalid_upgrade_strategy_causes_error script result script pip_install_local '--upgrade' '--upgrade-strategy bazinga' 'simple' expect_error True assert result returncodeassert 'invalidchoice' in result stderr
def marketing_link_context_processor request marketing_urls configuration_helpers get_value 'MKTG_URLS' settings MKTG_URLS return dict [ 'MKTG_URL_' + k marketing_link k for k in settings MKTG_URL_LINK_MAP viewkeys marketing_urls viewkeys ]
def marketing_link_context_processor request marketing_urls configuration_helpers get_value 'MKTG_URLS' settings MKTG_URLS return dict [ 'MKTG_URL_' + k marketing_link k for k in settings MKTG_URL_LINK_MAP viewkeys marketing_urls viewkeys ]
def marketing_link_context_processor request marketing_urls configuration_helpers get_value 'MKTG_URLS' settings MKTG_URLS return dict [ 'MKTG_URL_' + k marketing_link k for k in settings MKTG_URL_LINK_MAP viewkeys marketing_urls viewkeys ]
def marketing_link_context_processor request marketing_urls configuration_helpers get_value 'MKTG_URLS' settings MKTG_URLS return dict [ 'MKTG_URL_' + k marketing_link k for k in settings MKTG_URL_LINK_MAP viewkeys marketing_urls viewkeys ]
def from_array_like ary stream 0 gpu_data None if ary ndim 0 ary ary reshape 1 return DeviceNDArray ary shape ary strides ary dtype writeback ary stream stream gpu_data gpu_data
def test_attribute_access can_compile u' foobarbaz ' can_compile u' foo[bar]baz ' can_compile u' foobar[baz][0]quux[frob] ' can_compile u' foobar[ +1234 ]quux[frob] ' cant_compile u' foobar baz[0]quux[frob] ' cant_compile u' foobarbaz 0 quux[frob] ' cant_compile u' foobarbaz[0]quux{frob} '
def retrieve endpoint 'incidents' api_url None page_id None api_key None api_version None params _get_api_params api_url api_url page_id page_id api_key api_key api_version api_version if not _validate_api_params params log error 'InvalidAPIparams ' log error params return {'result' False 'comment' 'InvalidAPIparams Seelogfordetails'}headers _get_headers params retrieve_url '{base_url}/v{version}/pages/{page_id}/{endpoint} json' format base_url params['api_url'] version params['api_version'] page_id params['api_page_id'] endpoint endpoint return _http_request retrieve_url headers headers
def SetLevel level global _Level_Level level
def load_MNIST_labels filename with open filename 'r' as f magic np fromfile f dtype np dtype '>i4' count 1 num_labels np fromfile f dtype np dtype '>i4' count 1 labels np fromfile f dtype np ubyte f close return labels
def load_MNIST_labels filename with open filename 'r' as f magic np fromfile f dtype np dtype '>i4' count 1 num_labels np fromfile f dtype np dtype '>i4' count 1 labels np fromfile f dtype np ubyte f close return labels
def setup_platform hass config add_devices discovery_info None import pywinkadd_devices WinkCoverDevice shade hass for shade in pywink get_shades add_devices WinkCoverDevice door hass for door in pywink get_garage_doors
def get_cmd m subcommand is_install subcommand in ['install' 'update' 'patch'] is_refresh subcommand 'refresh' cmd ['/usr/bin/zypper' '--quiet' '--non-interactive' '--xmlout']if is_install or is_refresh and m params['disable_gpg_check'] cmd append '--no-gpg-checks' cmd append subcommand if subcommand 'patch' and not is_refresh cmd extend ['--type' m params['type']] if m check_mode and subcommand 'search' cmd append '--dry-run' if is_install cmd append '--auto-agree-with-licenses' if m params['disable_recommends'] cmd append '--no-recommends' if m params['force'] cmd append '--force' if m params['oldpackage'] cmd append '--oldpackage' return cmd
def HTTPS port 443 **kwargs return rule port **kwargs
def bump_cache_for_item item cache bump_version _get_namespace_for_item item
def delete_local_cache tex_root print u"Deletinglocalcachefor'{0}' " format repr tex_root local_cache_paths [_hidden_local_cache_path _local_cache_path tex_root ]for cache_path in local_cache_paths if os path exists cache_path print u"Deletelocalcachefolder'{0}'" format repr cache_path shutil rmtree cache_path
@login_requireddef project_version_delete_html request project_slug version_slug project get_object_or_404 Project objects for_admin_user request user slug project_slug version get_object_or_404 Version objects public user request user project project only_active False slug version_slug if not version active version built Falseversion save broadcast type 'app' task tasks clear_artifacts args [version pk] else return HttpResponseBadRequest "Can'tdeleteHTMLforanactiveversion " return HttpResponseRedirect reverse 'project_version_list' kwargs {'project_slug' project_slug}
def _format_return_data retcode stdout None stderr None ret {'retcode' retcode}if stdout is not None ret['stdout'] stdoutif stderr is not None ret['stderr'] stderrreturn ret
def get_preferred_environment_encoding return locale getpreferredencoding or u'utf-8'
def init path ' ' bare False if not os path exists path os mkdir path if bare return Repo init_bare path else return Repo init path
def validate_id_birthday gd fix_coordination_number_day True today datetime date today day int gd['day'] if fix_coordination_number_day and day > 60 day - 60if gd['century'] is None current_year today yearyear int today strftime '%Y' - int today strftime '%y' + int gd['year'] if '%s%s%02d' % gd['year'] gd['month'] day > today strftime '%y%m%d' year - 100if gd['sign'] '+' year - 100else year int gd['century'] + gd['year'] if year < 1800 raise ValueErrorbirth_day datetime date year int gd['month'] day if birth_day > today raise ValueErrorreturn birth_day
def validate_id_birthday gd fix_coordination_number_day True today datetime date today day int gd['day'] if fix_coordination_number_day and day > 60 day - 60if gd['century'] is None current_year today yearyear int today strftime '%Y' - int today strftime '%y' + int gd['year'] if '%s%s%02d' % gd['year'] gd['month'] day > today strftime '%y%m%d' year - 100if gd['sign'] '+' year - 100else year int gd['century'] + gd['year'] if year < 1800 raise ValueErrorbirth_day datetime date year int gd['month'] day if birth_day > today raise ValueErrorreturn birth_day
def extract_arguments text regexp re compile '\\/\\w* @\\w* *\\s* [\\s\\S]* ' re IGNORECASE result regexp match text return result group 2 if is_command text else None
def Element tag *args **kw if '{' not in tag tag '{%s}%s' % atom_ns tag return atom_parser makeelement tag *args **kw
@publicdef sring exprs *symbols **options single Falseif not is_sequence exprs exprs single [exprs] True exprs list map sympify exprs opt build_options symbols options reps opt _parallel_dict_from_expr exprs opt if opt domain is None coeffs sum [list rep values for rep in reps] [] opt domain _ construct_domain coeffs opt opt _ring PolyRing opt gens opt domain opt order polys list map _ring from_dict reps if single return _ring polys[0] else return _ring polys
@publicdef sring exprs *symbols **options single Falseif not is_sequence exprs exprs single [exprs] True exprs list map sympify exprs opt build_options symbols options reps opt _parallel_dict_from_expr exprs opt if opt domain is None coeffs sum [list rep values for rep in reps] [] opt domain _ construct_domain coeffs opt opt _ring PolyRing opt gens opt domain opt order polys list map _ring from_dict reps if single return _ring polys[0] else return _ring polys
def burt_table data variables values [ var value for var in variables for value in var values]table numpy zeros len values len values counts [len attr values for attr in variables]offsets numpy r_[ 0 numpy cumsum counts ]for i in range len variables for j in range i + 1 var1 variables[i]var2 variables[j]cm contingency get_contingency data var2 var1 start1 end1 offsets[i] offsets[i] + counts[i] start2 end2 offsets[j] offsets[j] + counts[j] table[start1 end1 start2 end2] + cmif i j table[start2 end2 start1 end1] + cm Treturn values table
def decrypt_int cyphertext dkey n assert_int cyphertext 'cyphertext' assert_int dkey 'dkey' assert_int n 'n' message pow cyphertext dkey n return message
@validate 'form' def valid_att_in_label arch return not arch xpath '//label[not @foror@string ]'
@validate 'form' def valid_att_in_label arch return not arch xpath '//label[not @foror@string ]'
def cleanup return _get_impl cleanup
def assert_calculated_changes_for_deployer case deployer node_state node_config nonmanifest_datasets additional_node_states additional_node_config expected_changes local_state leases Leases cluster_state compute_cluster_state node_state additional_node_states nonmanifest_datasets cluster_configuration Deployment nodes {node_config} additional_node_config leases leases changes deployer calculate_changes cluster_configuration cluster_state local_state case assertEqual expected_changes changes
def assert_calculated_changes_for_deployer case deployer node_state node_config nonmanifest_datasets additional_node_states additional_node_config expected_changes local_state leases Leases cluster_state compute_cluster_state node_state additional_node_states nonmanifest_datasets cluster_configuration Deployment nodes {node_config} additional_node_config leases leases changes deployer calculate_changes cluster_configuration cluster_state local_state case assertEqual expected_changes changes
def create_simple_html_directive name pre post has_content True match_titles False node_class type name replace '-' '_' nodes General nodes Element {} def visit_html self node self body append pre def depart_html self node self body append post def run_directive self node node_class if has_content text self contentself state nested_parse text self content_offset node match_titles match_titles self state document settings record_dependencies add __file__ return [node]directive_class type name title + 'Directive' Directive {'has_content' has_content 'run' run_directive} def setup app app add_node node_class html visit_html depart_html app add_directive name directive_class return node_class directive_class setup
def _generate_zip_package target sources sources_dir zip zipfile ZipFile target 'w' zipfile ZIP_DEFLATED manifest _archive_package_sources zip write sources sources_dir zip writestr _PACKAGE_MANIFEST '\n' join manifest + '\n' zip close return None
def _generate_zip_package target sources sources_dir zip zipfile ZipFile target 'w' zipfile ZIP_DEFLATED manifest _archive_package_sources zip write sources sources_dir zip writestr _PACKAGE_MANIFEST '\n' join manifest + '\n' zip close return None
def lazy_loading_proxy_for_interface interface loader class LazyLoadingProxy proxyForInterface interface '_original' _cached_original Nonedef __init__ self '\nTheinitializerofaclassgeneratedby``proxyForInterface``\nexpectsthewrapped"original"objectasanargument Overrride\nthathere \n'@propertydef _original self if self _cached_original is None self _cached_original loader return self _cached_originalreturn LazyLoadingProxy
def lazy_loading_proxy_for_interface interface loader class LazyLoadingProxy proxyForInterface interface '_original' _cached_original Nonedef __init__ self '\nTheinitializerofaclassgeneratedby``proxyForInterface``\nexpectsthewrapped"original"objectasanargument Overrride\nthathere \n'@propertydef _original self if self _cached_original is None self _cached_original loader return self _cached_originalreturn LazyLoadingProxy
def _repack_pkgs pkgs normalize True if normalize and 'pkg normalize_name' in __salt__ _normalize_name __salt__['pkg normalize_name']else _normalize_name lambda pkgname pkgname return dict [ _normalize_name str x str y if y is not None else y for x y in six iteritems salt utils repack_dictlist pkgs ]
def MakeDestinationKey directory filename return utils SmartStr utils JoinPath directory filename lstrip '/'
def MakeDestinationKey directory filename return utils SmartStr utils JoinPath directory filename lstrip '/'
def path_and_line req path line re match '-r * \\ line \\d+ \\ $' req comes_from groups return path int line
def tamper payload **kwargs def process match word match group 'word' if word upper in kb keywords return match group replace word '/* %s*/' % word else return match group retVal payloadif payload retVal re sub ' ?< \\W ?P<word>[A-Za-z_]+ ? [^\\w ] \\Z ' lambda match process match retVal retVal retVal replace '/* ' '/* ' replace '*/' '*/' return retVal
def add_input cmd immediate False if immediate process_stdin cmd else mpstate input_queue put cmd
@contextmanagerdef assertNoFDsLeaked test_case gc collect def process_fds path FilePath '/dev/fd' if not path exists raise SkipTest '/dev/fdisnotavailable ' return set [child basename for child in path children ] fds process_fds try yield finally test_case assertEqual process_fds fds
def _get_proctoring_requirements course_key from edx_proctoring api import get_all_exams_for_courserequirements []for exam in get_all_exams_for_course unicode course_key if exam['is_proctored'] and exam['is_active'] and not exam['is_practice_exam'] try usage_key UsageKey from_string exam['content_id'] proctor_block modulestore get_item usage_key except InvalidKeyError ItemNotFoundError LOGGER info "Invalidcontent_id'%s'forproctoredblock'%s'" exam['content_id'] exam['exam_name'] proctor_block Noneif proctor_block requirements append {'namespace' 'proctored_exam' 'name' exam['content_id'] 'display_name' exam['exam_name'] 'start_date' proctor_block start if proctor_block start else None 'criteria' {}} if requirements log_msg "Registeringthefollowingas'proctored_exam'creditrequirements {log_msg}" format log_msg requirements LOGGER info log_msg return requirements
def _get_proctoring_requirements course_key from edx_proctoring api import get_all_exams_for_courserequirements []for exam in get_all_exams_for_course unicode course_key if exam['is_proctored'] and exam['is_active'] and not exam['is_practice_exam'] try usage_key UsageKey from_string exam['content_id'] proctor_block modulestore get_item usage_key except InvalidKeyError ItemNotFoundError LOGGER info "Invalidcontent_id'%s'forproctoredblock'%s'" exam['content_id'] exam['exam_name'] proctor_block Noneif proctor_block requirements append {'namespace' 'proctored_exam' 'name' exam['content_id'] 'display_name' exam['exam_name'] 'start_date' proctor_block start if proctor_block start else None 'criteria' {}} if requirements log_msg "Registeringthefollowingas'proctored_exam'creditrequirements {log_msg}" format log_msg requirements LOGGER info log_msg return requirements
def GetRegisteredExe exeAlias return win32api RegQueryValue GetRootKey GetAppPathsKey + '\\' + exeAlias
def mimetype serial return {'Content-Type' 'application/vnd blaze+%s' % serial name }
def CreateRPC service stubmap None if stubmap is None stubmap apiproxystub stubmap GetStub service assert stub 'Noapiproxyfoundforservice"%s"' % service assert hasattr stub 'CreateRPC' 'Theservice"%s"doesn\'thave' + 'aCreateRPCmethod ' % service return stub CreateRPC
def addIntrospection xmlrpc xmlrpc putSubHandler 'system' XMLRPCIntrospection xmlrpc
def recreate_field unbound if not isinstance unbound UnboundField raise ValueError 'recreate_fieldexpectsUnboundFieldinstance %swaspassed ' % type unbound return unbound field_class *unbound args **unbound kwargs
def unpack_callbacks cbs if cbs return [[i for i in f if i] for f in zip *cbs ]else return [ ]
def _create_ofb_cipher factory **kwargs cipher_state factory _create_base_cipher kwargs iv kwargs pop 'IV' None IV kwargs pop 'iv' None if None None iv IV iv get_random_bytes factory block_size if iv is not None if IV is not None raise TypeError "Youmusteitheruse'iv'or'IV' notboth" else iv IVif kwargs raise TypeError 'UnknownparametersforOFB %s' % str kwargs return OfbMode cipher_state iv
def _create_ofb_cipher factory **kwargs cipher_state factory _create_base_cipher kwargs iv kwargs pop 'IV' None IV kwargs pop 'iv' None if None None iv IV iv get_random_bytes factory block_size if iv is not None if IV is not None raise TypeError "Youmusteitheruse'iv'or'IV' notboth" else iv IVif kwargs raise TypeError 'UnknownparametersforOFB %s' % str kwargs return OfbMode cipher_state iv
def in6_ismlladdr str return in6_isincluded str 'ff02 ' 16
def find_dynamicsymbols expression exclude None t_set {dynamicsymbols _t}if exclude if iterable exclude exclude_set set exclude else raise TypeError 'excludekwargmustbeiterable' else exclude_set set return set [i for i in expression atoms AppliedUndef Derivative if i free_symbols t_set ] - exclude_set
def top container client _get_client status base_status copy try dcontainer _get_container_infos container ['Id']if is_running dcontainer ret client top dcontainer if ret ret['mprocesses'] []titles ret['Titles']for i in ret['Processes'] data salt utils odict OrderedDict for k j in enumerate titles data[j] i[k]ret['mprocesses'] append data _valid status out ret id_ container comment 'Currenttopforcontainer' if not status['id'] _invalid status else _invalid status comment 'Container{0}isnotrunning' format container except Exception _invalid status id_ container out traceback format_exc return status
@cronjobs registerdef update_l10n_metric if settings STAGE returntop_60_docs _get_top_docs 60 end date today - timedelta days 1 start end - timedelta days 30 locale_visits googleanalytics visitors_by_locale start end total_visits sum locale_visits itervalues coverage 0for locale visits in locale_visits iteritems if locale settings WIKI_DEFAULT_LANGUAGE num_docs MAX_DOCS_UP_TO_DATEup_to_date_docs MAX_DOCS_UP_TO_DATEelse up_to_date_docs num_docs _get_up_to_date_count top_60_docs locale if num_docs and total_visits coverage + float up_to_date_docs / num_docs * float visits / total_visits metric_kind MetricKind objects get code L10N_METRIC_CODE day date today Metric objects create kind metric_kind start day end day + timedelta days 1 value int coverage * 100
def get_human_readable_disk_usage d if platform system in ['Linux' 'FreeBSD'] try return subprocess Popen ['du' '-sh' d] stdout subprocess PIPE communicate [0] split [0]except raise CleanupException 'roscleanisnotsupportedonthisplatform' else raise CleanupException 'roscleanisnotsupportedonthisplatform'
def create_event name message_type routing_key 'everyone' **kwargs ret {'name' name 'changes' {} 'result' None 'comment' ''}if __opts__['test'] ret['comment'] 'Needtocreateevent {0}' format name return retres __salt__['victorops create_event'] message_type message_type routing_key routing_key **kwargs if res['result'] 'success' ret['result'] Trueret['comment'] 'Createdevent {0}forentity{1}' format name res['entity_id'] else ret['result'] Falseret['comment'] 'Failedtocreateevent {0}' format res['message'] return ret
def checkCRC data check return computeCRC data check
def test_iter_evoked raw events picks _get_data epochs Epochs raw events[ 5] event_id tmin tmax picks picks for ii ev in enumerate epochs iter_evoked x ev datay epochs get_data [ii ]assert_array_equal x y
def create_membership **kwargs project kwargs pop 'project' ProjectFactory project points add PointsFactory create project project value None defaults {'project' project 'user' UserFactory create 'role' RoleFactory create project project permissions list map lambda x x[0] MEMBERS_PERMISSIONS }defaults update kwargs return MembershipFactory create **defaults
def check_package_data_first command class DecoratedCommand command def run self check_package_data self package_data command run self return DecoratedCommand
@cronjobs registerdef survey_recent_askers if settings STAGE returntwo_days_ago date today - timedelta days 2 yesterday date today - timedelta days 1 emails Question objects filter created__gte two_days_ago created__lt yesterday values_list 'creator__email' flat True for email in emails add_email_to_campaign 'askers' email statsd gauge 'survey askers' len emails
@cronjobs registerdef survey_recent_askers if settings STAGE returntwo_days_ago date today - timedelta days 2 yesterday date today - timedelta days 1 emails Question objects filter created__gte two_days_ago created__lt yesterday values_list 'creator__email' flat True for email in emails add_email_to_campaign 'askers' email statsd gauge 'survey askers' len emails
def dict_subset d keys result {}for key in keys if ' ' in key field subfield key split ' ' 1 if isinstance d get field collections Mapping subvalue dict_subset d[field] [subfield] result[field] dict_merge subvalue result get field {} elif field in d result[field] d[field]elif key in d result[key] d[key]return result
def make_half_violin x y fillcolor '#1f77b4' linecolor 'rgb 0 0 0 ' text [ ' pdf y y ' + '{ 0 2f}' format x[i] + ' ' + '{ 0 2f}' format y[i] + ' ' for i in range len x ]return graph_objs Scatter x x y y mode 'lines' name '' text text fill 'tonextx' fillcolor fillcolor line graph_objs Line width 0 5 color linecolor shape 'spline' hoverinfo 'text' opacity 0 5
def millisecond_to_clocktime value return value * Gst MSECOND
def get_event_loop return _current_loop
def libvlc_media_player_get_xwindow p_mi f _Cfunctions get 'libvlc_media_player_get_xwindow' None or _Cfunction 'libvlc_media_player_get_xwindow' 1 None ctypes c_uint32 MediaPlayer return f p_mi
def activity_create context activity_dict **kw _check_access 'activity_create' context activity_dict if 'ignore_auth' in kw raise Exception 'ActivityStreamcallingparametershavechangedignore_authmustbepassedinthecontextnotasaparam' if not paste deploy converters asbool config get 'ckan activity_streams_enabled' 'true' returnmodel context['model']if getattr model Session 'revision' None activity_dict['revision_id'] model Session revision idelse activity_dict['revision_id'] Noneschema context get 'schema' or ckan logic schema default_create_activity_schema data errors _validate activity_dict schema context if errors raise ValidationError errors activity model_save activity_dict_save data context if not context get 'defer_commit' model repo commit log debug "Created'%s'activity" % activity activity_type return model_dictize activity_dictize activity context
def groupfinder userid request backend getattr request registry 'permission' None if not backend return []if request prefixed_userid userid request prefixed_useridreify_key userid + '_principals' if reify_key not in request bound_data principals backend get_user_principals userid request bound_data[reify_key] principalsreturn request bound_data[reify_key]
@register u'yank-pop' def yank_pop event buff event current_bufferdoc_before_paste buff document_before_pasteclipboard event cli clipboardif doc_before_paste is not None buff document doc_before_pasteclipboard rotate buff paste_clipboard_data clipboard get_data paste_mode PasteMode EMACS
def _create_and_add_parameters params global _current_parameterif _is_simple_type params _current_parameter SimpleParameter params _current_option add_parameter _current_parameter else for i in params if _is_simple_type i _current_parameter SimpleParameter i else _current_parameter TypedParameter _parse_typed_parameter i _current_option add_parameter _current_parameter
def format_p_value_for_num_iters p num_iters if num_iters < 10 return 'Toofewiterstocomputep-value num_iters %d ' % num_iters decimal_places int log10 num_iters + 1 result '%1 ' + '%df' % decimal_places % p return result
def check_classification_toy name ForestClassifier FOREST_CLASSIFIERS[name]clf ForestClassifier n_estimators 10 random_state 1 clf fit X y assert_array_equal clf predict T true_result assert_equal 10 len clf clf ForestClassifier n_estimators 10 max_features 1 random_state 1 clf fit X y assert_array_equal clf predict T true_result assert_equal 10 len clf leaf_indices clf apply X assert_equal leaf_indices shape len X clf n_estimators
def logspace xmin xmax N return np exp np linspace np log xmin np log xmax N
def logspace xmin xmax N return np exp np linspace np log xmin np log xmax N
def logspace xmin xmax N return np exp np linspace np log xmin np log xmax N
def default_deadline_for_credit_eligibility return datetime datetime now pytz UTC + datetime timedelta days getattr settings 'CREDIT_ELIGIBILITY_EXPIRATION_DAYS' 365
def get_pdherr code code & 2 ** 32 - 1 return _pdh_errcodes get code code
def config_name_from_full_name full_name projects _ configs result full_name split '/' if projects 'projects' or configs 'configs' raise ValueError 'Unexpectedformatofresource' full_name 'Expected"projects/{proj}/configs/{cfg}"' return result
@ignore_warnings category DeprecationWarning def check_estimators_fit_returns_self name Estimator X y make_blobs random_state 0 n_samples 9 n_features 4 y multioutput_estimator_convert_y_2d name y X - X min estimator Estimator set_testing_parameters estimator set_random_state estimator assert_true estimator fit X y is estimator
@ignore_warnings category DeprecationWarning def check_estimators_fit_returns_self name Estimator X y make_blobs random_state 0 n_samples 9 n_features 4 y multioutput_estimator_convert_y_2d name y X - X min estimator Estimator set_testing_parameters estimator set_random_state estimator assert_true estimator fit X y is estimator
def _multi_call function contentkey *args **kwargs ret function *args **kwargs position ret get 'position' while position more function position position *args **kwargs ret[contentkey] extend more[contentkey] position more get 'position' return ret get contentkey
def _multi_call function contentkey *args **kwargs ret function *args **kwargs position ret get 'position' while position more function position position *args **kwargs ret[contentkey] extend more[contentkey] position more get 'position' return ret get contentkey
def pre_scm_buildstep registry xml_parent data bsp XML SubElement xml_parent 'org jenkinsci plugins preSCMbuildstep PreSCMBuildStepsWrapper' bs XML SubElement bsp 'buildSteps' for step in data for edited_node in create_builders registry step bs append edited_node
def pre_scm_buildstep registry xml_parent data bsp XML SubElement xml_parent 'org jenkinsci plugins preSCMbuildstep PreSCMBuildStepsWrapper' bs XML SubElement bsp 'buildSteps' for step in data for edited_node in create_builders registry step bs append edited_node
def zalpha colors zs colors get_colors colors len zs if len zs norm Normalize min zs max zs sats 1 - norm zs * 0 7 colors [ c[0] c[1] c[2] c[3] * s for c s in zip colors sats ]return colors
def zalpha colors zs colors get_colors colors len zs if len zs norm Normalize min zs max zs sats 1 - norm zs * 0 7 colors [ c[0] c[1] c[2] c[3] * s for c s in zip colors sats ]return colors
def _process_and_sort s force_ascii full_process True ts utils full_process s force_ascii force_ascii if full_process else s tokens ts split sorted_string u'' join sorted tokens return sorted_string strip
def get_profiler_results_dir autodir return os path join autodir 'results' 'default' 'profiler_sync' 'profiling'
def get_profiler_results_dir autodir return os path join autodir 'results' 'default' 'profiler_sync' 'profiling'
@_get_clientdef image_get_all client filters None marker None limit None sort_key None sort_dir None member_status 'accepted' is_public None admin_as_user False return_tag False v1_mode False sort_key ['created_at'] if not sort_key else sort_key sort_dir ['desc'] if not sort_dir else sort_dir return client image_get_all filters filters marker marker limit limit sort_key sort_key sort_dir sort_dir member_status member_status is_public is_public admin_as_user admin_as_user return_tag return_tag v1_mode v1_mode
def get_user_id username rv query_db 'selectuser_idfromuserwhereusername ?' [username] one True return rv[0] if rv else None
def websafe val if val is None return ''if not isinstance val unicode val str val return htmlquote val
def _translate_output output sensors_data_dict {}sensors_data_array output split '\n\n' for sensor_data in sensors_data_array sensor_data_dict _process_sensor sensor_data if not sensor_data_dict continuesensor_type _get_sensor_type sensor_data_dict sensor_id sensor_data_dict['SensorID']if 'SensorReading' in sensor_data_dict sensors_data_dict setdefault sensor_type {} [sensor_id] sensor_data_dictif not sensors_data_dict raise ipmiexcept IPMIException _ 'parseIPMIsensordatafailed Nodataretrievedfromgiveninput' return sensors_data_dict
def build_tool_panel_section_select_field app options []for section_id section_name in app toolbox get_sections options append section_name section_id select_field SelectField name 'tool_panel_section_id' field_id 'tool_panel_section_select' for option_tup in options select_field add_option option_tup[0] option_tup[1] return select_field
def seconds_to_time x t int x * 10 ** 6 ms t % 10 ** 6 t t // 10 ** 6 s t % 60 t t // 60 m t % 60 t t // 60 h treturn time h m s ms
def test_io_subclass from nipype interfaces io import IOBasefrom nipype interfaces base import DynamicTraitedSpecclass TestKV IOBase _always_run Trueoutput_spec DynamicTraitedSpecdef _list_outputs self outputs {}outputs[u'test'] 1outputs[u'foo'] u'bar'return outputswf pe Workflow u'testkv' def testx2 test return test * 2 kvnode pe Node TestKV name u'testkv' from nipype interfaces utility import Functionfunc pe Node Function input_names [u'test'] output_names [u'test2'] function testx2 name u'func' exception_not_raised Truetry wf connect kvnode u'test' func u'test' except Exception as e if u'Moduletestkvhasnooutputcalledtest' in e exception_not_raised Falseassert exception_not_raised
def test_io_subclass from nipype interfaces io import IOBasefrom nipype interfaces base import DynamicTraitedSpecclass TestKV IOBase _always_run Trueoutput_spec DynamicTraitedSpecdef _list_outputs self outputs {}outputs[u'test'] 1outputs[u'foo'] u'bar'return outputswf pe Workflow u'testkv' def testx2 test return test * 2 kvnode pe Node TestKV name u'testkv' from nipype interfaces utility import Functionfunc pe Node Function input_names [u'test'] output_names [u'test2'] function testx2 name u'func' exception_not_raised Truetry wf connect kvnode u'test' func u'test' except Exception as e if u'Moduletestkvhasnooutputcalledtest' in e exception_not_raised Falseassert exception_not_raised
def test_io_subclass from nipype interfaces io import IOBasefrom nipype interfaces base import DynamicTraitedSpecclass TestKV IOBase _always_run Trueoutput_spec DynamicTraitedSpecdef _list_outputs self outputs {}outputs[u'test'] 1outputs[u'foo'] u'bar'return outputswf pe Workflow u'testkv' def testx2 test return test * 2 kvnode pe Node TestKV name u'testkv' from nipype interfaces utility import Functionfunc pe Node Function input_names [u'test'] output_names [u'test2'] function testx2 name u'func' exception_not_raised Truetry wf connect kvnode u'test' func u'test' except Exception as e if u'Moduletestkvhasnooutputcalledtest' in e exception_not_raised Falseassert exception_not_raised
def tree_hash fo hashes []hashes extend fo while len hashes > 1 new_hashes []while True if len hashes > 1 first hashes pop 0 second hashes pop 0 new_hashes append hashlib sha256 first + second digest elif len hashes 1 only hashes pop 0 new_hashes append only else breakhashes extend new_hashes return hashes[0]
def tree_hash fo hashes []hashes extend fo while len hashes > 1 new_hashes []while True if len hashes > 1 first hashes pop 0 second hashes pop 0 new_hashes append hashlib sha256 first + second digest elif len hashes 1 only hashes pop 0 new_hashes append only else breakhashes extend new_hashes return hashes[0]
def relative_luminance color rgb mpl colors colorConverter to_rgba_array color [ 3]rgb np where rgb < 0 03928 rgb / 12 92 rgb + 0 055 / 1 055 ** 2 4 lum rgb dot [0 2126 0 7152 0 0722] try return lum item except ValueError return lum
def waitUntilAllDisconnected reactor protocols lc Nonedef _check if not True in [x transport connected for x in protocols] lc stop lc task LoopingCall _check lc clock reactorreturn lc start 0 01 now True
def _fix_multiple_roots node real_nodes [x for x in node if not isinstance x SKIPPED_ELEMENT_TYPES ]if len real_nodes > 1 data_node etree Element 'data' for child in node data_node append child node append data_node
def check_array_instances evaluator instance if not settings dynamic_array_additions return instance var_argsai _ArrayInstance evaluator instance from jedi evaluate import paramreturn param Arguments evaluator [AlreadyEvaluated [ai] ]
def fitsopen name mode 'readonly' memmap None save_backup False cache True lazy_load_hdus None **kwargs from import confif memmap is None memmap None if conf use_memmap else False else memmap bool memmap if lazy_load_hdus is None lazy_load_hdus conf lazy_load_hduselse lazy_load_hdus bool lazy_load_hdus if 'uint16' in kwargs and 'uint' not in kwargs kwargs['uint'] kwargs['uint16']del kwargs['uint16']warnings warn 'Theuint16keywordargumentisdeprecatedsincev1 1 0 Usetheuintargumentinstead ' AstropyDeprecationWarning if 'uint' not in kwargs kwargs['uint'] conf enable_uintif not name raise ValueError 'Emptyfilename {}' format repr name return HDUList fromfile name mode memmap save_backup cache lazy_load_hdus **kwargs
def fitsopen name mode 'readonly' memmap None save_backup False cache True lazy_load_hdus None **kwargs from import confif memmap is None memmap None if conf use_memmap else False else memmap bool memmap if lazy_load_hdus is None lazy_load_hdus conf lazy_load_hduselse lazy_load_hdus bool lazy_load_hdus if 'uint16' in kwargs and 'uint' not in kwargs kwargs['uint'] kwargs['uint16']del kwargs['uint16']warnings warn 'Theuint16keywordargumentisdeprecatedsincev1 1 0 Usetheuintargumentinstead ' AstropyDeprecationWarning if 'uint' not in kwargs kwargs['uint'] conf enable_uintif not name raise ValueError 'Emptyfilename {}' format repr name return HDUList fromfile name mode memmap save_backup cache lazy_load_hdus **kwargs
def attach_const_node node name value if not name in node special_attributes _attach_local_node node const_factory value name
def fontifyPython document def matcher node return node nodeName 'pre' and node hasAttribute 'class' and node getAttribute 'class' 'python' for node in domhelpers findElements document matcher fontifyPythonNode node
def _query event None method 'GET' args None header_dict None data None secret_key __salt__['config get'] 'ifttt secret_key' or __salt__['config get'] 'ifttt secret_key' path 'https //maker ifttt com/trigger/{0}/with/key/{1}' format event secret_key if header_dict is None header_dict {'Content-type' 'application/json'}if method 'POST' header_dict['Accept'] 'application/json'result salt utils http query path method params {} data data header_dict header_dict decode True decode_type 'auto' text True status True cookies True persist_session True opts __opts__ backend 'requests' return result
@depends HAS_PYVMOMI def get_vsan_enabled host username password protocol None port None host_names None service_instance salt utils vmware get_service_instance host host username username password password protocol protocol port port host_names _check_hosts service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_config host_ref config vsanHostConfigif vsan_config is None msg "VSANSystemConfigManagerisunsetforhost'{0}' " format host_name log debug msg ret update {host_name {'Error' msg}} else ret update {host_name {'VSANEnabled' vsan_config enabled}} return ret
def get_courses_accessible_to_user request if GlobalStaff has_user request user courses in_process_course_actions _accessible_courses_summary_list request else try courses in_process_course_actions _accessible_courses_list_from_groups request except AccessListFallback courses in_process_course_actions _accessible_courses_summary_list request return courses in_process_course_actions
def delete_manifestation node_state manifestation dataset_id manifestation dataset dataset_idnode_state node_state transform ['manifestations' dataset_id] discard node_state node_state transform ['paths' dataset_id] discard node_state node_state transform ['devices' UUID dataset_id ] discard return node_state
def insert_system_roles system_roles SystemRole get_valid_values for role_name in system_roles description role_namerole_db RoleDB name role_name description description system True try Role insert role_db log_not_unique_error_as_debug True except StackStormDBObjectConflictError NotUniqueError pass
@register inclusion_tag u'admin/widgets/w-actions html' takes_context True def admin_actions context request context get u'request' if u'_popup' not in request REQUEST or u'pop' not in request REQUEST request_context {u'show_sidebar' True u'count_users' User objects count u'count_review_groups' Group objects count u'count_default_reviewers' DefaultReviewer objects count u'count_repository' Repository objects accessible request user visible_only False count u'count_webhooks' WebHookTarget objects count u'count_hosting_accounts' HostingServiceAccount objects count u'has_cache_stats' get_has_cache_stats u'version' get_version_string }else request_context {u'show_sidebar' False}return RequestContext request request_context
def guess_kern_maxfiles return 65536
def _remove_identity_node graph node portinputs portoutputs _node_ports graph node for field connections in list portoutputs items if portinputs _propagate_internal_output graph node field connections portinputs else _propagate_root_output graph node field connections graph remove_nodes_from [node] logger debug u'Removedtheidentitynode%sfromthegraph ' % node
def WmiTimeToEpoch cimdatetime_str re_match TIME_WMI_RE match cimdatetime_str try t_dict re_match groupdict flt_time time strptime t_dict['date'] '%Y%m%d%H%M%S' epoch_time int calendar timegm flt_time * 1000000 epoch_time + int t_dict['subsecond'] return epoch_timeexcept KeyError AttributeError return 0
def list_public_ip_blocks module driver network_domain try blocks driver ex_list_public_ip_blocks network_domain return blocksexcept DimensionDataAPIException e get_exception module fail_json msg 'ErrorretrevingPublicIPBlocks %s' % e
def make_opt_parser command_descriptions []for name in sorted commands iterkeys command commands[name]params '' join [ '<%s>' % param for param in command required] + [ '[<%s>]' % param for param in command optional] command_descriptions append '%%prog[options]%s%s' % name params command_usage 'usage %s\n' % '\n' join command_descriptions parser optparse OptionParser usage command_usage parser add_option '-d' '--dest_dir' dest 'dest_dir' default os getcwd help 'WritegeneratedfilestoDIR' metavar 'DIR' parser add_option '-f' '--force' action 'store_true' dest 'force' default False help 'Forceoverwriteofexistingfiles' return parser
def ignore_missing key data errors context value data get key if value is missing or value is None data pop key None raise StopOnError
def getRegInfo disp host info {} sync True iq Iq 'get' NS_REGISTER to host for i in info keys iq setTagData i info[i] if sync resp disp SendAndWaitForResponse iq _ReceivedRegInfo disp Dispatcher resp host return respelse disp SendAndCallForResponse iq _ReceivedRegInfo {'agent' host}
def ThrottleLayout bandwidth_limit http_limit rps_limit bulkloader_limits dict remote_api_throttle NO_LIMITS bulkloader_limits update {remote_api_throttle BANDWIDTH_UP bandwidth_limit remote_api_throttle BANDWIDTH_DOWN bandwidth_limit remote_api_throttle REQUESTS http_limit remote_api_throttle HTTPS_BANDWIDTH_UP bandwidth_limit remote_api_throttle HTTPS_BANDWIDTH_DOWN bandwidth_limit remote_api_throttle HTTPS_REQUESTS http_limit remote_api_throttle ENTITIES_FETCHED rps_limit remote_api_throttle ENTITIES_MODIFIED rps_limit} return bulkloader_limits
def __virtual__ if 'vmadm create' in __salt__ and 'imgadm list' in __salt__ return Trueelse return False '{0}statemodulecanonlybeloadedonSmartOScomputednodes' format __virtualname__
def _exact_ratio x try if type x is float or type x is Decimal return x as_integer_ratio try return x numerator x denominator except AttributeError try return x as_integer_ratio except AttributeError passexcept OverflowError ValueError assert not _isfinite x return x None msg "can'tconverttype'{}'tonumerator/denominator"raise TypeError msg format type x __name__
def _exact_ratio x try if type x is float or type x is Decimal return x as_integer_ratio try return x numerator x denominator except AttributeError try return x as_integer_ratio except AttributeError passexcept OverflowError ValueError assert not _isfinite x return x None msg "can'tconverttype'{}'tonumerator/denominator"raise TypeError msg format type x __name__
def assert_logs log_action node_key index -1 def outer_wrapper func @functools wraps func def wrapper self *args **kwargs node getattr self node_key last_log node logs latest func self *args **kwargs node reload new_log node logs order_by '-date' [ - index - 1 ]assert_not_equal last_log _id new_log _id assert_equal new_log action log_action node save return wrapperreturn outer_wrapper
def assert_logs log_action node_key index -1 def outer_wrapper func @functools wraps func def wrapper self *args **kwargs node getattr self node_key last_log node logs latest func self *args **kwargs node reload new_log node logs order_by '-date' [ - index - 1 ]assert_not_equal last_log _id new_log _id assert_equal new_log action log_action node save return wrapperreturn outer_wrapper
def propset_dict propset if propset is None return {}return {prop name prop val for prop in propset}
def atleast_3d *arys res []for a in arys if not isinstance a cupy ndarray raise TypeError 'Onlycupyarrayscanbeatleast_3d' if a ndim 0 a a reshape 1 1 1 elif a ndim 1 a a[None None]elif a ndim 2 a a[ None]res append a if len res 1 res res[0]return res
def cyclic_pattern_search buf result []pattern cyclic_pattern p re compile '[' + re escape to_binary_string cyclic_pattern_charset + ']{4 }' found p finditer buf found list found for m in found s buf[m start m end ]i pattern find s k 0while i -1 and len s > 4 s s[1 ]k + 1i pattern find s if i -1 result + [ m start + k len s i ]return result
def cyclic_pattern_search buf result []pattern cyclic_pattern p re compile '[' + re escape to_binary_string cyclic_pattern_charset + ']{4 }' found p finditer buf found list found for m in found s buf[m start m end ]i pattern find s k 0while i -1 and len s > 4 s s[1 ]k + 1i pattern find s if i -1 result + [ m start + k len s i ]return result
def set_harddisk_sleep minutes value _validate_sleep minutes cmd 'systemsetup-setharddisksleep{0}' format value salt utils mac_utils execute_return_success cmd return salt utils mac_utils confirm_updated str value get_harddisk_sleep
def _get_proto use_ssl config get_cloud_config_value 'use_ssl' get_configured_provider __opts__ search_global False default True if use_ssl is True return 'https'return 'http'
def libvlc_vlm_set_mux p_instance psz_name psz_mux f _Cfunctions get 'libvlc_vlm_set_mux' None or _Cfunction 'libvlc_vlm_set_mux' 1 1 1 None ctypes c_int Instance ctypes c_char_p ctypes c_char_p return f p_instance psz_name psz_mux
def test_noall tmpmod with tmpmod mkdir 'xontrib' join 'spameggs py' open 'w' as x x write '\nspam 1\neggs 2\n_foobar 3\n' ctx xontrib_context 'spameggs' assert ctx {'spam' 1 'eggs' 2}
def salt_syndic import salt utils processsalt utils process notify_systemd import salt cli daemonspid os getpid try syndic salt cli daemons Syndic syndic start except KeyboardInterrupt os kill pid 15
def get_model_by_resource_ref db_api ref ref_obj ResourceReference from_string_reference ref ref result db_api query name ref_obj name pack ref_obj pack first return result
def make_subreddit_traffic_report subreddits None num None if subreddits subreddit_summary traffic PageviewsBySubreddit last_month subreddits else subreddit_summary traffic PageviewsBySubreddit top_last_month num report []for srname data in subreddit_summary if srname _DefaultSR name name _ '[frontpage]' url Noneelif srname in Subreddit _specials name '[%s]' % srname url Noneelse name '/r/%s' % srname url name + '/about/traffic' report append name url data return report
def pad_method_dict method_dict for key in AUTH_BACKEND_NAME_MAP if key not in method_dict method_dict[key] Falsereturn method_dict
def extract_auth_vars request if request META get 'HTTP_X_SENTRY_AUTH' '' startswith 'Sentry' return request META['HTTP_X_SENTRY_AUTH']elif request META get 'HTTP_AUTHORIZATION' '' startswith 'Sentry' return request META['HTTP_AUTHORIZATION']else args [ '%s %s' % i for i in request GET items if i[0] startswith 'sentry_' and i[0] 'sentry_data' ]if args return 'Sentry%s' % ' ' join args return None
def extract_auth_vars request if request META get 'HTTP_X_SENTRY_AUTH' '' startswith 'Sentry' return request META['HTTP_X_SENTRY_AUTH']elif request META get 'HTTP_AUTHORIZATION' '' startswith 'Sentry' return request META['HTTP_AUTHORIZATION']else args [ '%s %s' % i for i in request GET items if i[0] startswith 'sentry_' and i[0] 'sentry_data' ]if args return 'Sentry%s' % ' ' join args return None
def elide text length if length < 1 raise ValueError 'lengthmustbe> 1 ' if len text < length return textelse return text[ length - 1 ] + '\\u2026'
@pipeline stagedef manipulate_files session task if not task skip if task should_remove_duplicates task remove_duplicates session lib task manipulate_files move session config['move'] copy session config['copy'] write session config['write'] link session config['link'] session session task finalize session
@pipeline stagedef manipulate_files session task if not task skip if task should_remove_duplicates task remove_duplicates session lib task manipulate_files move session config['move'] copy session config['copy'] write session config['write'] link session config['link'] session session task finalize session
def parseSdr s assert isinstance s basestring sdr [int c for c in s if c in '0' '1' ]if len sdr len s raise ValueError "Theprovidedstring%sismalformed Thestringshouldhaveonly0'sand1's " return sdr
def tuplize_dict data_dict tuplized_dict {}for key value in data_dict iteritems key_list key split '__' for num key in enumerate key_list if num % 2 1 try key_list[num] int key except ValueError raise df DataError 'Badkey' tuplized_dict[tuple key_list ] valuereturn tuplized_dict
def topk k x if x ndim 1 raise ValueError 'Topkonlyworksonarraysofonedimension' token tokenize k x name 'chunk topk-' + token dsk dict name i chunk topk k key for i key in enumerate x _keys name2 'topk-' + token dsk[ name2 0 ] getitem np sort np concatenate list dsk slice -1 - k - 1 -1 chunks k return Array merge dsk x dask name2 chunks dtype x dtype
def topk k x if x ndim 1 raise ValueError 'Topkonlyworksonarraysofonedimension' token tokenize k x name 'chunk topk-' + token dsk dict name i chunk topk k key for i key in enumerate x _keys name2 'topk-' + token dsk[ name2 0 ] getitem np sort np concatenate list dsk slice -1 - k - 1 -1 chunks k return Array merge dsk x dask name2 chunks dtype x dtype
def calc_expected_status_length status short_url_length 23 status_length 0for word in re split u'\\s' status if is_url word status_length + short_url_lengthelse status_length + len word status_length + len re findall u'\\s' status return status_length
def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
def string_from_path path if not path return ''path [_path_part_escape compat to_unicode s for s in path]if not all map RE_ELEMENT match path get_logger warn "Cannotconvertpathtostring keyscontaininvalidcharacters shouldbealpha-numericorunderscore '%s'" % path string PATH_STRING_SEPARATOR_CHAR join path return string
def to_int input default 0 exception ValueError TypeError regexp None if regexp is True regexp re compile ' \\d+ ' elif isinstance regexp six string_types regexp re compile regexp elif hasattr regexp 'search' passelif regexp is not None raise TypeError 'unknownargumentforregexpparameter' try if regexp match regexp search input if match input match groups [ -1 ]return int input except exception return default
def to_int input default 0 exception ValueError TypeError regexp None if regexp is True regexp re compile ' \\d+ ' elif isinstance regexp six string_types regexp re compile regexp elif hasattr regexp 'search' passelif regexp is not None raise TypeError 'unknownargumentforregexpparameter' try if regexp match regexp search input if match input match groups [ -1 ]return int input except exception return default
def to_int input default 0 exception ValueError TypeError regexp None if regexp is True regexp re compile ' \\d+ ' elif isinstance regexp six string_types regexp re compile regexp elif hasattr regexp 'search' passelif regexp is not None raise TypeError 'unknownargumentforregexpparameter' try if regexp match regexp search input if match input match groups [ -1 ]return int input except exception return default
def to_int input default 0 exception ValueError TypeError regexp None if regexp is True regexp re compile ' \\d+ ' elif isinstance regexp six string_types regexp re compile regexp elif hasattr regexp 'search' passelif regexp is not None raise TypeError 'unknownargumentforregexpparameter' try if regexp match regexp search input if match input match groups [ -1 ]return int input except exception return default
def top_contributors_l10n start None end None locale None product None count 10 page 1 query RevisionMetricsMappingType search facet 'creator_id' filtered True size BIG_NUMBER if locale is None query query filter ~ F locale settings WIKI_DEFAULT_LANGUAGE query _apply_filters query start end locale product return _get_creator_counts query count page
def PRE k n return _XXX k n _PRE
def PRE k n return _XXX k n _PRE
def packages pkg_list update False pkg_list [pkg for pkg in pkg_list if not is_installed pkg ]if pkg_list install pkg_list update
def upgrade migrate_engine meta MetaData meta bind migrate_engineclusters Table 'clusters' meta autoload True replication_status Column 'replication_status' String length 36 default 'not-capable' active_backend_id Column 'active_backend_id' String length 255 frozen Column 'frozen' Boolean nullable False default False server_default text 'false' clusters create_column replication_status clusters create_column frozen clusters create_column active_backend_id
def cmd_action parent cmd fn *hotkeys return qtutils add_action parent cmd name lambda cmds do cmd fn *hotkeys
def cmd_action parent cmd fn *hotkeys return qtutils add_action parent cmd name lambda cmds do cmd fn *hotkeys
def cmd_action parent cmd fn *hotkeys return qtutils add_action parent cmd name lambda cmds do cmd fn *hotkeys
def get_results arg bookmarks tower get_bookmarks BOOKMARKS_FILE if arg '' results sorted bookmarks key lambda x x sort_order else titles alp fuzzy_search arg bookmarks key lambda x x title paths alp fuzzy_search arg bookmarks key lambda x x path results set titles union set paths return results
def get_latest_repository_metadata app decoded_repository_id downloadable False sa_session app model context currentrepository sa_session query app model Repository get decoded_repository_id repo hg_util get_repo_for_repository app repository repository repo_path None create False if downloadable changeset_revision get_latest_downloadable_changeset_revision app repository repo else changeset_revision get_latest_changeset_revision app repository repo return get_repository_metadata_by_changeset_revision app app security encode_id repository id changeset_revision
def remove_certificate_exception course_key student try certificate_exception CertificateWhitelist objects get user student course_id course_key except ObjectDoesNotExist raise ValueError _ 'Certificateexception user {user} doesnotexistincertificatewhitelist Pleaserefreshthepageandtryagain ' format user student username try generated_certificate GeneratedCertificate objects get user student course_id course_key generated_certificate invalidate log info u'Certificateinvalidatedfor%sincourse%swhenremovedfromcertificateexceptionlist' student username course_key except ObjectDoesNotExist passcertificate_exception delete
def remove_certificate_exception course_key student try certificate_exception CertificateWhitelist objects get user student course_id course_key except ObjectDoesNotExist raise ValueError _ 'Certificateexception user {user} doesnotexistincertificatewhitelist Pleaserefreshthepageandtryagain ' format user student username try generated_certificate GeneratedCertificate objects get user student course_id course_key generated_certificate invalidate log info u'Certificateinvalidatedfor%sincourse%swhenremovedfromcertificateexceptionlist' student username course_key except ObjectDoesNotExist passcertificate_exception delete
def make_minimal_cs_comment overrides None ret {'type' 'comment' 'id' 'dummy' 'commentable_id' 'dummy' 'thread_id' 'dummy' 'parent_id' None 'user_id' '0' 'username' 'dummy' 'anonymous' False 'anonymous_to_peers' False 'created_at' '1970-01-01T00 00 00Z' 'updated_at' '1970-01-01T00 00 00Z' 'body' 'dummy' 'abuse_flaggers' [] 'votes' {'up_count' 0} 'endorsed' False 'child_count' 0 'children' []}ret update overrides or {} return ret
def make_minimal_cs_comment overrides None ret {'type' 'comment' 'id' 'dummy' 'commentable_id' 'dummy' 'thread_id' 'dummy' 'parent_id' None 'user_id' '0' 'username' 'dummy' 'anonymous' False 'anonymous_to_peers' False 'created_at' '1970-01-01T00 00 00Z' 'updated_at' '1970-01-01T00 00 00Z' 'body' 'dummy' 'abuse_flaggers' [] 'votes' {'up_count' 0} 'endorsed' False 'child_count' 0 'children' []}ret update overrides or {} return ret
def create_palette light_color color palette QPalette palette setColor QPalette Inactive QPalette Light saturated light_color 50 palette setColor QPalette Inactive QPalette Midlight saturated light_color 90 palette setColor QPalette Inactive QPalette Button light_color palette setColor QPalette Active QPalette Light saturated color 50 palette setColor QPalette Active QPalette Midlight saturated color 90 palette setColor QPalette Active QPalette Button color palette setColor QPalette ButtonText QColor '#515151' return palette
def region_code_for_number numobj country_code numobj country_coderegions COUNTRY_CODE_TO_REGION_CODE get country_code None if regions is None return Noneif len regions 1 return regions[0]else return _region_code_for_number_from_list numobj regions
def _get_node_creation_time node date_string node extra get 'created' node extra get 'launch_time' if date_string is None return Noneelse return parse_date date_string
def get_correct_indentation_diff code filename code_buffer StringIO code output_buffer StringIO reindenter reindent Reindenter code_buffer reindenter run reindenter write output_buffer reindent_output output_buffer getvalue output_buffer close if code reindent_output diff_generator difflib unified_diff code splitlines True reindent_output splitlines True fromfile filename tofile filename + ' reindented ' diff_tuple map clean_diff_line_for_python_bug_2142 diff_generator diff '' join diff_tuple return diffelse return None
def get_correct_indentation_diff code filename code_buffer StringIO code output_buffer StringIO reindenter reindent Reindenter code_buffer reindenter run reindenter write output_buffer reindent_output output_buffer getvalue output_buffer close if code reindent_output diff_generator difflib unified_diff code splitlines True reindent_output splitlines True fromfile filename tofile filename + ' reindented ' diff_tuple map clean_diff_line_for_python_bug_2142 diff_generator diff '' join diff_tuple return diffelse return None
@get '/scan/<taskid>/log/<start>/<end>' def scan_log_limited taskid start end json_log_messages list if taskid not in DataStore tasks logger warning '[%s]InvalidtaskIDprovidedtoscan_log_limited ' % taskid return jsonize {'success' False 'message' 'InvalidtaskID'} if not start isdigit or not end isdigit or end < start logger warning '[%s]Invalidstartorendvalueprovidedtoscan_log_limited ' % taskid return jsonize {'success' False 'message' 'Invalidstartorendvalue mustbedigits'} start max 1 int start end max 1 int end for time_ level message in DataStore current_db execute 'SELECTtime level messageFROMlogsWHEREtaskid ?ANDid> ?ANDid< ?ORDERBYidASC' taskid start end json_log_messages append {'time' time_ 'level' level 'message' message} logger debug '[%s]Retrievedscanlogmessagessubset' % taskid return jsonize {'success' True 'log' json_log_messages}
def get_first_day dt d_years 0 d_months 0 dt getdate dt overflow_years month divmod dt month + d_months - 1 12 year dt year + d_years + overflow_years return datetime date year month + 1 1
def get_first_day dt d_years 0 d_months 0 dt getdate dt overflow_years month divmod dt month + d_months - 1 12 year dt year + d_years + overflow_years return datetime date year month + 1 1
def _probvec r out n r shape[0]r sort out[0] r[0]for i in range 1 n out[i] r[i] - r[ i - 1 ] out[n] 1 - r[ n - 1 ]
def create_transactions_table session create_table '\nCREATETABLEIFNOTEXISTStransactions \ntxid_hashblob \noperationtinyint \nnamespacetext \npathblob \nstart_timetimestamp \nis_xgboolean \nin_progressblob \nentityblob \ntaskblob \nPRIMARYKEY txid_hash operation namespace path \n \n'statement SimpleStatement create_table retry_policy NO_RETRIES try session execute statement except cassandra OperationTimedOut logging warning 'Encounteredanoperationtimeoutwhilecreatingtransactionstable Waiting1minuteforschematosettle ' time sleep 60 raise
def TopologicallySorted graph get_edges get_edges memoize get_edges visited set visiting set ordered_nodes []def Visit node if node in visiting raise CycleError visiting if node in visited returnvisited add node visiting add node for neighbor in get_edges node Visit neighbor visiting remove node ordered_nodes insert 0 node for node in sorted graph Visit node return ordered_nodes
def expand_action data if isinstance data string_types return u'{"index" {}}' data data data copy op_type data pop u'_op_type' u'index' action {op_type {}}for key in u'_index' u'_parent' u'_percolate' u'_routing' u'_timestamp' u'_ttl' u'_type' u'_version' u'_version_type' u'_id' u'_retry_on_conflict' if key in data action[op_type][key] data pop key if op_type u'delete' return action None return action data get u'_source' data
def is_visible_to_specific_content_groups xblock if not xblock group_access return Falsefor partition in get_user_partition_info xblock if any g['selected'] for g in partition['groups'] return Truereturn False
def system name ret {'name' name 'changes' {} 'result' None 'comment' ''}try if __salt__['locale get_locale'] name ret['result'] Trueret['comment'] 'Systemlocale{0}alreadyset' format name return retif __opts__['test'] ret['comment'] 'Systemlocale{0}needstobeset' format name return retif __salt__['locale set_locale'] name ret['changes'] {'locale' name}ret['result'] Trueret['comment'] 'Setsystemlocale{0}' format name return retelse ret['result'] Falseret['comment'] 'Failedtosetsystemlocaleto{0}' format name return retexcept CommandExecutionError as err ret['result'] Falseret['comment'] 'Failedtosetsystemlocale {0}' format err return ret
def get_num_host_queue_entries **filter_data return models HostQueueEntry query_count filter_data
@frappe whitelist def set_value doctype name fieldname value None if fieldname u'idx' and fieldname in frappe model default_fields frappe throw _ u'Cannoteditstandardfields' if not value values fieldnameif isinstance fieldname basestring try values json loads fieldname except ValueError values {fieldname u''}else values {fieldname value}doc frappe db get_value doctype name [u'parenttype' u'parent'] as_dict True if doc and doc parent and doc parenttype doc frappe get_doc doc parenttype doc parent child doc getone {u'doctype' doctype u'name' name} child update values else doc frappe get_doc doctype name doc update values doc save return doc as_dict
def set_log_file fname None output_format '% message s' overwrite None logger logging getLogger 'mne' handlers logger handlersfor h in handlers if isinstance h logging FileHandler logging StreamHandler if isinstance h logging FileHandler h close logger removeHandler h if fname is not None if op isfile fname and overwrite is None warnings warn 'Logentrieswillbeappendedtothefile Useoverwrite Falsetoavoidthismessageinthefuture ' RuntimeWarning stacklevel 2 overwrite Falsemode 'w' if overwrite else 'a' lh logging FileHandler fname mode mode else 'weshouldjustbeabletodo \nlh logging StreamHandler sys stdout \nbutbecausedoctestsusessomemagiconstdout wehavetodothis \n'lh logging StreamHandler WrapStdOut lh setFormatter logging Formatter output_format logger addHandler lh
def set_log_file fname None output_format '% message s' overwrite None logger logging getLogger 'mne' handlers logger handlersfor h in handlers if isinstance h logging FileHandler logging StreamHandler if isinstance h logging FileHandler h close logger removeHandler h if fname is not None if op isfile fname and overwrite is None warnings warn 'Logentrieswillbeappendedtothefile Useoverwrite Falsetoavoidthismessageinthefuture ' RuntimeWarning stacklevel 2 overwrite Falsemode 'w' if overwrite else 'a' lh logging FileHandler fname mode mode else 'weshouldjustbeabletodo \nlh logging StreamHandler sys stdout \nbutbecausedoctestsusessomemagiconstdout wehavetodothis \n'lh logging StreamHandler WrapStdOut lh setFormatter logging Formatter output_format logger addHandler lh
def resolve path urlconf None prefixer get_url_prefix if prefixer _lang _platform path_fragment prefixer split_path path path '/%s' % path_fragment return django_resolve path urlconf
def resolve path urlconf None prefixer get_url_prefix if prefixer _lang _platform path_fragment prefixer split_path path path '/%s' % path_fragment return django_resolve path urlconf
@app route '/' methods ['GET' 'POST'] def receive_message labels []face_annotations []attachments int request values get 'NumMedia' 0 if not attachments return 'Nomediaattachmentsfound 'for i in range attachments media_content_type request values get 'MediaContentType%i' % i None if media_content_type in ACCEPTABLE_FILE_TYPES media_url request values get 'MediaUrl%i' % i None image requests get media_url content labels face_annotations get_labels image breakresp construct_message labels face_annotations return str resp
def dump_privatekey type pkey cipher None passphrase None bio _new_mem_buf if cipher is not None if passphrase is None raise TypeError 'ifavalueisgivenforcipheronemustalsobegivenforpassphrase' cipher_obj _lib EVP_get_cipherbyname _byte_string cipher if cipher_obj _ffi NULL raise ValueError 'Invalidciphername' else cipher_obj _ffi NULLhelper _PassphraseHelper type passphrase if type FILETYPE_PEM result_code _lib PEM_write_bio_PrivateKey bio pkey _pkey cipher_obj _ffi NULL 0 helper callback helper callback_args helper raise_if_problem elif type FILETYPE_ASN1 result_code _lib i2d_PrivateKey_bio bio pkey _pkey elif type FILETYPE_TEXT rsa _ffi gc _lib EVP_PKEY_get1_RSA pkey _pkey _lib RSA_free result_code _lib RSA_print bio rsa 0 else raise ValueError 'typeargumentmustbeFILETYPE_PEM FILETYPE_ASN1 orFILETYPE_TEXT' _openssl_assert result_code 0 return _bio_to_string bio
def dump_privatekey type pkey cipher None passphrase None bio _new_mem_buf if cipher is not None if passphrase is None raise TypeError 'ifavalueisgivenforcipheronemustalsobegivenforpassphrase' cipher_obj _lib EVP_get_cipherbyname _byte_string cipher if cipher_obj _ffi NULL raise ValueError 'Invalidciphername' else cipher_obj _ffi NULLhelper _PassphraseHelper type passphrase if type FILETYPE_PEM result_code _lib PEM_write_bio_PrivateKey bio pkey _pkey cipher_obj _ffi NULL 0 helper callback helper callback_args helper raise_if_problem elif type FILETYPE_ASN1 result_code _lib i2d_PrivateKey_bio bio pkey _pkey elif type FILETYPE_TEXT rsa _ffi gc _lib EVP_PKEY_get1_RSA pkey _pkey _lib RSA_free result_code _lib RSA_print bio rsa 0 else raise ValueError 'typeargumentmustbeFILETYPE_PEM FILETYPE_ASN1 orFILETYPE_TEXT' _openssl_assert result_code 0 return _bio_to_string bio
@pytest mark skipif 'notHAS_BEAUTIFUL_SOUP' def test_no_names table_in ['<table>' '<tr><td>1</td></tr>' '<tr><td>2</td></tr>' '</table>']dat Table read table_in format 'ascii html' assert dat colnames ['col1'] assert len dat 2 dat Table read table_in format 'ascii html' names ['a'] assert dat colnames ['a'] assert len dat 2
def get_path_style path fill True style {}style['alpha'] path get_alpha if style['alpha'] is None style['alpha'] 1style['edgecolor'] color_to_hex path get_edgecolor if fill style['facecolor'] color_to_hex path get_facecolor else style['facecolor'] 'none'style['edgewidth'] path get_linewidth style['dasharray'] get_dasharray path style['zorder'] path get_zorder return style
def copy_volume src dest size_in_m blocksize sync False execute utils execute ionice None throttle None sparse False if isinstance src six string_types and isinstance dest six string_types if not throttle throttle throttling Throttle get_default with throttle subcommand src dest as throttle_cmd _copy_volume_with_path throttle_cmd['prefix'] src dest size_in_m blocksize sync sync execute execute ionice ionice sparse sparse else _copy_volume_with_file src dest size_in_m
def extract_question_values question required_fields is_reviewer response {'value' {'type' 'string'} 'comments' COMMENTS_SCHEMA 'extra' {'type' 'array'}}if question get 'type' 'object' response['value'] get_object_jsonschema question required_fields is_reviewer elif question get 'type' 'choose' options question get 'options' if options response['value'] get_options_jsonschema options elif question get 'type' 'osf-upload' response['extra'] OSF_UPLOAD_EXTRA_SCHEMAif is_reviewer del response['extra']if not question get 'type' 'object' del response['value']return response
def get_object_range page page_size max_id 5start min page - 1 * page_size max_id end min start + page_size max_id + 1 return range start end
def create_gzip_cache pelican for dirpath _ filenames in os walk pelican settings['OUTPUT_PATH'] for name in filenames if should_compress name filepath os path join dirpath name create_gzip_file filepath should_overwrite pelican settings
def create_gzip_cache pelican for dirpath _ filenames in os walk pelican settings['OUTPUT_PATH'] for name in filenames if should_compress name filepath os path join dirpath name create_gzip_file filepath should_overwrite pelican settings
def dllFromDll dllid if dllid None return Noneelif type '' type dllid return win32ui LoadLibrary dllid else try dllid GetFileName except AttributeError raise TypeError 'DLLparametermustbeNone afilenameoradllobject' return dllid
def new_scratch_view window text new_view window new_file new_view set_scratch True if is_ST3 new_view run_command 'append' {'characters' text} else new_edit new_view begin_edit new_view insert new_edit 0 text new_view end_edit new_edit return new_view
def submittable_timestamp timestamp return str timezone localtime timestamp split u' ' [0]
def submittable_timestamp timestamp return str timezone localtime timestamp split u' ' [0]
@doctest_decodef full_path startPath files files list_strings files base os path split startPath [0]return [os path join base f for f in files]
def mutate_image_dict_to_v1 image visibility image pop 'visibility' is_image_public 'public' visibility image['is_public'] is_image_publicreturn image
def mutate_image_dict_to_v1 image visibility image pop 'visibility' is_image_public 'public' visibility image['is_public'] is_image_publicreturn image
def sign_int message dkey n return decrypt_int message dkey n
def collapse_braces src_text nesting 0start_index 0collapsed_src_text u''for index char in enumerate src_text if nesting 0 collapsed_src_text + charif char u'{' if nesting 0 start_index index + 1 nesting + 1if char u'}' if nesting > 0 nesting - 1if nesting 0 collapsed_src_text + charif nesting 0 collapsed_src_text + src_text[start_index ]return collapsed_src_text
def make_paginated_api_response results None count 0 num_pages 0 next_link None previous_link None return {'pagination' {'next' next_link 'previous' previous_link 'count' count 'num_pages' num_pages} 'results' results or [] }
def _tgrep_macro_use_action _s _l tokens assert len tokens 1 assert tokens[0][0] u'@' macro_name tokens[0][1 ]def macro_use n m None l None if m is None or macro_name not in m raise TgrepException u'macro{0}notdefined' format macro_name return m[macro_name] n m l return macro_use
def cms_settings request from menus menu_pool import MenuRenderer@lru_cache lru_cache maxsize None def _get_menu_renderer from menus menu_pool import menu_poolreturn menu_pool get_renderer request toolbar get_toolbar_from_request request _get_menu_renderer lazy _get_menu_renderer MenuRenderer return {'cms_menu_renderer' _get_menu_renderer 'cms_content_renderer' toolbar content_renderer 'CMS_MEDIA_URL' get_cms_setting 'MEDIA_URL' 'CMS_TEMPLATE' lambda get_template_from_request request }
def rmse actual predicted return np sqrt mse actual predicted
def do_collectstatic try build make_collectstatic return Trueexcept OSError SystemError as ex LOG error "Failedtocollectthestaticfiles Pleasefixanyproblemandrun`%s--collectstatic'\n%s" % PROG_NAME ex return False
def _handle_blacklist blacklist dirnames filenames for norecurs in blacklist if norecurs in dirnames dirnames remove norecurs elif norecurs in filenames filenames remove norecurs
def connected_server_and_client case server_factory client_factory def connect_client listening_port return TCP4ClientEndpoint reactor '127 0 0 1' listening_port getHost port connect client_factory return listen case TCP4ServerEndpoint reactor 0 server_factory addCallback connect_client
def shanks A k n m 1 table [A subs k Integer j doit for j in range n + m + 2 ]table2 table[ ]for i in range 1 m + 1 for j in range i n + m + 1 x y z table[ j - 1 ] table[j] table[ j + 1 ] table2[j] z * x - y ** 2 / z + x - 2 * y table table2[ ]return table[n]
def _GetUnifiedDiff before after filename 'code' before before splitlines after after splitlines return '\n' join difflib unified_diff before after filename filename ' original ' ' reformatted ' lineterm '' + '\n'
def set_color_formatter logger None **kw if logger is None logger logging getLogger if not logger handlers logging basicConfig format_msg logger handlers[0] formatter _fmtfmt ColorFormatter format_msg **kw fmt colorfilters append xxx_cyan logger handlers[0] setFormatter fmt
def update_local_plugin_descriptor plugins structure []if os path isfile resources PLUGINS_DESCRIPTOR structure json_manager read_json resources PLUGINS_DESCRIPTOR for plug_list in plugins plug {}plug[u'name'] plug_list[0]plug[u'version'] plug_list[1]plug[u'description'] plug_list[2]plug[u'authors'] plug_list[3]plug[u'home'] plug_list[4]plug[u'download'] plug_list[5]plug[u'plugin-descriptor'] plug_list[6]structure append plug json_manager write_json structure resources PLUGINS_DESCRIPTOR
def get_queue name DEFAULT_QUEUE_NAME global _queuesfullname add_queue_name_prefix name try return _queues[fullname]except KeyError log debug u'Initializingbackgroundjobqueue"{}"' format name redis_conn _connect queue _queues[fullname] rq Queue fullname connection redis_conn return queue
def fn outs mode None model None *args **kwargs model modelcontext model return model fn outs mode *args **kwargs
def test_nospace entry tokenize ' foo onetwo ' [0]assert entry start_line 1 assert entry start_column 1 assert entry end_line 1 assert entry end_column 14 entry entry[1]assert entry start_line 1 assert entry start_column 5 assert entry end_line 1 assert entry end_column 13
def test_nospace entry tokenize ' foo onetwo ' [0]assert entry start_line 1 assert entry start_column 1 assert entry end_line 1 assert entry end_column 14 entry entry[1]assert entry start_line 1 assert entry start_column 5 assert entry end_line 1 assert entry end_column 13
def autoTrack clip pattern tt None fps None radius 20 xy0 None if not autotracking_possible raise IOError 'Sorry autotrackrequiresOpenCVforthemoment InstallOpenCV akacv2 touseit ' if not xy0 xy0 findAround clip get_frame tt[0] pattern if tt is None tt np arange 0 clip duration 1 0 / fps xys [xy0]for t in tt[1 ] xys append findAround clip get_frame t pattern xy xys[ -1 ] r radius xx yy zip *xys return Trajectory tt xx yy
def _get_info_from_caches app env account container None info _get_info_from_infocache env account container if info is None info _get_info_from_memcache app env account container return info
def _encode_bool name value dummy0 dummy1 return '\x08' + name + value and '\x01' or '\x00'
def add_to_path path if not os path isdir path raise RuntimeError 'Triedtoaddnonexistingpath' def _samefile x y if x y return Truetry return os path samefile x y except IOError OSError AttributeError return Falsesys path[ ] [x for x in sys path if not _samefile path x ]sys path insert 0 path
@hook command @hook command 'tv_prev' def tv_last text bot None api_key bot config get 'api_keys' {} get 'tvdb' None if api_key is None return 'error noapikeyset'episodes get_episodes_for_series text api_key if episodes['error'] return episodes['error']series_name episodes['name']ended episodes['ended']episodes episodes['episodes']prev_ep Nonetoday datetime date today for episode in reversed episodes ep_info get_episode_info episode if ep_info is None continue first_aired air_date episode_desc ep_infoif air_date < today prev_ep '{} {} ' format first_aired episode_desc breakif not prev_ep return 'Therearenopreviouslyairedepisodesfor{} ' format series_name if ended return '{}ended Thelastepisodeaired{} ' format series_name prev_ep return 'Thelastepisodeof{}aired{} ' format series_name prev_ep
@hook command @hook command 'tv_prev' def tv_last text bot None api_key bot config get 'api_keys' {} get 'tvdb' None if api_key is None return 'error noapikeyset'episodes get_episodes_for_series text api_key if episodes['error'] return episodes['error']series_name episodes['name']ended episodes['ended']episodes episodes['episodes']prev_ep Nonetoday datetime date today for episode in reversed episodes ep_info get_episode_info episode if ep_info is None continue first_aired air_date episode_desc ep_infoif air_date < today prev_ep '{} {} ' format first_aired episode_desc breakif not prev_ep return 'Therearenopreviouslyairedepisodesfor{} ' format series_name if ended return '{}ended Thelastepisodeaired{} ' format series_name prev_ep return 'Thelastepisodeof{}aired{} ' format series_name prev_ep
def test_world_should_be_able_to_absorb_lambdas assert not hasattr world 'named_func' world absorb lambda 'absorbed' 'named_func' assert hasattr world 'named_func' assert callable world named_func assert_equals world named_func 'absorbed' world spew 'named_func' assert not hasattr world 'named_func'
def _snapper_pre opts jid snapper_pre Nonetry if not opts['test'] and __opts__ get 'snapper_states' snapper_pre __salt__['snapper create_snapshot'] config __opts__ get 'snapper_states_config' 'root' snapshot_type 'pre' description 'SaltStaterunforjid{0}' format jid __pub_jid jid except Exception log error 'Failedtocreatesnapperpresnapshotforjid {0}' format jid return snapper_pre
def get_tox_env_from_version version_info sys version_info[ 2]try return ACCEPTED_VERSIONS[version_info]except KeyError raise EnvironmentError 'InvalidPythonversion' version_info 'Acceptedversionsare' sorted ACCEPTED_VERSIONS keys
def coherence x y fs 1 0 window 'hann' nperseg None noverlap None nfft None detrend 'constant' axis -1 freqs Pxx welch x fs window nperseg noverlap nfft detrend axis axis _ Pyy welch y fs window nperseg noverlap nfft detrend axis axis _ Pxy csd x y fs window nperseg noverlap nfft detrend axis axis Cxy np abs Pxy ** 2 / Pxx / Pyy return freqs Cxy
def _TR56 rv f g h max pow def _f rv if not rv is_Pow and rv base func f return rvif rv exp < 0 True return rvif rv exp > max True return rvif rv exp 2 return h g rv base args[0] ** 2 else if rv exp 4 e 2elif not pow if rv exp % 2 return rve rv exp // 2 else p perfect_power rv exp if not p return rve rv exp // 2 return h g rv base args[0] ** 2 ** e return bottom_up rv _f
def _TR56 rv f g h max pow def _f rv if not rv is_Pow and rv base func f return rvif rv exp < 0 True return rvif rv exp > max True return rvif rv exp 2 return h g rv base args[0] ** 2 else if rv exp 4 e 2elif not pow if rv exp % 2 return rve rv exp // 2 else p perfect_power rv exp if not p return rve rv exp // 2 return h g rv base args[0] ** 2 ** e return bottom_up rv _f
def cms_documentation r default_page default_url row r recordif not row name r get_vars get 'name' default_page table r resource tablequery table name name & table deleted True row current db query select table id table title table body limitby 0 1 first if not row if name default_page r error 404 current T 'Pagenotfound' next URL args current request args vars {} else from s3 import s3_redirect_defaults3_redirect_default default_url from s3 import S3XMLContentsreturn {'bypass' True 'output' {'title' row title 'contents' S3XMLContents row body }}
def _prompt_choice var_name options choice_map OrderedDict u'{0}' format i value for i value in enumerate options 1 if value[0] 'test' choices choice_map keys default u'1'choice_lines [u'{0}-{1}-{2}' format c[0] c[1][0] c[1][1] for c in choice_map items ]prompt u'\n' join u'Select{0} ' format var_name u'\n' join choice_lines u'Choosefrom{0}' format u' ' join choices user_choice click prompt prompt type click Choice choices default default return choice_map[user_choice]
@contextmanagerdef inside_transaction savepoint transaction savepoint try yield except Exception transaction savepoint_rollback savepoint raiseelse transaction savepoint_commit savepoint
@contextmanagerdef inside_transaction savepoint transaction savepoint try yield except Exception transaction savepoint_rollback savepoint raiseelse transaction savepoint_commit savepoint
@task task ignore_result True def retry_open_graph_shares_for_user user from django_facebook models import OpenGraphShareshares OpenGraphShare objects recently_failed filter user user [ 1000]shares list shares logger info 'retrying%ssharesforuser%s' len shares user for share in shares retry_open_graph_share share reset_retries True
@task task ignore_result True def retry_open_graph_shares_for_user user from django_facebook models import OpenGraphShareshares OpenGraphShare objects recently_failed filter user user [ 1000]shares list shares logger info 'retrying%ssharesforuser%s' len shares user for share in shares retry_open_graph_share share reset_retries True
@task task ignore_result True def retry_open_graph_shares_for_user user from django_facebook models import OpenGraphShareshares OpenGraphShare objects recently_failed filter user user [ 1000]shares list shares logger info 'retrying%ssharesforuser%s' len shares user for share in shares retry_open_graph_share share reset_retries True
def read_file name with _open name 'r' encoding 'utf-8' as f return f read
def event timing True evt current_context create_event timing timing return evt
def sanitizeStr value return getUnicode value replace '\n' '' replace '\r' ''
def pipeline_property name **kwargs cache_attr_name '_%s' % name def getter self cached_value getattr self cache_attr_name None if cached_value return cached_valueapp selfwhile True app getattr app 'app' None if not app breaktry value getattr app name except AttributeError continuesetattr self cache_attr_name value return valueif 'default' in kwargs return kwargs['default']raise AttributeError 'Noappsinpipelinehavea%sattribute' % name return property getter
def ball radius dtype np uint8 n 2 * radius + 1 Z Y X np mgrid[ - radius radius n * 1j - radius radius n * 1j - radius radius n * 1j ]s X ** 2 + Y ** 2 + Z ** 2 return np array s < radius * radius dtype dtype
@taskdef sharejs ctx host None port None db_url None cors_allow_origin None if host os environ['SHAREJS_SERVER_HOST'] hostif port os environ['SHAREJS_SERVER_PORT'] portif db_url os environ['SHAREJS_DB_URL'] db_urlif cors_allow_origin os environ['SHAREJS_CORS_ALLOW_ORIGIN'] cors_allow_originif settings SENTRY_DSN os environ['SHAREJS_SENTRY_DSN'] settings SENTRY_DSNshare_server os path join settings ADDON_PATH 'wiki' 'shareServer js' ctx run 'node{0}' format share_server
@register inclusion_tag 'bootstrap/breadcrumb html' takes_context True def breadcrumb_nav context breadcrumb []dashboard context request horizon['dashboard']try panel_groups dashboard get_panel_groups except KeyError panel_groups Nonepanel_group Nonepanel context request horizon['panel']if panel_groups for group in panel_groups values if panel slug in group panels and group slug 'default' panel_group groupbreakif panel get_absolute_url context request path panel Nonecustom_breadcrumb context get 'custom_breadcrumb' breadcrumb append dashboard name None if panel_group breadcrumb append panel_group name None if panel breadcrumb append panel name panel get_absolute_url if custom_breadcrumb breadcrumb extend custom_breadcrumb breadcrumb append context get 'page_title' None return {'breadcrumb' breadcrumb}
def is_builtin_class_method obj attr_name classes [c for c in inspect getmro obj if attr_name in c __dict__ ]cls classes[0] if classes else object if not hasattr builtins safe_getattr cls '__name__' '' return Falsereturn getattr builtins safe_getattr cls '__name__' '' is cls
def is_builtin_class_method obj attr_name classes [c for c in inspect getmro obj if attr_name in c __dict__ ]cls classes[0] if classes else object if not hasattr builtins safe_getattr cls '__name__' '' return Falsereturn getattr builtins safe_getattr cls '__name__' '' is cls
def get key service None profile None if not profile get 'url' or not profile get 'token' raise SaltConfigurationError 'urland/ortokenmissingfromthetismsdbprofile' request {'token' profile['token'] 'encsecret' key}result http query profile['url'] method 'POST' data json dumps request decrypted result get 'body' if not decrypted log warning 'tism getsdbdecryptionrequestfailedwitherror{0}' format result get 'error' 'unknown' return 'ERROR' + str result get 'status' 'unknown' return decrypted
def rackspace_provisioner username key region keyname from libcloud compute providers import get_driver Providerdriver get_driver Provider RACKSPACE key username secret key region region provisioner LibcloudProvisioner driver driver keyname keyname image_names IMAGE_NAMES create_node_arguments lambda **kwargs {'ex_config_drive' 'true'} provision provision_rackspace default_size 'performance1-8' get_default_user get_default_username return provisioner
def path_wrapper func def wrapped node context None _func func **kwargs 'wrapperfunctionhandlingcontext'if context is None context InferenceContext context push node yielded set for res in _func node context **kwargs if res __class__ is Instance ares res _proxiedelse ares resif not ares in yielded yield res yielded add ares return wrapped
def expand_trig expr deep True return sympify expr expand deep deep trig True basic False log False mul False power_exp False power_base False multinomial False
def lookupPointer name timeout None return getResolver lookupPointer name timeout
def split_python_version version None major version >> 24 & 255 minor version >> 16 & 255 micro version >> 8 & 255 release_level version >> 4 & 15 serial version & 15 release_level_string RELEASE_LEVEL_NAMES get release_level None if not release_level_string raise ValueError 'Badreleaselevel0x%xinversion0x%08x' % release_level version return major minor micro release_level_string serial
def split_python_version version None major version >> 24 & 255 minor version >> 16 & 255 micro version >> 8 & 255 release_level version >> 4 & 15 serial version & 15 release_level_string RELEASE_LEVEL_NAMES get release_level None if not release_level_string raise ValueError 'Badreleaselevel0x%xinversion0x%08x' % release_level version return major minor micro release_level_string serial
def set_kernel_var Popen ['sysctl' '-w' 'net ipv4 conf all route_localnet 1'] stdout DN stderr PIPE
def runner name **kwargs try jid __orchestration_jid__except NameError log debug 'Unabletofireargseventduetomissing__orchestration_jid__' jid Noneout __salt__['saltutil runner'] name __orchestration_jid__ jid __env__ __env__ full_return True **kwargs runner_return out get 'return' if 'success' in out and not out['success'] ret {'name' name 'result' False 'changes' {} 'comment' runner_return if runner_return else "Runnerfunction'{0}'failedwithoutcomment " format name }else ret {'name' name 'result' True 'changes' runner_return if runner_return else {} 'comment' "Runnerfunction'{0}'executed " format name }ret['__orchestration__'] Trueif 'jid' in out ret['__jid__'] out['jid']return ret
def revoke config unused_plugins config namespace installer config namespace authenticator 'None'if config key_path is not None logger debug 'Revoking%susingcertkey%s' config cert_path[0] config key_path[0] key jose JWK load config key_path[1] else logger debug 'Revoking%susingAccountKey' config cert_path[0] acc _ _determine_account config key acc keyacme client acme_from_config_key config key cert crypto_util pyopenssl_load_certificate config cert_path[1] [0]logger debug 'Reasoncodeforrevocation %s' config reason try acme revoke jose ComparableX509 cert config reason except acme_errors ClientError as e return e messagedisplay_ops success_revocation config cert_path[0]
def refresh app_version _ _ _inspect_environment global _cached_confignew_config _fetch_latest_from_memcache app_version if not new_config new_config _fetch_latest_from_datastore app_version if new_config _cached_config new_config
def where cond a b raise_on_error False use_numexpr True if use_numexpr return _where cond a b raise_on_error raise_on_error return _where_standard cond a b raise_on_error raise_on_error
def get_ip_nonlocal_bind namespace None cmd ['sysctl' '-bn' IP_NONLOCAL_BIND]ip_wrapper IPWrapper namespace return int ip_wrapper netns execute cmd run_as_root True
def decode_deflate content try try return zlib decompress content except zlib error return zlib decompress content -15 except zlib error return None
@register function@jinja2 contextfunctiondef favorites_widget context addon condensed False c dict context items request c['request']if request user is_authenticated is_favorite addon id in request user favorite_addons faved_class 'faved' if is_favorite else '' unfaved_text '' if condensed else _ 'Addtofavorites' faved_text _ 'Favorite' if condensed else _ 'Removefromfavorites' add_url reverse 'collections alter' args [request user username 'favorites' 'add'] remove_url reverse 'collections alter' args [request user username 'favorites' 'remove'] c update locals t get_env get_template 'bandwagon/favorites_widget html' render c return jinja2 Markup t
@register function@jinja2 contextfunctiondef favorites_widget context addon condensed False c dict context items request c['request']if request user is_authenticated is_favorite addon id in request user favorite_addons faved_class 'faved' if is_favorite else '' unfaved_text '' if condensed else _ 'Addtofavorites' faved_text _ 'Favorite' if condensed else _ 'Removefromfavorites' add_url reverse 'collections alter' args [request user username 'favorites' 'add'] remove_url reverse 'collections alter' args [request user username 'favorites' 'remove'] c update locals t get_env get_template 'bandwagon/favorites_widget html' render c return jinja2 Markup t
def _get_service_exec executable 'update-rc d'salt utils check_or_die executable return executable
def _get_service_exec executable 'update-rc d'salt utils check_or_die executable return executable
@step 'Icreatealogrecordwith' def step_I_create_logrecord_with_table context assert context table 'REQUIRE context table'assert len context table rows 1 'REQUIRE table row size 1'step_I_create_logrecords_with_table context
@step 'Icreatealogrecordwith' def step_I_create_logrecord_with_table context assert context table 'REQUIRE context table'assert len context table rows 1 'REQUIRE table row size 1'step_I_create_logrecords_with_table context
@step 'Icreatealogrecordwith' def step_I_create_logrecord_with_table context assert context table 'REQUIRE context table'assert len context table rows 1 'REQUIRE table row size 1'step_I_create_logrecords_with_table context
def types_of_fields fields expr if isinstance expr dshape measure Record return get fields expr dshape measure else if isinstance fields tuple list set assert len fields 1 fields fieldsassert fields expr _name return expr dshape measure
def signWrangler poi for field in ['Text1' 'Text2' 'Text3' 'Text4'] poi[field] jsonText poi[field] return poi
def _import_pydot import pydotif parse_version pydot __version__ < parse_version PYDOT_VERSION_MIN raise ImportError 'pydot%s<%s' % pydot __version__ PYDOT_VERSION_MIN return pydot
def build_dependency_list deps version_prefix u'' return sorted [ u'%s%s%s' % dep_name version_prefix dep_version for dep_name dep_version in deps items ] key lambda s s lower
def _ancillaryDescriptor fd packed struct pack 'i' fd return [ socket SOL_SOCKET sendmsg SCM_RIGHTS packed ]
@commands u'setchanneltz' u'setctz' @example u' setctzAmerica/New_York' def update_channel bot trigger if bot privileges[trigger sender][trigger nick] < OP returnelif not pytz bot reply u"Sorry Idon'thavetimezonesupportinstalled " else tz trigger group 2 if not tz bot reply u'Whattimezonedoyouwanttoset?Tryonefromhttp //sopel chat/tz' returnif tz not in pytz all_timezones bot reply u"Idon'tknowthattimezone Tryonefromhttp //sopel chat/tz" returnbot db set_channel_value trigger sender u'timezone' tz if len tz < 7 bot say u'Okay {} butyoushoulduseonefromhttp //sopel chat/tzifyouuseDST ' format trigger nick else bot reply u'Inowhave{}inthe{}timezone ' format trigger sender tz
def from_record_like rec stream 0 gpu_data None return DeviceRecord rec dtype stream stream gpu_data gpu_data
def _ensure_pynumpy import warningsfrom import numpy_supportpyver sys version_info[ 2]if pyver < 2 7 or 3 < pyver < 3 4 raise ImportError 'NumbaneedsPython2 7orgreater or3 4orgreater' np_version numpy_support version[ 2]if np_version < 1 7 raise ImportError 'NumbaneedsNumpy1 7orgreater'
def _ensure_pynumpy import warningsfrom import numpy_supportpyver sys version_info[ 2]if pyver < 2 7 or 3 < pyver < 3 4 raise ImportError 'NumbaneedsPython2 7orgreater or3 4orgreater' np_version numpy_support version[ 2]if np_version < 1 7 raise ImportError 'NumbaneedsNumpy1 7orgreater'
def create_continuous_query database name query **client_args client _client **client_args full_query 'CREATECONTINUOUSQUERY{0}ON{1}BEGIN{2}END'query full_query format name database query client query query return True
def _apply_assertion expected result log debug 'Expectedresult %s Actualresult %s' expected result if isinstance expected bool return result is expected elif isinstance expected dict try comparison getattr operator expected['comparison'] except AttributeError if expected get 'comparison' 'search' comparison re searchelse raise InvalidArgumentError 'Comparison{0}isnotavalidselection ' format expected get 'comparison' except KeyError log exception 'Thecomparisondictionaryprovidedismissingexpectedkeys Either"expected"or"comparison"arenotpresent ' raisereturn comparison expected['expected'] result else raise TypeError 'Expectedboolordictbutreceived{0}' format type expected
def assertVolumesEqual test first second first first get_filesystem get_path second second get_filesystem get_path def get_contents path result {}for child in path children if child isdir value get_contents child else value child getContent result[child basename ] valuereturn resulttest assertEqual get_contents first get_contents second
def assertVolumesEqual test first second first first get_filesystem get_path second second get_filesystem get_path def get_contents path result {}for child in path children if child isdir value get_contents child else value child getContent result[child basename ] valuereturn resulttest assertEqual get_contents first get_contents second
@task@timeddef i18n_rtl sh 'i18n_tooltransifexrtl' print 'Nowgeneratinglangugagefiles 'sh 'i18n_toolgenerate--rtl' print 'Committingtranslations 'sh 'gitclean-fdXconf/locale' sh 'gitaddconf/locale' sh 'gitcommit--amend'
def uplinkBusy name 'UplinkBusy'a TpPd pd 6 b MessageType mesType 42 packet a / b return packet
def task_doctest return {'actions' ['py test--doctest-modulesnikola/'] 'verbosity' 2}
def install if runtime platform getType 'posix' reactor Gtk3Reactor else reactor PortableGtk3Reactor from twisted internet main import installReactorinstallReactor reactor return reactor
def install if runtime platform getType 'posix' reactor Gtk3Reactor else reactor PortableGtk3Reactor from twisted internet main import installReactorinstallReactor reactor return reactor
def show_security_rule call None kwargs None global netconnif not netconn netconn get_conn NetworkManagementClient if kwargs is None kwargs {}if kwargs get 'resource_group' is None kwargs['resource_group'] config get_cloud_config_value 'resource_group' {} __opts__ search_global True rule netconn security_rules get resource_group_name kwargs['resource_group'] network_security_group_name kwargs['security_group'] security_rule_name kwargs['name'] return make_safe rule
def get_user_meta_prefix server_type return 'x-%s-%s-' % server_type lower 'meta'
def split_path path if not path startswith '/' path '/' + path return path rsplit '/' 1
def reflection_matrix point normal normal unit_vector normal[ 3] M numpy identity 4 M[ 3 3] - 2 0 * numpy outer normal normal M[ 3 3] 2 0 * numpy dot point[ 3] normal * normal return M
def ppcc_max x brack 0 0 1 0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm_uniform osr dist ppf
def ppcc_max x brack 0 0 1 0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm_uniform osr dist ppf
def ppcc_max x brack 0 0 1 0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm_uniform osr dist ppf
def ppcc_max x brack 0 0 1 0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm_uniform osr dist ppf
def ppcc_max x brack 0 0 1 0 dist 'tukeylambda' dist _parse_dist_kw dist osm_uniform _calc_uniform_order_statistic_medians len x osr sort x def tempfunc shape mi yvals func xvals func mi shape r prob stats pearsonr xvals yvals return 1 - r return optimize brent tempfunc brack brack args osm_uniform osr dist ppf
def resource_view_list context data_dict model context['model']id _get_or_bust data_dict 'id' resource model Resource get id if not resource raise NotFoundcontext['resource'] resource_check_access 'resource_view_list' context data_dict q model Session query model ResourceView filter_by resource_id id resource_views [resource_view for resource_view in q order_by model ResourceView order all if datapreview get_view_plugin resource_view view_type ]return model_dictize resource_view_list_dictize resource_views context
def create_ports_tree _check_config_exists cmd 'poudriereports-c'ret __salt__['cmd run'] cmd return ret
def serve_application application prefix port None host None max_children None class SCGIAppHandler SWAP def __init__ self *args **kwargs self prefix prefixself app_obj applicationSWAP __init__ self *args **kwargs kwargs dict handler_class SCGIAppHandler for kwarg in 'host' 'port' 'max_children' if locals [kwarg] is not None kwargs[kwarg] locals [kwarg]scgi_server SCGIServer **kwargs serve
def serve_application application prefix port None host None max_children None class SCGIAppHandler SWAP def __init__ self *args **kwargs self prefix prefixself app_obj applicationSWAP __init__ self *args **kwargs kwargs dict handler_class SCGIAppHandler for kwarg in 'host' 'port' 'max_children' if locals [kwarg] is not None kwargs[kwarg] locals [kwarg]scgi_server SCGIServer **kwargs serve
def main django setup try test_rtr1 NetworkDevice objects get device_name 'test-rtr1' test_rtr2 NetworkDevice objects get device_name 'test-rtr2' test_rtr1 delete test_rtr2 delete except NetworkDevice DoesNotExist passprintdevices NetworkDevice objects all for a_device in devices print a_deviceprint
def main django setup try test_rtr1 NetworkDevice objects get device_name 'test-rtr1' test_rtr2 NetworkDevice objects get device_name 'test-rtr2' test_rtr1 delete test_rtr2 delete except NetworkDevice DoesNotExist passprintdevices NetworkDevice objects all for a_device in devices print a_deviceprint
def main django setup try test_rtr1 NetworkDevice objects get device_name 'test-rtr1' test_rtr2 NetworkDevice objects get device_name 'test-rtr2' test_rtr1 delete test_rtr2 delete except NetworkDevice DoesNotExist passprintdevices NetworkDevice objects all for a_device in devices print a_deviceprint
def warning msg log msg logging WARNING
def find_entry_points ep ['ipython%s IPython start_ipython' 'iptest%s IPython testing iptestcontroller main']suffix str sys version_info[0] return [ e % '' for e in ep] + [ e % suffix for e in ep]
def _check_extension_attrs cls extends cls __extends__eattrs extends Attributescattrs cls Attributesckeys set [k for k in vars cls Attributes if not k startswith '_' ] ekeys set [k for k in vars extends Attributes if not k startswith '_' ] diff set for k in ckeys ekeys if getattr eattrs k None getattr cattrs k None diff add k attr_names ATTR_NAMES[cls]retval Nonewhile extends is not None retval extendsif len diff & attr_names > 0 return extendsextends extends __extends__return retval
def _check_extension_attrs cls extends cls __extends__eattrs extends Attributescattrs cls Attributesckeys set [k for k in vars cls Attributes if not k startswith '_' ] ekeys set [k for k in vars extends Attributes if not k startswith '_' ] diff set for k in ckeys ekeys if getattr eattrs k None getattr cattrs k None diff add k attr_names ATTR_NAMES[cls]retval Nonewhile extends is not None retval extendsif len diff & attr_names > 0 return extendsextends extends __extends__return retval
def _check_extension_attrs cls extends cls __extends__eattrs extends Attributescattrs cls Attributesckeys set [k for k in vars cls Attributes if not k startswith '_' ] ekeys set [k for k in vars extends Attributes if not k startswith '_' ] diff set for k in ckeys ekeys if getattr eattrs k None getattr cattrs k None diff add k attr_names ATTR_NAMES[cls]retval Nonewhile extends is not None retval extendsif len diff & attr_names > 0 return extendsextends extends __extends__return retval
def load_shortcuts global SHORTCUTS CUSTOM_SHORTCUTSsettings QSettings SETTINGS_PATH QSettings IniFormat for action in SHORTCUTS default_action SHORTCUTS[action] toString shortcut_action settings value u'shortcuts/%s' % action default_action CUSTOM_SHORTCUTS[action] QKeySequence shortcut_action
def sh_chebyt n monic False base sh_jacobi n 0 0 0 5 monic monic if monic return baseif n > 0 factor 4 ** n / 2 0 else factor 1 0base _scale factor return base
def RunTest test_suite stream None out_fd streamif stream out_fd StringIO StringIO try test_lib GrrTestProgram argv [sys argv[0] test_suite] testLoader GRREverythingTestLoader labels flags FLAGS labels testRunner unittest TextTestRunner stream out_fd finally if stream stream write 'Testname %s\n' % test_suite stream write out_fd getvalue stream flush
def convert_kvp_list_to_dict kvp_list if kvp_list ['True'] return {}kvp_map {}for kvp_str in kvp_list key value convert_kvp_str_to_list kvp_str kvp_map setdefault key set kvp_map[key] add value return dict x list y for x y in kvp_map iteritems
def generate_index_page index_links index_fp order [_index_headers['run_summary']] top_level_dir split split index_fp [0] [1]index_page_header get_index_page_header index_lines [index_page_header]d {}for e in index_links try d[e[2]] append e[0] e[1] except KeyError d[e[2]] [ e[0] e[1] ]index_lines append '<tableborder 1>\n' ordered_table_entries order + [k for k in d if k not in order ] for k in ordered_table_entries v d[k]index_lines append '<trcolspan 2align centerbgcolor #e8e8e8><tdcolspan 2align center>%s</td></tr>\n' % k for description path in v path re sub '^ *%s\\/' % top_level_dir ' /' path index_lines append '<tr>%s</tr>\n' % format_index_link description path index_lines append '</table>\n' index_page_footer get_index_page_footer index_lines append index_page_footer open index_fp 'w' write '' join index_lines
def put api_key url data url make_url api_key url req Request url headers {'Content-Type' 'application/json'} data json dumps data req get_method lambda 'PUT' return json loads urlopen req read
def partial_resids results focus_exog model results modelresid model endog - results predict if isinstance model GLM GEE resid * model family link deriv results fittedvalues elif isinstance model OLS GLS WLS passelse raise ValueError "Partialresidualsfor'%s'notimplemented " % type model if type focus_exog is str focus_col model exog_names index focus_exog else focus_col focus_exogfocus_val results params[focus_col] * model exog[ focus_col] return focus_val + resid
def scan_mail_log_line line collector m re match ' \\S+\\d+\\d+ \\d+ \\d+ \\S+ \\S+? \\[\\d+\\] ? * ' line if not m return date system service pid log m groups date dateutil parser parse date if service 'dovecot' scan_dovecot_line date log collector elif service 'postgrey' scan_postgrey_line date log collector elif service 'postfix/smtpd' scan_postfix_smtpd_line date log collector elif service 'postfix/cleanup' scan_postfix_cleanup_line date log collector elif service 'postfix/submission/smtpd' scan_postfix_submission_line date log collector elif service in 'postfix/qmgr' 'postfix/pickup' 'postfix/cleanup' 'postfix/scache' 'spampd' 'postfix/anvil' 'postfix/master' 'opendkim' 'postfix/lmtp' 'postfix/tlsmgr' passelse collector['other-services'] add service
def extra_host_filters multiple_labels extra_args {}where_str 'afe_hosts idin selecthost_idfromafe_hosts_labelswherelabel_id %s 'extra_args['where'] [where_str] * len multiple_labels extra_args['params'] [models Label smart_get label id for label in multiple_labels]return extra_args
def extra_host_filters multiple_labels extra_args {}where_str 'afe_hosts idin selecthost_idfromafe_hosts_labelswherelabel_id %s 'extra_args['where'] [where_str] * len multiple_labels extra_args['params'] [models Label smart_get label id for label in multiple_labels]return extra_args
@contextlib contextmanagerdef with_site_configuration_context domain 'test localhost' configuration None site __ Site objects get_or_create domain domain name domain site_configuration created SiteConfiguration objects get_or_create site site defaults {'enabled' True 'values' configuration} if not created site_configuration values configurationsite_configuration save with patch 'openedx core djangoapps site_configuration helpers get_current_site_configuration' return_value site_configuration with patch 'openedx core djangoapps theming helpers get_current_site' return_value site with patch 'django contrib sites models SiteManager get_current' return_value site yield
def media_endpoint _id file_ app media get _id if file_ is None return abort 404 if_modified_since weak_date request headers get 'If-Modified-Since' if if_modified_since is not None if if_modified_since tzinfo is None if_modified_since if_modified_since replace tzinfo tz_util utc if if_modified_since > file_ upload_date return Response status 304 headers {'Last-Modified' date_to_rfc1123 file_ upload_date 'Content-Length' file_ length}response Response file_ headers headers mimetype file_ content_type direct_passthrough True return response
def check_pairs func pairs name getattr func 'func_name' getattr func '__name__' '<unknown>' for inp expected in pairs out func inp assert out expected pair_fail_msg format name inp expected out
def bad_request req resp **kwargs raise HTTPBadRequest 'Badrequest' 'InvalidHTTPmethod'
def limited_epoch_train file_path max_epochs 1 train load_train_file file_path train algorithm termination_criterion EpochCounter max_epochs max_epochs train main_loop
def generateRSAKey bits implementations ['openssl' 'python'] for implementation in implementations if implementation 'openssl' and cryptomath m2cryptoLoaded return OpenSSL_RSAKey generate bits elif implementation 'python' return Python_RSAKey generate bits raise ValueError 'Noacceptableimplementations'
def _readline_workaround if not sys platform startswith 'win32' returntry import readlineexcept ImportError pass
def _readline_workaround if not sys platform startswith 'win32' returntry import readlineexcept ImportError pass
def _generateMetricsSubstitutions options tokenReplacements options['loggedMetrics'] [' *'] metricList optimizeMetricLabel _generateMetricSpecs options metricListString ' \n' join metricList metricListString _indentLines metricListString 2 indentFirstLine False permOptimizeSettingStr 'minimize "%s"' % optimizeMetricLabel loggedMetricsListAsStr '[%s]' % ' ' join [ "'%s'" % ptrn for ptrn in options['loggedMetrics']] tokenReplacements['\\$LOGGED_METRICS'] loggedMetricsListAsStrtokenReplacements['\\$METRICS'] metricListStringtokenReplacements['\\$PERM_OPTIMIZE_SETTING'] permOptimizeSettingStr
@_replaceIf _PY3 passthru @_replaceIf not _shouldEnableNewStyle _ensureOldClass def _oldStyle cls _ensureOldClass cls _bases cls __bases__ + object return type cls __name__ _bases cls __dict__
def get_resource_container context return context get RESOURCE_CONTAINER_VAR_NAME
def _mongo_client host port authenticate True direct False **kwargs client_options client_context ssl_client_options copy if client_context replica_set_name and not direct client_options['replicaSet'] client_context replica_set_nameclient_options update kwargs client MongoClient _connection_string host port authenticate port **client_options return client
def _mongo_client host port authenticate True direct False **kwargs client_options client_context ssl_client_options copy if client_context replica_set_name and not direct client_options['replicaSet'] client_context replica_set_nameclient_options update kwargs client MongoClient _connection_string host port authenticate port **client_options return client
def migration_get context migration_id return IMPL migration_get context migration_id
def test_rechunk_2d a np random uniform 0 1 300 reshape 10 30 x da from_array a chunks 1 2 3 4 5 * 6 new 5 5 15 * 2 x2 rechunk x chunks new assert x2 chunks new assert np all x2 compute a
def gaussian_convolution h Xi x return 1 0 / np sqrt 4 * np pi * np exp - Xi - x ** 2 / h ** 2 * 4 0
def _list_designs request owner name order_by '-last_modified' data Document objects get_docs request user Workflow extra 'jobsub' if owner data data filter owner__username__icontains owner if name data data filter name__icontains name data data order_by order_by designs []for doc in data[ MAX_DESIGNS] design doc content_objectif design is not None ko_design {'id' design id 'owner' design owner username 'name' design name 'description' design description 'node_type' design start get_child 'to' node_type 'last_modified' py_time mktime design last_modified timetuple 'editable' design owner id request user id 'is_shared' design is_shared 'is_trashed' doc is_trashed }designs append ko_design return designs
@frappe whitelist def get_backup delete_temp_backups odb BackupGenerator frappe conf db_name frappe conf db_name frappe conf db_password db_host frappe db host odb get_backup recipient_list odb send_email frappe msgprint _ u'Downloadlinkforyourbackupwillbeemailedonthefollowingemailaddress {0}' format u' ' join recipient_list
def lookup_template namespace name return LOOKUP[namespace] get_template name
def if_firewall_available distribution commands if is_centos_or_rhel distribution firewall_command 'firewall-cmd'elif is_ubuntu distribution firewall_command 'ufw'else raise DistributionNotSupported distribution distribution return run_from_args ['which' firewall_command] on success lambda result commands error catch_exit_code 1
@pytest mark modelsdef test_consistency_bug EN tokens EN u'Whererapessentiallywentmainstream illustratedbyseminalPublicEnemy BeastieBoysandL L CoolJ tracks ' tokens EN u'Charityandothershort-termaidhavebuoyedthemsofar andatax-reliefbillworkingitswaythroughCongresswouldhelp ButtheSeptember11VictimCompensationFund enactedbyCongresstodiscouragepeoplefromfilinglawsuits willdeterminetheshapeoftheirlivesforyearstocome \n\n' entity False tokens ents + tuple EN matcher tokens EN entity tokens
def cookie_signature seed *parts sha1 hmac new seed digestmod hashlib sha1 for part in parts if part sha1 update part return sha1 hexdigest
def label_present name value node None apiserver None ret __salt__['k8s label_present'] name value node apiserver return ret
def PostVimMessage message warning True truncate False echo_command u'echom' if warning else u'echo' vim command u'redraw' if warning vim command u'echohlWarningMsg' message ToUnicode message if truncate vim_width GetIntValue u'&columns' message message replace u'\n' u'' if len message > vim_width message message[ vim_width - 4 ] + u' ' old_ruler GetIntValue u'&ruler' old_showcmd GetIntValue u'&showcmd' vim command u'setnorulernoshowcmd' vim command u"{0}'{1}'" format echo_command EscapeForVim message SetVariableValue u'&ruler' old_ruler SetVariableValue u'&showcmd' old_showcmd else for line in message split u'\n' vim command u"{0}'{1}'" format echo_command EscapeForVim line if warning vim command u'echohlNone'
def delete_network_segment context segment_id with context session begin subtransactions True context session query segments_model NetworkSegment filter_by id segment_id delete
def get_service hass config discovery_info None from pushover import InitErrortry return PushoverNotificationService config[CONF_USER_KEY] config[CONF_API_KEY] except InitError _LOGGER error 'WrongAPIkeysupplied Getitathttps //pushover net' return None
def get field symbol return all_lookups[field] get symbol lower
def create_minibatch_x minibatches minibatch_markers epoch_axis if epoch_axis x np zeros minibatches last_e 0for e_idx e in enumerate minibatch_markers e_minibatches e - last_e x[last_e e] e_idx + np arange float e_minibatches / e_minibatches last_e eelse x np arange minibatches return x
def check_known_host user None hostname None key None fingerprint None config None port None if not hostname return {'status' 'error' 'error' 'hostnameargumentrequired'}if not user config config or '/etc/ssh/ssh_known_hosts' else config config or ' ssh/known_hosts' known_host get_known_host user hostname config config port port if not known_host or 'fingerprint' not in known_host return 'add'if key return 'exists' if key known_host['key'] else 'update' elif fingerprint return 'exists' if fingerprint known_host['fingerprint'] else 'update' else return 'exists'
def get_file_obj fname mode 'r' encoding None if _is_string_like fname return _open fname mode encoding try if 'r' in mode fname readif 'w' in mode or 'a' in mode fname writeexcept AttributeError raise ValueError 'fnamemustbeastringorafile-likeobject' return EmptyContextManager fname
def getRadiusByPrefix prefix sideLength xmlElement radius getFloatByPrefixSide prefix + 'radius' sideLength xmlElement radius + 0 5 * getFloatByPrefixSide prefix + 'diameter' sideLength xmlElement return radius + 0 5 * getFloatByPrefixSide prefix + 'size' sideLength xmlElement
def get_minions returner returners salt loader returners __opts__ __salt__ return returners['{0} get_minions' format returner ]
@require_level 'staff' @require_POSTdef sale_validation request course_id try invoice_number request POST['invoice_number']except KeyError return HttpResponseBadRequest 'Missingrequiredinvoice_numberparameter' try invoice_number int invoice_number except ValueError return HttpResponseBadRequest 'invoice_numbermustbeaninteger {value}provided' format value invoice_number try event_type request POST['event_type']except KeyError return HttpResponseBadRequest 'Missingrequiredevent_typeparameter' course_id SlashSeparatedCourseKey from_deprecated_string course_id try obj_invoice CourseRegistrationCodeInvoiceItem objects select_related 'invoice' get invoice_id invoice_number course_id course_id obj_invoice obj_invoice invoiceexcept CourseRegistrationCodeInvoiceItem DoesNotExist return HttpResponseNotFound _ "Invoicenumber'{num}'doesnotexist " format num invoice_number if event_type 'invalidate' return invalidate_invoice obj_invoice else return re_validate_invoice obj_invoice
def _clean_to_gce_name identifier return unicode identifier lower replace u'+' u'-' replace u'/' u'-'
def describe_api_method restApiId resourcePath httpMethod region None key None keyid None profile None try resource describe_api_resource restApiId resourcePath region region key key keyid keyid profile profile get 'resource' if resource conn _get_conn region region key key keyid keyid profile profile method conn get_method restApiId restApiId resourceId resource['id'] httpMethod httpMethod return {'method' _convert_datetime_str method }return {'error' 'getAPImethodfailed nosuchresource'}except ClientError as e return {'error' salt utils boto3 get_error e }
def set_interface dev bInterfaceNumber bAlternateSetting dev set_interface_altsetting bInterfaceNumber bAlternateSetting
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer warn "Therequestedsection'{section}'isnotexistent Thusitcannotbeexecuted " format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer warn "Therequestedsection'{section}'isnotexistent Thusitcannotbeexecuted " format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer warn "Therequestedsection'{section}'isnotexistent Thusitcannotbeexecuted " format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer warn "Therequestedsection'{section}'isnotexistent Thusitcannotbeexecuted " format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def warn_nonexistent_targets targets sections log_printer for target in targets if target not in sections log_printer warn "Therequestedsection'{section}'isnotexistent Thusitcannotbeexecuted " format section target files_config_absent warn_config_absent sections 'files' log_printer bears_config_absent warn_config_absent sections 'bears' log_printer if files_config_absent or bears_config_absent raise SystemExit 2
def _on_property_usage prop_name stacklevel stacklevel + 1deprecated_to_new_props {'slavename' 'workername'}if prop_name in deprecated_to_new_props reportDeprecatedWorkerNameUsage "Property'{old_name}'isdeprecated use'{new_name}'instead " format old_name prop_name new_name deprecated_to_new_props[prop_name] stacklevel stacklevel
def DayTimeStringsToUTCTimestamp day time try hour minute second _ re match kTimeRe time groups return util ISO8601ToUTCTimestamp day hour int hour minute int minute second int second except Exception as e logging warning 'Errorparsingdayandtimestrings %s%s error %r' % day time e return None
def tamper payload **kwargs retVal payloadif payload retVal ''i 0while i < len payload if payload[i] '%' and i < len payload - 2 and payload[ i + 1 i + 2 ] in string hexdigits and payload[ i + 2 i + 3 ] in string hexdigits retVal + payload[i i + 3 ]i + 3else if payload[i] not in string ascii_letters + string digits retVal + '%%C0%%% 2X' % 138 ord payload[i] else retVal + payload[i]i + 1return retVal
def _parse_snapshot_description snapshot unix_time False ret dict tree ElementTree fromstring snapshot getXMLDesc for node in tree if node tag 'name' ret['name'] node textelif node tag 'creationTime' ret['created'] not unix_time and datetime datetime fromtimestamp float node text isoformat '' or float node text elif node tag 'state' ret['running'] node text 'running' ret['current'] snapshot isCurrent 1 return ret
def receive share service if share in rx_msgs if rx_msgs[share] return rx_msgs[share] popleft return None
def check_dir directory failed_files []for root dirs files in os walk directory for f in files if f endswith ' py' and os path basename f '__init__ py' filename os path join root f if not check_header filename failed_files append filename return failed_files
def make_dict_copy from_dict copy_from_dict {}for key value in from_dict items if type value __name__ 'dict' copy_from_dict[key] make_dict_copy value elif isinstance value list copy_from_dict[key] make_list_copy value else copy_from_dict[key] valuereturn copy_from_dict
def linear_harvey_collier res rr recursive_olsresiduals res skip 3 alpha 0 95 from scipy import statsreturn stats ttest_1samp rr[3][3 ] 0
def preBuildStatic static pass
def make_generation_hash x return GenerationHash hash_value generation_hash x
def load_tool_sources_from_path path load_exception_handler load_exception_handler recursive False register_load_errors False return _load_tools_from_path path load_exception_handler load_exception_handler recursive recursive register_load_errors register_load_errors loader_func get_tool_source enable_beta_formats True
def write_test_files test_dir names None names names or range 10 for i in names with open os path join test_dir str i u'wb' as out out write u'' encode u'UTF-8'
def write_test_files test_dir names None names names or range 10 for i in names with open os path join test_dir str i u'wb' as out out write u'' encode u'UTF-8'
def write_test_files test_dir names None names names or range 10 for i in names with open os path join test_dir str i u'wb' as out out write u'' encode u'UTF-8'
def get_specific_user user get_user if is_windows if _win_current_user_is_admin return 'sudo_{0}' format user else env_vars 'SUDO_USER' if user 'root' for evar in env_vars if evar in os environ return 'sudo_{0}' format os environ[evar] return user
def _points_table for i in range 256 for j in itertools repeat i 256 yield j
def regions from boto elasticache layer1 import ElastiCacheConnectionreturn get_regions 'elasticache' connection_cls ElastiCacheConnection
def serializePath pathObj options return '' join [ cmd + scourCoordinates data options cmd 'a' for cmd data in pathObj]
def get_tile_set chunks tile_set defaultdict int for chunkx chunkz chunkmtime in chunks iteritems col row tileset convert_coords chunkx chunkz for tilec tiler in tileset get_tiles_by_chunk col row tile tileset RenderTile compute_path tilec tiler 5 tile_set[tile path] max tile_set[tile path] chunkmtime for tile tile_mtime in tile_set copy iteritems for i in reversed xrange 5 tile_set[tile[ i]] max tile_set[tile[ i]] tile_mtime return dict tile_set
def get_tile_set chunks tile_set defaultdict int for chunkx chunkz chunkmtime in chunks iteritems col row tileset convert_coords chunkx chunkz for tilec tiler in tileset get_tiles_by_chunk col row tile tileset RenderTile compute_path tilec tiler 5 tile_set[tile path] max tile_set[tile path] chunkmtime for tile tile_mtime in tile_set copy iteritems for i in reversed xrange 5 tile_set[tile[ i]] max tile_set[tile[ i]] tile_mtime return dict tile_set
def get_tile_set chunks tile_set defaultdict int for chunkx chunkz chunkmtime in chunks iteritems col row tileset convert_coords chunkx chunkz for tilec tiler in tileset get_tiles_by_chunk col row tile tileset RenderTile compute_path tilec tiler 5 tile_set[tile path] max tile_set[tile path] chunkmtime for tile tile_mtime in tile_set copy iteritems for i in reversed xrange 5 tile_set[tile[ i]] max tile_set[tile[ i]] tile_mtime return dict tile_set
def create_annotation module annotation {}if module params['duration'] None duration module params['duration']else duration 0if module params['start'] None start module params['start']else start int time time if module params['stop'] None stop module params['stop']else stop int time time + duration annotation['start'] int start annotation['stop'] int stop annotation['category'] module params['category']annotation['description'] module params['description']annotation['title'] module params['title']return annotation
def build_logger return log
def test_cache_config_change_cache_size config_stub tmpdir max_cache_size 1024config_stub data {'storage' {'cache-size' max_cache_size} 'general' {'private-browsing' False}}disk_cache cache DiskCache str tmpdir assert disk_cache maximumCacheSize max_cache_size config_stub set 'storage' 'cache-size' max_cache_size * 2 assert disk_cache maximumCacheSize max_cache_size * 2
def UrnStringToClientId urn if urn startswith AFF4_PREFIX urn urn[len AFF4_PREFIX ]components urn split '/' return components[0]
def save_instance form instance commit True from django db import modelsopts instance __class__ _metaif form errors raise ValueError "The%scouldnotbechangedbecausethedatadidn'tvalidate " % opts object_name clean_data form clean_datafor f in opts fields if not f editable or isinstance f models AutoField continuesetattr instance f name clean_data[f name] if commit instance save for f in opts many_to_many setattr instance f attname clean_data[f name] return instance
def save_instance form instance commit True from django db import modelsopts instance __class__ _metaif form errors raise ValueError "The%scouldnotbechangedbecausethedatadidn'tvalidate " % opts object_name clean_data form clean_datafor f in opts fields if not f editable or isinstance f models AutoField continuesetattr instance f name clean_data[f name] if commit instance save for f in opts many_to_many setattr instance f attname clean_data[f name] return instance
def getconsole buffer 1 c Console buffer return c
def GammaInverse name a b return rv name GammaInverseDistribution a b
def generate_frontpage_pngs only_if_needed True for fn_png fn_py in FRONTPAGE_PNGS items pn_png os path join FRONTPAGE_PNG_PATH fn_png pn_py os path join FRONTPAGE_PY_PATH fn_py mtime_py os path getmtime pn_py mtime_png os path getmtime pn_png if os path exists pn_png else mtime_py - 1 if only_if_needed and mtime_py < mtime_png continuesubprocess check_call ['python' pn_py] os rename fn_png pn_png
def add_svc_avail_path path if os path exists path if path not in AVAIL_SVR_DIRS AVAIL_SVR_DIRS append path return Truereturn False
def _parse_options opts delim options {}for opt in opts split delim key val opt split ' ' if key lower 'readpreferencetags' options setdefault 'readpreferencetags' [] append val else if str key in options warnings warn 'DuplicateURIoption%s' % str key options[str key ] unquote_plus val if 'wtimeout' in options if 'wtimeoutMS' in options options pop 'wtimeout' warnings warn "Optionwtimeoutisdeprecated use'wtimeoutMS'instead" return options
def _parse_options opts delim options {}for opt in opts split delim key val opt split ' ' if key lower 'readpreferencetags' options setdefault 'readpreferencetags' [] append val else if str key in options warnings warn 'DuplicateURIoption%s' % str key options[str key ] unquote_plus val if 'wtimeout' in options if 'wtimeoutMS' in options options pop 'wtimeout' warnings warn "Optionwtimeoutisdeprecated use'wtimeoutMS'instead" return options
def instantiate_bears section local_bear_list global_bear_list file_dict message_queue console_printer local_bear_list [bear for bear in filter_raising_callables local_bear_list RuntimeError section message_queue timeout 0 1 ]global_bear_list [bear for bear in filter_raising_callables global_bear_list RuntimeError file_dict section message_queue timeout 0 1 ]return local_bear_list global_bear_list
def assert_python_ok *args **env_vars return _assert_python True *args **env_vars
def db_add_group **kwargs name kwargs get 'name' group get_object UserGroup name name users kwargs pop 'users_id' if not group group UserGroup **kwargs group save for user_id in users group_add_user group user_id
def write_megam_file train_toks encoding stream bernoulli True explicit True labels encoding labels labelnum dict label i for i label in enumerate labels for featureset label in train_toks if hasattr encoding 'cost' stream write ' ' join str encoding cost featureset label l for l in labels else stream write '%d' % labelnum[label] if not explicit _write_megam_features encoding encode featureset label stream bernoulli else for l in labels stream write '#' _write_megam_features encoding encode featureset l stream bernoulli stream write '\n'
def pool_create request **kwargs body {'pool' {'name' kwargs['name'] 'description' kwargs['description'] 'subnet_id' kwargs['subnet_id'] 'protocol' kwargs['protocol'] 'lb_method' kwargs['lb_method'] 'admin_state_up' kwargs['admin_state_up']}}pool quantumclient request create_pool body get 'pool' return Pool pool
def get_blockdeviceapi config get_blockdevice_config backend api_args backend_and_api_args_from_configuration config api get_api backend backend api_args api_args reactor reactor cluster_id make_cluster_id TestTypes FUNCTIONAL return api
def get_blockdeviceapi config get_blockdevice_config backend api_args backend_and_api_args_from_configuration config api get_api backend backend api_args api_args reactor reactor cluster_id make_cluster_id TestTypes FUNCTIONAL return api
@get '/task/new' def task_new taskid hexencode os urandom 8 remote_addr request remote_addrDataStore tasks[taskid] Task taskid remote_addr logger debug "Creatednewtask '%s'" % taskid return jsonize {'success' True 'taskid' taskid}
def mutating_method func def wrapper self *__args **__kwargs old_mutable self _mutableself _mutable Truetry return func self *__args **__kwargs finally self _mutable old_mutablereturn wrapper
def setup_platform hass config add_devices_callback discovery_info None _configured_zones discovery_info['zones']for zone_num in _configured_zones _device_config_data ZONE_SCHEMA _configured_zones[zone_num] _device EnvisalinkBinarySensor zone_num _device_config_data[CONF_ZONENAME] _device_config_data[CONF_ZONETYPE] EVL_CONTROLLER alarm_state['zone'][zone_num] EVL_CONTROLLER add_devices_callback [_device]
def _buildElementNsmap using_elements thisMap {}for e in using_elements thisMap[e attrib['prefix']] e attrib['namespace']return thisMap
def filterStringValue value charRegex replacement '' retVal valueif value retVal re sub charRegex replace '[' '[^' if '[^' not in charRegex else charRegex replace '[^' '[' replacement value return retVal
def ek function *args **kwargs if name 'nt' result function *args **kwargs else result function *[ ss x if isinstance x str unicode else x for x in args] **kwargs if isinstance result list tuple return _fix_list_encoding result if isinstance result str return _to_unicode result return result
def set_recv_attr status recvtable s3db inv_recvship_status s3db inv_ship_statusrecvtable sender_id readable recvtable sender_id writable Falserecvtable grn_status readable recvtable grn_status writable Falserecvtable cert_status readable recvtable cert_status writable Falserecvtable eta readable Falserecvtable req_ref writable Trueif status ship_status['IN_PROCESS'] recvtable send_ref writable Truerecvtable recv_ref readable Falserecvtable sender_id readable Falseelse for field in recvtable fields recvtable[field] writable Falseif status ship_status['SENT'] recvtable date writable Truerecvtable recipient_id readable recvtable recipient_id writable Truerecvtable comments writable True
def _serialize_agent controlamp return str controlamp transport getPeer
@login_required@enforce_shopping_cart_enableddef show_cart request cart Order get_cart_for_user request user is_any_course_expired expired_cart_items expired_cart_item_names valid_cart_item_tuples verify_for_closed_enrollment request user cart site_name configuration_helpers get_value 'SITE_NAME' settings SITE_NAME if is_any_course_expired for expired_item in expired_cart_items Order remove_cart_item_from_order expired_item request user cart update_order_type callback_url request build_absolute_uri reverse 'shoppingcart views postpay_callback' form_html render_purchase_form_html cart callback_url callback_url context {'order' cart 'shoppingcart_items' valid_cart_item_tuples 'amount' cart total_cost 'is_course_enrollment_closed' is_any_course_expired 'expired_course_names' expired_cart_item_names 'site_name' site_name 'form_html' form_html 'currency_symbol' settings PAID_COURSE_REGISTRATION_CURRENCY[1] 'currency' settings PAID_COURSE_REGISTRATION_CURRENCY[0] 'enable_bulk_purchase' configuration_helpers get_value 'ENABLE_SHOPPING_CART_BULK_PURCHASE' True }return render_to_response 'shoppingcart/shopping_cart html' context
def _listOpenFDs return detector _listOpenFDs
def _listOpenFDs return detector _listOpenFDs
def enabled name **kwargs return info name ['StartType'] 'Auto'
def enabled name **kwargs return info name ['StartType'] 'Auto'
def clean_old_jobs for returner_ in __opts__[CONFIG_KEY] fstr '{0} clean_old_jobs' format returner_ if fstr in _mminion returners _mminion returners[fstr]
@superuser_requireddef site_settings request form_class template_name u'admin/settings html' return djblets_site_settings request form_class template_name {u'root_path' settings SITE_ROOT + u'admin/db/' }
def write_pack_index_v1 f entries pack_checksum f SHA1Writer f fan_out_table defaultdict lambda 0 for name offset entry_checksum in entries fan_out_table[ord name[ 1] ] + 1for i in range 256 f write struct pack '>L' fan_out_table[i] fan_out_table[ i + 1 ] + fan_out_table[i]for name offset entry_checksum in entries if not offset < 4294967295 raise TypeError 'packformat1onlysupportsoffsets<2Gb' f write struct pack '>L20s' offset name assert len pack_checksum 20 f write pack_checksum return f write_sha
def saferepr object return _safe_repr object {} None 0 [0]
@command 'historyrecent' def recent_history view_history duplicates False
@command 'historyrecent' def recent_history view_history duplicates False
@click command @click option '--reloader/--no-reloader' default True @click option '--debug/--no-debug' default True @click option '--host' default '127 0 0 1' @click option '--port' default 5000 def runserver reloader debug host port app run use_reloader reloader debug debug host host port port
def image_shape img if hasattr img 'shape' return img shape[1] img shape[0] return img width img height
def dict_to_protobuf pb_klass_or_instance values type_callable_map REVERSE_TYPE_CALLABLE_MAP strict True if isinstance pb_klass_or_instance Message instance pb_klass_or_instanceelse instance pb_klass_or_instance return _dict_to_protobuf instance values type_callable_map strict
def test_image_equals_mask assert_close reconstruction np ones 7 5 np ones 7 5 1
def absent name ret {'name' name 'changes' {} 'result' True 'comment' ''}index_template_exists __salt__['elasticsearch index_template_exists'] name name if index_template_exists if __opts__['test'] ret['comment'] 'Indextemplate{0}willberemoved' format name ret['result'] Noneelse ret['result'] __salt__['elasticsearch index_template_delete'] name name if ret['result'] ret['comment'] 'Removedindextemplate{0}successfully' format name else ret['comment'] 'Failedtoremoveindextemplate{0}' format name elif not index_template_exists ret['comment'] 'Indextemplate{0}isalreadyabsent' format name else ret['comment'] 'Failedtodeterminewhetherindextemplate{0}isabsent seeMinionlogformoreinformation' format name ret['result'] Falsereturn ret
def present name block_icmp None default None masquerade False ports None port_fwd None services None prune_services True interfaces None sources None rich_rules None ret _present name block_icmp default masquerade ports port_fwd services prune_services interfaces sources rich_rules if ret['changes'] {} __salt__['firewalld reload_rules'] ret['result'] Trueif ret['changes'] {} ret['comment'] "'{0}'isalreadyinthedesiredstate " format name return retif __opts__['test'] ret['result'] Noneret['comment'] "Configurationfor'{0}'willchange " format name return retret['comment'] "'{0}'wasconfigured " format name return ret
def present name block_icmp None default None masquerade False ports None port_fwd None services None prune_services True interfaces None sources None rich_rules None ret _present name block_icmp default masquerade ports port_fwd services prune_services interfaces sources rich_rules if ret['changes'] {} __salt__['firewalld reload_rules'] ret['result'] Trueif ret['changes'] {} ret['comment'] "'{0}'isalreadyinthedesiredstate " format name return retif __opts__['test'] ret['result'] Noneret['comment'] "Configurationfor'{0}'willchange " format name return retret['comment'] "'{0}'wasconfigured " format name return ret
def test_precision_exceeds_64bit t1 Time 123456789000 0 format 'cxcsec' t2 t1 + dt_tiny assert t1 jd t2 jd
def test_precision_exceeds_64bit t1 Time 123456789000 0 format 'cxcsec' t2 t1 + dt_tiny assert t1 jd t2 jd
def test_precision_exceeds_64bit t1 Time 123456789000 0 format 'cxcsec' t2 t1 + dt_tiny assert t1 jd t2 jd
def test_precision_exceeds_64bit t1 Time 123456789000 0 format 'cxcsec' t2 t1 + dt_tiny assert t1 jd t2 jd
def vm_stopped name name name lower ret {'name' name 'changes' {} 'result' None 'comment' ''}if name in __salt__['vmadm list'] order 'hostname' search 'state stopped' ret['result'] Trueret['comment'] 'vm{0}alreadystopped' format name else ret['result'] True if __opts__['test'] else __salt__['vmadm stop'] name key 'hostname' if not isinstance ret['result'] bool and ret['result'] get 'Error' ret['result'] Falseret['comment'] 'failedtostop{0}' format name else ret['changes'][name] 'stopped'ret['comment'] 'vm{0}stopped' format name return ret
def custom_tools registry xml_parent data base 'com cloudbees jenkins plugins customtools'wrapper XML SubElement xml_parent base + ' CustomToolInstallWrapper' wrapper_tools XML SubElement wrapper 'selectedTools' tools data get 'tools' [] tool_node base + ' CustomToolInstallWrapper_-SelectedTool' for tool in tools tool_wrapper XML SubElement wrapper_tools tool_node XML SubElement tool_wrapper 'name' text str tool opts XML SubElement wrapper 'multiconfigOptions' skip_install str data get 'skip-master-install' 'false' XML SubElement opts 'skipMasterInstallation' text skip_installconvert_home str data get 'convert-homes-to-upper' 'false' XML SubElement wrapper 'convertHomesToUppercase' text convert_home
def custom_tools registry xml_parent data base 'com cloudbees jenkins plugins customtools'wrapper XML SubElement xml_parent base + ' CustomToolInstallWrapper' wrapper_tools XML SubElement wrapper 'selectedTools' tools data get 'tools' [] tool_node base + ' CustomToolInstallWrapper_-SelectedTool' for tool in tools tool_wrapper XML SubElement wrapper_tools tool_node XML SubElement tool_wrapper 'name' text str tool opts XML SubElement wrapper 'multiconfigOptions' skip_install str data get 'skip-master-install' 'false' XML SubElement opts 'skipMasterInstallation' text skip_installconvert_home str data get 'convert-homes-to-upper' 'false' XML SubElement wrapper 'convertHomesToUppercase' text convert_home
def remove_tags html tags tags [re escape tag for tag in tags split ]tags_re u' %s ' % u' ' join tags starttag_re re compile u'<%s /?> \\s+[^>]*> ' % tags_re re U endtag_re re compile u'</%s>' % tags_re html starttag_re sub u'' html html endtag_re sub u'' html return html
def parse_address address m _PCI_ADDRESS_REGEX match address if not m raise exception PciDeviceWrongAddressFormat address address return m groups
def _bytelist2longBigEndian list imax len list / 4 hl [0L] * imax j 0i 0while i < imax b0 long ord list[j] << 24 b1 long ord list[ j + 1 ] << 16 b2 long ord list[ j + 2 ] << 8 b3 long ord list[ j + 3 ] hl[i] b0 b1 b2 b3 i i + 1 j j + 4 return hl
def create_collection_index collection keys ignore_created True ignore_created_opts True **kwargs INDEX_ALREADY_EXISTS 68INDEX_OPTIONS_CONFLICT 85try collection create_index keys **kwargs except pymongo errors OperationFailure as exc errors_to_ignore []if ignore_created errors_to_ignore append INDEX_ALREADY_EXISTS if ignore_created_opts errors_to_ignore append INDEX_OPTIONS_CONFLICT if exc code in errors_to_ignore logger warning "Existingindexincollection'{}'remainedunchanged {}" format collection full_name exc details['errmsg'] else raise exc
def enable_job name None if not name raise SaltInvocationError 'Requiredparameter`name`ismissing ' server _connect if not job_exists name raise SaltInvocationError 'Job`{0}`doesnotexists ' format name try server enable_job name except jenkins JenkinsException as err raise SaltInvocationError 'Somethingwentwrong{0} ' format err return True
def make_cascade loader global_conf catch '404' **local_conf catch map int converters aslist catch apps []for name value in local_conf items if not name startswith 'app' raise ValueError "Badconfigurationkey%r %r allconfigurationkeysmuststartwith'app'" % name value app loader get_app value global_conf global_conf apps append name app apps sort apps [app for name app in apps]return Cascade apps catch catch
def make_cascade loader global_conf catch '404' **local_conf catch map int converters aslist catch apps []for name value in local_conf items if not name startswith 'app' raise ValueError "Badconfigurationkey%r %r allconfigurationkeysmuststartwith'app'" % name value app loader get_app value global_conf global_conf apps append name app apps sort apps [app for name app in apps]return Cascade apps catch catch
def config_present name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if matches ret['result'] Trueret['comment'] 'Configisalreadyset'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillbeadded'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'add_config' name matches __salt__['nxos cmd'] 'find' name if matches ret['result'] Trueret['comment'] 'Successfullyaddedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtoaddconfig'return ret
def config_present name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if matches ret['result'] Trueret['comment'] 'Configisalreadyset'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillbeadded'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'add_config' name matches __salt__['nxos cmd'] 'find' name if matches ret['result'] Trueret['comment'] 'Successfullyaddedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtoaddconfig'return ret
def load_multi_database gb_filename_or_handle gb_filename_or_handle2 TESTDB create_database db_name 'biosql-test'db_name2 'biosql-test2'server BioSeqDatabase open_database driver DBDRIVER user DBUSER passwd DBPASSWD host DBHOST db TESTDB db server new_database db_name iterator SeqIO parse gb_filename_or_handle 'gb' count db load iterator db server new_database db_name2 iterator SeqIO parse gb_filename_or_handle2 'gb' count2 db load iterator server commit server close return count + count2
def load_multi_database gb_filename_or_handle gb_filename_or_handle2 TESTDB create_database db_name 'biosql-test'db_name2 'biosql-test2'server BioSeqDatabase open_database driver DBDRIVER user DBUSER passwd DBPASSWD host DBHOST db TESTDB db server new_database db_name iterator SeqIO parse gb_filename_or_handle 'gb' count db load iterator db server new_database db_name2 iterator SeqIO parse gb_filename_or_handle2 'gb' count2 db load iterator server commit server close return count + count2
def source_model view if isinstance view model QSortFilterProxyModel return view model sourceModel else return view model
def check_coverage images used_images uncovered set images - set [x[0] for x in used_images] if uncovered LOGGER error 'ThefollowingDockerfilesarenotdescribedintheparsefiles_config ymlfile {} PleaseseethefollowingdocumentationonhowtoaddDockerfilerankstotheconfigurationfile {}' format uncovered 'https //github com/edx/configuration/blob/master/util/README md' sys exit 1
@require_chanmsg@require_privilege OP u'Youarenotachanneloperator ' @commands u'tmask' def set_mask bot trigger bot db set_channel_value trigger sender u'topic_mask' trigger group 2 bot say u'Gotcha ' + trigger nick
def _get_params mapper_spec allowed_keys None if 'output_writer' not in mapper_spec params message "Outputwriter'sparametersshouldbespecifiedinoutput_writersubdictionary "if allowed_keys raise errors BadWriterParamsError message params mapper_spec paramsparams dict str n v for n v in params iteritems else if not isinstance mapper_spec params get 'output_writer' dict raise errors BadWriterParamsError 'Outputwriterparametersshouldbeadictionary' params mapper_spec params get 'output_writer' params dict str n v for n v in params iteritems if allowed_keys params_diff set params keys - allowed_keys if params_diff raise errors BadWriterParamsError 'Invalidoutput_writerparameters %s' % ' ' join params_diff return params
def render_from_lms template_name dictionary context None namespace 'main' return render_to_string template_name dictionary context namespace 'lms ' + namespace
def render_from_lms template_name dictionary context None namespace 'main' return render_to_string template_name dictionary context namespace 'lms ' + namespace
def blended_transform_factory x_transform y_transform if isinstance x_transform Affine2DBase and isinstance y_transform Affine2DBase return BlendedAffine2D x_transform y_transform return BlendedGenericTransform x_transform y_transform
def blended_transform_factory x_transform y_transform if isinstance x_transform Affine2DBase and isinstance y_transform Affine2DBase return BlendedAffine2D x_transform y_transform return BlendedGenericTransform x_transform y_transform
def blended_transform_factory x_transform y_transform if isinstance x_transform Affine2DBase and isinstance y_transform Affine2DBase return BlendedAffine2D x_transform y_transform return BlendedGenericTransform x_transform y_transform
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME host config get CONF_HOST port config get CONF_PORT device_id config get CONF_DEVICE try response requests get DEVICE_LIST_URL format host port json if device_id in response[CONF_DEVICES] keys add_devices [FireTVDevice host port device_id name ] _LOGGER info 'Device%saccessibleandreadyforcontrol' device_id else _LOGGER warning 'Device%sisnotregisteredwithfiretv-server' device_id except requests exceptions RequestException _LOGGER error 'Couldnotconnecttofiretv-serverat%s' host
def try_dbfield fn field_class for cls in field_class mro if cls is models Field continuedata fn cls if data return data
def try_dbfield fn field_class for cls in field_class mro if cls is models Field continuedata fn cls if data return data
def try_dbfield fn field_class for cls in field_class mro if cls is models Field continuedata fn cls if data return data
def extract_cluster_size line cluster_size line split ' ' [ -1 ]try cluster_size int cluster_size except ValueError return 0return cluster_size
def enable_tab_completion unused_command libedit 'libedit' in readline __doc__ command 'bind^Irl_complete' if libedit else 'tab complete' readline parse_and_bind command
def _create_meg_coils chs acc t None coilset None do_es False acc _accuracy_dict[acc] if isinstance acc string_types else acc coilset _read_coil_defs verbose False if coilset is None else coilset coils [_create_meg_coil coilset ch acc do_es for ch in chs]_transform_orig_meg_coils coils t do_es do_es return coils
def upfirdn_naive x h up 1 down 1 h np asarray h out np zeros len x * up x dtype out[ up] xout np convolve h out [ down][ _output_len len h len x up down ]return out
def sibpath filename return util sibpath __file__ filename
def get_course_tag user course_id key try record UserCourseTag objects get user user course_id course_id key key return record valueexcept UserCourseTag DoesNotExist return None
def get_settings_var directory DIRECTORY settings_var {}settings_var['EXTENSIONS'] EXTENSIONSsettings_var['SELECT_FORMATS'] SELECT_FORMATSsettings_var['ADMIN_VERSIONS'] ADMIN_VERSIONSsettings_var['ADMIN_THUMBNAIL'] ADMIN_THUMBNAILsettings_var['MAX_UPLOAD_SIZE'] MAX_UPLOAD_SIZEsettings_var['NORMALIZE_FILENAME'] NORMALIZE_FILENAMEsettings_var['CONVERT_FILENAME'] CONVERT_FILENAMEsettings_var['SEARCH_TRAVERSE'] SEARCH_TRAVERSEreturn settings_var
def set_log_file_dir directory global _log_file_dir_log_file_dir directory
def get_all_metrics limit None metrics []def get_leafs_of_node nodepath for obj in get_matching_metrics nodepath ['metrics'] if int obj['is_leaf'] 1 metrics append obj['path'] else get_leafs_of_node obj['path'] get_leafs_of_node '' return metrics
def get_all_metrics limit None metrics []def get_leafs_of_node nodepath for obj in get_matching_metrics nodepath ['metrics'] if int obj['is_leaf'] 1 metrics append obj['path'] else get_leafs_of_node obj['path'] get_leafs_of_node '' return metrics
def shortest_augmenting_path G s t capacity 'capacity' residual None value_only False two_phase False cutoff None R shortest_augmenting_path_impl G s t capacity residual two_phase cutoff R graph['algorithm'] 'shortest_augmenting_path'return R
def shortest_augmenting_path G s t capacity 'capacity' residual None value_only False two_phase False cutoff None R shortest_augmenting_path_impl G s t capacity residual two_phase cutoff R graph['algorithm'] 'shortest_augmenting_path'return R
def get_default_object_values return json loads utils get_file_contents feconf OBJECT_DEFAULT_VALUES_FILE_PATH
def compareYAscending point pointOther if point y < pointOther y return -1 return int point y > pointOther y
def make_image location size fmt if not os path isabs location return ''if not os path isdir os path dirname location return ''if not __salt__['cmd retcode'] 'qemu-imgcreate-f{0}{1}{2}M' format fmt location size python_shell False return locationreturn ''
def salt_auth_tool if 'token' not in cherrypy session raise cherrypy HTTPError 401 cherrypy response headers['Cache-Control'] 'private'
@register filterdef bug_url bug_id review_request if review_request repository and review_request repository bug_tracker and u'%s' in review_request repository bug_tracker try return review_request repository bug_tracker % bug_id except TypeError logging error u"ErrorcreatingbugURL ThebugtrackerURL'%s'islikelyinvalid " % review_request repository bug_tracker return None
@register filterdef bug_url bug_id review_request if review_request repository and review_request repository bug_tracker and u'%s' in review_request repository bug_tracker try return review_request repository bug_tracker % bug_id except TypeError logging error u"ErrorcreatingbugURL ThebugtrackerURL'%s'islikelyinvalid " % review_request repository bug_tracker return None
def libvlc_audio_output_device_get mp f _Cfunctions get 'libvlc_audio_output_device_get' None or _Cfunction 'libvlc_audio_output_device_get' 1 None ctypes c_char_p MediaPlayer return f mp
def check_password guess hashed if hashed startswith 'PBKDF2' if check_password_PBKDF2 guess hashed return Trueelif hashlib sha1 guess hexdigest hashed return Truereturn False
def relu x use_cudnn True return ReLU use_cudnn x
def _publish_file token room filepath message '' api_url None if not os path isfile filepath raise ValueError "File'{0}'doesnotexist" format filepath if len message > 1000 raise ValueError 'Messagetoolong' url '{0}/v2/room/{1}/share/file' format api_url room headers {'Content-type' 'multipart/related boundary boundary123456'}headers['Authorization'] 'Bearer' + token msg json dumps {'message' message} payload '--boundary123456\nContent-Type application/json charset UTF-8\nContent-Disposition attachment name "metadata"\n\n{0}\n\n--boundary123456\nContent-Disposition attachment name "file" filename "{1}"\n\n{2}\n\n--boundary123456--' format msg os path basename filepath open filepath 'rb' read salt utils http query url method 'POST' header_dict headers data payload
def _publish_file token room filepath message '' api_url None if not os path isfile filepath raise ValueError "File'{0}'doesnotexist" format filepath if len message > 1000 raise ValueError 'Messagetoolong' url '{0}/v2/room/{1}/share/file' format api_url room headers {'Content-type' 'multipart/related boundary boundary123456'}headers['Authorization'] 'Bearer' + token msg json dumps {'message' message} payload '--boundary123456\nContent-Type application/json charset UTF-8\nContent-Disposition attachment name "metadata"\n\n{0}\n\n--boundary123456\nContent-Disposition attachment name "file" filename "{1}"\n\n{2}\n\n--boundary123456--' format msg os path basename filepath open filepath 'rb' read salt utils http query url method 'POST' header_dict headers data payload
def exp x np import_module 'numpy' if isinstance x int float return interval np exp x np exp x elif isinstance x interval return interval np exp x start np exp x end is_valid x is_valid else raise NotImplementedError
def string_to_rgb s orig_s ss s strip if s startswith '#' s s[1 ]if not len s 6 raise ValueError "String%sdoesn'tlooklikeahexstring" % orig_s return int s[ 2] 16 int s[2 4] 16 int s[4 ] 16
def shellglob args expanded []unescape unescape_glob if sys platform 'win32' else lambda x x for a in args expanded extend glob glob a or [unescape a ] return expanded
def obscure_string input_string if input_string is None or len input_string < 4 return input_stringlast_four input_string[ -4 ]obscured '*' * len input_string - 4 return obscured + last_four
def obscure_string input_string if input_string is None or len input_string < 4 return input_stringlast_four input_string[ -4 ]obscured '*' * len input_string - 4 return obscured + last_four
def delete_security_group_rule security_group_rule_id profile None conn _auth profile return conn delete_security_group_rule security_group_rule_id
def check_meta_data facility check_fields ['user_count' 'latitude' 'longitude' 'address' 'contact_name' 'contact_phone' 'contact_email']return any [ getattr facility field None is None or getattr facility field '' for field in check_fields]
def setvariable cursor mysqlvar value query 'SETGLOBAL%s ' % mysql_quote_identifier mysqlvar 'vars' try cursor execute query + '%s' value cursor fetchall result Trueexcept Exception e get_exception result str e return result
def setvariable cursor mysqlvar value query 'SETGLOBAL%s ' % mysql_quote_identifier mysqlvar 'vars' try cursor execute query + '%s' value cursor fetchall result Trueexcept Exception e get_exception result str e return result
def setvariable cursor mysqlvar value query 'SETGLOBAL%s ' % mysql_quote_identifier mysqlvar 'vars' try cursor execute query + '%s' value cursor fetchall result Trueexcept Exception e get_exception result str e return result
def setvariable cursor mysqlvar value query 'SETGLOBAL%s ' % mysql_quote_identifier mysqlvar 'vars' try cursor execute query + '%s' value cursor fetchall result Trueexcept Exception e get_exception result str e return result
def dark_palette color n_colors 6 reverse False as_cmap False gray '#222222'colors [color gray] if reverse else [gray color] return blend_palette colors n_colors as_cmap
def check_non_negative X whom X X data if sp issparse X else X if X < 0 any raise ValueError 'Negativevaluesindatapassedto%s' % whom
def main initLogging verbose True initExperimentPrng @staticmethoddef _mockCreate *args **kwargs kwargs pop 'implementation' None return CLAClassifierDiff *args **kwargs CLAClassifierFactory create _mockCreaterunExperiment sys argv[1 ]
def non_structured_query table query None **kwargs client _get_client client table tableif query is None query_parts []for key value in kwargs items query_parts append '{0} {1}' format key value query '^' join query_parts query str query response client get query return response
def non_structured_query table query None **kwargs client _get_client client table tableif query is None query_parts []for key value in kwargs items query_parts append '{0} {1}' format key value query '^' join query_parts query str query response client get query return response
def generate_bins_generic values binner closed lenidx len values lenbin len binner if lenidx < 0 or lenbin < 0 raise ValueError 'Invalidlengthforvaluesorforbinner' if values[0] < binner[0] raise ValueError 'Valuesfallsbeforefirstbin' if values[ lenidx - 1 ] > binner[ lenbin - 1 ] raise ValueError 'Valuesfallsafterlastbin' bins np empty lenbin - 1 dtype np int64 j 0bc 0for i in range 0 lenbin - 1 r_bin binner[ i + 1 ]while j < lenidx and values[j] < r_bin or closed 'right' and values[j] r_bin j + 1bins[bc] jbc + 1return bins
def generate_bins_generic values binner closed lenidx len values lenbin len binner if lenidx < 0 or lenbin < 0 raise ValueError 'Invalidlengthforvaluesorforbinner' if values[0] < binner[0] raise ValueError 'Valuesfallsbeforefirstbin' if values[ lenidx - 1 ] > binner[ lenbin - 1 ] raise ValueError 'Valuesfallsafterlastbin' bins np empty lenbin - 1 dtype np int64 j 0bc 0for i in range 0 lenbin - 1 r_bin binner[ i + 1 ]while j < lenidx and values[j] < r_bin or closed 'right' and values[j] r_bin j + 1bins[bc] jbc + 1return bins
@undocdef filehash path warn 'filehash isdeprecatedsinceIPython4 0' DeprecationWarning stacklevel 2 with open path 'rU' as f return md5 py3compat str_to_bytes f read hexdigest
def get_config_by_name section name for config in section if config['name'] name return configreturn None
def libvlc_media_player_get_fps p_mi f _Cfunctions get 'libvlc_media_player_get_fps' None or _Cfunction 'libvlc_media_player_get_fps' 1 None ctypes c_float MediaPlayer return f p_mi
def _get_ctf_head_to_head_t idx_points fp idx_points astype '>f8' dp np sum fp[2] * fp[0] - fp[1] tmp1 tmp2 sum_squared fp[2] sum_squared fp[0] - fp[1] dcos - dp / np sqrt tmp1 * tmp2 dsin np sqrt 1 0 - dcos * dcos dt dp / np sqrt tmp2 t np array [[dcos - dsin 0 0 dt] [dsin dcos 0 0 0 0] [0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0]] return Transform 'ctf_head' 'head' t
def camel_to_underscore name import stringfor c in string ascii_uppercase name name replace c '_%c' % c return name strip '_' lower
def camel_to_underscore name import stringfor c in string ascii_uppercase name name replace c '_%c' % c return name strip '_' lower
def write_zfile file_handle data compress 1 file_handle write _ZFILE_PREFIX length hex_str len data file_handle write asbytes length ljust _MAX_LEN file_handle write zlib compress asbytes data compress
def _absolute_flat_glob pattern dirname basename os path split pattern if basename if os path exists pattern yield pattern elif os path isdir dirname yield pattern return
def _absolute_flat_glob pattern dirname basename os path split pattern if basename if os path exists pattern yield pattern elif os path isdir dirname yield pattern return
def _absolute_flat_glob pattern dirname basename os path split pattern if basename if os path exists pattern yield pattern elif os path isdir dirname yield pattern return
def runExperiment args model None opt _parseCommandLineOptions args model _runExperimentImpl opt model return model
def runExperiment args model None opt _parseCommandLineOptions args model _runExperimentImpl opt model return model
def check_path_traversal path user 'root' skip_perm_errors False for tpath in list_path_traversal path if not os access tpath os R_OK msg 'Couldnotaccess{0} ' format tpath if not os path exists tpath msg + 'Pathdoesnotexist 'else current_user salt utils get_user if user current_user msg + 'Tryrunningasuser{0} ' format user else msg + 'Pleasegive{0}readpermissions ' format user if skip_perm_errors returnraise SaltClientError msg
def check_path_traversal path user 'root' skip_perm_errors False for tpath in list_path_traversal path if not os access tpath os R_OK msg 'Couldnotaccess{0} ' format tpath if not os path exists tpath msg + 'Pathdoesnotexist 'else current_user salt utils get_user if user current_user msg + 'Tryrunningasuser{0} ' format user else msg + 'Pleasegive{0}readpermissions ' format user if skip_perm_errors returnraise SaltClientError msg
def makePrintable data charset quote None to_unicode False smart True if data if not isinstance data unicode data unicode data 'ISO-8859-1' charset 'ASCII'data regex_control_code sub lambda regs controlchars[ord regs group 1 ] data if quote if quote in '"\'' data data replace quote '\\' + quote data '' join quote data quote elif quote data ' empty 'data data encode charset 'backslashreplace' if smart data re sub '\\\\x0 [0-7] ? [^0-7] $ ' '\\\\\\1' data if to_unicode data unicode data charset return data
def absent name region None key None keyid None profile None ret {'name' name 'result' True 'comment' '' 'changes' {}}exists __salt__['boto_elb exists'] name region key keyid profile if exists if __opts__['test'] ret['comment'] 'ELB{0}issettoberemoved ' format name ret['result'] Nonereturn retdeleted __salt__['boto_elb delete'] name region key keyid profile if deleted ret['changes']['old'] {'elb' name}ret['changes']['new'] {'elb' None}ret['comment'] 'ELB{0}deleted ' format name else ret['result'] Falseret['comment'] 'Failedtodelete{0}ELB ' format name else ret['comment'] '{0}ELBdoesnotexist ' format name return ret
def create_lead email_id from email utils import parseaddrfrom frappe model naming import get_default_naming_series real_name email_id parseaddr email_id if frappe db get_value u'Lead' {u'email_id' email_id} returnlead frappe get_doc {u'doctype' u'Lead' u'email_id' email_id u'lead_name' real_name or email_id u'status' u'Lead' u'naming_series' get_default_naming_series u'Lead' u'company' frappe db get_default u'Company' u'source' u'Email'} lead insert
def local_home_directory name '' with settings hide 'running' 'stdout' return local 'echo~' + name capture True
def tokenize buf try return parser parse lexer lex buf except LexingError as e pos e getsourcepos raise LexException 'Couldnotidentifythenexttoken ' pos lineno pos colno except LexException as e if e source is None e source bufraise
def auto_decode data for bom encoding in BOMS if data startswith bom return data[len bom ] decode encoding for line in data split '\n' [ 2] if line[0 1] '#' and ENCODING_RE search line encoding ENCODING_RE search line groups [0] decode 'ascii' return data decode encoding return data decode locale getpreferredencoding False
def auto_decode data for bom encoding in BOMS if data startswith bom return data[len bom ] decode encoding for line in data split '\n' [ 2] if line[0 1] '#' and ENCODING_RE search line encoding ENCODING_RE search line groups [0] decode 'ascii' return data decode encoding return data decode locale getpreferredencoding False
def linear m 1 b 0 def f i return m * i + b return partial _force sequence _advance f
def request_user_has_resource_api_permission permission_type def decorate func function_name func __name__if function_name not in ['post'] raise Exception 'Thisdecoratorshouldonlybeusedtowrappostmethods' @wraps func def func_wrapper *args **kwargs resource_api args[1]utils assert_request_user_has_resource_api_permission request pecan request resource_api resource_api permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def request_user_has_resource_api_permission permission_type def decorate func function_name func __name__if function_name not in ['post'] raise Exception 'Thisdecoratorshouldonlybeusedtowrappostmethods' @wraps func def func_wrapper *args **kwargs resource_api args[1]utils assert_request_user_has_resource_api_permission request pecan request resource_api resource_api permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def request_user_has_resource_api_permission permission_type def decorate func function_name func __name__if function_name not in ['post'] raise Exception 'Thisdecoratorshouldonlybeusedtowrappostmethods' @wraps func def func_wrapper *args **kwargs resource_api args[1]utils assert_request_user_has_resource_api_permission request pecan request resource_api resource_api permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def hamming u v u _validate_vector u v _validate_vector v if u shape v shape raise ValueError 'The1darraysmusthaveequallengths ' return u v mean
def PresentDialog message choices default_choice_index 0 to_eval u"confirm '{0}' '{1}' {2} " format EscapeForVim ToUnicode message EscapeForVim ToUnicode u'\n' join choices default_choice_index + 1 try return GetIntValue to_eval - 1 except KeyboardInterrupt return -1
def PresentDialog message choices default_choice_index 0 to_eval u"confirm '{0}' '{1}' {2} " format EscapeForVim ToUnicode message EscapeForVim ToUnicode u'\n' join choices default_choice_index + 1 try return GetIntValue to_eval - 1 except KeyboardInterrupt return -1
def PresentDialog message choices default_choice_index 0 to_eval u"confirm '{0}' '{1}' {2} " format EscapeForVim ToUnicode message EscapeForVim ToUnicode u'\n' join choices default_choice_index + 1 try return GetIntValue to_eval - 1 except KeyboardInterrupt return -1
def newAction parent text slot None shortcut None icon None tip None checkable False enabled True a QAction text parent if icon is not None a setIcon newIcon icon if shortcut is not None if isinstance shortcut list tuple a setShortcuts shortcut else a setShortcut shortcut if tip is not None a setToolTip tip a setStatusTip tip if slot is not None a triggered connect slot if checkable a setCheckable True a setEnabled enabled return a
def _crop image offset_height offset_width crop_height crop_width original_shape tf shape image rank_assertion tf Assert tf equal tf rank image 3 ['Rankofimagemustbeequalto3 '] cropped_shape control_flow_ops with_dependencies [rank_assertion] tf pack [crop_height crop_width original_shape[2]] size_assertion tf Assert tf logical_and tf greater_equal original_shape[0] crop_height tf greater_equal original_shape[1] crop_width ['Cropsizegreaterthantheimagesize '] offsets tf to_int32 tf pack [offset_height offset_width 0] image control_flow_ops with_dependencies [size_assertion] tf slice image offsets cropped_shape return tf reshape image cropped_shape
def get_approved_tools app sa_session tools []for tool in sa_session query app model Tool order_by app model Tool table c name if tool state app model Tool states APPROVED tools append tool return tools
def migrate_tags_on_taxes cr registry env api Environment cr SUPERUSER_ID {} xml_records env['ir model data'] search [ 'model' ' ' 'account tax template' 'module' 'like' 'l10n_%' ] tax_template_ids [x['res_id'] for x in xml_records sudo read ['res_id'] ]for tax_template in env['account tax template'] browse tax_template_ids tax_id env['account tax'] search [ 'name' ' ' tax_template name 'type_tax_use' ' ' tax_template type_tax_use 'description' ' ' tax_template description ] if len tax_id ids 1 tax_id sudo write {'tag_ids' [ 6 0 tax_template tag_ids ids ]}
def migrate_tags_on_taxes cr registry env api Environment cr SUPERUSER_ID {} xml_records env['ir model data'] search [ 'model' ' ' 'account tax template' 'module' 'like' 'l10n_%' ] tax_template_ids [x['res_id'] for x in xml_records sudo read ['res_id'] ]for tax_template in env['account tax template'] browse tax_template_ids tax_id env['account tax'] search [ 'name' ' ' tax_template name 'type_tax_use' ' ' tax_template type_tax_use 'description' ' ' tax_template description ] if len tax_id ids 1 tax_id sudo write {'tag_ids' [ 6 0 tax_template tag_ids ids ]}
def migrate_tags_on_taxes cr registry env api Environment cr SUPERUSER_ID {} xml_records env['ir model data'] search [ 'model' ' ' 'account tax template' 'module' 'like' 'l10n_%' ] tax_template_ids [x['res_id'] for x in xml_records sudo read ['res_id'] ]for tax_template in env['account tax template'] browse tax_template_ids tax_id env['account tax'] search [ 'name' ' ' tax_template name 'type_tax_use' ' ' tax_template type_tax_use 'description' ' ' tax_template description ] if len tax_id ids 1 tax_id sudo write {'tag_ids' [ 6 0 tax_template tag_ids ids ]}
def migrate_tags_on_taxes cr registry env api Environment cr SUPERUSER_ID {} xml_records env['ir model data'] search [ 'model' ' ' 'account tax template' 'module' 'like' 'l10n_%' ] tax_template_ids [x['res_id'] for x in xml_records sudo read ['res_id'] ]for tax_template in env['account tax template'] browse tax_template_ids tax_id env['account tax'] search [ 'name' ' ' tax_template name 'type_tax_use' ' ' tax_template type_tax_use 'description' ' ' tax_template description ] if len tax_id ids 1 tax_id sudo write {'tag_ids' [ 6 0 tax_template tag_ids ids ]}
def get_static_welcome_message return '\n<h3>SearchHelp</h3>\n<ul><li>Thedisplaybelowthelineisanexampleoftheoutputthebrowser\nshowsyouwhenyouenterasearchword Thesearchwordwas<b>green</b> </li>\n<li>Thesearchresultshowsfordifferentpartsofspeechthe<b>synsets</b>\ni e differentmeaningsfortheword </li>\n<li>Allunderlinedtextsarehypertextlinks Therearetwotypesoflinks \nwordlinksandothers Clickingawordlinkcarriesoutasearchfortheword\nintheWordnetdatabase </li>\n<li>Clickingalinkoftheothertypeopensadisplaysectionofdataattached\ntothatlink Clickingthatlinkasecondtimeclosesthesectionagain </li>\n<li>Clicking<u>S </u>opensasectionshowingtherelationsforthatsynset </li>\n<li>Clickingonarelationnameopensasectionthatdisplaystheassociated\nsynsets </li>\n<li>Typeasearchwordinthe<b>NextWord</b>fieldandstartthesearchbythe\n<b>Enter/Return</b>keyorclickthe<b>Search</b>button </li>\n</ul>\n'
def get_cursor source spelling root_cursor source if isinstance source Cursor else source cursor for cursor in root_cursor walk_preorder if cursor spelling spelling return cursorreturn None
def sdm_ecart f return sdm_deg f - sdm_monomial_deg sdm_LM f
def set_log_level_for_all_handlers logger level logging DEBUG logger setLevel level handlers logger handlersfor handler in handlers handler setLevel level return logger
def _parse_interval value try return sorted aniso8601 parse_interval value except ValueError try return aniso8601 parse_datetime value None except ValueError return aniso8601 parse_date value None
def _parse_interval value try return sorted aniso8601 parse_interval value except ValueError try return aniso8601 parse_datetime value None except ValueError return aniso8601 parse_date value None
def cleanup_version sender instance **kw if kw get 'raw' returnfor file_ in instance files all cleanup_file file_ __class__ file_
def adjust_processing_time num_cores workload timing epoch sigma 0 0for i in range num_cores timing[i] workload[i] / timing[i] - epoch sigma + timing[i]spread [None for x in range num_cores ]for i in range num_cores spread[i] timing[i] * num_cores / sigma return spread
def adjust_processing_time num_cores workload timing epoch sigma 0 0for i in range num_cores timing[i] workload[i] / timing[i] - epoch sigma + timing[i]spread [None for x in range num_cores ]for i in range num_cores spread[i] timing[i] * num_cores / sigma return spread
def _create_change_list_from_suggestion suggestion return [{'cmd' exp_domain CMD_EDIT_STATE_PROPERTY 'state_name' suggestion state_name 'property_name' exp_domain STATE_PROPERTY_CONTENT 'new_value' [suggestion state_content]}]
def _create_change_list_from_suggestion suggestion return [{'cmd' exp_domain CMD_EDIT_STATE_PROPERTY 'state_name' suggestion state_name 'property_name' exp_domain STATE_PROPERTY_CONTENT 'new_value' [suggestion state_content]}]
def pseudocorpus source_vocab sep for k in source_vocab if sep not in k continueunigrams k split sep for i in range 1 len unigrams yield [sep join unigrams[ i] sep join unigrams[i ] ]
@_get_clientdef task_get client task_id session None force_show_deleted False return client task_get task_id task_id session session force_show_deleted force_show_deleted
def render_subcommand args if args subcommand 'delete' return 'delete' + args delete_subcommand if args subcommand in 'wal-prefetch' 'wal-push' 'wal-fetch' return Nonereturn args subcommand
@register as_tagdef models_for_pages *args from warnings import warnwarn u'templatetagmodels_for_pagesisdeprectaed usePageAdmin get_content_modelsinstead' from mezzanine pages admin import PageAdminreturn PageAdmin get_content_models
@register as_tagdef models_for_pages *args from warnings import warnwarn u'templatetagmodels_for_pagesisdeprectaed usePageAdmin get_content_modelsinstead' from mezzanine pages admin import PageAdminreturn PageAdmin get_content_models
@register as_tagdef models_for_pages *args from warnings import warnwarn u'templatetagmodels_for_pagesisdeprectaed usePageAdmin get_content_modelsinstead' from mezzanine pages admin import PageAdminreturn PageAdmin get_content_models
@register as_tagdef models_for_pages *args from warnings import warnwarn u'templatetagmodels_for_pagesisdeprectaed usePageAdmin get_content_modelsinstead' from mezzanine pages admin import PageAdminreturn PageAdmin get_content_models
@register as_tagdef models_for_pages *args from warnings import warnwarn u'templatetagmodels_for_pagesisdeprectaed usePageAdmin get_content_modelsinstead' from mezzanine pages admin import PageAdminreturn PageAdmin get_content_models
def get_inner_objects vim base_obj path inner_type properties_to_collect None all False client_factory vim client factorybase_type base_obj _typetraversal_spec vutil build_traversal_spec client_factory 'inner' base_type path False [] object_spec vutil build_object_spec client_factory base_obj [traversal_spec] property_spec vutil build_property_spec client_factory type_ inner_type properties_to_collect properties_to_collect all_properties all property_filter_spec vutil build_property_filter_spec client_factory [property_spec] [object_spec] options client_factory create 'ns0 RetrieveOptions' options maxObjects CONF vmware maximum_objectsreturn vim RetrievePropertiesEx vim service_content propertyCollector specSet [property_filter_spec] options options
def _convert val acceptable_types if isinstance val acceptable_types return valreturn parse_expression val acceptable_types raise_type ParseError
def hwaddr_interfaces ret {}ifaces _get_interfaces for face in ifaces if 'hwaddr' in ifaces[face] ret[face] ifaces[face]['hwaddr']return {'hwaddr_interfaces' ret}
def patched_get_children self usage_key_filter None def iter_children 'skipchildrennotvisibletostudents'for child in GET_CHILDREN self usage_key_filter usage_key_filter child _field_data_cache {}if not child visible_to_staff_only yield child return list iter_children
def patched_get_children self usage_key_filter None def iter_children 'skipchildrennotvisibletostudents'for child in GET_CHILDREN self usage_key_filter usage_key_filter child _field_data_cache {}if not child visible_to_staff_only yield child return list iter_children
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
def _write_key_file key_filename banner public_key secret_key None metadata None encoding 'utf-8' if isinstance public_key bytes public_key public_key decode encoding if isinstance secret_key bytes secret_key secret_key decode encoding with io open key_filename 'w' encoding 'utf8' as f f write banner format datetime datetime now f write u 'metadata\n' if metadata for k v in metadata items if isinstance k bytes k k decode encoding if isinstance v bytes v v decode encoding f write u '{0} {1}\n' format k v f write u 'curve\n' f write u 'public-key "{0}"\n' format public_key if secret_key f write u 'secret-key "{0}"\n' format secret_key
def bootstrap request create_fake_data table BootstrapTable Person objects all order_by '-name' RequestConfig request paginate {'per_page' 10} configure table return render request 'bootstrap_template html' {'table' table}
@taskdef generate_self_signed ctx domain cmd 'opensslreq-x509-nodes-days365-newkeyrsa 2048-keyout{0} key-out{0} crt' format domain ctx run cmd
def parse descriptor try return json load descriptor except logger error "Thefilecouldn'tbeparsed'" logger error descriptor return {}
def pytest_ignore_collect path config if 'appengine/standard' in str path if six PY3 return Trueif 'GAE_SDK_PATH' not in os environ return Truereturn False
def list_team_members team_name profile 'github' ignore_cache False cached_team get_team team_name profile profile if not cached_team log error 'Team{0}doesnotexist ' format team_name return Falseif cached_team get 'members' and not ignore_cache return cached_team get 'members' try client _get_client profile organization client get_organization _get_config_value profile 'org_name' team organization get_team cached_team['id'] except UnknownObjectException as e log exception 'Resourcenotfound {0}' format cached_team['id'] try cached_team['members'] [member login lower for member in team get_members ]return cached_team['members']except UnknownObjectException as e log exception 'Resourcenotfound {0}' format cached_team['id'] return []
def has_plugin_permission user plugin_type permission_type from cms plugin_pool import plugin_poolplugin_class plugin_pool get_plugin plugin_type codename get_model_permission_codename plugin_class model action permission_type return user has_perm codename
def has_plugin_permission user plugin_type permission_type from cms plugin_pool import plugin_poolplugin_class plugin_pool get_plugin plugin_type codename get_model_permission_codename plugin_class model action permission_type return user has_perm codename
def has_plugin_permission user plugin_type permission_type from cms plugin_pool import plugin_poolplugin_class plugin_pool get_plugin plugin_type codename get_model_permission_codename plugin_class model action permission_type return user has_perm codename
def has_plugin_permission user plugin_type permission_type from cms plugin_pool import plugin_poolplugin_class plugin_pool get_plugin plugin_type codename get_model_permission_codename plugin_class model action permission_type return user has_perm codename
def manual_search singleton artist input_ 'Artist ' name input_ 'Track ' if singleton else 'Album ' return artist strip name strip
def describe_api_method_response restApiId resourcePath httpMethod statusCode region None key None keyid None profile None try resource describe_api_resource restApiId resourcePath region region key key keyid keyid profile profile get 'resource' if resource conn _get_conn region region key key keyid keyid profile profile response conn get_method_response restApiId restApiId resourceId resource['id'] httpMethod httpMethod statusCode str statusCode return {'response' _convert_datetime_str response }return {'error' 'nosuchresource'}except ClientError as e return {'error' salt utils boto3 get_error e }
def setup_platform hass config add_callback_devices discovery_info None if discovery_info is None returnhomematic get_component 'homematic' return homematic setup_hmdevice_discovery_helper hass HMSwitch discovery_info add_callback_devices
def boykov_kolmogorov G s t capacity 'capacity' residual None value_only False cutoff None R boykov_kolmogorov_impl G s t capacity residual cutoff R graph['algorithm'] 'boykov_kolmogorov'return R
def boykov_kolmogorov G s t capacity 'capacity' residual None value_only False cutoff None R boykov_kolmogorov_impl G s t capacity residual cutoff R graph['algorithm'] 'boykov_kolmogorov'return R
@contextmanagerdef patch_client target mock_client None with mock patch target as client_getter client mock_client or MockBox client_getter return_value client yield client
def get_service hass config discovery_info None import boto3aws_config config copy del aws_config[CONF_PLATFORM]del aws_config[CONF_NAME]profile aws_config get CONF_PROFILE_NAME if profile is not None boto3 setup_default_session profile_name profile del aws_config[CONF_PROFILE_NAME]sqs_client boto3 client 'sqs' **aws_config return AWSSQS sqs_client
def test_all db from applications sahana modules test_cr import *test_cr db from applications sahana modules test_or import *test_or db from applications sahana modules test_pr import *test_pr db
def make_soap_enveloped_saml_thingy thingy headers None soap_envelope soapenv Envelope if headers _header soapenv Header _header add_extension_elements headers soap_envelope header _headersoap_envelope body soapenv Body soap_envelope body add_extension_element thingy return '%s' % soap_envelope
def _tgrep_bind_node_label_action _s _l tokens if len tokens 1 return tokens[0]else assert len tokens 3 assert tokens[1] u' ' node_pred tokens[0]node_label tokens[2]def node_label_bind_pred n m None l None if node_pred n m l if l is None raise TgrepException u'cannotbindnode_label{0} label_dictisNone' format node_label l[node_label] nreturn Trueelse return Falsereturn node_label_bind_pred
def _tgrep_bind_node_label_action _s _l tokens if len tokens 1 return tokens[0]else assert len tokens 3 assert tokens[1] u' ' node_pred tokens[0]node_label tokens[2]def node_label_bind_pred n m None l None if node_pred n m l if l is None raise TgrepException u'cannotbindnode_label{0} label_dictisNone' format node_label l[node_label] nreturn Trueelse return Falsereturn node_label_bind_pred
def _tgrep_bind_node_label_action _s _l tokens if len tokens 1 return tokens[0]else assert len tokens 3 assert tokens[1] u' ' node_pred tokens[0]node_label tokens[2]def node_label_bind_pred n m None l None if node_pred n m l if l is None raise TgrepException u'cannotbindnode_label{0} label_dictisNone' format node_label l[node_label] nreturn Trueelse return Falsereturn node_label_bind_pred
@api_view u'GET' @renderer_classes TemplateHTMLRenderer def example request data {u'object' u'foobar'}return Response data template_name u'example html'
def createAssembly file_id namespace_id bar_num default_filename 'foo' file_name Directory GetCurrentDirectory + '\\' + default_filename + str file_id + ' cs' file open file_name 'w' print >>file cs_ipy % str namespace_id bar_num file close compileAssembly file_name
def compute_node_get_by_host context host session get_session with session begin service session query models Service filter_by host host binary 'monitor-bmc' first node session query models ComputeNode options joinedload 'service' filter_by deleted False service_id service id return node first
def bin_output func func argtypes [GEOM_PTR POINTER c_size_t ]func errcheck check_sized_stringfunc restype c_uchar_preturn func
def bin_output func func argtypes [GEOM_PTR POINTER c_size_t ]func errcheck check_sized_stringfunc restype c_uchar_preturn func
@webob dec wsgify@util check_accept 'application/json' def get_inventory req context req environ['placement context']uuid util wsgi_path_item req environ 'uuid' resource_class util wsgi_path_item req environ 'resource_class' resource_provider objects ResourceProvider get_by_uuid context uuid inventory objects InventoryList get_all_by_resource_provider_uuid context resource_provider uuid find resource_class if not inventory raise webob exc HTTPNotFound _ 'Noinventoryofclass% class sfor% rp_uuid s' % {'class' resource_class 'rp_uuid' resource_provider uuid} json_formatter util json_error_formatter return _send_inventory req response resource_provider inventory
def load name_or_file f name_or_fileopened Falseif isinstance name_or_file basestring f open name_or_file 'rb' opened Trueelif not hasattr f 'read' raise ValueError 'Readablestreamexpected' name values decode f read s SOL name for n v in values iteritems s[n] vif opened is True f close return s
def list_passwords kwargs None call None response _query 'support' 'password/list' ret {}for item in response['list'] if 'server' in item server item['server']['name']if server not in ret ret[server] []ret[server] append item return ret
def list_passwords kwargs None call None response _query 'support' 'password/list' ret {}for item in response['list'] if 'server' in item server item['server']['name']if server not in ret ret[server] []ret[server] append item return ret
def get_date_formats from django conf import settingsdate_format _ 'DATE_FORMAT' datetime_format _ 'DATETIME_FORMAT' time_format _ 'TIME_FORMAT' if date_format 'DATE_FORMAT' date_format settings DATE_FORMATif datetime_format 'DATETIME_FORMAT' datetime_format settings DATETIME_FORMATif time_format 'TIME_FORMAT' time_format settings TIME_FORMATreturn date_format datetime_format time_format
def env_to_statement env source_file env get 'file' None if source_file return ' %s' % __escape source_file env execute env get 'execute' None if execute return executename env['name']value __escape env['value'] env return '%s %s export%s' % name value name
def describe_file_set modules descriptor FileSet file_descriptors []for module in modules file_descriptors append describe_file module if file_descriptors descriptor files file_descriptorsreturn descriptor
def get_reviews_by_repository_id_changeset_revision app repository_id changeset_revision sa_session app model context currentreturn sa_session query app model RepositoryReview filter and_ app model RepositoryReview repository_id app security decode_id repository_id app model RepositoryReview changeset_revision changeset_revision all
def get_reviews_by_repository_id_changeset_revision app repository_id changeset_revision sa_session app model context currentreturn sa_session query app model RepositoryReview filter and_ app model RepositoryReview repository_id app security decode_id repository_id app model RepositoryReview changeset_revision changeset_revision all
def setup hass config logger logging getLogger __name__ from netdisco service import DiscoveryServicelogging getLogger 'zeroconf' setLevel logging CRITICAL lock threading Lock def new_service_listener service info 'Calledwhenanewserviceisfound 'with lock logger info 'Foundnewservice %s%s' service info comp_plat SERVICE_HANDLERS get service if not comp_plat return component platform comp_platif platform is None discover hass service info component config else load_platform hass component platform info config def start_discovery event 'Startdiscovering 'netdisco DiscoveryService SCAN_INTERVAL netdisco add_listener new_service_listener netdisco start hass bus listen_once EVENT_HOMEASSISTANT_START start_discovery return True
def merge_mean_color graph src dst graph node[dst]['totalcolor'] + graph node[src]['totalcolor']graph node[dst]['pixelcount'] + graph node[src]['pixelcount']graph node[dst]['meancolor'] graph node[dst]['totalcolor'] / graph node[dst]['pixelcount']
def apiname funcname if funcname startswith 'gl' return funcnameelif funcname startswith '_' return '_gl' + funcname[1] upper + funcname[2 ] else return 'gl' + funcname[0] upper + funcname[1 ]
def apiname funcname if funcname startswith 'gl' return funcnameelif funcname startswith '_' return '_gl' + funcname[1] upper + funcname[2 ] else return 'gl' + funcname[0] upper + funcname[1 ]
def plot_lbp_model ax binary_values theta np deg2rad 45 R 1r 0 15w 1 5gray '0 5'plot_circle ax 0 0 radius r color gray for i facecolor in enumerate binary_values x R * np cos i * theta y R * np sin i * theta plot_circle ax x y radius r color str facecolor for x in np linspace - w w 4 ax axvline x color gray ax axhline x color gray ax axis 'image' ax axis 'off' size w + 0 2 ax set_xlim - size size ax set_ylim - size size
def sew_messages_and_reactions messages reactions for message in messages message['reactions'] []converted_messages {message['id'] message for message in messages}for reaction in reactions converted_messages[reaction['message_id']]['reactions'] append reaction return list converted_messages values
def prettify_name name return name replace '_' '' title
def assert_all_changes start_state end_state expected_changes __tracebackhide__ Truestart_files start_stateend_files end_stateif isinstance start_state TestPipResult start_files start_state files_beforeif isinstance end_state TestPipResult end_files end_state files_afterdiff diff_states start_files end_files ignore expected_changes if list diff values [{} {} {}] raise TestFailure 'Unexpectedchanges \n' + '\n' join [ k + ' ' + ' ' join v keys for k v in diff items ] return diff
def assert_all_changes start_state end_state expected_changes __tracebackhide__ Truestart_files start_stateend_files end_stateif isinstance start_state TestPipResult start_files start_state files_beforeif isinstance end_state TestPipResult end_files end_state files_afterdiff diff_states start_files end_files ignore expected_changes if list diff values [{} {} {}] raise TestFailure 'Unexpectedchanges \n' + '\n' join [ k + ' ' + ' ' join v keys for k v in diff items ] return diff
def assert_all_changes start_state end_state expected_changes __tracebackhide__ Truestart_files start_stateend_files end_stateif isinstance start_state TestPipResult start_files start_state files_beforeif isinstance end_state TestPipResult end_files end_state files_afterdiff diff_states start_files end_files ignore expected_changes if list diff values [{} {} {}] raise TestFailure 'Unexpectedchanges \n' + '\n' join [ k + ' ' + ' ' join v keys for k v in diff items ] return diff
def get vm key 'uuid' ret {}vmadm _check_vmadm if key not in ['uuid' 'alias' 'hostname'] ret['Error'] 'Keymustbeeitheruuid aliasorhostname'return retvm lookup '{0} {1}' format key vm one True if 'Error' in vm return vmcmd '{vmadm}get{uuid}' format vmadm vmadm uuid vm res __salt__['cmd run_all'] cmd retcode res['retcode']if retcode 0 ret['Error'] res['stderr'] if 'stderr' in res else _exit_status retcode return retreturn json loads res['stdout']
def get vm key 'uuid' ret {}vmadm _check_vmadm if key not in ['uuid' 'alias' 'hostname'] ret['Error'] 'Keymustbeeitheruuid aliasorhostname'return retvm lookup '{0} {1}' format key vm one True if 'Error' in vm return vmcmd '{vmadm}get{uuid}' format vmadm vmadm uuid vm res __salt__['cmd run_all'] cmd retcode res['retcode']if retcode 0 ret['Error'] res['stderr'] if 'stderr' in res else _exit_status retcode return retreturn json loads res['stdout']
def runProtocolsWithReactor reactorBuilder serverProtocol clientProtocol endpointCreator reactor reactorBuilder buildReactor serverProtocol _setAttributes reactor Deferred clientProtocol _setAttributes reactor Deferred serverFactory _SingleProtocolFactory serverProtocol clientFactory _SingleProtocolFactory clientProtocol serverEndpoint endpointCreator server reactor d serverEndpoint listen serverFactory def gotPort p clientEndpoint endpointCreator client reactor p getHost return clientEndpoint connect clientFactory d addCallback gotPort def failed result log err result 'Connectionsetupfailed ' disconnected gatherResults [serverProtocol _done clientProtocol _done] d addCallback lambda _ disconnected d addErrback failed d addCallback lambda _ needsRunningReactor reactor reactor stop reactorBuilder runReactor reactor return reactor
def runProtocolsWithReactor reactorBuilder serverProtocol clientProtocol endpointCreator reactor reactorBuilder buildReactor serverProtocol _setAttributes reactor Deferred clientProtocol _setAttributes reactor Deferred serverFactory _SingleProtocolFactory serverProtocol clientFactory _SingleProtocolFactory clientProtocol serverEndpoint endpointCreator server reactor d serverEndpoint listen serverFactory def gotPort p clientEndpoint endpointCreator client reactor p getHost return clientEndpoint connect clientFactory d addCallback gotPort def failed result log err result 'Connectionsetupfailed ' disconnected gatherResults [serverProtocol _done clientProtocol _done] d addCallback lambda _ disconnected d addErrback failed d addCallback lambda _ needsRunningReactor reactor reactor stop reactorBuilder runReactor reactor return reactor
def FancyAnalyzer expression '\\s+' stoplist STOP_WORDS minsize 2 maxsize None gaps True splitwords True splitnums True mergewords False mergenums False ret RegexTokenizer expression expression gaps gaps iwf IntraWordFilter splitwords splitwords splitnums splitnums mergewords mergewords mergenums mergenums lcf LowercaseFilter swf StopFilter stoplist stoplist minsize minsize return ret iwf lcf swf
def packages pkg_list repos None yes None options None pkg_list [pkg for pkg in pkg_list if not is_installed pkg ]if pkg_list install pkg_list repos yes options
@removals remove message 'keystoneclientauthpluginsaredeprecated Usekeystoneauth ' version '2 1 0' removal_version '3 0 0' def get_available_plugin_names mgr stevedore ExtensionManager namespace PLUGIN_NAMESPACE invoke_on_load False return frozenset mgr names
def atfork _UserFriendlyRNG reinit
@event listens_for ServiceRouterBinding resource_type 'set' retval True def validate_resource_type target value oldvalue initiator maxlen ServiceRouterBinding resource_type property columns[0] type lengthif len value > maxlen raise AttributeException resource_type value maxlen maxlen return value
@event listens_for ServiceRouterBinding resource_type 'set' retval True def validate_resource_type target value oldvalue initiator maxlen ServiceRouterBinding resource_type property columns[0] type lengthif len value > maxlen raise AttributeException resource_type value maxlen maxlen return value
def clean_app_id app_id if app_id startswith 's~' return app_id[2 ]return app_id
def clean_app_id app_id if app_id startswith 's~' return app_id[2 ]return app_id
def MakeOtherAppResponse reference json loads kVerifyResponseRenewedExpired new {'status' 0 'receipt' reference['receipt']}new['receipt']['bid'] 'com angrybirds AngryBirds'return json dumps new
def createservicesid svc uni '' join [ c + '\x00' for c in svc] sha hashlib sha1 uni upper digest dec list for i in range 5 dec append struct unpack '<I' sha[ i * 4 i * 4 + 4 ] [0] return 'S-1-5-80-' + '-' join [str n for n in dec]
def model_form model db_session None base_class Form only None exclude None field_args None converter None exclude_pk True exclude_fk True type_name None if not hasattr model u'_sa_class_manager' raise TypeError u'modelmustbeasqlalchemymappedmodel' if not exclude exclude []model_mapper model __mapper__for prop in model_mapper iterate_properties if not hasattr prop u'direction' and prop columns[0] primary_key if exclude_pk exclude append prop key if hasattr prop u'direction' and exclude_fk and prop direction name u'MANYTOMANY' for pair in prop local_remote_pairs exclude append pair[0] key type_name type_name or str model __name__ + u'Form' field_dict model_fields model db_session only exclude field_args converter return type type_name base_class field_dict
def mulmatscaler matlist scaler K return [mulrowscaler row scaler K for row in matlist]
def mulmatscaler matlist scaler K return [mulrowscaler row scaler K for row in matlist]
@memoize prefix 'get_excluded_in' def get_excluded_in region_id aers list AddonExcludedRegion objects filter region region_id values_list 'addon' flat True geodata_qs Q region parse_region region_id if region in mkt regions BRA mkt regions DEU geodata_qs Q **{ 'region_%s_iarc_exclude' % region slug True} if region mkt regions DEU geodata_qs Q **{'region_de_usk_exclude' True} geodata_exclusions []if geodata_qs geodata_exclusions list Geodata objects filter geodata_qs values_list 'addon' flat True return set aers + geodata_exclusions
def stftSynth mY pY M H hM1 int math floor M + 1 / 2 hM2 int math floor M / 2 nFrames mY[ 0] sizey np zeros nFrames * H + hM1 + hM2 pin hM1for i in range nFrames y1 DFT dftSynth mY[i ] pY[i ] M y[ pin - hM1 pin + hM2 ] + H * y1 pin + Hy np delete y range hM2 y np delete y range y size - hM1 y size return y
def get_task name host __salt__['config option'] 'kapacitor host' 'localhost' port __salt__['config option'] 'kapacitor port' 9092 if version < '0 13' url 'http //{0} {1}/task?name {2}' format host port name else url 'http //{0} {1}/kapacitor/v1/tasks/{2}?skip-format true' format host port name response salt utils http query url status True if response['status'] 404 return Nonedata json loads response['body'] if version < '0 13' return {'script' data['TICKscript'] 'type' data['Type'] 'dbrps' data['DBRPs'] 'enabled' data['Enabled']}return {'script' data['script'] 'type' data['type'] 'dbrps' data['dbrps'] 'enabled' data['status'] 'enabled' }
def compact_text text elidelength None lines []for line in text splitlines lines append line strip out '' join lines if elidelength is not None out elide out elidelength return out
def _find_channels ch_names ch_type 'EOG' substrings ch_type substrings [s upper for s in substrings]if ch_type 'EOG' substrings 'EOG' 'EYE' eog_idx [idx for idx ch in enumerate ch_names if any substring in ch upper for substring in substrings ]return eog_idx
def _find_match ele lst for _ele in lst for match_key in _MATCH_KEYS if _ele get match_key ele get match_key return _ele
def dump_objects blocks []lines []blocks append 'global' global_registry dump_objects for win_id in window_registry registry _get_registry 'window' window win_id blocks append 'window-{}' format win_id registry dump_objects tab_registry get 'tab-registry' scope 'window' window win_id for tab_id tab in tab_registry items dump tab registry dump_objects data [ '' + line for line in dump]blocks append 'tab-{}' format tab_id data for name data in blocks lines append '' lines append '{}objectregistry-{}objects ' format name len data for line in data lines append '{}' format line return lines
def random_organism genome random_genome return Organism genome test_fitness
def tree_support master subsampled_tree master_tipnames set master getTipNames subsampled_tree_trimmed copy deepcopy subsampled_tree def delete_test node if not node isTip return Falseelse return node Name not in master_tipnames subsampled_tree_trimmed removeDeleted delete_test subsampled_tree_trimmed prune subsampled_tree_nodes_names []for node in subsampled_tree_trimmed iterNontips include_self True subsampled_tree_nodes_names append node getTipNames subsampled_tree_nodes_names map set subsampled_tree_nodes_names for master_node in master iterNontips include_self True if set master_node getTipNames in subsampled_tree_nodes_names try master_node bootstrap_support + 1except AttributeError master_node bootstrap_support 1
def tree_support master subsampled_tree master_tipnames set master getTipNames subsampled_tree_trimmed copy deepcopy subsampled_tree def delete_test node if not node isTip return Falseelse return node Name not in master_tipnames subsampled_tree_trimmed removeDeleted delete_test subsampled_tree_trimmed prune subsampled_tree_nodes_names []for node in subsampled_tree_trimmed iterNontips include_self True subsampled_tree_nodes_names append node getTipNames subsampled_tree_nodes_names map set subsampled_tree_nodes_names for master_node in master iterNontips include_self True if set master_node getTipNames in subsampled_tree_nodes_names try master_node bootstrap_support + 1except AttributeError master_node bootstrap_support 1
def _read_cookie cookie_path is_safecookie if not os path exists cookie_path exc_msg "Authenticationfailed '%s'doesn'texist" % cookie_path raise UnreadableCookieFile exc_msg cookie_path is_safecookie auth_cookie_size os path getsize cookie_path if auth_cookie_size 32 exc_msg "Authenticationfailed authenticationcookie'%s'isthewrongsize %ibytesinsteadof32 " % cookie_path auth_cookie_size raise IncorrectCookieSize exc_msg cookie_path is_safecookie try with open cookie_path 'rb' 0 as f return f read except IOError as exc exc_msg "Authenticationfailed unabletoread'%s' %s " % cookie_path exc raise UnreadableCookieFile exc_msg cookie_path is_safecookie
def showglobal **connection_args mod sys _getframe f_code co_namelog debug '{0}<--' format mod conn _connect **connection_args if conn is None return []rtnv __do_query_into_hash conn 'SHOWGLOBALVARIABLES' conn close if len rtnv 0 rtnv append [] log debug '{0}-->{1}' format mod len rtnv[0] return rtnv
def build_branches project branch_list for branch in branch_list versions project versions_from_branch_name branch to_build set not_building set for version in versions log info ' BranchBuild Processing%s %s' % project slug version slug ret _build_version project version slug already_built to_build if ret to_build add ret else not_building add version slug return to_build not_building
def build_branches project branch_list for branch in branch_list versions project versions_from_branch_name branch to_build set not_building set for version in versions log info ' BranchBuild Processing%s %s' % project slug version slug ret _build_version project version slug already_built to_build if ret to_build add ret else not_building add version slug return to_build not_building
def __virtual__ if HAS_ALL_IMPORTS return Truereturn False 'Themssqlexecutionmodulecannotbeloaded thepymssqlpythonlibraryisnotavailable '
def __virtual__ if HAS_ALL_IMPORTS return Truereturn False 'Themssqlexecutionmodulecannotbeloaded thepymssqlpythonlibraryisnotavailable '
def acc_check expected got rel_err 2e-15 abs_err 5e-323 if math isinf expected and got expected return Noneerror got - expected permitted_error max abs_err rel_err * abs expected if abs error < permitted_error return Nonereturn 'error {} permittederror {}' format error permitted_error
def _normalize_step_parameters steps param_map legacy False already_normalized False normalized_param_map {}for step in steps if already_normalized param_dict param_map get str step order_index {} else param_dict _step_parameters step param_map legacy legacy if param_dict normalized_param_map[step id] param_dictreturn normalized_param_map
def _normalize_step_parameters steps param_map legacy False already_normalized False normalized_param_map {}for step in steps if already_normalized param_dict param_map get str step order_index {} else param_dict _step_parameters step param_map legacy legacy if param_dict normalized_param_map[step id] param_dictreturn normalized_param_map
def _normalize_step_parameters steps param_map legacy False already_normalized False normalized_param_map {}for step in steps if already_normalized param_dict param_map get str step order_index {} else param_dict _step_parameters step param_map legacy legacy if param_dict normalized_param_map[step id] param_dictreturn normalized_param_map
@task@needs ['setup_geoserver'] def setup options info 'GeoNodedevelopmentenvironmentsuccessfullysetup Ifyouhavenotsetupanadministrativeaccount pleasedosonow Use"paverstart"tostartuptheserver '
def _roll_vectorized M roll_indices axis assert axis in [0 1] ndim M ndimassert ndim 3 ndim_roll roll_indices ndimassert ndim_roll 1 sh M shape r c sh[ -2 ]assert sh[0] roll_indices shape[0] vec_indices np arange sh[0] dtype np int32 M_roll np empty_like M if axis 0 for ir in range r for ic in range c M_roll[ ir ic] M[ vec_indices - roll_indices + ir % r ic ]elif axis 1 for ir in range r for ic in range c M_roll[ ir ic] M[ vec_indices ir - roll_indices + ic % c ]return M_roll
def _expand_expected_codes codes retval set for code in codes replace ' ' '' split '' code code strip if not code continueelif '-' in code low hi code split '-' [ 2]retval update str i for i in xrange int low int hi + 1 else retval add code return retval
def observe_lr optimizer_name 'main' observation_key 'lr' return observe_value observation_key lambda trainer trainer updater get_optimizer optimizer_name lr
def _get_enabled_provider provider_id enabled_provider provider Registry get provider_id if not enabled_provider raise ValueError 'Provider%snotenabled' % provider_id return enabled_provider
def _get_enabled_provider provider_id enabled_provider provider Registry get provider_id if not enabled_provider raise ValueError 'Provider%snotenabled' % provider_id return enabled_provider
def escape_identifier text reg KWD_RE if not text return '_'if text[0] isdigit text '_' + text return reg sub '\\1_' text
def reload_modules return True
def reload_modules return True
def CMakeStringEscape a return a replace '\\' '\\\\' replace ' ' '\\ ' replace '"' '\\"'
def process_tex lines new_lines []for line in lines line re sub '^\\s*\\\\strong{SeeAlso }\\s*$' '\\paragraph{SeeAlso}' line if line startswith '\\section{scipy ' or line startswith '\\subsection{scipy ' or line startswith '\\subsubsection{scipy ' or line startswith '\\paragraph{scipy ' or line startswith '\\subparagraph{scipy ' passelse new_lines append line return new_lines
def run api_port 8082 address None unix_socket None scheduler None if scheduler is None scheduler Scheduler scheduler load _init_api scheduler scheduler api_port api_port address address unix_socket unix_socket pruner tornado ioloop PeriodicCallback scheduler prune 60000 pruner start def shutdown_handler signum frame exit_handler sys exit 0 @atexit registerdef exit_handler logger info 'Schedulerinstanceshuttingdown' scheduler dump stop signal signal signal SIGINT shutdown_handler signal signal signal SIGTERM shutdown_handler if os name 'nt' signal signal signal SIGBREAK shutdown_handler else signal signal signal SIGQUIT shutdown_handler logger info 'Schedulerstartingup' tornado ioloop IOLoop instance start
def build_pillar_data options pillar {'test_transport' options test_transport 'cloud_only' options cloud_only 'with_coverage' options test_without_coverage is False }if options test_git_commit is not None pillar['test_git_commit'] options test_git_commitif options test_git_url is not None pillar['test_git_url'] options test_git_urlif options bootstrap_salt_url is not None pillar['bootstrap_salt_url'] options bootstrap_salt_urlif options bootstrap_salt_commit is not None pillar['bootstrap_salt_commit'] options bootstrap_salt_commitif options package_source_dir pillar['package_source_dir'] options package_source_dirif options package_build_dir pillar['package_build_dir'] options package_build_dirif options package_artifact_dir pillar['package_artifact_dir'] options package_artifact_dirif options pillar pillar update dict options pillar return yaml dump pillar default_flow_style True indent 0 width sys maxint rstrip
def build_pillar_data options pillar {'test_transport' options test_transport 'cloud_only' options cloud_only 'with_coverage' options test_without_coverage is False }if options test_git_commit is not None pillar['test_git_commit'] options test_git_commitif options test_git_url is not None pillar['test_git_url'] options test_git_urlif options bootstrap_salt_url is not None pillar['bootstrap_salt_url'] options bootstrap_salt_urlif options bootstrap_salt_commit is not None pillar['bootstrap_salt_commit'] options bootstrap_salt_commitif options package_source_dir pillar['package_source_dir'] options package_source_dirif options package_build_dir pillar['package_build_dir'] options package_build_dirif options package_artifact_dir pillar['package_artifact_dir'] options package_artifact_dirif options pillar pillar update dict options pillar return yaml dump pillar default_flow_style True indent 0 width sys maxint rstrip
def lighten color percent return adjust color 2 percent
def apply_single_tag_set tag_set selection def tags_match server_tags for key value in tag_set items if key not in server_tags or server_tags[key] value return Falsereturn Truereturn selection with_server_descriptions [s for s in selection server_descriptions if tags_match s tags ]
def apply_single_tag_set tag_set selection def tags_match server_tags for key value in tag_set items if key not in server_tags or server_tags[key] value return Falsereturn Truereturn selection with_server_descriptions [s for s in selection server_descriptions if tags_match s tags ]
def serverFactoryFor protocol factory ServerFactory factory protocol protocolreturn factory
def load data _get_data names data dtype namesdataset Dataset data data names names return dataset
@domain_constructor loss_target -2 def distractor x hp uniform 'x' -15 15 f1 old_div 1 0 1 0 + scope exp - x f2 2 * scope exp - x + 10 ** 2 return {'loss' - f1 - f2 'status' base STATUS_OK}
def splittext text line_len if len text < line_len return text '' pos min len text - 1 line_len while pos > 0 and text[pos] '' pos - 1if pos 0 pos min len text line_len while len text > pos and text[pos] '' pos + 1return text[ pos] text[ pos + 1 ] strip
def splittext text line_len if len text < line_len return text '' pos min len text - 1 line_len while pos > 0 and text[pos] '' pos - 1if pos 0 pos min len text line_len while len text > pos and text[pos] '' pos + 1return text[ pos] text[ pos + 1 ] strip
def _validate G for name in G nodes if 'value' not in G node[name] and 'template' not in G node[name] msg 'Dependecyunsatisfiedin%s' % name raise ParamException msg if not nx is_directed_acyclic_graph G msg 'Cyclicdependecyfound'raise ParamException msg
def bzr_wc_default_target test 'bzr_wc_default_target'puts magenta 'Executingtest %s' % test from fabtools files import is_dirfrom fabtools import requireassert not is_dir DIR require bazaar working_copy REMOTE_URL assert_wc_exists DIR
@pytest mark cmd@pytest mark django_dbdef test_update_tmserver_files_no_displayname capfd settings tmpdir settings POOTLE_TM_SERVER {'external' {'ENGINE' 'pootle core search backends ElasticSearchBackend' 'HOST' 'localhost' 'PORT' 9200 'INDEX_NAME' 'translations-external'}}with pytest raises CommandError as e call_command 'update_tmserver' '--tm external' 'fake_file po' assert '--display-name' in str e
@pytest mark cmd@pytest mark django_dbdef test_update_tmserver_files_no_displayname capfd settings tmpdir settings POOTLE_TM_SERVER {'external' {'ENGINE' 'pootle core search backends ElasticSearchBackend' 'HOST' 'localhost' 'PORT' 9200 'INDEX_NAME' 'translations-external'}}with pytest raises CommandError as e call_command 'update_tmserver' '--tm external' 'fake_file po' assert '--display-name' in str e
def setup_platform hass config add_devices_callback discovery_info None add_devices_callback [DemoRemote 'RemoteOne' False None DemoRemote 'RemoteTwo' True 'mdi remote' ]
def _ansi method def wrapper self *args **kwargs def convert inp if isinstance inp basestring return parse_ansi '{n%s{n' % inp elif hasattr inp '__iter__' li []for element in inp if isinstance element basestring li append convert element elif hasattr element '__iter__' li append convert element else li append element return lireturn inpargs [convert arg for arg in args]return method self *args **kwargs return wrapper
def is_base text return min [ ord char in BASE_CHARS for char in text]
def AddCrossEntropy batch_size n cross_entropies []def _Pass return tf constant 0 dtype tf float32 shape [1] for beam_id in range batch_size beam_gold_slot tf reshape tf slice n['gold_slot'] [beam_id] [1] [1] def _ComputeCrossEntropy 'Addsopstocomputecrossentropyofthegoldpathinabeam 'idx tf cast tf reshape tf where tf equal n['beam_ids'] beam_id [ -1 ] tf int32 beam_scores tf reshape tf gather n['all_path_scores'] idx [1 -1 ] num tf shape idx return tf nn softmax_cross_entropy_with_logits beam_scores tf expand_dims tf sparse_to_dense beam_gold_slot num [1 0] 0 0 0 cross_entropies append cf cond beam_gold_slot[0] > 0 _ComputeCrossEntropy _Pass return {'cross_entropy' tf div tf add_n cross_entropies batch_size }
def fix_pyext mod_path if mod_path[ -4 ] in [' pyo' 'pyc'] mod_path mod_path[ -1 ]return mod_path
def fix_pyext mod_path if mod_path[ -4 ] in [' pyo' 'pyc'] mod_path mod_path[ -1 ]return mod_path
def fit_fr self data *args **kwds loc0 scale0 lmap kwds get ['loc' 'scale'] [0 0 1 0] Narg len args if Narg 0 and hasattr self '_fitstart' x0 self _fitstart data elif Narg > self numargs raise ValueError 'Toomanyinputarguments ' else args + 1 0 * self numargs - Narg x0 args + loc0 scale0 if 'frozen' in kwds frmask np array kwds['frozen'] if len frmask self numargs + 2 raise ValueError 'Incorrectnumberoffrozenarguments ' else x0 np array x0 [np isnan frmask ]else frmask Nonereturn optimize fmin self nnlf_fr x0 args np ravel data frmask disp 0
def fit_fr self data *args **kwds loc0 scale0 lmap kwds get ['loc' 'scale'] [0 0 1 0] Narg len args if Narg 0 and hasattr self '_fitstart' x0 self _fitstart data elif Narg > self numargs raise ValueError 'Toomanyinputarguments ' else args + 1 0 * self numargs - Narg x0 args + loc0 scale0 if 'frozen' in kwds frmask np array kwds['frozen'] if len frmask self numargs + 2 raise ValueError 'Incorrectnumberoffrozenarguments ' else x0 np array x0 [np isnan frmask ]else frmask Nonereturn optimize fmin self nnlf_fr x0 args np ravel data frmask disp 0
def fit_fr self data *args **kwds loc0 scale0 lmap kwds get ['loc' 'scale'] [0 0 1 0] Narg len args if Narg 0 and hasattr self '_fitstart' x0 self _fitstart data elif Narg > self numargs raise ValueError 'Toomanyinputarguments ' else args + 1 0 * self numargs - Narg x0 args + loc0 scale0 if 'frozen' in kwds frmask np array kwds['frozen'] if len frmask self numargs + 2 raise ValueError 'Incorrectnumberoffrozenarguments ' else x0 np array x0 [np isnan frmask ]else frmask Nonereturn optimize fmin self nnlf_fr x0 args np ravel data frmask disp 0
def maybe_unwrap_results results return getattr results '_results' results
def summarize_items items singleton summary_parts []if not singleton summary_parts append '{0}items' format len items format_counts {}for item in items format_counts[item format] format_counts get item format 0 + 1 if len format_counts 1 summary_parts append items[0] format else for format count in format_counts iteritems summary_parts append '{0}{1}' format format count average_bitrate sum [item bitrate for item in items] / len items total_duration sum [item length for item in items] summary_parts append '{0}kbps' format int average_bitrate / 1000 summary_parts append ui human_seconds_short total_duration return ' ' join summary_parts
def summarize_items items singleton summary_parts []if not singleton summary_parts append '{0}items' format len items format_counts {}for item in items format_counts[item format] format_counts get item format 0 + 1 if len format_counts 1 summary_parts append items[0] format else for format count in format_counts iteritems summary_parts append '{0}{1}' format format count average_bitrate sum [item bitrate for item in items] / len items total_duration sum [item length for item in items] summary_parts append '{0}kbps' format int average_bitrate / 1000 summary_parts append ui human_seconds_short total_duration return ' ' join summary_parts
def summarize_items items singleton summary_parts []if not singleton summary_parts append '{0}items' format len items format_counts {}for item in items format_counts[item format] format_counts get item format 0 + 1 if len format_counts 1 summary_parts append items[0] format else for format count in format_counts iteritems summary_parts append '{0}{1}' format format count average_bitrate sum [item bitrate for item in items] / len items total_duration sum [item length for item in items] summary_parts append '{0}kbps' format int average_bitrate / 1000 summary_parts append ui human_seconds_short total_duration return ' ' join summary_parts
def get_major_version version None version get_complete_version version parts 2 if version[2] 0 else 3 major u' ' join str x for x in version[ parts] return major
def _init_pathinfo d set for dir in sys path try if os path isdir dir dir dircase makepath dir d add dircase except TypeError continuereturn d
def _test_output ret action params if action 'list' ret['comment'] + 'Thelistactionwilljustlistanentityandwillmakenochanges \n'elif action 'create' or action 'add' ret['comment'] + 'Thecreateactionwillattempttocreateanentityifitdoesnotalreadyexist \n'elif action 'delete' ret['comment'] + 'Thedeleteactionwillattempttodeleteanexistingentityifitexists \n'elif action 'manage' ret['comment'] + 'Themanageactionwillcreateanewentityifitdoesnotexist Ifitdoesexist itwillbeenforcedtothedesiredstate \n'elif action 'modify' ret['comment'] + 'Themodifyactionwillattempttomodifyanexistingentityonlyifitexists \n'ret['comment'] + 'AniControlRESTRequestwillbemadeusingtheparameters \n'ret['comment'] + json dumps params indent 4 ret['changes'] {}ret['result'] Nonereturn ret
def _make_compound_key table key if not isinstance key list tuple key [key]return [table columns[name] for name in key]
def _build_id_tuple params spec if spec is None return None None required_class spec class_required_tag spec tagtag_type params get u'tag_type' spec tag_type if tag_type is not None required_class 2required_class params get u'class_' required_class required_tag params get u'tag' required_tag return required_class required_tag
def _build_id_tuple params spec if spec is None return None None required_class spec class_required_tag spec tagtag_type params get u'tag_type' spec tag_type if tag_type is not None required_class 2required_class params get u'class_' required_class required_tag params get u'tag' required_tag return required_class required_tag
def _build_id_tuple params spec if spec is None return None None required_class spec class_required_tag spec tagtag_type params get u'tag_type' spec tag_type if tag_type is not None required_class 2required_class params get u'class_' required_class required_tag params get u'tag' required_tag return required_class required_tag
def DNSServiceResolve flags 0 interfaceIndex _NO_DEFAULT name _NO_DEFAULT regtype _NO_DEFAULT domain _NO_DEFAULT callBack None _NO_DEFAULT check interfaceIndex _NO_DEFAULT check name _NO_DEFAULT check regtype _NO_DEFAULT check domain @_DNSServiceResolveReplydef _callback sdRef flags interfaceIndex errorCode fullname hosttarget port txtLen txtRecord context if callBack is not None port socket ntohs port txtRecord _length_and_void_p_to_string txtLen txtRecord callBack sdRef flags interfaceIndex errorCode fullname decode hosttarget decode port txtRecord _global_lock acquire try sdRef _DNSServiceResolve flags interfaceIndex name regtype domain _callback None finally _global_lock release sdRef _add_callback _callback return sdRef
def DNSServiceResolve flags 0 interfaceIndex _NO_DEFAULT name _NO_DEFAULT regtype _NO_DEFAULT domain _NO_DEFAULT callBack None _NO_DEFAULT check interfaceIndex _NO_DEFAULT check name _NO_DEFAULT check regtype _NO_DEFAULT check domain @_DNSServiceResolveReplydef _callback sdRef flags interfaceIndex errorCode fullname hosttarget port txtLen txtRecord context if callBack is not None port socket ntohs port txtRecord _length_and_void_p_to_string txtLen txtRecord callBack sdRef flags interfaceIndex errorCode fullname decode hosttarget decode port txtRecord _global_lock acquire try sdRef _DNSServiceResolve flags interfaceIndex name regtype domain _callback None finally _global_lock release sdRef _add_callback _callback return sdRef
def get_link_name connection link if link return connection follow_link link nameelse return None
def perform_check prerelease current_version is_prerelease pypi current_versiontry pypi available_on_pypi prerelease except Exception log warning 'AnissueoccurredwhilecheckingPyPI' best max pypi current_version where Nonecommand Nonecache cache_file if cache os utime cache None if best current_version log info 'YouhavethelatestversionofPwntools %s ' % best returncommand ['pip' 'install' '-U']if best pypi where 'pypi'pypi_package package_nameif best is_prerelease pypi_package + ' %s' % best command + [pypi_package]command_str '' join command log info 'Anewerversionof%sisavailableon%s %s-->%s \n' % package_name where current_version best + 'Updatewith $%s' % command_str return command
def virtual_root resource request try reg request registryexcept AttributeError reg get_current_registry url_adapter reg queryMultiAdapter resource request IResourceURL if url_adapter is None url_adapter ResourceURL resource request vpath rpath url_adapter virtual_path url_adapter physical_path if rpath vpath and rpath endswith vpath vroot_path rpath[ - len vpath ]return find_resource resource vroot_path try return request rootexcept AttributeError return find_root resource
def get_annotated_content_infos course_id thread user user_info infos {}def annotate content infos[str content['id'] ] get_annotated_content_info course_id content user user_info for child in content get 'children' [] + content get 'endorsed_responses' [] + content get 'non_endorsed_responses' [] annotate child annotate thread return infos
def mount filesystem mountpoint options None filesystem IMountableFilesystem filesystem command ['mount']if options command extend ['--options' ' ' join options ] command extend [filesystem identifier mountpoint path] try run_process command except CalledProcessError as e raise MountError blockdevice filesystem device_path mountpoint mountpoint source_message e output return MountedFileSystem mountpoint mountpoint
def strip_remotes remote_branches branches [utils strip_one branch for branch in remote_branches]return [branch for branch in branches if branch u'HEAD' ]
def present name filename section value parameter None if parameter is None parameter nameret {'name' name 'changes' {} 'result' False 'comment' ''}try old_value __salt__['openstack_config get'] filename filename section section parameter parameter if old_value value ret['result'] Trueret['comment'] 'Thevalueisalreadysettothecorrectvalue'return retif __opts__['test'] ret['result'] Noneret['comment'] "Value'{0}'issettobechangedto'{1}' " format old_value value return retexcept CommandExecutionError as e if not str e lower startswith 'parameternotfound ' raise__salt__['openstack_config set'] filename filename section section parameter parameter value value ret['changes'] {'Value' 'Updated'}ret['result'] Trueret['comment'] 'Thevaluehasbeenupdated'return ret
def _get_summary rsync_out return '-' + '\n-' join [elm for elm in rsync_out split '\n\n' [ -1 ] replace '' '\n' split '\n' if elm]
def read handle record __read handle remainder handle read if remainder raise ValueError 'MorethanonePrositerecordfound' return record
def parse_comment message return {'event' 'commented' 'type' message['type'] 'values' {'user' get_owner_name message 'subject' get_subject message }}
def _fit_edges_polyfit x window_length polyorder deriv delta axis y halflen window_length // 2 _fit_edge x 0 window_length 0 halflen axis polyorder deriv delta y n x shape[axis]_fit_edge x n - window_length n n - halflen n axis polyorder deriv delta y
def _fit_edges_polyfit x window_length polyorder deriv delta axis y halflen window_length // 2 _fit_edge x 0 window_length 0 halflen axis polyorder deriv delta y n x shape[axis]_fit_edge x n - window_length n n - halflen n axis polyorder deriv delta y
def asynchronous datastore False obj_store False log_store False def _asynchronous method def _wrapper self *args **kwargs 'DisablesautomaticHTTPresponsecompletiononexit 'self _auto_finish Falseif datastore self _client DBClient Instance if obj_store self _obj_store ObjectStore GetInstance ObjectStore PHOTO if log_store self _log_store ObjectStore GetInstance ObjectStore USER_LOG with util ExceptionBarrier self _stack_context_handle_exception return method self *args **kwargs return functools wraps method _wrapper return _asynchronous
def expand_env_var env_var if not env_var return env_varwhile True interpolated os path expanduser os path expandvars str env_var if interpolated env_var return interpolatedelse env_var interpolated
def expand_env_var env_var if not env_var return env_varwhile True interpolated os path expanduser os path expandvars str env_var if interpolated env_var return interpolatedelse env_var interpolated
def expand_env_var env_var if not env_var return env_varwhile True interpolated os path expanduser os path expandvars str env_var if interpolated env_var return interpolatedelse env_var interpolated
def expand_env_var env_var if not env_var return env_varwhile True interpolated os path expanduser os path expandvars str env_var if interpolated env_var return interpolatedelse env_var interpolated
def drt_discourse_demo reading_command None dt DiscourseTester ['everydogchasesaboy' 'heruns'] reading_command dt models print dt sentences print dt readings print dt readings show_thread_readings True print dt readings filter True show_thread_readings True
def quicksort a n len a if n < 1 return aelse from random import randrangepivot a pop randrange n lesser quicksort [x for x in a if x < pivot ] greater quicksort [x for x in a if x > pivot ] return lesser + [pivot] + greater
def quicksort a n len a if n < 1 return aelse from random import randrangepivot a pop randrange n lesser quicksort [x for x in a if x < pivot ] greater quicksort [x for x in a if x > pivot ] return lesser + [pivot] + greater
def _crawl_attribute this_data this_attr if isinstance this_data list t_list []for d in this_data t_list append _crawl_attribute d this_attr return t_listelif isinstance this_attr dict t_dict {}for k in this_attr keys if hasattr this_data k t_dict[k] _crawl_attribute getattr this_data k None this_attr[k] return t_dictelif isinstance this_attr list this_dict {}for l in this_attr this_dict dictupdate update this_dict _crawl_attribute this_data l return this_dictelse return {this_attr _recurse_config_to_dict getattr this_data this_attr None }
def getElementsByTagName iNode name matches []matches_append matches appendslice [iNode]while len slice > 0 c slice pop 0 if c nodeName name matches_append c slice[ 0] c childNodesreturn matches
def browser_sessid session *args **kwargs if not session browserid print 'storedbrowserid ' session args[0]session browserid args[0]if not session logged_in browsersession BrowserSessionStore session_key args[0] uid browsersession get 'logged_in' None if uid try player PlayerDB objects get pk uid except Exception returnsession sessionhandler login session player
def browser_sessid session *args **kwargs if not session browserid print 'storedbrowserid ' session args[0]session browserid args[0]if not session logged_in browsersession BrowserSessionStore session_key args[0] uid browsersession get 'logged_in' None if uid try player PlayerDB objects get pk uid except Exception returnsession sessionhandler login session player
def _run_checker_for_package checker package_name extra_ignore None ignore_strings IGNORE_ERRORSif extra_ignore ignore_strings + extra_ignorepackage_path path_for_import package_name for root dirs files in os walk str package_path for f in files if f u'local_settings py' or not f endswith u' py' or root split os sep [ -1 ] in [u'migrations'] continuefor warning in checker os path join root f for ignore in ignore_strings if ignore in warning breakelse yield warning replace package_path package_name 1
def _run_checker_for_package checker package_name extra_ignore None ignore_strings IGNORE_ERRORSif extra_ignore ignore_strings + extra_ignorepackage_path path_for_import package_name for root dirs files in os walk str package_path for f in files if f u'local_settings py' or not f endswith u' py' or root split os sep [ -1 ] in [u'migrations'] continuefor warning in checker os path join root f for ignore in ignore_strings if ignore in warning breakelse yield warning replace package_path package_name 1
def poll *args **kwargs return _get_poller *args **kwargs
def override_pylons_about_with_core_template return render_template u'home/about html'
def update_tr_radius Delta actual_reduction predicted_reduction step_norm bound_hit if predicted_reduction > 0 ratio actual_reduction / predicted_reduction else ratio 0if ratio < 0 25 Delta 0 25 * step_norm elif ratio > 0 75 and bound_hit Delta * 2 0return Delta ratio
def run_test_on_partitions job test partitions mountpoint_func tag fs_opt do_fsck True **dargs for p in partitions p set_fs_options fs_opt parallel partitions 'setup_before_test' mountpoint_func mountpoint_func mountpoint mountpoint_func partitions[0] job run_test test tag tag partitions partitions dir mountpoint **dargs parallel partitions 'unmount' if do_fsck parallel partitions 'fsck'
def run_test_on_partitions job test partitions mountpoint_func tag fs_opt do_fsck True **dargs for p in partitions p set_fs_options fs_opt parallel partitions 'setup_before_test' mountpoint_func mountpoint_func mountpoint mountpoint_func partitions[0] job run_test test tag tag partitions partitions dir mountpoint **dargs parallel partitions 'unmount' if do_fsck parallel partitions 'fsck'
def _formatExample example substitutions yield u'**Example **{}' format example doc yield u'' yield u'Request' yield u'' yield u' sourcecode http' yield u'' lines example request % substitutions splitlines lines insert 1 u'Content-Type application/json' lines insert 1 u'Host api % DOMAIN s' % substitutions for line in lines yield u'' + line rstrip yield u'' yield u'Response' yield u'' yield u' sourcecode http' yield u'' lines example response % substitutions splitlines lines insert 1 u'Content-Type application/json' for line in lines yield u'' + line rstrip yield u''
def current sam False try if sam user_name win32api GetUserNameEx win32con NameSamCompatible else user_name win32api GetUserName except pywintypes error as exc number context message exclog error 'Failedtogetcurrentuser' log error 'nbr {0}' format number log error 'ctx {0}' format context log error 'msg {0}' format message return Falseif not user_name return Falsereturn user_name
def getSeconds strTime try x dt strptime strTime '%H %M %S' seconds int timedelta hours x hour minutes x minute seconds x second total_seconds except ValueError seconds 0if seconds < 0 seconds 0return seconds
def create_game_directory dirname global GAMEDIRGAMEDIR os path abspath os path join CURRENT_DIR dirname if os path exists GAMEDIR print "CannotcreatenewEvenniagamedir '%s'alreadyexists " % dirname sys exit shutil copytree EVENNIA_TEMPLATE GAMEDIR create_settings_file
def create_game_directory dirname global GAMEDIRGAMEDIR os path abspath os path join CURRENT_DIR dirname if os path exists GAMEDIR print "CannotcreatenewEvenniagamedir '%s'alreadyexists " % dirname sys exit shutil copytree EVENNIA_TEMPLATE GAMEDIR create_settings_file
def build_simple_tree node TreeNode 1 node left TreeNode 2 node right TreeNode 3 node right left TreeNode 4 node right right TreeNode 5 return node
def show_instance name call None if call 'action' raise SaltCloudSystemExit 'Theshow_instanceactionmustbecalledwith-aor--action ' node _get_node name __utils__['cloud cache_node'] node __active_provider_name__ __opts__ return node
def show_instance name call None if call 'action' raise SaltCloudSystemExit 'Theshow_instanceactionmustbecalledwith-aor--action ' node _get_node name __utils__['cloud cache_node'] node __active_provider_name__ __opts__ return node
def show_instance name call None if call 'action' raise SaltCloudSystemExit 'Theshow_instanceactionmustbecalledwith-aor--action ' node _get_node name __utils__['cloud cache_node'] node __active_provider_name__ __opts__ return node
def get_exploration_recommendations exp_id recommendations_model recommendations_models ExplorationRecommendationsModel get exp_id strict False if recommendations_model is None return []else return recommendations_model recommended_exploration_ids
def add_error_codes new_codes for code message in new_codes iteritems error_list[code] _ message errors[code] code
def affinity_locality_predicate write_affinity_str affinity_str write_affinity_str strip if not affinity_str return Nonematchers []pieces [s strip for s in affinity_str split ' ' ]for piece in pieces match re match 'r \\d+ ? z \\d+ ?$' piece if match region zone match groups region int region zone int zone if zone else None matcher {'region' region}if zone is not None matcher['zone'] zonematchers append matcher else raise ValueError 'Invalidwrite-affinityvalue %r' % affinity_str def is_local ring_node for matcher in matchers if matcher['region'] ring_node['region'] and 'zone' not in matcher or matcher['zone'] ring_node['zone'] return Truereturn Falsereturn is_local
def _get_download_cache_locs from config paths import get_cache_dirpy_version u'py' + str sys version_info major datadir os path join get_cache_dir u'download' py_version shelveloc os path join datadir u'urlmap' if not os path exists datadir try os makedirs datadir except OSError as e if not os path exists datadir raiseelif not os path isdir datadir msg u'Datacachedirectory{0}isnotadirectory'raise IOError msg format datadir if os path isdir shelveloc msg u'Datacacheshelveobjectlocation{0}isadirectory'raise IOError msg format shelveloc return datadir shelveloc
def removeDynamicContent page if page for item in kb dynamicMarkings prefix suffix itemif prefix is None and suffix is None continueelif prefix is None page re sub ' ?s ^ +%s' % re escape suffix suffix replace '\\' '\\\\' page elif suffix is None page re sub ' ?s %s +$' % re escape prefix prefix replace '\\' '\\\\' page else page re sub ' ?s %s +%s' % re escape prefix re escape suffix '%s%s' % prefix replace '\\' '\\\\' suffix replace '\\' '\\\\' page return page
def xonsh_pathsearch pattern pymode False lineno None col None pymode ast NameConstant value pymode lineno lineno col_offset col searchfunc pattern RE_SEARCHPATH match pattern groups pattern ast Str s pattern lineno lineno col_offset col pathobj Falseif searchfunc startswith '@' func searchfunc[1 ]elif 'g' in searchfunc func '__xonsh_globsearch__'pathobj 'p' in searchfunc else func '__xonsh_regexsearch__'pathobj 'p' in searchfunc func ast Name id func ctx ast Load lineno lineno col_offset col pathobj ast NameConstant value pathobj lineno lineno col_offset col return xonsh_call '__xonsh_pathsearch__' args [func pattern pymode pathobj] lineno lineno col col
def test_scenario_post_email feature Feature from_string FEATURE21 scenario1 scenario2 feature scenariosscenario1 tags should be emptyscenario2 tags should equal ['tag']
def test_scenario_post_email feature Feature from_string FEATURE21 scenario1 scenario2 feature scenariosscenario1 tags should be emptyscenario2 tags should equal ['tag']
def test_scenario_post_email feature Feature from_string FEATURE21 scenario1 scenario2 feature scenariosscenario1 tags should be emptyscenario2 tags should equal ['tag']
def qr a mode 'reduced' x [[2 1] [3 4]]if isinstance numpy linalg qr x mode tuple return QRFull mode a else return QRIncomplete mode a
def assertResponseFailed self deferred reasonTypes return assertWrapperExceptionTypes self deferred ResponseFailed reasonTypes
def enable_inheritance path objectType clear False dc daclConstants objectType dc getObjectTypeBit objectType path dc processPath path objectType return _set_dacl_inheritance path objectType True None clear
def has_value key value None if not isinstance key six string_types log debug "{0} 'key'argumentisnotastringtype '{1}'" format __name__ key return Falsetry cur_val os environ[key]if value is not None if cur_val value return Trueelse return Falseexcept KeyError return Falsereturn True
def getInclination end start if end None or start None return 0 0endMinusStart end - start return math atan2 endMinusStart z abs endMinusStart dropAxis
def evaluate_inipath path if sabnzbd WIN32 path unicoder path path os path normpath os path abspath path inipath os path join path DEF_INI_FILE if os path isdir path return inipathelif os path isfile path or os path isfile path + ' bak' return pathelse _dirpart name os path split path if name find ' ' < 1 return inipathelse return path
def evaluate_inipath path if sabnzbd WIN32 path unicoder path path os path normpath os path abspath path inipath os path join path DEF_INI_FILE if os path isdir path return inipathelif os path isfile path or os path isfile path + ' bak' return pathelse _dirpart name os path split path if name find ' ' < 1 return inipathelse return path
@log_calldef metadef_tag_get_all context namespace_name filters None marker None limit None sort_key 'created_at' sort_dir None session None namespace metadef_namespace_get context namespace_name _check_namespace_visibility context namespace namespace_name tags []for tag in DATA['metadef_tags'] if tag['namespace_id'] namespace['id'] tags append tag return tags
def clean_db scenario call_command 'flush' interactive False
def clean_db scenario call_command 'flush' interactive False
def replace name repl full_match False ret {'name' name 'result' False 'changes' {} 'comment' ''}if full_match is False search '^ *{0} *$' format name else search namematches __salt__['nxos cmd'] 'find' search if not matches ret['result'] Trueret['comment'] 'Nothingfoundtoreplace'return retif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configswillbechanged'ret['changes']['old'] matchesret['changes']['new'] [re sub name repl match for match in matches]return retret['changes'] __salt__['nxos cmd'] 'replace' name repl full_match full_match matches __salt__['nxos cmd'] 'find' search if matches ret['result'] Falseret['comment'] 'Failedtoreplaceallinstancesof"{0}"' format name else ret['result'] Trueret['comment'] 'Successfullyreplacedallinstancesof"{0}"with"{1}"' format name repl return ret
def _my_trans data data_t fft data data_t np concatenate [data_t[ None] data_t[ None]] axis 2 return data_t None
def _my_trans data data_t fft data data_t np concatenate [data_t[ None] data_t[ None]] axis 2 return data_t None
@pytest mark parametrize u'collection' [[u'user_action' u'user'] [u'user_group' u'user'] [u'user_group' u'user_action']] def test_should_break_ties_using_lexical_order completer collection text u'user'matches completer find_matches text collection assert matches[1] priority > matches[0] priority
@pytest mark parametrize u'collection' [[u'user_action' u'user'] [u'user_group' u'user'] [u'user_group' u'user_action']] def test_should_break_ties_using_lexical_order completer collection text u'user'matches completer find_matches text collection assert matches[1] priority > matches[0] priority
def gist id_num return gh gist id_num
def create_tree_folders folderName if os path exists folderName raise NinjaIOException u'Thefolderalreadyexist' os makedirs folderName
def volume_metadata_get context volume_id return IMPL volume_metadata_get context volume_id
def trimone x front 0 back 0 axis 0 shape np array x shape shape[axis] - front + back shapearr np array x shape startind np zeros x ndim startind[axis] frontendind startind + shape myslice [slice startind[k] endind[k] for k in range len endind ]return x[tuple myslice ]
def trimone x front 0 back 0 axis 0 shape np array x shape shape[axis] - front + back shapearr np array x shape startind np zeros x ndim startind[axis] frontendind startind + shape myslice [slice startind[k] endind[k] for k in range len endind ]return x[tuple myslice ]
@pytest mark parametrize 'attr' ['stderr' '__stderr__'] def test_init_faulthandler_stderr_none monkeypatch attr monkeypatch setattr sys attr None earlyinit init_faulthandler
def add_path path config None log debug 'Addpath%s' % path if not path return []added []parent os path dirname path if parent and os path exists os path join path '__init__ py' added extend add_path parent config elif not path in sys path log debug 'insert%sintosys path' path sys path insert 0 path added append path if config and config srcDirs for dirname in config srcDirs dirpath os path join path dirname if os path isdir dirpath sys path insert 0 dirpath added append dirpath return added
def compute_average imlist averageim array Image open imlist[0] 'f' skipped 0for imname in imlist[1 ] try averageim + array Image open imname except print imname + ' skipped' skipped + 1averageim / len imlist - skipped return array averageim 'uint8'
def disassociate_eip_address public_ip None association_id None region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile try return conn disassociate_address public_ip association_id except boto exception BotoServerError as e log error e return False
def generate_data_key_without_plaintext key_id encryption_context None number_of_bytes None key_spec None grant_tokens None region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r {}try data_key conn generate_data_key_without_plaintext key_id encryption_context encryption_context number_of_bytes number_of_bytes key_spec key_spec grant_tokens grant_tokens r['data_key'] data_keyexcept boto exception BotoServerError as e r['error'] __utils__['boto get_error'] e return r
def test_format_config f HTMLFormatter cfg Config with capture_output as captured result f cfg nt assert_is result None nt assert_equal captured stderr '' with capture_output as captured result f Config nt assert_is result None nt assert_equal captured stderr ''
def test_format_config f HTMLFormatter cfg Config with capture_output as captured result f cfg nt assert_is result None nt assert_equal captured stderr '' with capture_output as captured result f Config nt assert_is result None nt assert_equal captured stderr ''
def test_format_config f HTMLFormatter cfg Config with capture_output as captured result f cfg nt assert_is result None nt assert_equal captured stderr '' with capture_output as captured result f Config nt assert_is result None nt assert_equal captured stderr ''
def test_format_config f HTMLFormatter cfg Config with capture_output as captured result f cfg nt assert_is result None nt assert_equal captured stderr '' with capture_output as captured result f Config nt assert_is result None nt assert_equal captured stderr ''
def test_format_config f HTMLFormatter cfg Config with capture_output as captured result f cfg nt assert_is result None nt assert_equal captured stderr '' with capture_output as captured result f Config nt assert_is result None nt assert_equal captured stderr ''
def _filtfilt x iir_params picks n_jobs copy from scipy signal import filtfiltpadlen min iir_params['padlen'] len x n_jobs check_n_jobs n_jobs x orig_shape picks _prep_for_filtering x copy picks if 'sos' in iir_params sosfiltfilt get_sosfiltfilt fun partial sosfiltfilt sos iir_params['sos'] padlen padlen _check_coefficients iir_params['sos'] else fun partial filtfilt b iir_params['b'] a iir_params['a'] padlen padlen _check_coefficients iir_params['b'] iir_params['a'] if n_jobs 1 for p in picks x[p] fun x x[p] else parallel p_fun _ parallel_func fun n_jobs data_new parallel p_fun x x[p] for p in picks for pp p in enumerate picks x[p] data_new[pp]x shape orig_shapereturn x
def randSplitFeatures features partTrain featuresTrain []featuresTest []for i f in enumerate features [numOfSamples numOfDims] f shaperandperm numpy random permutation range numOfSamples nTrainSamples int round partTrain * numOfSamples featuresTrain append f[randperm[0 nTrainSamples]] featuresTest append f[randperm[nTrainSamples None]] return featuresTrain featuresTest
def get name default None return getattr _get_config name default
def start port root_directory '/tmp/s3' bucket_depth 0 application S3Application root_directory bucket_depth http_server httpserver HTTPServer application http_server listen port ioloop IOLoop current start
def generate_helper_script pkg_manager_cmd os_packages pip_cmd failed_deps temp_dir tempfile gettempdir script_path os path join temp_dir SCRIPT_NAME script_file file script_path 'w' script_file write '# /bin/bash\n' if os_packages missing_pkgs '' join os_packages script_file write '%s%s\n' % pkg_manager_cmd missing_pkgs if failed_deps script_file write '\n' if running_in_virtualenv script_file write '#Runwithoutsudotoinstallinsidevenv\n' not_git_pkgs [fdep for fdep in failed_deps if not fdep is_git ]git_pkgs [fdep git_src for fdep in failed_deps if fdep is_git]if not_git_pkgs cmd generate_pip_install_non_git pip_cmd not_git_pkgs script_file write '%s\n' % cmd if git_pkgs for missing_git_pkg in git_pkgs cmd generate_pip_install_git pip_cmd missing_git_pkg script_file write '%s\n' % cmd os chmod script_path 493 script_file close return script_path
def generate_helper_script pkg_manager_cmd os_packages pip_cmd failed_deps temp_dir tempfile gettempdir script_path os path join temp_dir SCRIPT_NAME script_file file script_path 'w' script_file write '# /bin/bash\n' if os_packages missing_pkgs '' join os_packages script_file write '%s%s\n' % pkg_manager_cmd missing_pkgs if failed_deps script_file write '\n' if running_in_virtualenv script_file write '#Runwithoutsudotoinstallinsidevenv\n' not_git_pkgs [fdep for fdep in failed_deps if not fdep is_git ]git_pkgs [fdep git_src for fdep in failed_deps if fdep is_git]if not_git_pkgs cmd generate_pip_install_non_git pip_cmd not_git_pkgs script_file write '%s\n' % cmd if git_pkgs for missing_git_pkg in git_pkgs cmd generate_pip_install_git pip_cmd missing_git_pkg script_file write '%s\n' % cmd os chmod script_path 493 script_file close return script_path
def template_file path None template_contents None template_source None context None **kwargs if template_contents is None with open template_source as template_file template_contents template_file read if context is None context {}file path path contents template_contents % context **kwargs
def cached_query model filter_fn filter_identity def cached_query_decorator fn def cached_query_wrapper *args assert fn __name__ startswith 'get_' row_key_components [fn __name__[len 'get_' ]]if len args > 0 if isinstance args[0] Thing args list args args[0] args[0] _idif isinstance args[0] int long serialized to36 args[0] else serialized str args[0] row_key_components append serialized row_key_components extend str x for x in args[1 ] row_key ' ' join row_key_components query fn *args query_sort query _sorttry is_precomputed query precomputedexcept AttributeError is_precomputed _is_query_precomputed query return CachedQuery model row_key query_sort filter_fn is_precomputed return cached_query_wrapperreturn cached_query_decorator
def cached_query model filter_fn filter_identity def cached_query_decorator fn def cached_query_wrapper *args assert fn __name__ startswith 'get_' row_key_components [fn __name__[len 'get_' ]]if len args > 0 if isinstance args[0] Thing args list args args[0] args[0] _idif isinstance args[0] int long serialized to36 args[0] else serialized str args[0] row_key_components append serialized row_key_components extend str x for x in args[1 ] row_key ' ' join row_key_components query fn *args query_sort query _sorttry is_precomputed query precomputedexcept AttributeError is_precomputed _is_query_precomputed query return CachedQuery model row_key query_sort filter_fn is_precomputed return cached_query_wrapperreturn cached_query_decorator
def get_validation_schema models default_namespace None if default_namespace is None default_namespace models[0] get_namespace fake_app FakeApplication fake_app tns default_namespacefake_app services []interface Interface fake_app for m in models m resolve_namespace m default_namespace interface add_class m schema XmlSchema interface schema build_validation_schema return schema validation_schema
def getCraftedText fileName text lashRepository None return getCraftedTextFromText archive getTextIfEmpty fileName text lashRepository
@_helpers positional 2 def generate_token key user_id action_id '' when None digester hmac new _helpers _to_bytes key encoding 'utf-8' digester update _helpers _to_bytes str user_id encoding 'utf-8' digester update DELIMITER digester update _helpers _to_bytes action_id encoding 'utf-8' digester update DELIMITER when _helpers _to_bytes str when or int time time encoding 'utf-8' digester update when digest digester digest token base64 urlsafe_b64encode digest + DELIMITER + when return token
def make_api_request http http_request retries 7 redirections _REDIRECTIONS retry 0while True try return _make_api_request_no_retry http http_request redirections redirections except _RETRYABLE_EXCEPTIONS as exc retry + 1if retry > retries raiseretry_after getattr exc 'retry_after' None if retry_after is None retry_after calculate_wait_for_retry retry _reset_http_connections http logging debug 'Retryingrequesttourl%safterexception%s' http_request url type exc __name__ time sleep retry_after
def get_primary_at source_code offset retry True obj ''left re split '[^0-9a-zA-Z_ ]' source_code[ offset] if left and left[ -1 ] obj left[ -1 ]right re split '\\W' source_code[offset ] if right and right[0] obj + right[0]if obj and obj[0] isdigit obj ''if not obj and retry and offset and source_code[ offset - 1 ] in ' [ ' return get_primary_at source_code offset - 1 retry False return obj
def get_primary_at source_code offset retry True obj ''left re split '[^0-9a-zA-Z_ ]' source_code[ offset] if left and left[ -1 ] obj left[ -1 ]right re split '\\W' source_code[offset ] if right and right[0] obj + right[0]if obj and obj[0] isdigit obj ''if not obj and retry and offset and source_code[ offset - 1 ] in ' [ ' return get_primary_at source_code offset - 1 retry False return obj
def plt_show show True **kwargs import matplotlibimport matplotlib pyplot as pltif show and matplotlib get_backend 'agg' plt show **kwargs
def get_http_data data get_stack_trace_data_real data['request'] {'cookies' VARS 'data' VARS 'env' VARS 'headers' VARS 'method' 'GET' 'query_string' '' 'url' 'http //localhost/'}return data
@world absorbdef verify_setting_entry setting display_name value explicitly_set label_element setting find_by_css ' setting-label' [0]assert_equal display_name label_element html strip label_for label_element['for']if setting has_class 'metadata-list-enum' or setting has_class 'metadata-dict' or setting has_class 'metadata-video-translations' list_value ' ' join ele value for ele in setting find_by_css ' list-settings-item' assert_equal value list_value elif setting has_class 'metadata-videolist-enum' list_value ' ' join ele find_by_css 'input' [0] value for ele in setting find_by_css ' videolist-settings-item' assert_equal value list_value else assert_equal value setting find_by_id label_for value if not setting has_class 'metadata-videolist-enum' settingClearButton setting find_by_css ' setting-clear' [0]assert_equal explicitly_set settingClearButton has_class 'active' assert_equal not explicitly_set settingClearButton has_class 'inactive'
@world absorbdef verify_setting_entry setting display_name value explicitly_set label_element setting find_by_css ' setting-label' [0]assert_equal display_name label_element html strip label_for label_element['for']if setting has_class 'metadata-list-enum' or setting has_class 'metadata-dict' or setting has_class 'metadata-video-translations' list_value ' ' join ele value for ele in setting find_by_css ' list-settings-item' assert_equal value list_value elif setting has_class 'metadata-videolist-enum' list_value ' ' join ele find_by_css 'input' [0] value for ele in setting find_by_css ' videolist-settings-item' assert_equal value list_value else assert_equal value setting find_by_id label_for value if not setting has_class 'metadata-videolist-enum' settingClearButton setting find_by_css ' setting-clear' [0]assert_equal explicitly_set settingClearButton has_class 'active' assert_equal not explicitly_set settingClearButton has_class 'inactive'
def ensure_not_exists filename try os unlink filename except OSError as e if e errno ENOENT raise
def get_credentials yaml_key 'nginx_admin_password 'try with open 'security yml' 'r' as f for line in f if yaml_key in line password line[len yaml_key ] strip return 'admin ' + password except IOError logging info 'security ymlmissing return""forunittestinstead' return ''
def _get_legen_lut_fast x lut block None n_interp lut shape[0] - 1 0 mm x * n_interp / 2 0 mm + 0 5 * n_interp idx np round mm astype int if block is None vals lut[idx]else vals lut[idx block]return vals
def _get_legen_lut_fast x lut block None n_interp lut shape[0] - 1 0 mm x * n_interp / 2 0 mm + 0 5 * n_interp idx np round mm astype int if block is None vals lut[idx]else vals lut[idx block]return vals
def getCascadeFloatWithoutSelf defaultFloat elementNode key if key in elementNode attributes value elementNode attributes[key]functionName 'get' + key[0] upper + key[1 ] if functionName in value if elementNode parentNode None return defaultFloatelse elementNode elementNode parentNodereturn elementNode getCascadeFloat defaultFloat key
def seed seed None if isinstance seed str and seed 'default' backend id_srando elif hasattr seed '__len__' state np asfortranarray seed dtype float if state shape 55 raise ValueError 'invalidinputsize' elif state min < 0 or state max > 1 raise ValueError 'valuesnotinrange[0 1]' backend id_srandi state elif seed is None backend id_srandi np random rand 55 else rnd np random RandomState seed backend id_srandi rnd rand 55
def seed seed None if isinstance seed str and seed 'default' backend id_srando elif hasattr seed '__len__' state np asfortranarray seed dtype float if state shape 55 raise ValueError 'invalidinputsize' elif state min < 0 or state max > 1 raise ValueError 'valuesnotinrange[0 1]' backend id_srandi state elif seed is None backend id_srandi np random rand 55 else rnd np random RandomState seed backend id_srandi rnd rand 55
def _validate_constraints supported_constraints model message u'Optimizercannothandle{0}constraints 'if any six itervalues model fixed and u'fixed' not in supported_constraints raise UnsupportedConstraintError message format u'fixedparameter' if any six itervalues model tied and u'tied' not in supported_constraints raise UnsupportedConstraintError message format u'tiedparameter' if any tuple b None None for b in six itervalues model bounds and u'bounds' not in supported_constraints raise UnsupportedConstraintError message format u'boundparameter' if model eqcons and u'eqcons' not in supported_constraints raise UnsupportedConstraintError message format u'equality' if model ineqcons and u'ineqcons' not in supported_constraints raise UnsupportedConstraintError message format u'inequality'
@verbosedef spatial_tris_connectivity tris remap_vertices False verbose None return spatio_temporal_tris_connectivity tris 1 remap_vertices
def get_tests_for python_name def _extract_ids t if isinstance t TestSuite result pset for sub_tests in t result result _extract_ids sub_tests return resultelse return pset [t id ] loader TestLoader tests loader loadByName python_name recurse True return _extract_ids tests
def _FilesMatching root predicate lambda f True matches []for path _ files in os walk root matches + [os path join path f for f in files if predicate f ]return matches
def swappable_dependency value return SwappableTuple value split ' ' 1 [0] '__first__' value
def fetch_nb_dependencies files repo REPO raw RAW branch BRANCH deps DEPS overwrite False verbose True if type files list files {'' files}for directory in files keys if directory '' if verbose print 'Parsingdirectory %s'for fl in files[directory] if directory '' fl directory + '/' + fl if not overwrite if os path isfile fl if verbose print 'Afilenamed%salreadyexistsinthespecifieddirectory skippingdownload ' % fl continueelif verbose print 'Overwritingfile%s ' % fl if verbose print 'Fetchingfile %s' % fl url '/' join [repo raw branch deps fl] r requests get url with open fl 'wb' as fl fl write r content
def _has_method arg method return hasattr arg method and callable getattr arg method
def describe_key key_id region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r {}try key conn describe_key key_id r['key_metadata'] key['KeyMetadata']except boto exception BotoServerError as e r['error'] __utils__['boto get_error'] e return r
def _filter_ticks lims fscale if fscale 'linear' return None None lims np array lims ticks list for exp in range int np floor np log10 lims[0] int np floor np log10 lims[1] + 1 ticks + np array [1 2 4] * 10 ** exp tolist ticks np array ticks ticks ticks[ ticks > lims[0] & ticks < lims[1] ]ticklabels [ '%g' if t < 1 else '%d' % t for t in ticks]return ticks ticklabels
def _filter_ticks lims fscale if fscale 'linear' return None None lims np array lims ticks list for exp in range int np floor np log10 lims[0] int np floor np log10 lims[1] + 1 ticks + np array [1 2 4] * 10 ** exp tolist ticks np array ticks ticks ticks[ ticks > lims[0] & ticks < lims[1] ]ticklabels [ '%g' if t < 1 else '%d' % t for t in ticks]return ticks ticklabels
def sum_shapes shapes rows max [shape[0] for shape in shapes] cols max [shape[1] for shape in shapes] for shape in shapes if not shape 1 1 and shape rows cols raise ValueError 'Incompatibledimensions' + len shapes * '%s' % tuple shapes return rows cols
def atomic_rename oldpath newpath if iswindows import win32filefor i in xrange 10 try win32file MoveFileEx oldpath newpath win32file MOVEFILE_REPLACE_EXISTING win32file MOVEFILE_WRITE_THROUGH breakexcept Exception if i > 8 raisetime sleep 1 else os rename oldpath newpath
@mock_ec2def test_eip_boto3_vpc_association session boto3 session Session region_name u'us-west-1' service session resource u'ec2' client session client u'ec2' vpc_res client create_vpc CidrBlock u'10 0 0 0/24' subnet_res client create_subnet VpcId vpc_res[u'Vpc'][u'VpcId'] CidrBlock u'10 0 0 0/24' instance service create_instances **{u'InstanceType' u't2 micro' u'ImageId' u'ami-test' u'MinCount' 1 u'MaxCount' 1 u'SubnetId' subnet_res[u'Subnet'][u'SubnetId']} [0]allocation_id client allocate_address Domain u'vpc' [u'AllocationId']association_id client associate_address InstanceId instance id AllocationId allocation_id AllowReassociation False instance load instance public_ip_address should_not be noneinstance public_dns_name should_not be none
def track_forum_event request event_name course obj data id_map None user request userdata['id'] obj idcommentable_id data['commentable_id']team get_team commentable_id if team is not None data update team_id team team_id if id_map is None id_map get_cached_discussion_id_map course [commentable_id] user if commentable_id in id_map data['category_name'] id_map[commentable_id]['title']data['category_id'] commentable_iddata['url'] request META get 'HTTP_REFERER' '' data['user_forums_roles'] [role name for role in user roles filter course_id course id ]data['user_course_roles'] [role role for role in user courseaccessrole_set filter course_id course id ]tracker emit event_name data
def track_forum_event request event_name course obj data id_map None user request userdata['id'] obj idcommentable_id data['commentable_id']team get_team commentable_id if team is not None data update team_id team team_id if id_map is None id_map get_cached_discussion_id_map course [commentable_id] user if commentable_id in id_map data['category_name'] id_map[commentable_id]['title']data['category_id'] commentable_iddata['url'] request META get 'HTTP_REFERER' '' data['user_forums_roles'] [role name for role in user roles filter course_id course id ]data['user_course_roles'] [role role for role in user courseaccessrole_set filter course_id course id ]tracker emit event_name data
def chown_log_dir uid gid if _log_dir is None return Falsetry os chown _log_dir uid gid for entry in os listdir _log_dir os chown os path join _log_dir entry uid gid return Trueexcept OSError as ex print >>sys stderr 'Failedtochownlogdirectory%s ex' % _log_dir ex return False
def DihedralGroup n if n 1 return PermutationGroup [Permutation [1 0] ] if n 2 return PermutationGroup [Permutation [1 0 3 2] Permutation [2 3 0 1] Permutation [3 2 1 0] ] a list range 1 n a append 0 gen1 _af_new a a list range n a reverse gen2 _af_new a G PermutationGroup [gen1 gen2] if n & n - 1 0 G _is_nilpotent Trueelse G _is_nilpotent FalseG _is_abelian FalseG _is_solvable TrueG _degree nG _is_transitive TrueG _order 2 * n return G
def get_osc_stats directory fs ost out []for fspath in os listdir directory if fs in fspath and ost in fspath logging debug 'openingfile' + str directory + '/' + str fspath + '/stats' try osc_statsfile open '%s/%s/stats' % directory fspath except IOError osc_statsfile []for line in osc_statsfile item re split '\\s+' line rstrip out append item return out
def test_optimizer nan_detected [False]def detect_nan i node fn for output in fn outputs if numpy isnan output[0] any print '***NaNdetected***' theano printing debugprint node print 'Inputs %s' % [input[0] for input in fn inputs] print 'Outputs %s' % [output[0] for output in fn outputs] nan_detected[0] Truebreakx theano tensor dscalar 'x' mode theano compile MonitorMode post_func detect_nan mode mode excluding 'fusion' f theano function [x] [ theano tensor log x * x ] mode mode assert len f maker fgraph apply_nodes 2 f 0 assert nan_detected[0]
def strFile p f caseSensitive True buf type p buf_len max len p 2 ** 2 ** 2 ** 2 if not caseSensitive p p lower while 1 r f read buf_len - len p if not caseSensitive r r lower bytes_read len r if bytes_read 0 return Falsel len buf + bytes_read - buf_len if l < 0 buf buf + r else buf buf[l ] + r if buf find p -1 return True
def strFile p f caseSensitive True buf type p buf_len max len p 2 ** 2 ** 2 ** 2 if not caseSensitive p p lower while 1 r f read buf_len - len p if not caseSensitive r r lower bytes_read len r if bytes_read 0 return Falsel len buf + bytes_read - buf_len if l < 0 buf buf + r else buf buf[l ] + r if buf find p -1 return True
def strFile p f caseSensitive True buf type p buf_len max len p 2 ** 2 ** 2 ** 2 if not caseSensitive p p lower while 1 r f read buf_len - len p if not caseSensitive r r lower bytes_read len r if bytes_read 0 return Falsel len buf + bytes_read - buf_len if l < 0 buf buf + r else buf buf[l ] + r if buf find p -1 return True
def replace_slices index if isinstance index hashable_list return list index elif isinstance index _slice return index as_slice elif isinstance index tuple return tuple map replace_slices index return index
def find_xontrib name if name startswith ' ' spec importlib util find_spec name package 'xontrib' else spec importlib util find_spec ' ' + name package 'xontrib' return spec or importlib util find_spec name
def ElementWithReading tag text reading False if text is None readingText ''elif isinstance text basestring readingText textelse readingText text[1]text text[0]if not reading readingText ''return ElementWithText tag text reading readingText
def build_mock_object obj_id mock_object Mock object_config {'pk' obj_id 'name' 'object{}' format obj_id }mock_object configure_mock **object_config return mock_object
@db api_context_manager writerdef _delete_request_spec context instance_uuid context session query api_models RequestSpec filter_by instance_uuid instance_uuid delete
def get_best_match target_name names exact []wildcard_start []wildcard_end []regex []for name in names if _exact_match target_name name exact append name elif _wildcard_match target_name name True wildcard_start append name elif _wildcard_match target_name name False wildcard_end append name elif _regex_match target_name name regex append name if len exact > 0 match min exact key len return 'exact' match if len wildcard_start > 0 match max wildcard_start key len return 'wildcard_start' match if len wildcard_end > 0 match max wildcard_end key len return 'wildcard_end' match if len regex > 0 match regex[0]return 'regex' match return None None
def get_best_match target_name names exact []wildcard_start []wildcard_end []regex []for name in names if _exact_match target_name name exact append name elif _wildcard_match target_name name True wildcard_start append name elif _wildcard_match target_name name False wildcard_end append name elif _regex_match target_name name regex append name if len exact > 0 match min exact key len return 'exact' match if len wildcard_start > 0 match max wildcard_start key len return 'wildcard_start' match if len wildcard_end > 0 match max wildcard_end key len return 'wildcard_end' match if len regex > 0 match regex[0]return 'regex' match return None None
def _get_patterns installed_only None patterns {}for element in __zypper__ nolock xml call 'se' '-t' 'pattern' getElementsByTagName 'solvable' installed element getAttribute 'status' 'installed' if installed_only and installed or not installed_only patterns[element getAttribute 'name' ] {'installed' installed 'summary' element getAttribute 'summary' }return patterns
def _get_patterns installed_only None patterns {}for element in __zypper__ nolock xml call 'se' '-t' 'pattern' getElementsByTagName 'solvable' installed element getAttribute 'status' 'installed' if installed_only and installed or not installed_only patterns[element getAttribute 'name' ] {'installed' installed 'summary' element getAttribute 'summary' }return patterns
def migPipe deme k pipein pipeout selection replacement None emigrants selection deme k if replacement is None immigrants emigrantselse immigrants replacement deme k pipeout send emigrants buf pipein recv for place immigrant in zip immigrants buf indx deme index place deme[indx] immigrant
def allocate_ids model size **kwargs return allocate_ids_async model size **kwargs get_result
def _expected observed o observedif len o 0 return []if len o 1 return [ [ sum o[0] / float len o[0] ] * len o[0] ]n [sum o[i] for i in xrange len o ]m [sum o[i][j] for i in xrange len o for j in xrange len o[0] ]s float sum n return [[ n[i] * m[j] / s for j in xrange len o[i] ] for i in xrange len o ]
def TrimmedMeanVar t p 0 01 t Trim t p mu var MeanVar t return mu var
def getEmptyZ shape z zoneIndex round z / shape zoneInterval if zoneIndex not in shape zZoneTable return zzoneAround 1while 1 zoneDown zoneIndex - zoneAround if zoneDown not in shape zZoneTable return zoneDown * shape zoneInterval zoneUp zoneIndex + zoneAround if zoneUp not in shape zZoneTable return zoneUp * shape zoneInterval zoneAround + 1
def has_metadata trait metadata value None recursive True count 0if hasattr trait u'_metadata' and metadata in list trait _metadata keys and trait _metadata[metadata] value or value is None count + 1if recursive if hasattr trait u'inner_traits' for inner_trait in trait inner_traits count + has_metadata inner_trait trait_type metadata recursive if hasattr trait u'handlers' and trait handlers is not None for handler in trait handlers count + has_metadata handler metadata recursive return count > 0
def has_metadata trait metadata value None recursive True count 0if hasattr trait u'_metadata' and metadata in list trait _metadata keys and trait _metadata[metadata] value or value is None count + 1if recursive if hasattr trait u'inner_traits' for inner_trait in trait inner_traits count + has_metadata inner_trait trait_type metadata recursive if hasattr trait u'handlers' and trait handlers is not None for handler in trait handlers count + has_metadata handler metadata recursive return count > 0
def munge_name name if isinstance name unicode name substitute_ascii_equivalents name name re sub '[ /]' '-' name name re sub '[^a-zA-Z0-9-_]' '' name lower name _munge_to_length name model PACKAGE_NAME_MIN_LENGTH model PACKAGE_NAME_MAX_LENGTH return name
def munge_name name if isinstance name unicode name substitute_ascii_equivalents name name re sub '[ /]' '-' name name re sub '[^a-zA-Z0-9-_]' '' name lower name _munge_to_length name model PACKAGE_NAME_MIN_LENGTH model PACKAGE_NAME_MAX_LENGTH return name
def _get_bufsize_linux iface ret {'result' False}cmd '/sbin/ethtool-g{0}' format iface out __salt__['cmd run'] cmd pat re compile '^ + \\s+ \\d+ $' suffix 'max-'for line in out splitlines res pat match line if res ret[ res group 1 lower replace '' '-' + suffix ] int res group 2 ret['result'] Trueelif line endswith 'maximums ' suffix '-max'elif line endswith 'settings ' suffix ''if not ret['result'] parts out split if parts[0] endswith 'sh ' out '' join parts[1 ] ret['comment'] outreturn ret
def draw_random G **kwargs draw G random_layout G **kwargs
def skip_if_not_available modules None datasets None configurations None if modules is None modules []if datasets is None datasets []if configurations is None configurations []for module in modules try import_module module except Exception raise SkipTestif module 'bokeh' ConnectionError import_module 'requests exceptions' ConnectionErrorsession import_module 'bokeh session' Session try session execute 'get' session base_url except ConnectionError raise SkipTestif datasets and not hasattr config 'data_path' raise SkipTestfor dataset in datasets if not os path exists os path join config data_path dataset raise SkipTestfor configuration in configurations if not hasattr config configuration raise SkipTest
def skip_if_not_available modules None datasets None configurations None if modules is None modules []if datasets is None datasets []if configurations is None configurations []for module in modules try import_module module except Exception raise SkipTestif module 'bokeh' ConnectionError import_module 'requests exceptions' ConnectionErrorsession import_module 'bokeh session' Session try session execute 'get' session base_url except ConnectionError raise SkipTestif datasets and not hasattr config 'data_path' raise SkipTestfor dataset in datasets if not os path exists os path join config data_path dataset raise SkipTestfor configuration in configurations if not hasattr config configuration raise SkipTest
def _meta_links req count meta {config QUERY_PAGE req page config QUERY_MAX_RESULTS req max_results}if config OPTIMIZE_PAGINATION_FOR_SPEED is False meta['total'] countreturn meta
def main global settingscreateSettingsFile settings alp readPlist SETTINGS_PATH if settings['firstRun'] 'true' udpateDatabaseFromKippt settings['firstRun'] 'false'settings['credentialsChanged'] 'false'alp writePlist settings SETTINGS_PATH elif settings['credentialsChanged'] 'true' udpateDatabaseFromKippt settings['credentialsChanged'] 'false'alp writePlist settings SETTINGS_PATH elif settings['updateClips'] 'true' udpateDatabaseFromKippt settings['updateClips'] 'false'alp writePlist settings SETTINGS_PATH args alp args if len args < 1 returnitems search args if items is not None alp feedback items else print 'Noitemsfound'
@download_tool 'urllib2' def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
@download_tool 'urllib2' def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
@download_tool 'urllib2' def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
@download_tool 'urllib2' def urllib2_download client download_url filename resuming False assert not resuming print 'Downloading' download_url 'to' filename ' 'request urllib2 Request download_url headers {'Cookie' 'gdriveid ' + client get_gdriveid } response urllib2 urlopen request import shutilwith open filename 'wb' as output shutil copyfileobj response output
def _get_userprofile_from_registry user sid profile_dir __salt__['reg read_value'] 'HKEY_LOCAL_MACHINE' u'SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\ProfileList\\{0}' format sid 'ProfileImagePath' ['vdata']log debug u'user{0}withsid {2}profileislocatedat"{1}"' format user profile_dir sid return profile_dir
def _get_userprofile_from_registry user sid profile_dir __salt__['reg read_value'] 'HKEY_LOCAL_MACHINE' u'SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\ProfileList\\{0}' format sid 'ProfileImagePath' ['vdata']log debug u'user{0}withsid {2}profileislocatedat"{1}"' format user profile_dir sid return profile_dir
def _get_userprofile_from_registry user sid profile_dir __salt__['reg read_value'] 'HKEY_LOCAL_MACHINE' u'SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\ProfileList\\{0}' format sid 'ProfileImagePath' ['vdata']log debug u'user{0}withsid {2}profileislocatedat"{1}"' format user profile_dir sid return profile_dir
def close_logger for handler in _logger handlers _logger removeHandler handler if isinstance handler logging FileHandler handler close
def _orbits_transversals_from_bsgs base strong_gens_distr transversals_only False from sympy combinatorics perm_groups import _orbit_transversalbase_len len base degree strong_gens_distr[0][0] sizetransversals [None] * base_len if transversals_only is False basic_orbits [None] * base_len for i in range base_len transversals[i] dict _orbit_transversal degree strong_gens_distr[i] base[i] pairs True if transversals_only is False basic_orbits[i] list transversals[i] keys if transversals_only return transversalselse return basic_orbits transversals
def map_version version version_map if version is None raise TypeErrorif not version_map raise ValueErrorif isinstance version_map dict version_map sorted LooseVersion k v for k v in version_map items req_version LooseVersion version for min_version value in reversed version_map if req_version > min_version return valueelse return version_map[0][1]
def load_drivers service_type plugin service_type_manager sdb ServiceTypeManager get_instance providers service_type_manager get_service_providers None filters {'service_type' [service_type]} if not providers msg _LE "Noprovidersspecifiedfor'%s'service exiting" % service_type LOG error msg raise SystemExit 1 drivers {}for provider in providers try drivers[provider['name']] importutils import_object provider['driver'] plugin LOG debug "Loaded'% provider s'providerforservice% service_type s" {'provider' provider['driver'] 'service_type' service_type} except ImportError with excutils save_and_reraise_exception LOG exception _LE "Errorloadingprovider'% provider s'forservice% service_type s" {'provider' provider['driver'] 'service_type' service_type} default_provider Nonetry provider service_type_manager get_default_service_provider None service_type default_provider provider['name']except pconf DefaultServiceProviderNotFound LOG info _LI 'Defaultproviderisnotspecifiedforservicetype%s' service_type return drivers default_provider
def getHalfSimplifiedPath path radius remainder if len path < 2 return pathchannelRadius radius * 0 01 simplified [path[0]]for pointIndex in xrange 1 len path - 1 point path[pointIndex]if pointIndex % 2 remainder simplified append point elif not isWithinChannel channelRadius pointIndex path simplified append point simplified append path[ -1 ] return simplified
def encryptARC s iv helpers randomKey 8 key helpers randomKey 8 arc4main ARC4 new key encrypted arc4main encrypt s return encrypted key iv
def solveBilinearTransform points1 points2 import numpy linalgA np array [[ points1[i] x * points1[i] y points1[i] x points1[i] y 1] for i in range 4 ] B np array [[points2[i] x points2[i] y ] for i in range 4 ] matrix np zeros 2 4 for i in range 2 matrix[i] numpy linalg solve A B[ i] return matrix
def solveBilinearTransform points1 points2 import numpy linalgA np array [[ points1[i] x * points1[i] y points1[i] x points1[i] y 1] for i in range 4 ] B np array [[points2[i] x points2[i] y ] for i in range 4 ] matrix np zeros 2 4 for i in range 2 matrix[i] numpy linalg solve A B[ i] return matrix
def libvlc_media_player_get_chapter_count_for_title p_mi i_title f _Cfunctions get 'libvlc_media_player_get_chapter_count_for_title' None or _Cfunction 'libvlc_media_player_get_chapter_count_for_title' 1 1 None ctypes c_int MediaPlayer ctypes c_int return f p_mi i_title
def remove_indents txt txt re sub ' ?miu ^\\s+' '' txt return txt
def _escape_backslashes data jinja_env if '\\' in data and '{{' in data new_data []d2 jinja_env preprocess data in_var Falsefor token in jinja_env lex d2 if token[1] 'variable_begin' in_var Truenew_data append token[2] elif token[1] 'variable_end' in_var Falsenew_data append token[2] elif in_var and token[1] 'string' new_data append token[2] replace '\\' '\\\\' else new_data append token[2] data '' join new_data return data
def _escape_backslashes data jinja_env if '\\' in data and '{{' in data new_data []d2 jinja_env preprocess data in_var Falsefor token in jinja_env lex d2 if token[1] 'variable_begin' in_var Truenew_data append token[2] elif token[1] 'variable_end' in_var Falsenew_data append token[2] elif in_var and token[1] 'string' new_data append token[2] replace '\\' '\\\\' else new_data append token[2] data '' join new_data return data
def create_volume ctxt host 'test_host' display_name 'test_volume' display_description 'thisisatestvolume' status 'available' migration_status None size 1 availability_zone 'fake_az' volume_type_id None replication_status 'disabled' replication_extended_status None replication_driver_data None consistencygroup_id None group_id None previous_status None testcase_instance None **kwargs vol {}vol['size'] sizevol['host'] hostvol['user_id'] ctxt user_idvol['project_id'] ctxt project_idvol['status'] statusif migration_status vol['migration_status'] migration_statusvol['display_name'] display_namevol['display_description'] display_descriptionvol['attach_status'] fields VolumeAttachStatus DETACHEDvol['availability_zone'] availability_zoneif consistencygroup_id vol['consistencygroup_id'] consistencygroup_idif group_id vol['group_id'] group_idif volume_type_id vol['volume_type_id'] volume_type_idfor key in kwargs vol[key] kwargs[key]vol['replication_status'] replication_statusif replication_extended_status vol['replication_extended_status'] replication_extended_statusif replication_driver_data vol['replication_driver_data'] replication_driver_dataif previous_status vol['previous_status'] previous_statusvolume objects Volume ctxt **vol volume create if testcase_instance testcase_instance addCleanup volume destroy return volume
def _get_root_versions_dir config root_dir _get_package_root_dir config script_location config get_main_option 'script_location' part1 part2 script_location split ' ' parts part1 split ' ' + part2 split ' ' + ['versions'] return os path join root_dir *parts
def _get_root_versions_dir config root_dir _get_package_root_dir config script_location config get_main_option 'script_location' part1 part2 script_location split ' ' parts part1 split ' ' + part2 split ' ' + ['versions'] return os path join root_dir *parts
def pw_affine fromim toim fp tp tri im toim copy is_color len fromim shape 3 im_t zeros im shape 'uint8' for t in tri H homography Haffine_from_points tp[ t] fp[ t] if is_color for col in range fromim shape[2] im_t[ col] ndimage affine_transform fromim[ col] H[ 2 2] H[ 0 2 ] H[ 1 2 ] im shape[ 2] else im_t ndimage affine_transform fromim H[ 2 2] H[ 0 2 ] H[ 1 2 ] im shape[ 2] alpha alpha_for_triangle tp[ t] im shape[0] im shape[1] im[ alpha > 0 ] im_t[ alpha > 0 ]return im
def save_password password port password_file abspath 'parameters_%i py' % port if password '<random>' chars string letters + string digits password '' join [random choice chars for _ in range 8 ] cpassword CRYPT password [0]print '*******************IMPORTANT ************************' print 'youradminpasswordis"%s"' % password print '*********************************************************' elif password '<recycle>' if exists password_file returnelse password ''elif password startswith '<pam_user ' cpassword password[1 -1 ]else cpassword CRYPT password [0]fp open password_file 'w' if password fp write 'password "%s"\n' % cpassword else fp write 'password None\n' fp close
def save_password password port password_file abspath 'parameters_%i py' % port if password '<random>' chars string letters + string digits password '' join [random choice chars for _ in range 8 ] cpassword CRYPT password [0]print '*******************IMPORTANT ************************' print 'youradminpasswordis"%s"' % password print '*********************************************************' elif password '<recycle>' if exists password_file returnelse password ''elif password startswith '<pam_user ' cpassword password[1 -1 ]else cpassword CRYPT password [0]fp open password_file 'w' if password fp write 'password "%s"\n' % cpassword else fp write 'password None\n' fp close
def save_password password port password_file abspath 'parameters_%i py' % port if password '<random>' chars string letters + string digits password '' join [random choice chars for _ in range 8 ] cpassword CRYPT password [0]print '*******************IMPORTANT ************************' print 'youradminpasswordis"%s"' % password print '*********************************************************' elif password '<recycle>' if exists password_file returnelse password ''elif password startswith '<pam_user ' cpassword password[1 -1 ]else cpassword CRYPT password [0]fp open password_file 'w' if password fp write 'password "%s"\n' % cpassword else fp write 'password None\n' fp close
def _set_argv process_name if Py_GetArgcArgv is None returnglobal _PROCESS_NAMEcurrent_name get_process_name argv argc ctypes c_int 0 argc_t Py_GetArgcArgv argv ctypes pointer argc if len process_name > _MAX_NAME_LENGTH raise IOError "Can'trenameprocesstosomethinglongerthanourinitialname thiswouldoverwritememoryusedfortheenv " zero_size max len current_name len process_name ctypes memset argc contents 0 zero_size + 1 process_name_encoded process_name encode 'utf8' ctypes memmove argc contents process_name_encoded len process_name _PROCESS_NAME process_name
def _set_argv process_name if Py_GetArgcArgv is None returnglobal _PROCESS_NAMEcurrent_name get_process_name argv argc ctypes c_int 0 argc_t Py_GetArgcArgv argv ctypes pointer argc if len process_name > _MAX_NAME_LENGTH raise IOError "Can'trenameprocesstosomethinglongerthanourinitialname thiswouldoverwritememoryusedfortheenv " zero_size max len current_name len process_name ctypes memset argc contents 0 zero_size + 1 process_name_encoded process_name encode 'utf8' ctypes memmove argc contents process_name_encoded len process_name _PROCESS_NAME process_name
def _set_argv process_name if Py_GetArgcArgv is None returnglobal _PROCESS_NAMEcurrent_name get_process_name argv argc ctypes c_int 0 argc_t Py_GetArgcArgv argv ctypes pointer argc if len process_name > _MAX_NAME_LENGTH raise IOError "Can'trenameprocesstosomethinglongerthanourinitialname thiswouldoverwritememoryusedfortheenv " zero_size max len current_name len process_name ctypes memset argc contents 0 zero_size + 1 process_name_encoded process_name encode 'utf8' ctypes memmove argc contents process_name_encoded len process_name _PROCESS_NAME process_name
def attach_notify_policies queryset as_field 'notify_policies_attr' model queryset modelsql '\nSELECTjson_agg row_to_json notifications_notifypolicy \nFROMnotifications_notifypolicy\nWHEREnotifications_notifypolicy project_id {tbl} id\n'sql sql format tbl model _meta db_table queryset queryset extra select {as_field sql} return queryset
@taskdef get_healthz url 'https //localhost 8443/healthz'ret 'FAIL'with settings warn_only True ret run 'curl-k%s' % url fprint 'Healthzstatus %s' % ret return ret 'OK'
def build_set context builder set_type items nitems len items inst SetInstance allocate context builder set_type nitems array cgutils pack_array builder items array_ptr cgutils alloca_once_value builder array count context get_constant types intp nitems with cgutils for_range builder count as loop item builder load cgutils gep builder array_ptr 0 loop index inst add item return impl_ret_new_ref context builder set_type inst value
def MultifieldParser fieldnames schema fieldboosts None **kwargs from whoosh qparser plugins import MultifieldPluginp QueryParser None schema **kwargs mfp MultifieldPlugin fieldnames fieldboosts fieldboosts p add_plugin mfp return p
def MultifieldParser fieldnames schema fieldboosts None **kwargs from whoosh qparser plugins import MultifieldPluginp QueryParser None schema **kwargs mfp MultifieldPlugin fieldnames fieldboosts fieldboosts p add_plugin mfp return p
def libvlc_media_player_get_agl p_mi f _Cfunctions get 'libvlc_media_player_get_agl' None or _Cfunction 'libvlc_media_player_get_agl' 1 None ctypes c_uint32 MediaPlayer return f p_mi
def format_histogram_one_count counts bin_edges lines []lines append 'Length DCTB Count' for edge count in zip bin_edges counts lines append ' DCTB ' join map str [edge count] return '\n' join lines
def rm_alias alias if not get_target alias return Truelines __parse_aliases out []for line_alias line_target line_comment in lines if line_alias alias out append line_alias line_target line_comment __write_aliases_file out return True
def destroy_sink sink global sinksdel sinks[sink sink_id]del sink
def destroy_sink sink global sinksdel sinks[sink sink_id]del sink
def get_nova_v2_client session region return NovaClient session session region_name region version 2
def apply_penalty tensor_or_tensors penalty **kwargs try return sum penalty x **kwargs for x in tensor_or_tensors except TypeError ValueError return penalty tensor_or_tensors **kwargs
def lsmr_operator Jop d active_set m n Jop shapedef matvec x x_free x ravel copy x_free[active_set] 0return Jop matvec x * d def rmatvec x r d * Jop rmatvec x r[active_set] 0return rreturn LinearOperator m n matvec matvec rmatvec rmatvec dtype float
def follow_subrequest request subrequest **kwargs try try return request invoke_subrequest subrequest **kwargs subrequest except Exception as e resp render_view_to_response e subrequest if not resp or resp status_code > 500 raise eraise respexcept httpexceptions HTTPRedirection as e new_location e headers['Location']new_request Request blank path new_location headers subrequest headers POST subrequest body method subrequest method new_request bound_data subrequest bound_datanew_request parent getattr subrequest 'parent' None return request invoke_subrequest new_request **kwargs new_request
def plain text return re sub ' \x08' '' text
@api_wrapperdef update_export module export filesystem system changed Falsename module params['name']client_list module params['client_list']if export is None if not module check_mode export system exports create export_path name filesystem filesystem if client_list export update_permissions client_list changed Trueelif client_list if set map transform unmunchify export get_permissions set map transform client_list if not module check_mode export update_permissions client_list changed Truemodule exit_json changed changed
def getBridgeLoops layerThickness loop halfWidth 1 5 * layerThickness slightlyGreaterThanHalfWidth 1 1 * halfWidth extrudateLoops []centers intercircle getCentersFromLoop loop slightlyGreaterThanHalfWidth for center in centers extrudateLoop intercircle getSimplifiedInsetFromClockwiseLoop center halfWidth if intercircle isLargeSameDirection extrudateLoop center halfWidth if euclidean isPathInsideLoop loop extrudateLoop euclidean isWiddershins loop extrudateLoop reverse extrudateLoops append extrudateLoop return extrudateLoops
def find_cover_image container strict False ver container opf_version_parsedif ver major < 3 return find_cover_image2 container strict strict else return find_cover_image3 container
def pipeline_code_wrapper pipeline_code return '\nexported_pipeline {}\n\nexported_pipeline fit training_features training_classes \nresults exported_pipeline predict testing_features \n' format pipeline_code
def pipeline_code_wrapper pipeline_code return '\nexported_pipeline {}\n\nexported_pipeline fit training_features training_classes \nresults exported_pipeline predict testing_features \n' format pipeline_code
def libvlc_audio_get_track_count p_mi f _Cfunctions get 'libvlc_audio_get_track_count' None or _Cfunction 'libvlc_audio_get_track_count' 1 None ctypes c_int MediaPlayer return f p_mi
def pcoa lines dist_mtx DistanceMatrix read lines pcoa_obj PCoA dist_mtx return pcoa_obj scores
def del_password name cmd "dscl -passwd/Users/{0}''" format name try salt utils mac_utils execute_return_success cmd except CommandExecutionError as exc if 'eDSUnknownNodeName' in exc strerror raise CommandExecutionError 'Usernotfound {0}' format name raise CommandExecutionError 'Unknownerror {0}' format exc strerror cmd "dscl -create/Users/{0}Password'*'" format name salt utils mac_utils execute_return_success cmd return info name ['passwd'] '*'
def _parse_dbus_locale bus dbus SystemBus localed bus get_object 'org freedesktop locale1' '/org/freedesktop/locale1' properties dbus Interface localed 'org freedesktop DBus Properties' system_locale properties Get 'org freedesktop locale1' 'Locale' ret {}for env_var in system_locale match re match '^ [A-Z_]+ * $' env_var if match ret[match group 1 ] match group 2 replace '"' '' else log error 'Oddlocaleparameter"{0}"detectedindbuslocaleoutput Thisshouldnothappen Youshouldprobablyinvestigatewhatcausedthis ' format env_var return ret
def expand_to_match items cfg2newlines {}for configuration lines in items cfg2newlines[configuration] []maxguard 2 ** 30 while True minimalsourceline maxguardfor configuration lines in items if lines minimalsourceline min minimalsourceline lines[0] sourceline if minimalsourceline maxguard breakfor configuration lines in items if lines and lines[0] sourceline < minimalsourceline cfg2newlines[configuration] append lines[0] del lines[0]number_of_lines max len x for x in cfg2newlines values for newlines in cfg2newlines values add number_of_lines - len newlines newlines extend ['\n'] * add return cfg2newlines
def expand_to_match items cfg2newlines {}for configuration lines in items cfg2newlines[configuration] []maxguard 2 ** 30 while True minimalsourceline maxguardfor configuration lines in items if lines minimalsourceline min minimalsourceline lines[0] sourceline if minimalsourceline maxguard breakfor configuration lines in items if lines and lines[0] sourceline < minimalsourceline cfg2newlines[configuration] append lines[0] del lines[0]number_of_lines max len x for x in cfg2newlines values for newlines in cfg2newlines values add number_of_lines - len newlines newlines extend ['\n'] * add return cfg2newlines
def expand_to_match items cfg2newlines {}for configuration lines in items cfg2newlines[configuration] []maxguard 2 ** 30 while True minimalsourceline maxguardfor configuration lines in items if lines minimalsourceline min minimalsourceline lines[0] sourceline if minimalsourceline maxguard breakfor configuration lines in items if lines and lines[0] sourceline < minimalsourceline cfg2newlines[configuration] append lines[0] del lines[0]number_of_lines max len x for x in cfg2newlines values for newlines in cfg2newlines values add number_of_lines - len newlines newlines extend ['\n'] * add return cfg2newlines
def resolve_all anno task return x for x in _first_match anno task _first_match_any anno if x
def normalize_to_string host_string return join_host_strings *normalize host_string
def splitunc p import warningswarnings warn 'ntpath splituncisdeprecated usentpath splitdriveinstead' DeprecationWarning 2 drive path splitdrive p if len drive 2 return p[ 0] p return drive path
def _arr2img ar return Image frombytes 'L' ar shape[1] ar shape[0] ar astype numpy ubyte tostring
def safe_loads arg try loaded json loads arg except TypeError ValueError loaded argreturn loaded
def safe_loads arg try loaded json loads arg except TypeError ValueError loaded argreturn loaded
def string_eval source node ast parse source '<source>' mode 'eval' if not isinstance node body ast Str raise ValueError '%risnotastringliteral' % source return node body s
def test_start_no_items hist with pytest raises cmdhistory HistoryEmptyError hist start 'k' assert not hist _tmphist
def addObserver section name target attr None dtype str callback None default None observers config observers setdefault section lower name lower {} if not attr tokens name lower split attr tokens[0] + '' join t title for t in tokens[1 ] log debug 'Subscribing%s %s' target attr attr intern attr targetref weakref ref target observers setdefault targetref attr callback val _getProperty section name dtype default setattr target attr val if callback callback val
def _check_vlim vlim return not np isscalar vlim and vlim is not None
def _call_test_function func *args **dargs try return func *args **dargs except error AutotestError raiseexcept Exception as e raise error UnhandledTestFail e
def CreateMDIInteractiveWindow makeDoc None makeFrame None global editif makeDoc is None makeDoc InteractiveDocumentif makeFrame is None makeFrame InteractiveFrameedit CInteractivePython makeDoc makeDoc makeFrame makeFrame
def compute_change labels before after result {}for label before after in zip labels before after matched_keys set before & set after value {key after[key] - before[key] for key in matched_keys}result[label] valuereturn result
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
@pytest mark parametrize 'parallel' [True False] def test_default_data_start parallel read_basic text 'ignorethisline\nabc\n123\n456'table read_basic text header_start 1 parallel parallel expected Table [[1 4] [2 5] [3 6]] names 'a' 'b' 'c' assert_table_equal table expected
def strordict_fullname item key 'fullname' try d pickle loads item except d {key item}if not isinstance d dict or key not in d or not isinstance d[key] str raise ValueError 'Errortryingtomigrate%r %r ' % item d return d
def strordict_fullname item key 'fullname' try d pickle loads item except d {key item}if not isinstance d dict or key not in d or not isinstance d[key] str raise ValueError 'Errortryingtomigrate%r %r ' % item d return d
def _image_locations_delete_all context image_id delete_time None session None session session or get_session location_refs session query models ImageLocation filter_by image_id image_id filter_by deleted False all for loc_id in [loc_ref id for loc_ref in location_refs] image_location_delete context image_id loc_id 'deleted' delete_time delete_time session session
def write_double_matrix fid kind mat FIFFT_MATRIX 1 << 30 FIFFT_MATRIX_DOUBLE FIFF FIFFT_DOUBLE FIFFT_MATRIX data_size 8 * mat size + 4 * mat ndim + 1 fid write np array kind dtype '>i4' tostring fid write np array FIFFT_MATRIX_DOUBLE dtype '>i4' tostring fid write np array data_size dtype '>i4' tostring fid write np array FIFF FIFFV_NEXT_SEQ dtype '>i4' tostring fid write np array mat dtype '>f8' tostring dims np empty mat ndim + 1 dtype np int32 dims[ mat ndim] mat shape[ -1 ]dims[ -1 ] mat ndimfid write np array dims dtype '>i4' tostring check_fiff_length fid
def make_logged_in_client username 'test' password 'test' is_superuser True recreate False groupname None try user User objects get username username if recreate user delete raise User DoesNotExistexcept User DoesNotExist user User objects create_user username username + '@localhost' password user is_superuser is_superuseruser save else if user is_superuser is_superuser user is_superuser is_superuseruser save if groupname is not None group created Group objects get_or_create name groupname if not user groups filter name group name exists user groups add group user save c Client ret c login username username password password assert ret "Loginfailed user'%s' " % username return c
@taskdef virtualenv_verify requirements_revision None req_rev requirements_revision or latest_requirements_revision env_dir 'env %s' % req_rev package_dir 'python-package %s' % req_rev requirements_file 'prod-requirements txt %s' % req_rev with settings warn_only True out run '~/%s/viewfinder/bin/pipinstall-ffile //$HOME/%s--no-index-r~/%s--no-install--no-download-q' % env_dir package_dir requirements_file if out return_code 0 fprint 'Validvirtualenvironmentforprod-requirements rev%s ' % req_rev return Trueelse fprint 'Badvirtualenvironmentforprod-requirements rev%s ' % req_rev return False
def get_logging_manager manage_stdout_and_stderr False redirect_fds False if redirect_fds manager FdRedirectionLoggingManager else manager LoggingManager if manage_stdout_and_stderr manager manage_stdout manager manage_stderr return manager
def get_logging_manager manage_stdout_and_stderr False redirect_fds False if redirect_fds manager FdRedirectionLoggingManager else manager LoggingManager if manage_stdout_and_stderr manager manage_stdout manager manage_stderr return manager
@app route '/<slug_candidate>' def index slug_candidate check_slug_candidate slug_candidate add_request REQUEST_LOAD request path global stay_open download_in_progressdeny_download not stay_open and download_in_progress if deny_download return render_template_string open helpers get_resource_path 'html/denied html' read return render_template_string open helpers get_resource_path 'html/index html' read slug slug file_info file_info filename os path basename zip_filename filesize zip_filesize filesize_human helpers human_readable_filesize zip_filesize
def run_remotely username address commands port 22 log_command_filter identity return Effect RunRemotely username username address address commands commands port port log_command_filter log_command_filter
def main password getpass for a_dict in pynet1 pynet2 juniper_srx a_dict['password'] passworda_dict['verbose'] Falsenet_connect ConnectHandler **pynet2 config_commands ['loggingbuffered20000']net_connect send_config_set config_commands output net_connect send_command 'showrun incloggingbuffer' printprint '#' * 80 print 'Device {} {}' format net_connect ip net_connect port printprint outputprint '#' * 80 print
def main password getpass for a_dict in pynet1 pynet2 juniper_srx a_dict['password'] passworda_dict['verbose'] Falsenet_connect ConnectHandler **pynet2 config_commands ['loggingbuffered20000']net_connect send_config_set config_commands output net_connect send_command 'showrun incloggingbuffer' printprint '#' * 80 print 'Device {} {}' format net_connect ip net_connect port printprint outputprint '#' * 80 print
def main password getpass for a_dict in pynet1 pynet2 juniper_srx a_dict['password'] passworda_dict['verbose'] Falsenet_connect ConnectHandler **pynet2 config_commands ['loggingbuffered20000']net_connect send_config_set config_commands output net_connect send_command 'showrun incloggingbuffer' printprint '#' * 80 print 'Device {} {}' format net_connect ip net_connect port printprint outputprint '#' * 80 print
def iter_traceback_frames tb while tb and hasattr tb 'tb_frame' f_locals getattr tb tb_frame 'f_locals' {} if not _getitem_from_frame f_locals '__traceback_hide__' yield tb tb_frame getattr tb 'tb_lineno' None tb tb tb_next
def fix_index builder idx size is_negative builder icmp_signed '<' idx ir Constant size type 0 wrapped_index builder add idx size return builder select is_negative wrapped_index idx
@Profiler profiledef test_dbapi_raw n conn engine pool _creator cursor conn cursor compiled Customer __table__ insert values name bindparam 'name' description bindparam 'description' compile dialect engine dialect if compiled positional args 'customername%d' % i 'customerdescription%d' % i for i in range n else args dict name 'customername%d' % i description 'customerdescription%d' % i for i in range n cursor executemany str compiled list args conn commit conn close
def _table_proportion count nobs table np column_stack count nobs - count expected table sum 0 * table sum 1 [ None] * 1 0 / table sum n_rows table shape[0]return table expected n_rows
def getDBTables uri None DB_TABLES []for table in DB_SCHEMA if table name in TABLES_REPOSITORY DB_TABLES append TABLES_REPOSITORY[table name] continueattrs {'_imdbpyName' table name '_imdbpySchema' table 'addIndexes' addIndexes 'addForeignKeys' addForeignKeys}for col in table cols if col name 'id' continueattrs[col name] MAP_COLS[col kind] **col params cls type table name SQLObject attrs DB_TABLES append cls TABLES_REPOSITORY[table name] clsreturn DB_TABLES
def InstallTemplatePackage virtualenv_bin os path dirname sys executable extension os path splitext sys executable [1]pip '%s/pip%s' % virtualenv_bin extension major_minor_version ' ' join pkg_resources get_distribution 'grr-response-core' version split ' ' [0 2] subprocess check_call [sys executable pip 'install' '--upgrade' '-f' 'https //storage googleapis com/releases grr-response com/index html' 'grr-response-templates %s *' % major_minor_version ]
def addAcceleratorCommand acceleratorBinding commandFunction master menu text acceleratorText acceleratorBinding[1 -1 ]lastIndexOfMinus acceleratorText rfind '-' if lastIndexOfMinus > -1 acceleratorText acceleratorText[ lastIndexOfMinus + 1 ] + acceleratorText[ lastIndexOfMinus + 1 ] capitalize acceleratorText acceleratorText replace 'KeyPress-' '' acceleratorText acceleratorText replace '-' '+' acceleratorText acceleratorText replace 'Control' 'Ctrl' acceleratorBinding acceleratorBinding replace 'KeyPress' '' menu add_command accelerator acceleratorText label text underline 0 command commandFunction master bind acceleratorBinding commandFunction
def get_parent_unit xblock while xblock xblock xblock get_parent if xblock is None return Noneparent xblock get_parent if parent is None return Noneif parent category 'sequential' return xblock
def get_parent_unit xblock while xblock xblock xblock get_parent if xblock is None return Noneparent xblock get_parent if parent is None return Noneif parent category 'sequential' return xblock
def startTLS transport contextFactory normal bypass if normal client transport _tlsClientDefaultelse client not transport _tlsClientDefault producer streaming None None if transport producer is not None producer streaming transport producer transport streamingProducer transport unregisterProducer tlsFactory TLSMemoryBIOFactory contextFactory client None tlsProtocol TLSMemoryBIOProtocol tlsFactory transport protocol False transport protocol tlsProtocoltransport getHandle tlsProtocol getHandletransport getPeerCertificate tlsProtocol getPeerCertificatedirectlyProvides transport ISSLTransport transport TLS Truetransport protocol makeConnection _BypassTLS bypass transport if producer transport registerProducer producer streaming
def mock_resource_with filename resource_type VALID_RESOURCES ['html' 'txt']if resource_type not in VALID_RESOURCES raise Exception 'Mockedresourcemustbeoneof %s' % ' ' join VALID_RESOURCES subfolder 'text' if resource_type 'txt' else 'html' resource_path os path join TEST_DIR 'data/%s/%s %s' % subfolder filename resource_type with open resource_path 'r' as f return f read
def check_paypal_id name d dict version settings PAYPAL_API_VERSION buttoncode 'cleartext' buttontype 'donate' method 'BMCreateButton' l_buttonvar0 'business %s' % name d['user'] settings PAYPAL_EMBEDDED_AUTH['USER']d['pwd'] settings PAYPAL_EMBEDDED_AUTH['PASSWORD']d['signature'] settings PAYPAL_EMBEDDED_AUTH['SIGNATURE']r requests get settings PAYPAL_API_URL params d timeout 10 response dict urlparse parse_qsl r text valid response['ACK'] 'Success' msg None if valid else response['L_LONGMESSAGE0'] return valid msg
def check_paypal_id name d dict version settings PAYPAL_API_VERSION buttoncode 'cleartext' buttontype 'donate' method 'BMCreateButton' l_buttonvar0 'business %s' % name d['user'] settings PAYPAL_EMBEDDED_AUTH['USER']d['pwd'] settings PAYPAL_EMBEDDED_AUTH['PASSWORD']d['signature'] settings PAYPAL_EMBEDDED_AUTH['SIGNATURE']r requests get settings PAYPAL_API_URL params d timeout 10 response dict urlparse parse_qsl r text valid response['ACK'] 'Success' msg None if valid else response['L_LONGMESSAGE0'] return valid msg
def check_for_obj_leakage f *args **kwargs f gc collect gc collect gc collect f gc collect gc collect gc collect r1 gc get_objects f gc collect gc collect gc collect r2 gc get_objects d2 dict [ id x x for x in r2] del d2[id r1 ]for o in r1 if id o in d2 del d2[id o ]return len r2 - len r1 - 1 d2
def test_mark_done_problem pg_xlog monkeypatch seg make_segment 1 explicit False with pytest raises exception UserCritical seg mark_done
def signalcommand func def inner self *args **kwargs pre_command send self __class__ args args kwargs kwargs ret func self *args **kwargs post_command send self __class__ args args kwargs kwargs outcome ret return retreturn inner
def signalcommand func def inner self *args **kwargs pre_command send self __class__ args args kwargs kwargs ret func self *args **kwargs post_command send self __class__ args args kwargs kwargs outcome ret return retreturn inner
def encode_short_string pieces value encoded_value as_bytes value length len encoded_value if length > 255 raise exceptions ShortStringTooLong encoded_value pieces append struct pack 'B' length pieces append encoded_value return 1 + length
def handle_protectederror obj request e dependent_objects e[1]try dep_class dependent_objects[0] _meta verbose_name_pluralexcept IndexError raise eif type obj in list tuple err_message 'Unabletodeletetherequested{} Thefollowingdependent{}werefound ' format obj[0] _meta verbose_name_plural dep_class else err_message 'Unabletodelete{}{} Thefollowingdependent{}werefound ' format obj _meta verbose_name obj dep_class dependent_objects []for o in e[1] if hasattr o 'get_absolute_url' dependent_objects append '<ahref "{}">{}</a>' format o get_absolute_url str o else dependent_objects append str o err_message + ' ' join dependent_objects messages error request err_message
def handle_protectederror obj request e dependent_objects e[1]try dep_class dependent_objects[0] _meta verbose_name_pluralexcept IndexError raise eif type obj in list tuple err_message 'Unabletodeletetherequested{} Thefollowingdependent{}werefound ' format obj[0] _meta verbose_name_plural dep_class else err_message 'Unabletodelete{}{} Thefollowingdependent{}werefound ' format obj _meta verbose_name obj dep_class dependent_objects []for o in e[1] if hasattr o 'get_absolute_url' dependent_objects append '<ahref "{}">{}</a>' format o get_absolute_url str o else dependent_objects append str o err_message + ' ' join dependent_objects messages error request err_message
def test_replace_update_column_via_setitem_warnings_always t table Table [[1 2 3] [4 5 6]] names ['a' 'b'] with catch_warnings as w with table conf set_temp 'replace_warnings' ['always'] t['a'] 0assert len w 0 from inspect import currentframe getframeinfoframeinfo getframeinfo currentframe t['a'] [10 20 30]assert len w 1 assert "replacedcolumn'a'" str w[0] message assert w[0] lineno frameinfo lineno + 1 assert w[0] category is table TableReplaceWarning assert 'test_table' in w[0] filename
def _penn_to_wordnet tag if tag in u'NN' u'NNS' u'NNP' u'NNPS' return _wordnet NOUNif tag in u'JJ' u'JJR' u'JJS' return _wordnet ADJif tag in u'VB' u'VBD' u'VBG' u'VBN' u'VBP' u'VBZ' return _wordnet VERBif tag in u'RB' u'RBR' u'RBS' return _wordnet ADVreturn None
def _penn_to_wordnet tag if tag in u'NN' u'NNS' u'NNP' u'NNPS' return _wordnet NOUNif tag in u'JJ' u'JJR' u'JJS' return _wordnet ADJif tag in u'VB' u'VBD' u'VBG' u'VBN' u'VBP' u'VBZ' return _wordnet VERBif tag in u'RB' u'RBR' u'RBS' return _wordnet ADVreturn None
def _passphrase_callback passphrase def f *args return passphrasereturn f
def hex2rgb255 hexColor if hexColor[0] '#' hexColor hexColor[1 ]elif hexColor[0 2] lower '0x' hexColor hexColor[2 ]if len hexColor 3 hexColor hexColor[0] + '0' + hexColor[1] + '0' + hexColor[2] + '0' rgb int hexColor[0 2] 16 int hexColor[2 4] 16 int hexColor[4 6] 16 return rgb
def demo_error_analysis postag error_output 'errors txt'
def demo_error_analysis postag error_output 'errors txt'
def combine_types x y if isinstance x Unknown return yif isinstance y Unknown return xif isinstance x Any return xif isinstance y Any return yif isinstance x Union return combine_either x y if isinstance y Union return combine_either y x if x y return xreturn simplify_either [x] [y]
def checks sfile logger if sfile['idkey'] 'idkey' logger error 'idkeyhasnotbeenspecified' return Falseif os pathi isfile sfile['idkey'] False logger error 'couldnotlocateyourIDKey' return Falseelif sfile['lp'] '' logger error 'lpiphasnotbeenspecified' return Falseelif sfile['implant'] '' logger error 'implantiphasnotbeenspecified' return Falseelif sfile['sport'] '' logger error 'sourceporthasnotbeenspecified' return Falseelif sfile['dport'] '' logger error 'destinationporthadnotbeenspecified' return Falseelif sfile['target'] '' logger error 'targetiphasnotbeenspecified' return Falseelif sfile['hostname'] '' logger error 'targethostnamehasnotbeenspecified' return Falseelse logger debug 'allcheckshavepassed' return True
def islink p return _false
def islink p return _false
def BuildToken request execution_time token access_control ACLToken username request user reason request REQ get 'reason' '' process 'GRRAdminUI' expiry rdfvalue RDFDatetime Now + execution_time for field in ['REMOTE_ADDR' 'HTTP_X_FORWARDED_FOR'] remote_addr request META get field '' if remote_addr token source_ips append remote_addr return token
def libvlc_media_get_duration p_md f _Cfunctions get 'libvlc_media_get_duration' None or _Cfunction 'libvlc_media_get_duration' 1 None ctypes c_longlong Media return f p_md
def run_examples windowed False quiet False summary True successes []failures []examples TERMINAL_EXAMPLESif windowed examples + WINDOWED_EXAMPLESif quiet from sympy utilities runtests import PyTestReporterreporter PyTestReporter reporter write 'TestingExamples\n' reporter write '-' * reporter terminal_width else reporter Nonefor example in examples if run_example example reporter reporter successes append example else failures append example if summary show_summary successes failures reporter reporter return len failures 0
def run_examples windowed False quiet False summary True successes []failures []examples TERMINAL_EXAMPLESif windowed examples + WINDOWED_EXAMPLESif quiet from sympy utilities runtests import PyTestReporterreporter PyTestReporter reporter write 'TestingExamples\n' reporter write '-' * reporter terminal_width else reporter Nonefor example in examples if run_example example reporter reporter successes append example else failures append example if summary show_summary successes failures reporter reporter return len failures 0
def decode file data json load file features []for feature in data['features'] if feature['type'] 'Feature' continueif feature['geometry']['type'] 'GeometryCollection' continueprop feature['properties']geom transform asShape feature['geometry'] mercator features append geom wkb prop return features
def get_extended_due course unit user try override StudentFieldOverride objects get course_id course id student user location unit location field 'due' return DATE_FIELD from_json json loads override value except StudentFieldOverride DoesNotExist return None
def intFromBytes data byteorder signed False assert byteorder 'big' assert not signed if len data % 4 0 data '\x00' * 4 - len data % 4 + data result 0while len data > 0 digit struct unpack '>I' data[ 4] result result << 32 + digit data data[4 ]return result
def get_cluster_manager config_file None cache False cfg get_config config_file cache return cfg get_cluster_manager
def invitation_detail request token invitation Invitation objects get_invitation token if not invitation return invitation_error request 'Thisinvitationisnolongervalid ' backend getattr settings 'REGISTRATION_BACKEND' 'registration backends default DefaultBackend' return register request backend
def wrap_fragment fragment new_content wrapper_frag Fragment content new_content wrapper_frag add_frag_resources fragment return wrapper_frag
def wrap_fragment fragment new_content wrapper_frag Fragment content new_content wrapper_frag add_frag_resources fragment return wrapper_frag
def test_performance clock task Clock call task LoopingCall lambda None call clock clockcall start 0 1 clock advance 1000000
def test_performance clock task Clock call task LoopingCall lambda None call clock clockcall start 0 1 clock advance 1000000
def initializeZoneIntervalTable shape vertexes shape zoneInterval shape layerThickness / math sqrt len vertexes / 1000 0 shape zZoneTable {}for point in vertexes addToZoneTable point shape
@pytest mark parametrize 'fast_writer' [True False] @pytest mark parametrize 'fmt' ['%0 1f' ' 1f' '0 1f' '{0 0 1f}'] def test_write_format fast_writer fmt data ascii read '#c1\n#c2 DCTB \na b c\n#c3\n1 11 2 22 3 33' out StringIO expected ['#c1' '#c2' '#c3' 'abc' '1 12 223 33']data['a'] format fmtascii write data out format 'basic' fast_writer fast_writer assert out getvalue splitlines expected
def E_n n omega return hbar * omega * n + Rational 1 2
def E_n n omega return hbar * omega * n + Rational 1 2
def on_plugin_shutdown config pass
def libvlc_audio_equalizer_get_band_count f _Cfunctions get 'libvlc_audio_equalizer_get_band_count' None or _Cfunction 'libvlc_audio_equalizer_get_band_count' None ctypes c_uint return f
@FileSystem in_directory current_directory 'django' 'alfaces' def test_django_specifying_scenarios_to_run status out commands getstatusoutput 'pythonmanage pyharvest--verbosity 3--no-color--scenarios 2 5-afoobar' assert_equals status 0 out assert '2ndscenario' in out assert '5thscenario' in out assert '1stscenario' not in out assert '3rdscenario' not in out assert '4thscenario' not in out assert '6thscenario' not in out
def handle_error result if result return _ error_string get_error if not isinstance error_string str_cls error_string _try_decode error_string raise OSError error_string
def test_datasource_untouched original_data copy deepcopy MEMORY_DATA table UnorderedTable MEMORY_DATA table order_by u'i'list table rows assert MEMORY_DATA original_data table UnorderedTable MEMORY_DATA table order_by u'beta'list table rows assert MEMORY_DATA original_data
def build_options gens args None if args is None gens args gens if len args 1 or 'opt' not in args or gens return Options gens args else return args['opt']
def postprocess_for_cse expr optimizations for pre post in reversed optimizations if post is not None expr post expr return expr
def _new_value_pb entity_pb name return entity_pb properties get_or_create name
def boundaries x depth None kind None if not isinstance kind dict kind dict i kind for i in range x ndim if not isinstance depth dict depth dict i depth for i in range x ndim for i in range x ndim d depth get i 0 if d 0 continuethis_kind kind get i 'none' if this_kind 'none' continueelif this_kind 'periodic' x periodic x i d elif this_kind 'reflect' x reflect x i d elif this_kind 'nearest' x nearest x i d elif i in kind x constant x i d kind[i] return x
def boundaries x depth None kind None if not isinstance kind dict kind dict i kind for i in range x ndim if not isinstance depth dict depth dict i depth for i in range x ndim for i in range x ndim d depth get i 0 if d 0 continuethis_kind kind get i 'none' if this_kind 'none' continueelif this_kind 'periodic' x periodic x i d elif this_kind 'reflect' x reflect x i d elif this_kind 'nearest' x nearest x i d elif i in kind x constant x i d kind[i] return x
def dangling prune False force False all_images images all True dangling_images [x[ 12] for x in _get_top_level_images all_images if all_images[x]['RepoTags'] is None ]if not prune return dangling_imagesret {}for image in dangling_images try ret setdefault image {} ['Removed'] rmi image force force except Exception as exc err '{0}' format exc log error err ret setdefault image {} ['Comment'] errret[image]['Removed'] Falsereturn ret
def dangling prune False force False all_images images all True dangling_images [x[ 12] for x in _get_top_level_images all_images if all_images[x]['RepoTags'] is None ]if not prune return dangling_imagesret {}for image in dangling_images try ret setdefault image {} ['Removed'] rmi image force force except Exception as exc err '{0}' format exc log error err ret setdefault image {} ['Comment'] errret[image]['Removed'] Falsereturn ret
def dangling prune False force False all_images images all True dangling_images [x[ 12] for x in _get_top_level_images all_images if all_images[x]['RepoTags'] is None ]if not prune return dangling_imagesret {}for image in dangling_images try ret setdefault image {} ['Removed'] rmi image force force except Exception as exc err '{0}' format exc log error err ret setdefault image {} ['Comment'] errret[image]['Removed'] Falsereturn ret
def greedyQPolicy Qs dim len Qs numA len Qs[0] policy zeros dim numA for si in range dim actions all_argmax Qs[si] for a in actions policy[ si a ] 1 0 / len actions return policy
def date_from_adverb base_date name adverb_date datetime base_date year base_date month base_date day if name 'today' or name 'tonite' or name 'tonight' return adverb_date today elif name 'yesterday' return adverb_date - timedelta days 1 elif name 'tomorrow' or name 'tom' return adverb_date + timedelta days 1
def date_from_adverb base_date name adverb_date datetime base_date year base_date month base_date day if name 'today' or name 'tonite' or name 'tonight' return adverb_date today elif name 'yesterday' return adverb_date - timedelta days 1 elif name 'tomorrow' or name 'tom' return adverb_date + timedelta days 1
def rand_uuid return uuidutils generate_uuid
def randprime a b if a > b return a b map int a b n random randint a - 1 b p nextprime n if p > b p prevprime b if p < a raise ValueError 'noprimesexistinthespecifiedrange' return p
def randprime a b if a > b return a b map int a b n random randint a - 1 b p nextprime n if p > b p prevprime b if p < a raise ValueError 'noprimesexistinthespecifiedrange' return p
def getServiceEndpoints input_url flt None result discover input_url try endpoints applyFilter result normalized_uri result response_text flt except XRDSError as err raise DiscoveryFailure str err None return result normalized_uri endpoints
def getServiceEndpoints input_url flt None result discover input_url try endpoints applyFilter result normalized_uri result response_text flt except XRDSError as err raise DiscoveryFailure str err None return result normalized_uri endpoints
def getServiceEndpoints input_url flt None result discover input_url try endpoints applyFilter result normalized_uri result response_text flt except XRDSError as err raise DiscoveryFailure str err None return result normalized_uri endpoints
def value_present name datastore path config ret {'name' name 'result' False 'changes' {} 'comment' ''}existing __salt__['cisconso get_data'] datastore path if cmp existing config ret['result'] Trueret['comment'] 'Configisalreadyset'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillbeadded'diff _DictDiffer existing config ret['changes']['new'] diff added ret['changes']['removed'] diff removed ret['changes']['changed'] diff changed else __salt__['cisconso set_data_value'] datastore path config ret['result'] Trueret['comment'] 'Successfullyaddedconfig'diff _DictDiffer existing config ret['changes']['new'] diff added ret['changes']['removed'] diff removed ret['changes']['changed'] diff changed return ret
@api_versions wraps '2 8' @utils arg 'server' metavar '<server>' help _ 'NameorIDofserver ' def do_get_mks_console cs args server _find_server cs args server data server get_mks_console print_console cs data
def get_config_path home_dir None val op join _get_extra_data_path home_dir home_dir 'mne-python json' return val
def show_growth limit 10 peak_stats {} shortnames True gc collect stats typestats shortnames shortnames deltas {}for name count in iteritems stats old_count peak_stats get name 0 if count > old_count deltas[name] count - old_count peak_stats[name] countdeltas sorted deltas items key operator itemgetter 1 reverse True if limit deltas deltas[ limit]if deltas width max len name for name count in deltas for name delta in deltas print '%-*s%9d%+9d' % width name stats[name] delta
def range_error_message error_message what_to_enter minimum maximum if error_message is None error_message 'Enter' + what_to_enter if minimum is not None and maximum is not None error_message + 'between% min gand% max g'elif minimum is not None error_message + 'greaterthanorequalto% min g'elif maximum is not None error_message + 'lessthanorequalto% max g'if type maximum in [int long] maximum - 1return translate error_message % dict min minimum max maximum
def names_to_indices names ordered_names indices []names_list list names for ordered_name in ordered_names if ordered_name in names_list indices append names_list index ordered_name return np array indices
def fmin_bfgs f x0 fprime None args gtol 1e-05 norm Inf epsilon _epsilon maxiter None full_output 0 disp 1 retall 0 callback None opts {'gtol' gtol 'norm' norm 'eps' epsilon 'disp' disp 'maxiter' maxiter 'return_all' retall}res _minimize_bfgs f x0 args fprime callback callback **opts if full_output retlist res['x'] res['fun'] res['jac'] res['hess_inv'] res['nfev'] res['njev'] res['status'] if retall retlist + res['allvecs'] return retlistelif retall return res['x'] res['allvecs'] else return res['x']
def MACDFIX ds count signalperiod - 2 ** 31 ret call_talib_with_ds ds count talib MACDFIX signalperiod if ret is None ret None None None return ret
def get_key_reference scope name user None if scope SYSTEM_SCOPE or scope FULL_SYSTEM_SCOPE return nameelif scope USER_SCOPE or scope FULL_USER_SCOPE if not user raise InvalidUserException 'Avalidusermustbespecifiedforuserkeyref ' return UserKeyReference name name user user refelse raise InvalidScopeException 'Scope"%s"isnotvalid Allowedscopesare%s ' % scope ALLOWED_SCOPES
def get_key_reference scope name user None if scope SYSTEM_SCOPE or scope FULL_SYSTEM_SCOPE return nameelif scope USER_SCOPE or scope FULL_USER_SCOPE if not user raise InvalidUserException 'Avalidusermustbespecifiedforuserkeyref ' return UserKeyReference name name user user refelse raise InvalidScopeException 'Scope"%s"isnotvalid Allowedscopesare%s ' % scope ALLOWED_SCOPES
def get_key_reference scope name user None if scope SYSTEM_SCOPE or scope FULL_SYSTEM_SCOPE return nameelif scope USER_SCOPE or scope FULL_USER_SCOPE if not user raise InvalidUserException 'Avalidusermustbespecifiedforuserkeyref ' return UserKeyReference name name user user refelse raise InvalidScopeException 'Scope"%s"isnotvalid Allowedscopesare%s ' % scope ALLOWED_SCOPES
def get_key_reference scope name user None if scope SYSTEM_SCOPE or scope FULL_SYSTEM_SCOPE return nameelif scope USER_SCOPE or scope FULL_USER_SCOPE if not user raise InvalidUserException 'Avalidusermustbespecifiedforuserkeyref ' return UserKeyReference name name user user refelse raise InvalidScopeException 'Scope"%s"isnotvalid Allowedscopesare%s ' % scope ALLOWED_SCOPES
def add_remote path name remote_url use_sudo False user None fetch True if path is None raise ValueError 'Pathtotheworkingcopyisneededtoaddaremote' if fetch cmd 'gitremoteadd-f%s%s' % name remote_url else cmd 'gitremoteadd%s%s' % name remote_url with cd path if use_sudo and user is None run_as_root cmd elif use_sudo sudo cmd user user else run cmd
def EvalHypergeomPmf k N K n return stats hypergeom pmf k N K n
def test_sorted_bases assert u m * u Jy bases u Jy * u m bases
@gen enginedef RunOnce client job callback today util NowUTCToISO8601 last_run yield gen Task job FindLastSuccess with_payload_key 'stats last_day' if last_run is not None and last_run['stats last_day'] today and not options options force_recompute logging info 'Alreadyransuccessfullytoday skipping Specify--force_recomputetorecompute ' callback None returnday_stats yield gen Task ProcessTables client assert day_stats is not None hms logs_util kDailyMetricsTimeByLogType['dynamodb_user'] yield gen Task logs_util UpdateMetrics client {today day_stats} dry_run options options dry_run hms_tuple hms prefix_to_erase 'dynamodb user' callback today
def placeholder shape None ndim None dtype None sparse False name None if dtype is None dtype floatx if shape is None and ndim is None raise ValueError 'Specifyeitherashapeorndimvalue ' if shape is not None ndim len shape else shape tuple [None for _ in range ndim ] broadcast False * ndim if sparse _assert_sparse_module x th_sparse_module csr_matrix name name dtype dtype else x T TensorType dtype broadcast name x _keras_shape shapex _uses_learning_phase Falsereturn x
def test_rechunk_1d a np random uniform 0 1 300 x da from_array a chunks 100 * 3 new 50 * 6 x2 rechunk x chunks new assert x2 chunks new assert np all x2 compute a
def get_filters_for doctype config get_notification_config return config get u'for_doctype' get doctype {}
def assert_has_line_matching output expression match re search '^%s$' % expression output flags re MULTILINE assert match is not None "Nolinematchingexpression'%s'wasfoundinoutputfile " % expression
def assert_has_line_matching output expression match re search '^%s$' % expression output flags re MULTILINE assert match is not None "Nolinematchingexpression'%s'wasfoundinoutputfile " % expression
def test_discard_invalid_filenames runner Runner join abspath dirname __file__ 'invalid_module_name' verbosity 0 runner run
def quote s if not isinstance s str s s encode 'utf8' quoted stdlib_quote s if isinstance quoted bytes quoted quoted decode 'utf8' return quoted
def strip_uri_prefix path return re sub '^ /v\\d+ ?' '' six text_type path
def dynamic_string_param registry xml_parent data dynamic_param_common registry xml_parent data 'StringParameterDefinition'
def _is_minimal_bsgs base gens base1 []sgs1 gens[ ]size gens[0] sizefor i in range size if not all h _array_form[i] i for h in sgs1 base1 append i sgs1 [h for h in sgs1 if h _array_form[i] i ]return base1 base
def _is_minimal_bsgs base gens base1 []sgs1 gens[ ]size gens[0] sizefor i in range size if not all h _array_form[i] i for h in sgs1 base1 append i sgs1 [h for h in sgs1 if h _array_form[i] i ]return base1 base
def _is_minimal_bsgs base gens base1 []sgs1 gens[ ]size gens[0] sizefor i in range size if not all h _array_form[i] i for h in sgs1 base1 append i sgs1 [h for h in sgs1 if h _array_form[i] i ]return base1 base
@utils arg 'hypervisor' metavar '<hypervisor>' help _ 'NameorIDofthehypervisortoshowthedetailsof ' @utils arg '--wrap' dest 'wrap' metavar '<integer>' default 40 help _ 'Wraptheoutputtoaspecifiedlength Defaultis40or0todisable' def do_hypervisor_show cs args hyper _find_hypervisor cs args hypervisor utils print_dict utils flatten_dict hyper to_dict wrap int args wrap
def ui_open *files if files osname get_os_name opener _OPENER_BY_OS get osname if opener opener files else raise OpenError u'Opencurrentlynotsupportedfor' + osname
def getEvaluatedInt defaultValue elementNode key if elementNode None return Noneif key in elementNode attributes try return getIntFromFloatString getEvaluatedValueObliviously elementNode key except print 'Warning couldnotevaluatetheint 'print keyprint elementNode attributes[key]return defaultValue
def is_pure_elemwise graph inputs allowed_ops tensor basic DimShuffle tensor basic Elemwise owner graph ownerop graph owner op if graph owner is not None else None if owner is None and graph in inputs return Trueelif owner is None and isinstance graph tensor basic TensorConstant return Trueelif owner is None and graph not in inputs return Falseelif op is not None and not isinstance op allowed_ops return Falseelse if isinstance graph owner op tensor basic DimShuffle shuffled graph owner inputs[0]if not isinstance shuffled tensor basic TensorConstant return Falsefor inp in graph owner inputs if not is_pure_elemwise inp inputs return Falsereturn True
def instance_get_floating_address context instance_id return IMPL instance_get_floating_address context instance_id
def _replace reps if not reps return lambda x x D lambda match reps[match group 0 ] pattern _re compile ' ' join [_re escape k for k v in reps items ] _re M return lambda string pattern sub D string
def config_check name passed default module diff DefaultVMConfig passed default if len diff shallow_diff module fail_json msg 'Missingrequiredkey/pair[%s] %smustcontain%s' % ' ' join diff shallow_diff name default if diff recursive_diff module fail_json msg 'Configmismatchfor%son%s' % name diff recursive_diff return True
def config_check name passed default module diff DefaultVMConfig passed default if len diff shallow_diff module fail_json msg 'Missingrequiredkey/pair[%s] %smustcontain%s' % ' ' join diff shallow_diff name default if diff recursive_diff module fail_json msg 'Configmismatchfor%son%s' % name diff recursive_diff return True
def make_secgroup_list security_groups secgroups objects SecurityGroupList secgroups objects []for sg in security_groups secgroup objects SecurityGroup if uuidutils is_uuid_like sg secgroup uuid sgelse secgroup name sgsecgroups objects append secgroup return secgroups
def str2gib_size s size_in_bytes str2size s return size_in_bytes // units Gi
def str2gib_size s size_in_bytes str2size s return size_in_bytes // units Gi
def base64_decode string string want_bytes string encoding 'ascii' errors 'ignore' return base64 urlsafe_b64decode string + ' ' * - len string % 4
def modifiers_dict modifiers return {mod[4 ] lower modifiers & getattr sys modules[__name__] mod > 0 for mod in ['MOD_SHIFT' 'MOD_CTRL' 'MOD_ALT' 'MOD_CAPSLOCK' 'MOD_NUMLOCK' 'MOD_WINDOWS' 'MOD_COMMAND' 'MOD_OPTION' 'MOD_SCROLLLOCK']}
def read_certificates glob_path ret {}for path in glob glob glob_path if os path isfile path try ret[path] read_certificate certificate path except ValueError passreturn ret
def wheel name **kwargs ret {'name' name 'result' False 'changes' {} 'comment' ''}try jid __orchestration_jid__except NameError log debug 'Unabletofireargseventduetomissing__orchestration_jid__' jid Noneout __salt__['saltutil wheel'] name __orchestration_jid__ jid __env__ __env__ **kwargs ret['result'] Trueret['comment'] "Wheelfunction'{0}'executed " format name ret['__orchestration__'] Trueif 'jid' in out ret['__jid__'] out['jid']runner_return out get 'return' if runner_return ret['changes'] runner_returnreturn ret
@check_dataset_access_permission@check_dataset_edition_permission def edit_coordinator_dataset request dataset response {'status' -1 'data' 'None'}if request method 'POST' dataset_form DatasetForm request POST instance dataset prefix 'edit' if dataset_form is_valid dataset dataset_form save response['status'] 0response['data'] reverse 'oozie edit_coordinator' kwargs {'coordinator' dataset coordinator id} + '#listDataset' request info _ 'Datasetmodified' if dataset start > dataset coordinator start request warn _ 'Beware datasetstartdatewasafterthecoordinatorstartdate ' else response['data'] dataset_form errorselse dataset_form DatasetForm instance dataset prefix 'edit' if response['status'] 0 response['data'] render 'editor/edit_coordinator_dataset mako' request {'coordinator' dataset coordinator 'dataset_form' dataset_form 'dataset' dataset 'path' request path} force_template True contentreturn JsonResponse response safe False
def is_proj_plane_distorted wcs maxerr 1e-05 cwcs wcs celestialreturn not _is_cd_orthogonal cwcs pixel_scale_matrix maxerr or _has_distortion cwcs
def test_continue_on_collection_errors testdir testdir makepyfile **COLLECTION_ERROR_PY_FILES res testdir runpytest '--continue-on-collection-errors' assert res ret 1 res stdout fnmatch_lines ['collected2items/2errors' '*1failed 1passed 2error*']
def GlobalProcess return _dev_process
@pytest fixturedef key_config_stub stubs stub stubs KeyConfigStub objreg register 'key-config' stub yield stub objreg delete 'key-config'
def calculate_children evaluator children iterator iter children types evaluator eval_element next iterator for operator in iterator right next iterator if tree is_node operator 'comp_op' operator '' join str c value for c in operator children if operator in 'and' 'or' left_bools set [left py__bool__ for left in types] if left_bools set [True] if operator 'and' types evaluator eval_element right elif left_bools set [False] if operator 'and' types evaluator eval_element right else types calculate evaluator types operator evaluator eval_element right debug dbg 'calculate_childrentypes%s' types return types
def test_cos_dataset skip_if_no_data dataset CosDataset sample_batch dataset get_batch_design batch_size 10000 assert sample_batch shape 10000 2 assert sample_batch[ 0] min > dataset min_x assert sample_batch[ 0] max < dataset max_x
def test_cos_dataset skip_if_no_data dataset CosDataset sample_batch dataset get_batch_design batch_size 10000 assert sample_batch shape 10000 2 assert sample_batch[ 0] min > dataset min_x assert sample_batch[ 0] max < dataset max_x
def detect_config_path try proc subprocess Popen ['nginx' '-V'] stderr subprocess PIPE except OSError error_exit 'Accesslogfileorformatwasnotsetandnginxconfigfilecannotbedetected ' + 'PerhapsnginxisnotinyourPATH?' stdout stderr proc communicate version_output stderr decode 'utf-8' conf_path_match re search '--conf-path \\S* ' version_output if conf_path_match is not None return conf_path_match group 1 prefix_match re search '--prefix \\S* ' version_output if prefix_match is not None return prefix_match group 1 + '/conf/nginx conf' return '/etc/nginx/nginx conf'
def can_list access_key secret_key if not access_key and secret_key return Falsetry connect_s3 access_key secret_key get_all_buckets except exception S3ResponseError return Falsereturn True
def normalize_keys_upper data return dict key upper val for key val in data items
def _http_request url method 'GET' headers None data None req requests request method url headers headers data data ret _default_ret ok_status METHOD_OK_STATUS get method 200 if req status_code ok_status ret update {'comment' req json get 'error' '' } return retret update {'result' True 'out' req json if method 'DELETE' else None } return ret
def _est_time_to_hour cluster_summary now None if now is None now datetime utcnow timeline getattr getattr cluster_summary 'status' None 'timeline' None creationdatetime getattr timeline 'creationdatetime' None if creationdatetime start iso8601_to_datetime creationdatetime else return timedelta minutes 60 run_time now - start return timedelta seconds - run_time seconds % 3600 0 or 3600 0
def _est_time_to_hour cluster_summary now None if now is None now datetime utcnow timeline getattr getattr cluster_summary 'status' None 'timeline' None creationdatetime getattr timeline 'creationdatetime' None if creationdatetime start iso8601_to_datetime creationdatetime else return timedelta minutes 60 run_time now - start return timedelta seconds - run_time seconds % 3600 0 or 3600 0
def _est_time_to_hour cluster_summary now None if now is None now datetime utcnow timeline getattr getattr cluster_summary 'status' None 'timeline' None creationdatetime getattr timeline 'creationdatetime' None if creationdatetime start iso8601_to_datetime creationdatetime else return timedelta minutes 60 run_time now - start return timedelta seconds - run_time seconds % 3600 0 or 3600 0
def GetSecretFile secret if sys platform startswith 'linux' if secret not in _tempfile_map f tempfile TemporaryFile set_close_exec f fileno f write GetSecret secret f flush _tempfile_map[secret] freturn '/dev/fd/%d' % _tempfile_map[secret] fileno else if secret not in _tempfile_map _ name tempfile mkstemp with open name 'w' as f f write GetSecret secret _tempfile_map[secret] nameatexit register os remove name return _tempfile_map[secret]
def GetSecretFile secret if sys platform startswith 'linux' if secret not in _tempfile_map f tempfile TemporaryFile set_close_exec f fileno f write GetSecret secret f flush _tempfile_map[secret] freturn '/dev/fd/%d' % _tempfile_map[secret] fileno else if secret not in _tempfile_map _ name tempfile mkstemp with open name 'w' as f f write GetSecret secret _tempfile_map[secret] nameatexit register os remove name return _tempfile_map[secret]
def GetSecretFile secret if sys platform startswith 'linux' if secret not in _tempfile_map f tempfile TemporaryFile set_close_exec f fileno f write GetSecret secret f flush _tempfile_map[secret] freturn '/dev/fd/%d' % _tempfile_map[secret] fileno else if secret not in _tempfile_map _ name tempfile mkstemp with open name 'w' as f f write GetSecret secret _tempfile_map[secret] nameatexit register os remove name return _tempfile_map[secret]
def test_instantiate_regression yaml "{'a' &test obj pylearn2 config tests test_yaml_parse DumDum{} 'b' *test}"obj load yaml assert obj['a'] is obj['b']
def test_instantiate_regression yaml "{'a' &test obj pylearn2 config tests test_yaml_parse DumDum{} 'b' *test}"obj load yaml assert obj['a'] is obj['b']
def test_instantiate_regression yaml "{'a' &test obj pylearn2 config tests test_yaml_parse DumDum{} 'b' *test}"obj load yaml assert obj['a'] is obj['b']
def test_instantiate_regression yaml "{'a' &test obj pylearn2 config tests test_yaml_parse DumDum{} 'b' *test}"obj load yaml assert obj['a'] is obj['b']
def _convert_etree_element_to_topic entry_element topic Topic invalid_topic Truetopic_element entry_element find ' /atom content/sb TopicDescription' _etree_sb_feed_namespaces if topic_element is not None mappings [ 'DefaultMessageTimeToLive' 'default_message_time_to_live' None 'MaxSizeInMegabytes' 'max_size_in_megabytes' int 'RequiresDuplicateDetection' 'requires_duplicate_detection' _parse_bool 'DuplicateDetectionHistoryTimeWindow' 'duplicate_detection_history_time_window' None 'EnableBatchedOperations' 'enable_batched_operations' _parse_bool 'SizeInBytes' 'size_in_bytes' int ]for map in mappings if _read_etree_element topic_element map[0] topic map[1] map[2] invalid_topic Falseif invalid_topic raise AzureServiceBusResourceNotFound _ERROR_TOPIC_NOT_FOUND for name value in _ETreeXmlToObject get_entry_properties_from_element entry_element True items setattr topic name value return topic
def _convert_etree_element_to_topic entry_element topic Topic invalid_topic Truetopic_element entry_element find ' /atom content/sb TopicDescription' _etree_sb_feed_namespaces if topic_element is not None mappings [ 'DefaultMessageTimeToLive' 'default_message_time_to_live' None 'MaxSizeInMegabytes' 'max_size_in_megabytes' int 'RequiresDuplicateDetection' 'requires_duplicate_detection' _parse_bool 'DuplicateDetectionHistoryTimeWindow' 'duplicate_detection_history_time_window' None 'EnableBatchedOperations' 'enable_batched_operations' _parse_bool 'SizeInBytes' 'size_in_bytes' int ]for map in mappings if _read_etree_element topic_element map[0] topic map[1] map[2] invalid_topic Falseif invalid_topic raise AzureServiceBusResourceNotFound _ERROR_TOPIC_NOT_FOUND for name value in _ETreeXmlToObject get_entry_properties_from_element entry_element True items setattr topic name value return topic
def filter_none **kwargs return dict k v for k v in six iteritems kwargs if v is not None
@processor_for Category exact_page True def category_processor request page settings clear_cache products Product objects published for_user request user filter page category filters distinct sort_options [ slugify option[0] option[1] for option in settings SHOP_PRODUCT_SORT_OPTIONS]sort_by request GET get u'sort' sort_options[0][1] if sort_options else u'-date_added' products paginate products order_by sort_by request GET get u'page' 1 settings SHOP_PER_PAGE_CATEGORY settings MAX_PAGING_LINKS products sort_by sort_bysub_categories page category children published child_categories Category objects filter id__in sub_categories return {u'products' products u'child_categories' child_categories}
@click command u'use' @click argument u'site' def _use site sites_path u' ' use site sites_path sites_path
def security_group_get_all context return IMPL security_group_get_all context
def enabled name runas None ret {'name' name 'result' True 'comment' '' 'changes' {}}try plugin_enabled __salt__['rabbitmq plugin_is_enabled'] name runas runas except CommandExecutionError as err ret['result'] Falseret['comment'] 'Error {0}' format err return retif plugin_enabled ret['comment'] "Plugin'{0}'isalreadyenabled " format name return retif not __opts__['test'] try __salt__['rabbitmq enable_plugin'] name runas runas except CommandExecutionError as err ret['result'] Falseret['comment'] 'Error {0}' format err return retret['changes'] update {'old' '' 'new' name} if __opts__['test'] and ret['changes'] ret['result'] Noneret['comment'] "Plugin'{0}'issettobeenabled " format name return retret['comment'] "Plugin'{0}'wasenabled " format name return ret
def cc arg return mcolors to_rgba arg alpha 0 6
def generate_age issue_time td datetime datetime now - issue_time age td microseconds + td seconds + td days * 24 * 3600 * 10 ** 6 / 10 ** 6 return unicode_type age
def _maximal_independent_set G result set remaining set G while remaining G G subgraph remaining v min remaining key G degree result add v remaining - set G[v] {v} return result
def to_unicode obj encoding 'utf-8' force_string False if force_string and not isinstance obj basestring if hasattr obj '__str__' obj obj __str__ elif hasattr obj '__unicode__' obj obj __unicode__ else obj str obj if isinstance obj basestring and not isinstance obj unicode try obj unicode obj encoding return objexcept UnicodeDecodeError for alt_encoding in ENCODINGS try obj unicode obj alt_encoding return objexcept UnicodeDecodeError passraise Exception "Error '%s'containsinvalidcharacter s notin%s " % obj encoding return obj
def opt_factory name default_value desc _type help '' tabid '' option_klasses {BOOL BoolOption INT IntegerOption POSITIVE_INT PositiveIntegerOption FLOAT FloatOption STRING StringOption URL URLOption URL_LIST URLListOption IPPORT IPPortOption LIST ListOption REGEX RegexOption COMBO ComboOption INPUT_FILE InputFileOption OUTPUT_FILE OutputFileOption PORT PortOption IP IPOption}return option_klasses[_type] name default_value desc _help help tabid tabid
def test_grouped_copy T1 for masked in False True t1 Table T1 masked masked tg t1 group_by 'a' tgc tg copy assert np all tgc groups indices tg groups indices assert np all tgc groups keys tg groups keys tac tg['a'] copy assert np all tac groups indices tg['a'] groups indices c1 t1['a'] copy gc1 c1 group_by t1['a'] gc1c gc1 copy assert np all gc1c groups indices np array [0 1 4 8]
def tidy_fragment text options None keep_doc False document errors tidy_document text options keep_doc match RE_BODY search document if match document match group 1 strip return document errors else raise ValueError 'tidy_fragmentfailedtoprocesstext'
def _mostfunc lhs func X None fterms [tmp for tmp in lhs atoms func if not X or X is_Symbol and X in tmp free_symbols or not X is_Symbol and tmp has X ]if len fterms 1 return fterms[0]elif fterms return max list ordered fterms key lambda x x count func return None
def require_change_password self if 'desktop auth backend AllowFirstUserDjangoBackend' in desktop conf AUTH BACKEND get and self first_login and desktop conf AUTH CHANGE_DEFAULT_PASSWORD get return True
def _toset thing if thing is None return set if isinstance thing six string_types return set thing try return set str x for x in thing except TypeError return set str thing
def _toset thing if thing is None return set if isinstance thing six string_types return set thing try return set str x for x in thing except TypeError return set str thing
def circle_perimeter_aa r c radius shape None return _circle_perimeter_aa r c radius shape
@deprecated since u'1 3' message _DEPRECATION_MESSAGE alternative u' func `~astropy coordinates matrix_utilities angle_axis`' def angle_axis matrix m np asmatrix matrix return matrix_utilities angle_axis m view np ndarray
def haddr_to_int addr try return int addr replace ' ' '' 16 except raise ValueError
def _ansi_expand_style cmap for key val in list cmap items if key 'NO_COLOR' continueelif len val 0 cmap[ 'BOLD_' + key ] '1'cmap[ 'UNDERLINE_' + key ] '4'cmap[ 'BOLD_UNDERLINE_' + key ] '1 4'cmap[ 'BACKGROUND_' + key ] valelse cmap[ 'BOLD_' + key ] '1 ' + val cmap[ 'UNDERLINE_' + key ] '4 ' + val cmap[ 'BOLD_UNDERLINE_' + key ] '1 4 ' + val cmap[ 'BACKGROUND_' + key ] val replace '38' '48' 1
def _ansi_expand_style cmap for key val in list cmap items if key 'NO_COLOR' continueelif len val 0 cmap[ 'BOLD_' + key ] '1'cmap[ 'UNDERLINE_' + key ] '4'cmap[ 'BOLD_UNDERLINE_' + key ] '1 4'cmap[ 'BACKGROUND_' + key ] valelse cmap[ 'BOLD_' + key ] '1 ' + val cmap[ 'UNDERLINE_' + key ] '4 ' + val cmap[ 'BOLD_UNDERLINE_' + key ] '1 4 ' + val cmap[ 'BACKGROUND_' + key ] val replace '38' '48' 1
def SetupSimAfter fname _IOS_FNAME fname_IOS_FNAME_BACKUP '%s backup' % fname _IOS_FNAME_TEMP '%s temp' % fname _SNAPSHOTS_BACKUP_PATH os path join _SNAPSHOTS_PATH _IOS_FNAME_BACKUP ios_sim_path '/Users/%s/Library/ApplicationSupport/iPhoneSimulator/%s/' % os environ['USER'] _SCHEME['ios'] ios_fname_path os path join ios_sim_path _IOS_FNAME ios_fname_temp_path os path join ios_sim_path _IOS_FNAME_TEMP try shutil move ios_fname_path ios_fname_temp_path shutil copytree _SNAPSHOTS_BACKUP_PATH ios_fname_path shutil rmtree ios_fname_temp_path True None shutil rmtree _SNAPSHOTS_BACKUP_PATH True None except EnvironmentError as e print 'AnerroroccurredinSetupSimAfter %s %s' % fname e raiseelse print 'SetupSimAfter %s successful ' % fname return 1
def SetupSimAfter fname _IOS_FNAME fname_IOS_FNAME_BACKUP '%s backup' % fname _IOS_FNAME_TEMP '%s temp' % fname _SNAPSHOTS_BACKUP_PATH os path join _SNAPSHOTS_PATH _IOS_FNAME_BACKUP ios_sim_path '/Users/%s/Library/ApplicationSupport/iPhoneSimulator/%s/' % os environ['USER'] _SCHEME['ios'] ios_fname_path os path join ios_sim_path _IOS_FNAME ios_fname_temp_path os path join ios_sim_path _IOS_FNAME_TEMP try shutil move ios_fname_path ios_fname_temp_path shutil copytree _SNAPSHOTS_BACKUP_PATH ios_fname_path shutil rmtree ios_fname_temp_path True None shutil rmtree _SNAPSHOTS_BACKUP_PATH True None except EnvironmentError as e print 'AnerroroccurredinSetupSimAfter %s %s' % fname e raiseelse print 'SetupSimAfter %s successful ' % fname return 1
def get iterable **attrs def predicate elem for attr val in attrs items nested attr split '__' obj elemfor attribute in nested obj getattr obj attribute if obj val return Falsereturn Truereturn find predicate iterable
def get iterable **attrs def predicate elem for attr val in attrs items nested attr split '__' obj elemfor attribute in nested obj getattr obj attribute if obj val return Falsereturn Truereturn find predicate iterable
def get iterable **attrs def predicate elem for attr val in attrs items nested attr split '__' obj elemfor attribute in nested obj getattr obj attribute if obj val return Falsereturn Truereturn find predicate iterable
def get iterable **attrs def predicate elem for attr val in attrs items nested attr split '__' obj elemfor attribute in nested obj getattr obj attribute if obj val return Falsereturn Truereturn find predicate iterable
def submit_albums collection_id release_ids for i in range 0 len release_ids SUBMISSION_CHUNK_SIZE chunk release_ids[i i + SUBMISSION_CHUNK_SIZE ]mb_call musicbrainzngs add_releases_to_collection collection_id chunk
def get_other_dvr_serviced_device_owners return [n_const DEVICE_OWNER_LOADBALANCER n_const DEVICE_OWNER_LOADBALANCERV2 n_const DEVICE_OWNER_DHCP]
def get_other_dvr_serviced_device_owners return [n_const DEVICE_OWNER_LOADBALANCER n_const DEVICE_OWNER_LOADBALANCERV2 n_const DEVICE_OWNER_DHCP]
def get_other_dvr_serviced_device_owners return [n_const DEVICE_OWNER_LOADBALANCER n_const DEVICE_OWNER_LOADBALANCERV2 n_const DEVICE_OWNER_DHCP]
def remove_compiled_application folder try shutil rmtree pjoin folder 'compiled' path pjoin folder 'controllers' for file in listdir path ' *\\ pyc$' drop False os unlink file except OSError pass
def remove_compiled_application folder try shutil rmtree pjoin folder 'compiled' path pjoin folder 'controllers' for file in listdir path ' *\\ pyc$' drop False os unlink file except OSError pass
def in_ a b msg None assert a in b msg or '%rnotin%r' % a b
def freemem extra_alloc 0 gc collect gc collect gc collect n_mallocs cuda cuda_ndarray cuda_ndarray outstanding_mallocs if hasattr cuda cuda_ndarray cuda_ndarray 'theano_allocated' theano_alloc cuda cuda_ndarray cuda_ndarray theano_allocated return ' nmalloc/theanomemallocatedinKB ' n_mallocs + extra_alloc int theano_alloc / 1024 return 'nmalloconthegpu' n_mallocs + extra_alloc mem_info cuda cuda_ndarray cuda_ndarray mem_info gpu_used mem_info[1] - mem_info[0] / 1024 ** 2 mem_info_msg ' nmalloc/gpumemusedinMB 'return mem_info_msg n_mallocs int gpu_used
def make_singlethread inner_func def func *args length len args[0] result np empty length dtype np float64 inner_func result *args return resultreturn func
def _get_closest_ansi_color r g b exclude assert isinstance exclude tuple saturation abs r - g + abs g - b + abs b - r if saturation > 30 exclude + u'ansilightgray' u'ansidarkgray' u'ansiwhite' u'ansiblack' distance 257 * 257 * 3 match u'ansidefault'for name r2 g2 b2 in ANSI_COLORS_TO_RGB items if name u'ansidefault' and name not in exclude d r - r2 ** 2 + g - g2 ** 2 + b - b2 ** 2 if d < distance match namedistance dreturn match
def getNearestDistanceIndex point loop smallestDistance 1e+18nearestDistanceIndex Nonefor pointIndex in xrange len loop segmentBegin loop[pointIndex]segmentEnd loop[ pointIndex + 1 % len loop ]distance getDistanceToPlaneSegment segmentBegin segmentEnd point if distance < smallestDistance smallestDistance distancenearestDistanceIndex DistanceIndex distance pointIndex return nearestDistanceIndex
def create vm_ None call None if call raise SaltCloudSystemExit 'Youcannotcreateaninstancewith-aor-f ' node_info request_instance vm_ if isinstance node_info bool raise SaltCloudSystemExit 'TherewasanerrorcreatingtheGCEinstance ' node_dict node_info[0]node_data node_info[1] ssh_user ssh_key __get_ssh_credentials vm_ vm_['ssh_host'] __get_host node_data vm_ vm_['key_filename'] ssh_key__utils__['cloud bootstrap'] vm_ __opts__ log info "CreatedCloudVM'{0[name]}'" format vm_ log trace "'{0[name]}'VMcreationdetails \n{1}" format vm_ pprint pformat node_dict __utils__['cloud fire_event'] 'event' 'createdinstance' 'salt/cloud/{0}/created' format vm_['name'] args {'name' vm_['name'] 'profile' vm_['profile'] 'provider' vm_['driver']} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return node_dict
def _launch_reaper id pid from subprocess import Popen PIPEme __file__if me endswith ' pyc' me me[ -1 ]myloc os path dirname me if not myloc myloc os getcwd reaper_cmd os path join myloc 'run_on_me_or_pid_quit' Popen [reaper_cmd str pid me '--free' str id ] stdout open '/dev/null' 'w'
def _launch_reaper id pid from subprocess import Popen PIPEme __file__if me endswith ' pyc' me me[ -1 ]myloc os path dirname me if not myloc myloc os getcwd reaper_cmd os path join myloc 'run_on_me_or_pid_quit' Popen [reaper_cmd str pid me '--free' str id ] stdout open '/dev/null' 'w'
def consume iterator deque iterator maxlen 0
def survey_getTemplateFromSeries series_id s3db current s3dbstable s3db survey_seriesttable s3db survey_templatequery stable id series_id & ttable id stable template_id row current db query select ttable ALL limitby 0 1 first return row
def survey_getTemplateFromSeries series_id s3db current s3dbstable s3db survey_seriesttable s3db survey_templatequery stable id series_id & ttable id stable template_id row current db query select ttable ALL limitby 0 1 first return row
def get_authenticated_user auth_provider username uid match models DjangoStorage user get_social_auth provider auth_provider backend_name uid uid if not match or match user username username raise User DoesNotExistuser match useruser backend auth_provider get_authentication_backend return user
def fiducials subject None fid_file None subjects_dir None _check_mayavi_version from _backend import _check_backend_check_backend from _fiducials_gui import FiducialsFramegui FiducialsFrame subject subjects_dir fid_file fid_file gui configure_traits return gui
def meta_nonempty x if isinstance x pd Index return _nonempty_index x elif isinstance x pd Series idx _nonempty_index x index return _nonempty_series x idx elif isinstance x pd DataFrame idx _nonempty_index x index data {i _nonempty_series x iloc[ i] idx for i c in enumerate x columns }res pd DataFrame data index idx columns np arange len x columns res columns x columnsreturn reselif is_scalar x return _nonempty_scalar x else raise TypeError 'ExpectedIndex Series DataFrame orscalar got{0}' format type x __name__
def meta_nonempty x if isinstance x pd Index return _nonempty_index x elif isinstance x pd Series idx _nonempty_index x index return _nonempty_series x idx elif isinstance x pd DataFrame idx _nonempty_index x index data {i _nonempty_series x iloc[ i] idx for i c in enumerate x columns }res pd DataFrame data index idx columns np arange len x columns res columns x columnsreturn reselif is_scalar x return _nonempty_scalar x else raise TypeError 'ExpectedIndex Series DataFrame orscalar got{0}' format type x __name__
def logger_name_from_path path return _name_from_project_path path None _LOGGER_TEMPLATE
def logger_name_from_path path return _name_from_project_path path None _LOGGER_TEMPLATE
def diff f *symbols **kwargs kwargs setdefault 'evaluate' True try return f _eval_diff *symbols **kwargs except AttributeError passreturn Derivative f *symbols **kwargs
def enable_microsites_pre_startup log if is_feature_enabled BACKEND enable_microsites_pre_startup log
def enable_microsites_pre_startup log if is_feature_enabled BACKEND enable_microsites_pre_startup log
def skipIfDBFeature *features return _deferredSkip lambda any getattr connection features feature False for feature in features 'Databasehasfeature s %s' % ' ' join features
def Gompertz name b eta return rv name GompertzDistribution b eta
def _TestRemoveViewpoint tester user_cookie request_dict validator tester validator user_id device_id tester GetIdsFromCookie user_cookie request_dict deepcopy request_dict viewpoint_id request_dict['viewpoint_id']actual_dict tester SendRequest 'remove_viewpoint' user_cookie request_dict op_dict tester _DeriveNotificationOpDict user_id device_id request_dict request_dict['user_id'] user_idfollower validator GetModelObject Follower DBKey user_id viewpoint_id if not follower IsRemoved labels follower labels union [Follower REMOVED] validator ValidateUpdateDBObject Follower user_id user_id viewpoint_id viewpoint_id labels labels invalidate {'viewpoints' [{'viewpoint_id' viewpoint_id 'get_attributes' True}]}validator ValidateNotification 'remove_viewpoint' user_id op_dict invalidate viewpoint_id viewpoint_id validator ValidateViewpointAccounting viewpoint_id tester _CompareResponseDicts 'remove_viewpoint' user_id request_dict {} actual_dict return actual_dict
def PutSecret secret secret_value GetSecretsManagerForSecret secret PutSecret secret secret_value
def test_seed_same skip_if_no_scipy rng np random RandomState [1 2 3] seed rng randint 2147462579 dim 3mu rng randn dim rank dimX rng randn rank dim cov np dot X T X mnd1 MND sigma cov mu mu seed seed num_samples 5rd1 mnd1 random_design_matrix num_samples rd1 function [] rd1 mnd2 MND sigma cov mu mu seed seed rd2 mnd2 random_design_matrix num_samples rd2 function [] rd2 assert np all rd1 rd2
def test_seed_same skip_if_no_scipy rng np random RandomState [1 2 3] seed rng randint 2147462579 dim 3mu rng randn dim rank dimX rng randn rank dim cov np dot X T X mnd1 MND sigma cov mu mu seed seed num_samples 5rd1 mnd1 random_design_matrix num_samples rd1 function [] rd1 mnd2 MND sigma cov mu mu seed seed rd2 mnd2 random_design_matrix num_samples rd2 function [] rd2 assert np all rd1 rd2
def api_github_v1 user_profile event payload branches stream **kwargs commit_stream streamissue_stream 'issues'return api_github_v2 user_profile event payload branches stream commit_stream issue_stream **kwargs
def _full_archive_path config_obj cli_config lineagename if config_obj and 'archive_dir' in config_obj return config_obj['archive_dir']else return os path join cli_config default_archive_dir lineagename
def _full_archive_path config_obj cli_config lineagename if config_obj and 'archive_dir' in config_obj return config_obj['archive_dir']else return os path join cli_config default_archive_dir lineagename
def connect_action_bool action fn action triggered[bool] connect fn
def prepare routes def expand_route route if isinstance route Mapping list tuple return MapRoute route if isinstance route string_t return mlazy expand_router_string route return routeif routes is None return if not isinstance routes list tuple routes routes return [expand_route route for route in routes]
def addYIntersectionPathToList pathIndex pointIndex y yIntersection yIntersectionPaths if yIntersection None returnyIntersectionPath YIntersectionPath pathIndex pointIndex yIntersection yIntersectionPath yMinusCenter yIntersection - y yIntersectionPaths append yIntersectionPath
def form_ntuples_from_machines machines n 2 mapping_func default_mappings ntuples [] mappings failures mapping_func machines for key in mappings key_machines mappings[key]total_machines len key_machines while len key_machines > n ntuples append key_machines[0 n] key_machines key_machines[n ]for mach in key_machines failures append mach 'machinecannotbetupled' return ntuples failures
def form_ntuples_from_machines machines n 2 mapping_func default_mappings ntuples [] mappings failures mapping_func machines for key in mappings key_machines mappings[key]total_machines len key_machines while len key_machines > n ntuples append key_machines[0 n] key_machines key_machines[n ]for mach in key_machines failures append mach 'machinecannotbetupled' return ntuples failures
def dfs_postorder_nodes G source None post v for u v d in nx dfs_labeled_edges G source source if d 'reverse' return post
def delete_exploration committer_id exploration_id force_deletion False exploration_rights_model exp_models ExplorationRightsModel get exploration_id exploration_rights_model delete committer_id '' force_deletion force_deletion exploration_model exp_models ExplorationModel get exploration_id exploration_model delete committer_id feconf COMMIT_MESSAGE_EXPLORATION_DELETED force_deletion force_deletion exploration_memcache_key _get_exploration_memcache_key exploration_id memcache_services delete exploration_memcache_key delete_documents_from_search_index [exploration_id] delete_exploration_summary exploration_id activity_services remove_featured_activity feconf ACTIVITY_TYPE_EXPLORATION exploration_id
def delete_exploration committer_id exploration_id force_deletion False exploration_rights_model exp_models ExplorationRightsModel get exploration_id exploration_rights_model delete committer_id '' force_deletion force_deletion exploration_model exp_models ExplorationModel get exploration_id exploration_model delete committer_id feconf COMMIT_MESSAGE_EXPLORATION_DELETED force_deletion force_deletion exploration_memcache_key _get_exploration_memcache_key exploration_id memcache_services delete exploration_memcache_key delete_documents_from_search_index [exploration_id] delete_exploration_summary exploration_id activity_services remove_featured_activity feconf ACTIVITY_TYPE_EXPLORATION exploration_id
def package_finder argv try command InstallCommand except TypeError from pip baseparser import create_main_parsercommand InstallCommand create_main_parser options _ loads dumps command parser parse_args argv possible_options ['find_links' FORMAT_CONTROL_ARG 'allow_external' 'allow_unverified' 'allow_all_external' 'allow_all_prereleases' 'pre' 'process_dependency_links']kwargs {}for option in possible_options kw attr option if isinstance option tuple else option option value getattr options attr MARKER if value is not MARKER kwargs[kw] valueindex_urls [options index_url] + options extra_index_urls if options no_index index_urls []index_urls + getattr options 'mirrors' [] if hasattr command '_build_session' kwargs['session'] command _build_session options return PackageFinder index_urls index_urls **kwargs
def package_finder argv try command InstallCommand except TypeError from pip baseparser import create_main_parsercommand InstallCommand create_main_parser options _ loads dumps command parser parse_args argv possible_options ['find_links' FORMAT_CONTROL_ARG 'allow_external' 'allow_unverified' 'allow_all_external' 'allow_all_prereleases' 'pre' 'process_dependency_links']kwargs {}for option in possible_options kw attr option if isinstance option tuple else option option value getattr options attr MARKER if value is not MARKER kwargs[kw] valueindex_urls [options index_url] + options extra_index_urls if options no_index index_urls []index_urls + getattr options 'mirrors' [] if hasattr command '_build_session' kwargs['session'] command _build_session options return PackageFinder index_urls index_urls **kwargs
def step_runner_environ from lettuce import registryregistry clear @step 'Ihaveadefinedstep' def have_a_defined_step *args **kw assert True@step 'otherstepfails' def and_another *args **kw assert False 'Itshouldfail'@step 'defineastep' def define_a_step *args **kw assert True@step u'WhenIhaveastepthatraisesanexception' def raises_exception step raise Exception @step 'Ihaveastepwhichcallsthe" * "stepwithbehave_as' def runs_some_other_step_with_behave_as step something_else step behave_as 'When% i_do_something_else s' % {'i_do_something_else' something_else}
def step_runner_environ from lettuce import registryregistry clear @step 'Ihaveadefinedstep' def have_a_defined_step *args **kw assert True@step 'otherstepfails' def and_another *args **kw assert False 'Itshouldfail'@step 'defineastep' def define_a_step *args **kw assert True@step u'WhenIhaveastepthatraisesanexception' def raises_exception step raise Exception @step 'Ihaveastepwhichcallsthe" * "stepwithbehave_as' def runs_some_other_step_with_behave_as step something_else step behave_as 'When% i_do_something_else s' % {'i_do_something_else' something_else}
def _has_uncommitted_files uncommitted_files subprocess check_output GIT_IS_DIRTY_CMD split '' return bool len uncommitted_files
def compareAttributeKeyAscending key otherKey if key 'id' return -1 if otherKey 'id' return 1if key 'name' return -1 if otherKey 'name' return 1if key < otherKey return -1 return int key > otherKey
def render_template template **context if current_user is_authenticated and current_user theme theme current_user themeelse theme session get 'theme' flaskbb_config['DEFAULT_THEME'] return render_theme_template theme template **context
def render_template template **context if current_user is_authenticated and current_user theme theme current_user themeelse theme session get 'theme' flaskbb_config['DEFAULT_THEME'] return render_theme_template theme template **context
def render_template template **context if current_user is_authenticated and current_user theme theme current_user themeelse theme session get 'theme' flaskbb_config['DEFAULT_THEME'] return render_theme_template theme template **context
def setup_platform hass config add_devices discovery_info None from amcrest import AmcrestCameracamera AmcrestCamera config get CONF_HOST config get CONF_PORT config get CONF_USERNAME config get CONF_PASSWORD camerapersistent_notification loader get_component 'persistent_notification' try camera current_timeexcept ConnectTimeout HTTPError as ex _LOGGER error 'UnabletoconnecttoAmcrestcamera %s' str ex persistent_notification create hass 'Error {}<br/>Youwillneedtorestarthassafterfixing ' format ex title NOTIFICATION_TITLE notification_id NOTIFICATION_ID return Falsesensors []for sensor_type in config get CONF_MONITORED_CONDITIONS sensors append AmcrestSensor config camera sensor_type add_devices sensors True return True
def _find_address_range addresses first last addresses[0]for ip in addresses[1 ] if ip _ip last _ip + 1 last ipelse breakreturn first last
def url_prefix mat return '/' + mat string[ mat start ] strip '/'
def get_profile_id service domain accounts service management accounts list execute account_ids [a['id'] for a in accounts get 'items' ]for account_id in account_ids webproperties service management webproperties list accountId account_id execute webproperty_ids [p['id'] for p in webproperties get 'items' ]for webproperty_id in webproperty_ids profiles service management profiles list accountId account_id webPropertyId webproperty_id execute for p in profiles get 'items' if ' //' in p['websiteUrl'] name p['websiteUrl'] partition ' //' [ -1 ]else name p['websiteUrl']if name domain return p['id']
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep join seq else return '%sor%s' % sep join seq[ -1 ] seq[ -1 ]
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep join seq else return '%sor%s' % sep join seq[ -1 ] seq[ -1 ]
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep join seq else return '%sor%s' % sep join seq[ -1 ] seq[ -1 ]
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep join seq else return '%sor%s' % sep join seq[ -1 ] seq[ -1 ]
def nice_join seq sep ' ' seq [str x for x in seq]if len seq < 1 return sep join seq else return '%sor%s' % sep join seq[ -1 ] seq[ -1 ]
def create_url hostname port None isSecure False if port is not None netloc '%s %d' % hostname port elif isSecure netloc u'{} 443' format hostname else netloc u'{} 80' format hostname if isSecure scheme u'rss'else scheme u'rs'return u'{} //{}' format scheme netloc
def lookup_connections backend identities if isinstance backend string_types backend _ Backend objects get_or_create name backend connections []for identity in identities connection _ backend connection_set get_or_create identity identity connections append connection return connections
def get_timeline_data doctype name from frappe desk form load import get_communication_datadata get_communication_data doctype name fields u'unix_timestamp date creation count name ' after add_years None -1 strftime u'%Y-%m-%d' limit 366 group_by u'groupbydate creation ' as_dict False return dict data
def pyramid_soap11_application services tns 'spyne simple soap' validator None name None from spyne protocol soap import Soap11from spyne server pyramid import PyramidApplicationapplication Application services tns name name in_protocol Soap11 validator validator out_protocol Soap11 return PyramidApplication application
def pyramid_soap11_application services tns 'spyne simple soap' validator None name None from spyne protocol soap import Soap11from spyne server pyramid import PyramidApplicationapplication Application services tns name name in_protocol Soap11 validator validator out_protocol Soap11 return PyramidApplication application
def validate_row app_id row zookeeper db_access row_key row keys [0]entity row values [0]if APP_ENTITY_SCHEMA[1] not in entity return rowrow_txn long entity[APP_ENTITY_SCHEMA[1]] valid_txn zookeeper get_valid_transaction_id app_id row_txn row_key if row_txn valid_txn return rowif valid_txn 0 return Nonepadded_version str valid_txn zfill ID_KEY_LENGTH journal_key dbconstants KEY_DELIMITER join [row_key padded_version] journal_results db_access batch_get_entity dbconstants JOURNAL_TABLE [journal_key] dbconstants JOURNAL_SCHEMA journal_row journal_results[journal_key]if dbconstants JOURNAL_SCHEMA[0] not in journal_row return Nonevalid_entity journal_row[dbconstants JOURNAL_SCHEMA[0]]return {row_key {APP_ENTITY_SCHEMA[0] valid_entity APP_ENTITY_SCHEMA[1] str valid_txn }}
def _get_changed_files if not ci_diff_helper return Nonetry config ci_diff_helper get_config except OSError return Nonechanged_files ci_diff_helper get_changed_files 'HEAD' config base changed_files set [' /{}' format filename for filename in changed_files] return changed_files
def test_install_package_with_root script data root_dir script scratch_path / 'root' result script pip 'install' '--root' root_dir '-f' data find_links '--no-index' 'simple 1 0' normal_install_path script base_path / script site_packages / 'simple-1 0-py%s egg-info' % pyversion from distutils util import change_rootroot_path change_root os path join script scratch 'root' normal_install_path assert root_path in result files_created str result
def test_install_package_with_root script data root_dir script scratch_path / 'root' result script pip 'install' '--root' root_dir '-f' data find_links '--no-index' 'simple 1 0' normal_install_path script base_path / script site_packages / 'simple-1 0-py%s egg-info' % pyversion from distutils util import change_rootroot_path change_root os path join script scratch 'root' normal_install_path assert root_path in result files_created str result
def make_lpdf mu sigma x T matrix mu theano shared mu a x dimshuffle 0 'x' 1 - mu dimshuffle 'x' 0 1 / sigma E log_mean_exp -0 5 * a ** 2 sum 2 Z mu shape[1] * T log sigma * numpy sqrt numpy pi * 2 return theano function [x] E - Z
def make_lpdf mu sigma x T matrix mu theano shared mu a x dimshuffle 0 'x' 1 - mu dimshuffle 'x' 0 1 / sigma E log_mean_exp -0 5 * a ** 2 sum 2 Z mu shape[1] * T log sigma * numpy sqrt numpy pi * 2 return theano function [x] E - Z
def make_lpdf mu sigma x T matrix mu theano shared mu a x dimshuffle 0 'x' 1 - mu dimshuffle 'x' 0 1 / sigma E log_mean_exp -0 5 * a ** 2 sum 2 Z mu shape[1] * T log sigma * numpy sqrt numpy pi * 2 return theano function [x] E - Z
def relevent_issue issue after return closed_issue issue after and issue_completed issue and issue_section issue
def after function annotate False def decorated matcher def make_matcher *args **kwargs return AfterPreprocessing function matcher *args **kwargs annotate annotate return make_matcherreturn decorated
def after function annotate False def decorated matcher def make_matcher *args **kwargs return AfterPreprocessing function matcher *args **kwargs annotate annotate return make_matcherreturn decorated
def replace_dots_in_field_names document for key value in list document items if isinstance value dict value replace_dots_in_field_names value if isinstance key string_types and key find ' ' -1 del document[key]document[key replace ' ' '_' ] valuereturn document
def replace_dots_in_field_names document for key value in list document items if isinstance value dict value replace_dots_in_field_names value if isinstance key string_types and key find ' ' -1 del document[key]document[key replace ' ' '_' ] valuereturn document
def _find_dependent_monitors monitors monitor_names last_iteration_count 0while len monitor_names last_iteration_count last_iteration_count len monitor_names for mon in monitors for auditor in mon auditors for support_index in auditor support_auditor_indexes if support_index in monitor_names and mon watcher index not in monitor_names monitor_names append mon watcher index for support_index in auditor support_watcher_indexes if support_index in monitor_names and mon watcher index not in monitor_names monitor_names append mon watcher index return monitor_names
def at_initial_setup modname settings AT_INITIAL_SETUP_HOOK_MODULEif not modname returntry mod __import__ modname fromlist [None] except ImportError ValueError returnlogger log_info 'Runningat_initial_setup hook ' if mod __dict__ get 'at_initial_setup' None mod at_initial_setup
def copy_descriptor descriptor newname None if newname is None newname descriptor nameif descriptor is_discrete newf Orange data DiscreteVariable newname values descriptor values base_value descriptor base_value ordered descriptor ordered newf attributes dict descriptor attributes elif descriptor is_continuous newf Orange data ContinuousVariable newname newf number_of_decimals descriptor number_of_decimalsnewf attributes dict descriptor attributes else newf type descriptor newname newf attributes dict descriptor attributes return newf
def _new_extension name value critical 0 issuer None _pyfree 1 if name 'subjectKeyIdentifier' and value strip '0123456789abcdefABCDEF ' is not '' raise salt exceptions SaltInvocationError 'valuemustbeprecomputedhash' try ctx M2Crypto m2 x509v3_set_nconf _fix_ctx ctx issuer if ctx is None raise MemoryError 'NotenoughmemorywhencreatinganewX509extension' x509_ext_ptr M2Crypto m2 x509v3_ext_conf None ctx name value lhash Noneexcept AttributeError lhash M2Crypto m2 x509v3_lhash ctx M2Crypto m2 x509v3_set_conf_lhash lhash _fix_ctx ctx issuer x509_ext_ptr M2Crypto m2 x509v3_ext_conf lhash ctx name value if x509_ext_ptr is None raise M2Crypto X509 X509Error "CannotcreateX509_Extensionwithname'{0}'andvalue'{1}'" format name value x509_ext M2Crypto X509 X509_Extension x509_ext_ptr _pyfree x509_ext set_critical critical return x509_ext
def set_modified_on f from olympia amo tasks import set_modified_on_object@functools wraps f def wrapper *args **kw objs kw pop 'set_modified_on' None result f *args **kw if objs and result for obj in objs task_log info 'Delayingsettingmodifiedonobject %s %s' % obj __class__ __name__ obj pk set_modified_on_object apply_async args [obj] kwargs None eta datetime datetime now + datetime timedelta seconds settings NFS_LAG_DELAY return resultreturn wrapper
def mkdirs path if not os path isdir path try os makedirs path except OSError as err if err errno errno EEXIST or not os path isdir path raise
def _ZeroPad addr_string chunks addr_string split ' ' total_length len chunks if total_length > 8 raise socket error 'Toomanyaddresschunksin%s expected8' % addr_string double_colon Falseaddr_array []for chunk in chunks if chunk chunk_len len chunk if chunk_len > 4 raise socket error 'Chunkmustbelength4 %s' % addr_string if chunk_len 4 chunk '0' * 4 - chunk_len + chunk addr_array append chunk elif double_colon raise socket error 'Morethanonedoublecolonin%s' % addr_string else double_colon Trueaddr_array extend ['0000'] * 8 - total_length + 1 if len addr_array 8 raise socket error 'Badaddresslength expected8chunks %s' % addr_array return '' join addr_array
def make_overload_method_template typ attr overload_func return make_overload_attribute_template typ attr overload_func base _OverloadMethodTemplate
def add_like obj user obj_type apps get_model 'contenttypes' 'ContentType' objects get_for_model obj with atomic like created Like objects get_or_create content_type obj_type object_id obj id user user if like project is not None like project refresh_totals return like
def GetRemoteAppId servername path auth_func rpc_server_factory appengine_rpc HttpRpcServer rtok None secure False save_cookies False server rpc_server_factory servername auth_func GetUserAgent GetSourceName save_cookies save_cookies debug_data False secure secure app_id GetRemoteAppIdFromServer server path rtok return app_id server
def _get_repo_info alias repos_cfg None try meta dict repos_cfg or _get_configured_repos items alias meta['alias'] aliasfor key val in six iteritems meta if val in ['0' '1'] meta[key] int meta[key] 1 elif val 'NONE' meta[key] Nonereturn metaexcept ValueError configparser NoSectionError return {}
def dict_to_keyval value key_base None val_iter key_func None None if isinstance value dict val_iter six iteritems value key_func lambda k key_base + ' ' + k if key_base else k elif isinstance value tuple list val_iter enumerate value key_func lambda k key_base + '[%d]' % k if val_iter for k v in val_iter key_gen key_func k if isinstance v dict or isinstance v tuple list for key_gen v in dict_to_keyval v key_gen yield key_gen v else yield key_gen v
def _is_shell_needed_for_subprocess_calls return os name u'nt'
def _get_object data position obj_end opts dummy obj_size _UNPACK_INT data[position position + 4 ] [0]end position + obj_size - 1 if data[end position + obj_size ] '\x00' raise InvalidBSON 'badeoo' if end > obj_end raise InvalidBSON 'invalidobjectlength' if _raw_document_class opts document_class return opts document_class data[position end + 1 ] opts position + obj_size obj _elements_to_dict data position + 4 end opts position + obj_sizeif '$ref' in obj return DBRef obj pop '$ref' obj pop '$id' None obj pop '$db' None obj position return obj position
def connected return {'out' __proxy__['napalm ping'] }
def test_redirect Client get '/' redirect shortcuts redirect 'home' assert redirect['Location'] '/en-US/firefox/'
def effective_get get None collection None collection_get collection _default_get if collection else None return get or _globals get 'get' or collection_get
def effective_get get None collection None collection_get collection _default_get if collection else None return get or _globals get 'get' or collection_get
def effective_get get None collection None collection_get collection _default_get if collection else None return get or _globals get 'get' or collection_get
def remove_excess_padding text text re sub '^\\n' '' text text re sub '\\n$' '' text return text
def overridable_property name doc None getter_name intern 'get_' + name setter_name intern 'set_' + name return property lambda self getattr self getter_name lambda self value getattr self setter_name value None doc
def overridable_property name doc None getter_name intern 'get_' + name setter_name intern 'set_' + name return property lambda self getattr self getter_name lambda self value getattr self setter_name value None doc
def overridable_property name doc None getter_name intern 'get_' + name setter_name intern 'set_' + name return property lambda self getattr self getter_name lambda self value getattr self setter_name value None doc
def overridable_property name doc None getter_name intern 'get_' + name setter_name intern 'set_' + name return property lambda self getattr self getter_name lambda self value getattr self setter_name value None doc
def _decrypt_object obj if isinstance obj six string_types return _fetch_secret obj elif isinstance obj dict for pass_key pass_path in six iteritems obj obj[pass_key] _decrypt_object pass_path elif isinstance obj list for pass_key pass_path in enumerate obj obj[pass_key] _decrypt_object pass_path return obj
def warn_deprecated since message '' name '' alternative '' pending False obj_type 'attribute' addendum '' message _generate_deprecation_message since message name alternative pending obj_type warnings warn message mplDeprecation stacklevel 1
@frappe whitelist def get_app_list out {}installed frappe get_installed_apps for app in frappe get_all_apps True app_hooks frappe get_hooks app_name app if app not in installed and app_hooks get u'hide_in_installer' continueout[app] {}for key in u'app_name' u'app_title' u'app_description' u'app_icon' u'app_publisher' u'app_version' u'app_url' u'app_color' val app_hooks get key or [] out[app][key] val[0] if len val else u'' if app in installed out[app][u'installed'] 1for app_from_list in get_app_listing values if app_from_list app_name in out out[app_from_list app_name] update app_from_list elif not frappe conf disallow_app_listing out[app_from_list app_name] app_from_listreturn out
def _get_options ret None attrs {'host' 'host' 'port' 'port' 'db' 'db' 'user' 'user' 'password' 'password'}_options salt returners get_returner_options __virtualname__ ret attrs __salt__ __salt__ __opts__ __opts__ return _options
def _const_compare_digest_backport a b result abs len a - len b for l r in zip bytearray a bytearray b result l ^ r return result 0
def lsb_release_info return _distro lsb_release_info
def is_valid_url url validate URLValidator try validate url return Trueexcept ValidationError return False
def RegisterUtility utility_name version_mapping None def MethodDecorator utility_method version 'Decoratesamethodintheutilityclass 'registry_name '%s/%s' % utility_name version if version else utility_name @wraps utility_method def Wrapper *args **kwargs with _UTILITY_LOCK _utility_registry Add registry_name return utility_method *args **kwargs return Wrapperdef ClassDecorator cls 'Decoratesautilityclass 'for name method in inspect getmembers cls inspect ismethod if not name startswith '_' if not getattr method '__self__' None setattr cls name MethodDecorator method version_mapping get name if version_mapping else None return clsreturn ClassDecorator
def addXIntersectionsFromLoops loops xIntersections y for loop in loops addXIntersections loop xIntersections y
def get_expr_vars operator if operator type lo VARIABLE return [ operator data operator size ]else vars_ []for arg in operator args vars_ + get_expr_vars arg return vars_
def alpha_max emp_cov A np copy emp_cov A flat[ A shape[0] + 1 ] 0return np max np abs A
def get_storage storage_class cached_load u'SHUUP_BASKET_STORAGE_CLASS_SPEC' return storage_class
def cg_simp e if isinstance e Add return _cg_simp_add e elif isinstance e Sum return _cg_simp_sum e elif isinstance e Mul return Mul *[cg_simp arg for arg in e args] elif isinstance e Pow return Pow cg_simp e base e exp else return e
def cg_simp e if isinstance e Add return _cg_simp_add e elif isinstance e Sum return _cg_simp_sum e elif isinstance e Mul return Mul *[cg_simp arg for arg in e args] elif isinstance e Pow return Pow cg_simp e base e exp else return e
def cg_simp e if isinstance e Add return _cg_simp_add e elif isinstance e Sum return _cg_simp_sum e elif isinstance e Mul return Mul *[cg_simp arg for arg in e args] elif isinstance e Pow return Pow cg_simp e base e exp else return e
def enhance_info_description info line_length 50 paragraphs info['description'] split '\n\n' lines [paragraph replace '\n' '' for paragraph in paragraphs]text '\n' join lines info['files'] [ info['file'] + ' ' + info['ext'] ]regex '[tT]he ? file image [\\w\\/]+\\ \\w+ 'for name in re findall regex text if name not in info['files'] info['files'] append name folder '_' join info['source'] split sep [ -1 ] + '_' text re sub ' [tT]he ? file image [\\w\\/]+\\ \\w+ ' '\\1 ref `\\2<$folder$\\2>`' text text text replace '$folder$' folder lines text split '\n' paragraphs [textwrap wrap line line_length for line in lines]info['enhanced_description'] paragraphs
def certificate_create context values return IMPL certificate_create context values
def make_digest_acl_credential username password credential username encode 'utf-8' + ' ' + password encode 'utf-8' cred_hash b64encode hashlib sha1 credential digest strip return username + ' ' + cred_hash decode 'utf-8'
def set_backend name None possible list _BACKENDS if name is None names []else names name split ' ' for name in reversed names for backend in list possible if backend NAME name possible remove backend possible insert 0 backend breakelse raise LookupError 'Unkownbackend %r' % name if 'null' not in names possible [b for b in possible if b NAME 'null' ]_ACTIVE_BACKENDS[ ] possible
def _make_stc data vertices tmin None tstep None subject None if isinstance vertices list and len vertices 2 stc SourceEstimate data vertices vertices tmin tmin tstep tstep subject subject elif isinstance vertices np ndarray or isinstance vertices list and len vertices 1 stc VolSourceEstimate data vertices vertices tmin tmin tstep tstep subject subject elif isinstance vertices list and len vertices > 2 stc MixedSourceEstimate data vertices vertices tmin tmin tstep tstep subject subject else raise ValueError 'verticeshastobeeitheralistwithoneormorearraysoranarray' return stc
def test_magic_parse_options ip get_ipython path 'c \\x'm DummyMagics ip opts m parse_options '-f%s' % path 'f ' [0]if os name 'posix' expected 'c x'else expected pathnt assert_equal opts['f'] expected
def test_magic_parse_options ip get_ipython path 'c \\x'm DummyMagics ip opts m parse_options '-f%s' % path 'f ' [0]if os name 'posix' expected 'c x'else expected pathnt assert_equal opts['f'] expected
def test_magic_parse_options ip get_ipython path 'c \\x'm DummyMagics ip opts m parse_options '-f%s' % path 'f ' [0]if os name 'posix' expected 'c x'else expected pathnt assert_equal opts['f'] expected
def confidenceIntervalSize stdev nbsamples return 2 * 1 98 * stdev / sqrt nbsamples
def get_new_file_id secs usecs divmod time time 1 0 secs usecs int secs int usecs * 1000000 0 return {'machid' get_machid 'version' FIFF FIFFC_VERSION 'secs' secs 'usecs' usecs}
def _find_iso_sr session host session host_reffor sr_ref sr_rec in session get_all_refs_and_recs 'SR' LOG debug 'ISO lookingatSR%s' sr_rec if not sr_rec['content_type'] 'iso' LOG debug 'ISO notisocontent' continueif 'i18n-key' not in sr_rec['other_config'] LOG debug "ISO isocontent_type no'i18n-key'key" continueif not sr_rec['other_config']['i18n-key'] 'local-storage-iso' LOG debug "ISO isocontent_type i18n-keyvaluenot'local-storage-iso'" continueLOG debug 'ISO SRMATCHingourcriteria' for pbd_ref in sr_rec['PBDs'] LOG debug 'ISO ISO lookingtoseeifitishostlocal' pbd_rec session get_rec 'PBD' pbd_ref if not pbd_rec LOG debug 'ISO PBD%sdisappeared' pbd_ref continuepbd_rec_host pbd_rec['host']LOG debug 'ISO PBDmatching want% pbd_rec s have% host s' {'pbd_rec' pbd_rec 'host' host} if pbd_rec_host host LOG debug 'ISO SRwithlocalPBD' return sr_refreturn None
def get_resource_docname resource is_list if inspect isclass resource class_name resource __name__else class_name resource __class__ __name__class_name class_name replace 'Resource' '' docname uncamelcase class_name '-' if is_list and resource name resource name_plural docname '%s-list' % docname return docname
def set_power_state state utils write_one_line '/sys/power/state' state
def test_ast_invalid_unary_op cant_compile u' not234 ' cant_compile u' not ' cant_compile u' not234 ' cant_compile u' ~2234 ' cant_compile u' ~ '
def test_ast_invalid_unary_op cant_compile u' not234 ' cant_compile u' not ' cant_compile u' not234 ' cant_compile u' ~2234 ' cant_compile u' ~ '
def test_ast_invalid_unary_op cant_compile u' not234 ' cant_compile u' not ' cant_compile u' not234 ' cant_compile u' ~2234 ' cant_compile u' ~ '
def test_ast_invalid_unary_op cant_compile u' not234 ' cant_compile u' not ' cant_compile u' not234 ' cant_compile u' ~2234 ' cant_compile u' ~ '
def tropo from tropo import Tropo Sessiontry s Session request body read t Tropo try row_id s parameters['row_id']table s3db msg_tropo_scratchquery table row_id row_id row db query select first t call to row recipient network row network t say row message outbox s3db msg_outboxdb outbox id row row_id update status 2 db query delete return t RenderJson except try message s initialTextuuid s idrecipient s to['id']try fromaddress s fromaddress['id']except fromaddress ''reply msg parse_message message t say [reply] return t RenderJson except raise HTTP 501 except pass
def tropo from tropo import Tropo Sessiontry s Session request body read t Tropo try row_id s parameters['row_id']table s3db msg_tropo_scratchquery table row_id row_id row db query select first t call to row recipient network row network t say row message outbox s3db msg_outboxdb outbox id row row_id update status 2 db query delete return t RenderJson except try message s initialTextuuid s idrecipient s to['id']try fromaddress s fromaddress['id']except fromaddress ''reply msg parse_message message t say [reply] return t RenderJson except raise HTTP 501 except pass
def rax_find_bootable_volume module rax_module server exit True cs rax_module cloudserverscbs rax_module cloud_blockstorageserver_id rax_module utils get_id server volumes cs volumes get_server_volumes server_id bootable_volumes []for volume in volumes vol cbs get volume if module boolean vol bootable bootable_volumes append vol if not bootable_volumes if exit module fail_json msg 'Nobootablevolumescouldbefoundforserver%s' % server_id else return Falseelif len bootable_volumes > 1 if exit module fail_json msg 'Multiplebootablevolumesfoundforserver%s' % server_id else return Falsereturn bootable_volumes[0]
def clear_memo_cache source d_pth os path join settings MEMO_DIR domain_to_filename source domain if os path exists d_pth os remove d_pth else print 'memofilefor' source domain 'hasalreadybeendeleted '
def coerce_to_dtype dtype value name dtype nameif name startswith 'datetime64' if name 'datetime64[D]' return make_datetime64D value elif name 'datetime64[ns]' return make_datetime64ns value else raise TypeError "Don'tknowhowtocoercevaluesofdtype%s" % dtype return dtype type value
def cc_stats x1 x2 demean True nobs1 k1 x1 shape nobs2 k2 x2 shapecc cancorr x1 x2 demean demean cc2 cc ** 2 lam cc2 / 1 - cc2 df_model k1 * k2 df_resid k1 * nobs1 - k2 - demean s min df_model k1 m 0 5 * df_model - k1 n 0 5 * df_resid - k1 - 1 df1 k1 * df_model df2 k2pt_value cc2 sum wl_value np product 1 / 1 + lam ht_value lam sum rm_value lam max res {}res['canonicalcorrelationcoefficient'] ccres['eigenvalues'] lamres["Pillai'sTrace"] pt_valueres["Wilk'sLambda"] wl_valueres["Hotelling'sTrace"] ht_valueres["Roy'sLargestRoot"] rm_valueres['df_resid'] df_residres['df_m'] mreturn res
def cc_stats x1 x2 demean True nobs1 k1 x1 shape nobs2 k2 x2 shapecc cancorr x1 x2 demean demean cc2 cc ** 2 lam cc2 / 1 - cc2 df_model k1 * k2 df_resid k1 * nobs1 - k2 - demean s min df_model k1 m 0 5 * df_model - k1 n 0 5 * df_resid - k1 - 1 df1 k1 * df_model df2 k2pt_value cc2 sum wl_value np product 1 / 1 + lam ht_value lam sum rm_value lam max res {}res['canonicalcorrelationcoefficient'] ccres['eigenvalues'] lamres["Pillai'sTrace"] pt_valueres["Wilk'sLambda"] wl_valueres["Hotelling'sTrace"] ht_valueres["Roy'sLargestRoot"] rm_valueres['df_resid'] df_residres['df_m'] mreturn res
def tril m k 0 m np asarray m out tri m shape[0] m shape[1] k k dtype m dtype char * m return out
def collection_creation_options return CREATION_ONLY_OPTION
def collection_creation_options return CREATION_ONLY_OPTION
def collection_creation_options return CREATION_ONLY_OPTION
def make_hidden_alias argument_table existing_name alias_name current argument_table[existing_name]copy_arg _copy_argument argument_table existing_name alias_name copy_arg _UNDOCUMENTED Trueif current required copy_arg required Falsecurrent required Falsecurrent _DOCUMENT_AS_REQUIRED True
def minibatches inputs None targets None batch_size None shuffle False assert len inputs len targets if shuffle indices np arange len inputs np random shuffle indices for start_idx in range 0 len inputs - batch_size + 1 batch_size if shuffle excerpt indices[start_idx start_idx + batch_size ]else excerpt slice start_idx start_idx + batch_size yield inputs[excerpt] targets[excerpt]
def _stop_on_read fd _triggered clear fdref CFFileDescriptorCreate None fd False _c_input_callback None CFFileDescriptorEnableCallBacks fdref kCFFileDescriptorReadCallBack source CFFileDescriptorCreateRunLoopSource None fdref 0 loop CFRunLoopGetCurrent CFRunLoopAddSource loop source kCFRunLoopCommonModes CFRelease source
def connect_host kwargs None call None if call 'function' raise SaltCloudSystemExit 'Theconnect_hostfunctionmustbecalledwith-for--function ' host_name kwargs get 'host' if kwargs and 'host' in kwargs else None if not host_name raise SaltCloudSystemExit 'Youmustspecifynameofthehostsystem ' si _get_si host_ref salt utils vmware get_mor_by_property si vim HostSystem host_name if not host_ref raise SaltCloudSystemExit 'Specifiedhostsystemdoesnotexist ' if host_ref runtime connectionState 'connected' return {host_name 'hostsystemalreadyconnected'}try task host_ref ReconnectHost_Task salt utils vmware wait_for_task task host_name 'connecthost' 5 'info' except Exception as exc log error 'Errorwhileconnectinghost{0} {1}' format host_name exc exc_info_on_loglevel logging DEBUG return {host_name 'failedtoconnecthost'}return {host_name 'connectedhost'}
def initial_state layer dimensions None if dimensions is None return layer initial_hidden_state if has_hidden layer else None else return matrixify layer initial_hidden_state dimensions if has_hidden layer else None
def initial_state layer dimensions None if dimensions is None return layer initial_hidden_state if has_hidden layer else None else return matrixify layer initial_hidden_state dimensions if has_hidden layer else None
def load_context context file_path _get_context_filepath if os path exists file_path with io open file_path encoding 'utf-8' as f for line in f execute line context
def get_children x collection None if collection is None collection random_variables node_dict {node value node for node in collection}output set [] nodes set [x] while nodes node nodes pop if isinstance node RandomVariable node node value candidate_node node_dict get node None if candidate_node and candidate_node x output add candidate_node else for op in node consumers nodes update op outputs return list output
def password_change_email user from r2 lib pages import PasswordChangeEmailreturn _system_email user email PasswordChangeEmail user user render style 'email' Email Kind PASSWORD_CHANGE user user
def getMinimum firstComplex secondComplex return complex min firstComplex real secondComplex real min firstComplex imag secondComplex imag
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def test_dont_collect_non_function_callable testdir testdir makepyfile '\nclassOh object \ndef__call__ self \npass\n\ntest_a Oh \n\ndeftest_real \npass\n' result testdir runpytest '-rw' result stdout fnmatch_lines ['*collected1item*' 'WC2*' '*1passed 1pytest-warningsin*']
def load_router full_router_path path_bits full_router_path split u' ' if len path_bits < 2 raise ImproperlyConfigured u"Theprovidedrouter'%s'isnotacompletePythonpathtoaBaseRoutersubclass " % full_router_path return import_class full_router_path
def _create_test_message sqs SQSConnection sqs_q sqs get_queue g sitemap_sqs_queue assert sqs_q 'failedtoconnecttoqueue'message sqs_q new_message body json dumps {'job_name' 'daily-sr-sitemap-reporting' 'location' 's3 //reddit-data-analysis/big-data/r2/prod/' + 'daily_sr_sitemap_reporting/dt 2016-06-14' 'timestamp' _current_timestamp } sqs_q write message
def _create_test_message sqs SQSConnection sqs_q sqs get_queue g sitemap_sqs_queue assert sqs_q 'failedtoconnecttoqueue'message sqs_q new_message body json dumps {'job_name' 'daily-sr-sitemap-reporting' 'location' 's3 //reddit-data-analysis/big-data/r2/prod/' + 'daily_sr_sitemap_reporting/dt 2016-06-14' 'timestamp' _current_timestamp } sqs_q write message
def _ImageHeaderFactory stream from docx image import SIGNATURESdef read_32 stream stream seek 0 return stream read 32 header read_32 stream for cls offset signature_bytes in SIGNATURES end offset + len signature_bytes found_bytes header[offset end]if found_bytes signature_bytes return cls from_stream stream raise UnrecognizedImageError
def _ImageHeaderFactory stream from docx image import SIGNATURESdef read_32 stream stream seek 0 return stream read 32 header read_32 stream for cls offset signature_bytes in SIGNATURES end offset + len signature_bytes found_bytes header[offset end]if found_bytes signature_bytes return cls from_stream stream raise UnrecognizedImageError
def broadcast_change _ res SendMessageTimeout HWND_BROADCAST WM_SETTINGCHANGE 0 0 SMTO_ABORTIFHUNG 5000 return not bool res
def index_for _type try _type_n _normalize_type _type return _INDICES[_type_n] except KeyError as ke log warn 'Unknownsearchtype %s' % _type return NoopSearchIndex
def on_report_to_master client_id data data['content-length'] stats['content-length']stats['content-length'] 0
def on_report_to_master client_id data data['content-length'] stats['content-length']stats['content-length'] 0
def on_report_to_master client_id data data['content-length'] stats['content-length']stats['content-length'] 0
def create_all_dirs path umask False result Trueif sabnzbd WIN32 try os makedirs path except result Falseelse lst []lst extend path split '/' path ''for d in lst if d path + '/' + d if not os path exists path try os mkdir path result Trueexcept result Falseif umask mask cfg umask if mask try os chmod path int mask 8 448 except passreturn result
def create_all_dirs path umask False result Trueif sabnzbd WIN32 try os makedirs path except result Falseelse lst []lst extend path split '/' path ''for d in lst if d path + '/' + d if not os path exists path try os mkdir path result Trueexcept result Falseif umask mask cfg umask if mask try os chmod path int mask 8 448 except passreturn result
def latex check_build if sys platform 'win32' if os system 'sphinx-build-blatex-dbuild/doctrees build/latex' raise SystemExit 'BuildingLaTeXfailed ' os chdir 'build/latex' if os system 'make' raise SystemExit 'RenderingLaTeXfailed ' os chdir ' / ' else print 'latexbuildhasnotbeentestedonwindows'
def setUpModule global context models adaptercontext {'sys path' sys path[ ] 'sys modules' sys modules copy 'os environ' os environ copy }if init_django from pyamf tests adapters django_app adapters import modelsfrom pyamf adapters import _django_db_models_base as adaptersetup_test_environment settings DATABASE_NAME create_test_db 0 True
def setUpModule global context models adaptercontext {'sys path' sys path[ ] 'sys modules' sys modules copy 'os environ' os environ copy }if init_django from pyamf tests adapters django_app adapters import modelsfrom pyamf adapters import _django_db_models_base as adaptersetup_test_environment settings DATABASE_NAME create_test_db 0 True
def selected_row view if view selectionMode in [QAbstractItemView MultiSelection QAbstractItemView ExtendedSelection] raise ValueError "invalid'selectionMode'" sel_model view selectionModel indexes sel_model selectedRows if indexes assert len indexes 1 return indexes[0] row else return None
def only_ci decorated_func @wraps decorated_func def _inner_func *args **kwds if is_running_on_ci return decorated_func *args **kwds return _inner_func
def only_ci decorated_func @wraps decorated_func def _inner_func *args **kwds if is_running_on_ci return decorated_func *args **kwds return _inner_func
def restart name sig None proxy_fn 'rest_sample service_restart'return __proxy__[proxy_fn] name
def get_votes obj obj_type apps get_model 'contenttypes' 'ContentType' objects get_for_model obj try return Votes objects get content_type obj_type object_id obj id countexcept Votes DoesNotExist return 0
def get_build_id_offsets return {'i386' [372] 'arm' [372] 'thumb' [372] 'aarch64' [568] 'amd64' [624 372] 'powerpc' [372] 'powerpc64' [568] 'sparc' [372] 'sparc64' [624]} get context arch []
def get_precision currency global _cacheif _cache is None _cache _generate_cache return _cache[currency]
@pytest fixturedef pytyping pytyping pytest importorskip 'typing' return pytyping
def gen_jid return '{0 %Y%m%d%H%M%S%f}' format datetime datetime now
@partial partialdef set_logged_in_cookies backend None user None strategy None auth_entry None *args **kwargs if not is_api auth_entry and user is not None and user is_authenticated request strategy request if strategy else None if request is not None has_cookie student cookies is_logged_in_cookie_set request if not has_cookie try redirect_url get_complete_url backend name except ValueError passelse response redirect redirect_url return student cookies set_logged_in_cookies request response user
def clean_path_filename url filename url get_file_name path url get_path_without_file encode DEFAULT_ENCODING if filename res path[1 ]res + clean_filename filename else res clean_path url get_path encode DEFAULT_ENCODING [1 ]return res
def clean_path_filename url filename url get_file_name path url get_path_without_file encode DEFAULT_ENCODING if filename res path[1 ]res + clean_filename filename else res clean_path url get_path encode DEFAULT_ENCODING [1 ]return res
def odd_ext x n axis -1 if n < 1 return xif n > x shape[axis] - 1 raise ValueError 'Theextensionlengthn %d istoobig ' + 'Itmustnotexceedx shape[axis]-1 whichis%d ' % n x shape[axis] - 1 left_end axis_slice x start 0 stop 1 axis axis left_ext axis_slice x start n stop 0 step -1 axis axis right_end axis_slice x start -1 axis axis right_ext axis_slice x start -2 stop - n + 2 step -1 axis axis ext np concatenate 2 * left_end - left_ext x 2 * right_end - right_ext axis axis return ext
def graph_atlas_g return list _generate_graphs
def get_cache key default None struct _channel_repository_cache get key {} expires struct get 'expires' if expires and expires > time time return struct get 'data' return default
def get_possible_name_fields_for_model model if hasattr model u'name_field' yield model name_field for field in model _meta local_fields if field name in [u'name' u'title'] yield field name if hasattr model u'_parler_meta' for field in model _parler_meta root_model _meta get_fields if field name not in u'master' u'id' u'language_code' u'description' yield field name
def get_possible_name_fields_for_model model if hasattr model u'name_field' yield model name_field for field in model _meta local_fields if field name in [u'name' u'title'] yield field name if hasattr model u'_parler_meta' for field in model _parler_meta root_model _meta get_fields if field name not in u'master' u'id' u'language_code' u'description' yield field name
def setup_generic_relations model_class Action get_model 'actstream' 'action' if Action is None raise RegistrationError 'Unablegetactstream Action Potentialcircularimportsininitialisation TrymovingactstreamapptocomeaftertheappswhichhavemodelstoregisterintheINSTALLED_APPSsetting ' related_attr_name 'related_name'related_attr_value 'actions_with_%s' % label model_class if django VERSION[ 2] > 1 7 related_attr_name 'related_query_name'relations {}for field in 'actor' 'target' 'action_object' attr '%s_actions' % field attr_value '%s_as_%s' % related_attr_value field kwargs {'content_type_field' '%s_content_type' % field 'object_id_field' '%s_object_id' % field related_attr_name attr_value}rel generic GenericRelation 'actstream Action' **kwargs rel contribute_to_class model_class attr relations[field] relsetattr Action attr_value None return relations
def encode_as_multipart multipart_container boundary v_vars v_files _split_vars_files multipart_container _ data multipart_encode v_vars v_files boundary boundary return data
def _determine_default_project project None if project is None project _get_gcd_project if project is None project _base_default_project project project return project
def _validate_int name value limits strip '%' comment ''try if isinstance value string_types value value strip '' + strip value int value except TypeError ValueError comment + '{0}mustbeaninteger' format name else if len limits 2 if value < limits[0] or value > limits[1] comment + '{0}mustbeintherange[{1[0]} {1[1]}]' format name limits return value comment
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def timedtest max_time tolerance TOLERANCE def _timedtest function def wrapper *args **kw start_time time time try function *args **kw finally total_time time time - start_time if total_time > max_time + tolerance raise DurationError 'Testwastoolong % 2fs ' % total_time return wrapperreturn _timedtest
def construct **kwargs point_x kwargs pop 'point_x' None point_y kwargs pop 'point_y' None if 'point' in kwargs raise TypeError 'Unknownkeyword point' if None not in point_x point_y kwargs['point'] EccPoint point_x point_y eq1 pow Integer point_y 2 _curve p x Integer point_x eq2 pow x 3 _curve p x * -3 eq2 + xeq2 + _curve beq2 % _curve pif eq1 eq2 raise ValueError 'Thepointisnotonthecurve' d kwargs get 'd' None if d is not None and 'point' in kwargs pub_key _curve G * d if pub_key x point_x or pub_key y point_y raise ValueError 'PrivateandpublicECCkeysdonotmatch' return EccKey **kwargs
def test_fits_hst_unit x u Unit u'erg/s/cm**2/angstrom' assert x u erg * u s ** -1 * u cm ** -2 * u angstrom ** -1
def build_files_list root_dir return [os path join dirpath file_path for dirpath subdirs files in os walk root_dir for file_path in files]
def build_files_list root_dir return [os path join dirpath file_path for dirpath subdirs files in os walk root_dir for file_path in files]
def _ShardName name number return _SuffixName name str number
def update cmd 'eix-update--quiet'return __salt__['cmd retcode'] cmd 0
def min_weight graph src dst n default {'weight' np inf}w1 graph[n] get src default ['weight']w2 graph[n] get dst default ['weight']return {'weight' min w1 w2 }
def notify_about_server_group_update context event_suffix sg_payload notifier rpc get_notifier service 'servergroup' notifier info context 'servergroup %s' % event_suffix sg_payload
def make_cidx_file fp if which 'cdbfasta' args ['cdbfasta' fp] stdout stderr Popen args stderr PIPE stdout PIPE communicate else raise ApplicationNotFoundError
def get_info photo_id api_key query urlencode {'method' 'flickr photos getInfo' 'api_key' api_key 'photo_id' photo_id 'format' 'json' 'nojsoncallback' '1'} r urlopen 'https //api flickr com/services/rest/?' + query info json loads r read decode 'utf-8' if info['stat'] 'fail' raise ValueError info['message'] return info
def add_users_autogroup apps schema_editor Group apps get_model u'auth' u'Group' AutoGroup apps get_model u'accounts' u'AutoGroup' group Group objects get_or_create name u'Users' [0]if not AutoGroup objects filter group group exists AutoGroup objects create group group match u'^ *$'
@register filter def oneline value return value replace '\n' ''
def task_locale def set_nikola_test_locales try out subprocess check_output ['locale' '-a'] out out decode 'utf-8' locales []languages set for line in out splitlines if line endswith ' utf8' or line endswith ' UTF-8' and '_' in line lang line split '_' [0]if lang not in languages try locale setlocale locale LC_ALL str line except continuelanguages add lang locales append lang line if len locales 2 breakif len locales 2 return Falseelse os environ['NIKOLA_LOCALE_DEFAULT'] ' ' join locales[0] os environ['NIKOLA_LOCALE_OTHER'] ' ' join locales[1] finally locale resetlocale return {'actions' [set_nikola_test_locales] 'verbosity' 2}
def create_default_context purpose Purpose SERVER_AUTH cafile None capath None cadata None if not isinstance purpose _ASN1Object raise TypeError purpose context SSLContext PROTOCOL_SSLv23 context options OP_NO_SSLv2context options OP_NO_SSLv3context options getattr _ssl 'OP_NO_COMPRESSION' 0 if purpose Purpose SERVER_AUTH context verify_mode CERT_REQUIREDcontext check_hostname Trueelif purpose Purpose CLIENT_AUTH context options getattr _ssl 'OP_CIPHER_SERVER_PREFERENCE' 0 context options getattr _ssl 'OP_SINGLE_DH_USE' 0 context options getattr _ssl 'OP_SINGLE_ECDH_USE' 0 context set_ciphers _RESTRICTED_SERVER_CIPHERS if cafile or capath or cadata context load_verify_locations cafile capath cadata elif context verify_mode CERT_NONE context load_default_certs purpose return context
def init_console_logging formatter logging Formatter '% asctime s[% name s]% levelname s % message s' ch ConsoleHandler ch setFormatter formatter log addHandler ch log setLevel logging INFO
def access_settings service groupId settings group service groups g group get groupUniqueId groupId execute print '\nGrouppropertiesforgroup%s\n' % g['name'] pprint pprint g if not settings keys print '\nGiveaccessparameterstoupdategroupaccesspermissions\n' returnbody {}for key in settings iterkeys if settings[key] is not None body[key] settings[key]g1 group update groupUniqueId groupId body body execute print '\nUpdatedAccessPermissionstothegroup\n' pprint pprint g1
def access_settings service groupId settings group service groups g group get groupUniqueId groupId execute print '\nGrouppropertiesforgroup%s\n' % g['name'] pprint pprint g if not settings keys print '\nGiveaccessparameterstoupdategroupaccesspermissions\n' returnbody {}for key in settings iterkeys if settings[key] is not None body[key] settings[key]g1 group update groupUniqueId groupId body body execute print '\nUpdatedAccessPermissionstothegroup\n' pprint pprint g1
def exists *nictag **kwargs ret {}nictagadm _check_nictagadm if len nictag 0 return {'Error' 'Pleaseprovideatleastonenictagtocheck '}cmd '{nictagadm}exists-l{nictags}' format nictagadm nictagadm nictags '' join nictag res __salt__['cmd run_all'] cmd if not kwargs get 'verbose' False ret res['retcode'] 0 else missing res['stderr'] splitlines for nt in nictag ret[nt] nt not in missing return ret
def _consolidate blocks gkey lambda x x _consolidate_key grouper itertools groupby sorted blocks key gkey gkey new_blocks []for _can_consolidate dtype group_blocks in grouper merged_blocks _merge_blocks list group_blocks dtype dtype _can_consolidate _can_consolidate new_blocks _extend_blocks merged_blocks new_blocks return new_blocks
def test_edf_annotations raw read_raw_edf edf_path preload True edf_events find_events raw output 'step' shortest_event 0 stim_channel 'STI014' events [[0 1344 0 256 2] [0 3904 1 0 2] [2 0 0 0 3] [2 5 2 5 2]]events np array events events[ 2] * 512events np array events dtype int events[ 1] - 1events[ events[ 1] < 0 1 ] 1events[ 1] + events[ 0]onsets events[ [0 2]]offsets events[ [1 2]]events np zeros 2 * events shape[0] 3 dtype int events[0 2 [0 2]] onsetsevents[1 2 [0 1]] offsetsassert_array_equal edf_events events
def stop vm_name call None if call 'action' raise SaltCloudSystemExit 'Thestopactionmustbecalledwith-aor--action ' conn get_conn __utils__['cloud fire_event'] 'event' 'stopinstance' 'salt/cloud/{0}/stopping' format vm_name args {'name' vm_name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] result conn ex_stop_node conn ex_get_node vm_name __utils__['cloud fire_event'] 'event' 'stopinstance' 'salt/cloud/{0}/stopped' format vm_name args {'name' vm_name} sock_dir __opts__['sock_dir'] transport __opts__['transport'] return result
def get_value_from_user message default_value '' hidden False return _validate_user_input InputDialog message default_value is_truthy hidden
def tied_rank x sorted_x sorted zip x range len x r [0 for k in x]cur_val sorted_x[0][0]last_rank 0for i in range len sorted_x if cur_val sorted_x[i][0] cur_val sorted_x[i][0]for j in range last_rank i r[sorted_x[j][1]] float last_rank + 1 + i / 2 0 last_rank iif i len sorted_x - 1 for j in range last_rank i + 1 r[sorted_x[j][1]] float last_rank + i + 2 / 2 0 return r
def hilbert n values 1 0 / 1 0 + np arange 2 * n - 1 h hankel values[ n] r values[ n - 1 ] return h
def xml_decode string string string replace '&amp ' '&' string string replace '&lt ' '<' string string replace '&gt ' '>' string string replace '&quot ' '"' string string replace '/' SLASH return string
@registry add_binding Keys ControlC eager True @registry add_binding Keys ControlQ eager True def _ event event cli set_return_value None
@registry add_binding Keys ControlC eager True @registry add_binding Keys ControlQ eager True def _ event event cli set_return_value None
@registry add_binding Keys ControlC eager True @registry add_binding Keys ControlQ eager True def _ event event cli set_return_value None
def push_notebook document None state None handle None if state is None state _stateif state server_enabled raise RuntimeError 'output_server hasbeencalled whichisincompatiblewithpush_notebook' if not document document state documentif not document warnings warn 'Nodocumenttopush' returnif handle is None handle state last_comms_handleif not handle warnings warn 'Cannotfindalastshownplottoupdate Calloutput_notebook andshow notebook_handle True beforepush_notebook ' returnto_json document to_json if handle doc is not document msg dict doc to_json else msg Document _compute_patch_between_json handle json to_json handle comms send json dumps msg handle update document to_json
def push_notebook document None state None handle None if state is None state _stateif state server_enabled raise RuntimeError 'output_server hasbeencalled whichisincompatiblewithpush_notebook' if not document document state documentif not document warnings warn 'Nodocumenttopush' returnif handle is None handle state last_comms_handleif not handle warnings warn 'Cannotfindalastshownplottoupdate Calloutput_notebook andshow notebook_handle True beforepush_notebook ' returnto_json document to_json if handle doc is not document msg dict doc to_json else msg Document _compute_patch_between_json handle json to_json handle comms send json dumps msg handle update document to_json
def push_notebook document None state None handle None if state is None state _stateif state server_enabled raise RuntimeError 'output_server hasbeencalled whichisincompatiblewithpush_notebook' if not document document state documentif not document warnings warn 'Nodocumenttopush' returnif handle is None handle state last_comms_handleif not handle warnings warn 'Cannotfindalastshownplottoupdate Calloutput_notebook andshow notebook_handle True beforepush_notebook ' returnto_json document to_json if handle doc is not document msg dict doc to_json else msg Document _compute_patch_between_json handle json to_json handle comms send json dumps msg handle update document to_json
def test_unicode_column tmpdir t Table [np array [u'a' u'b' u'cd'] ] t write str tmpdir join 'test fits' overwrite True with fits open str tmpdir join 'test fits' as hdul assert np all hdul[1] data['col0'] ['a' 'b' 'cd'] assert hdul[1] header['TFORM1'] '2A' t2 Table [np array [u'\u2603'] ] with pytest raises UnicodeEncodeError t2 write str tmpdir join 'test fits' overwrite True
def test_unicode_column tmpdir t Table [np array [u'a' u'b' u'cd'] ] t write str tmpdir join 'test fits' overwrite True with fits open str tmpdir join 'test fits' as hdul assert np all hdul[1] data['col0'] ['a' 'b' 'cd'] assert hdul[1] header['TFORM1'] '2A' t2 Table [np array [u'\u2603'] ] with pytest raises UnicodeEncodeError t2 write str tmpdir join 'test fits' overwrite True
def test_unicode_column tmpdir t Table [np array [u'a' u'b' u'cd'] ] t write str tmpdir join 'test fits' overwrite True with fits open str tmpdir join 'test fits' as hdul assert np all hdul[1] data['col0'] ['a' 'b' 'cd'] assert hdul[1] header['TFORM1'] '2A' t2 Table [np array [u'\u2603'] ] with pytest raises UnicodeEncodeError t2 write str tmpdir join 'test fits' overwrite True
def matmul a b transa False transb False return MatMul transa transa transb transb a b
def test_scenario_may_own_outlines scenario Scenario from_string OUTLINED_SCENARIO assert_equals len scenario steps 4 expected_sentences ['GivenIhaveentered<input_1>intothecalculator' 'AndIhaveentered<input_2>intothecalculator' 'WhenIpress<button>' 'Thentheresultshouldbe<output>onthescreen']for step expected_sentence in zip scenario steps expected_sentences assert_equals type step Step assert_equals step sentence expected_sentence assert_equals scenario name 'Addtwonumbers' assert_equals scenario outlines [{'input_1' '20' 'input_2' '30' 'button' 'add' 'output' '50'} {'input_1' '2' 'input_2' '5' 'button' 'add' 'output' '7'} {'input_1' '0' 'input_2' '40' 'button' 'add' 'output' '40'}]
def BdbQuit_excepthook et ev tb excepthook None warnings warn '`BdbQuit_excepthook`isdeprecatedsinceversion5 1' DeprecationWarning stacklevel 2 if et bdb BdbQuit print 'ExitingDebugger 'elif excepthook is not None excepthook et ev tb else BdbQuit_excepthook excepthook_ori et ev tb
def BdbQuit_excepthook et ev tb excepthook None warnings warn '`BdbQuit_excepthook`isdeprecatedsinceversion5 1' DeprecationWarning stacklevel 2 if et bdb BdbQuit print 'ExitingDebugger 'elif excepthook is not None excepthook et ev tb else BdbQuit_excepthook excepthook_ori et ev tb
def _get_nets vif subnet version net_num link_id if subnet get_meta 'dhcp_server' is not None net_info {'id' 'network%d' % net_num 'type' 'ipv%d_dhcp' % version 'link' link_id 'network_id' vif['network']['id']}return net_infoip subnet['ips'][0]address ip['address']if version 4 netmask model get_netmask ip subnet elif version 6 netmask str subnet as_netaddr netmask net_info {'id' 'network%d' % net_num 'type' 'ipv%d' % version 'link' link_id 'ip_address' address 'netmask' netmask 'routes' _get_default_route version subnet 'network_id' vif['network']['id']}for route in subnet['routes'] route_addr netaddr IPNetwork route['cidr'] new_route {'network' str route_addr network 'netmask' str route_addr netmask 'gateway' route['gateway']['address']}net_info['routes'] append new_route return net_info
def add_views_to_dataset_resources context dataset_dict view_types [] create_datastore_views False created_views []for resource_dict in dataset_dict get 'resources' [] new_views add_views_to_resource context resource_dict dataset_dict view_types create_datastore_views created_views extend new_views return created_views
def remove_value module consul_api get_consul_api module key module params get 'key' value module params get 'value' index existing consul_api kv get key recurse module params get 'recurse' changed existing None if changed and not module check_mode consul_api kv delete key module params get 'recurse' module exit_json changed changed index index key key data existing
def make_paginator request items per_page 50 try page int request GET get 'page' '1' except ValueError page 1paginator Paginator items per_page try items paginator page page except InvalidPage EmptyPage items paginator page paginator num_pages return items
def read_double fid return _unpack_simple fid '>f8' np float64
def test_example2 vert_template Function '\nvoidmain void \n{\ngl_Position $position \n}\n' transformScale Function '\nvec4transform_scale vec4pos \n{\npos xyz* $scale \nreturnpos \n}\n' class Transform object def __init__ self self func Function transformScale self func['scale'] 'uniformfloat'def set_scale self scale self func['scale'] value scaletransforms [Transform Transform Transform ]code Function vert_template ob Variable 'attributevec3a_position' for trans in transforms ob trans func ob code['position'] obprint code
def hash obj hash_name 'md5' coerce_mmap False if 'numpy' in sys modules hasher NumpyHasher hash_name hash_name coerce_mmap coerce_mmap else hasher Hasher hash_name hash_name return hasher hash obj
def edgelist_for_workflow_steps steps edges []steps_to_index dict step i for i step in enumerate steps for step in steps edges append steps_to_index[step] steps_to_index[step] for conn in step input_connections edges append steps_to_index[conn output_step] steps_to_index[conn input_step] return edges
def edgelist_for_workflow_steps steps edges []steps_to_index dict step i for i step in enumerate steps for step in steps edges append steps_to_index[step] steps_to_index[step] for conn in step input_connections edges append steps_to_index[conn output_step] steps_to_index[conn input_step] return edges
def stub_out_registry_image_update stubs test_stubs stub_out_registry_server stubs def fake_image_update ctx image_id values purge_props False return {'properties' {}}stubs Set db_api 'image_update' fake_image_update
def stub_out_registry_image_update stubs test_stubs stub_out_registry_server stubs def fake_image_update ctx image_id values purge_props False return {'properties' {}}stubs Set db_api 'image_update' fake_image_update
def button_action button action connect_button button action trigger
def cxTwoPointCopy ind1 ind2 size len ind1 cxpoint1 random randint 1 size cxpoint2 random randint 1 size - 1 if cxpoint2 > cxpoint1 cxpoint2 + 1else cxpoint1 cxpoint2 cxpoint2 cxpoint1 ind1[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] copy ind1[cxpoint1 cxpoint2] copy return ind1 ind2
def cxTwoPointCopy ind1 ind2 size len ind1 cxpoint1 random randint 1 size cxpoint2 random randint 1 size - 1 if cxpoint2 > cxpoint1 cxpoint2 + 1else cxpoint1 cxpoint2 cxpoint2 cxpoint1 ind1[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] ind2[cxpoint1 cxpoint2] copy ind1[cxpoint1 cxpoint2] copy return ind1 ind2
def denoms eq symbols None pot preorder_traversal eq dens set for p in pot den denom p if den is S One continuefor d in Mul make_args den dens add d if not symbols return densrv []for d in dens free d free_symbolsif any s in free for s in symbols rv append d return set rv
def denoms eq symbols None pot preorder_traversal eq dens set for p in pot den denom p if den is S One continuefor d in Mul make_args den dens add d if not symbols return densrv []for d in dens free d free_symbolsif any s in free for s in symbols rv append d return set rv
def Unicode2Str s d return s encode
def build_request_with_data url data api_key method http_redirect_with_data_handler HTTPRedirectWithDataHandler method method opener urllib2 build_opener http_redirect_with_data_handler urllib2 install_opener opener url make_url url api_key api_key args None request urllib2 Request url headers {'Content-Type' 'application/json'} data json dumps data request_method request get_method if request_method method request get_method lambda method return opener request
def roles_accepted *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perm Permission *[RoleNeed role for role in roles] if perm can return fn *args **kwargs if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return decorated_viewreturn wrapper
def roles_accepted *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perm Permission *[RoleNeed role for role in roles] if perm can return fn *args **kwargs if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return decorated_viewreturn wrapper
def roles_accepted *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perm Permission *[RoleNeed role for role in roles] if perm can return fn *args **kwargs if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return decorated_viewreturn wrapper
def has_uniform_batch_size mode return resolve_iterator_class mode uniform_batch_size
def has_uniform_batch_size mode return resolve_iterator_class mode uniform_batch_size
def swap_inf_nan val if isinstance val string_types return valelif isinstance val collections Sequence return [swap_inf_nan v for v in val]elif isinstance val collections Mapping return dict [ swap_inf_nan k swap_inf_nan v for k v in iteritems val ] elif isinstance val float if math isnan val return '__NaN__'elif val float 'inf' return '__Infinity__'elif val float '-inf' return '__-Infinity__'else return valelse return val
def filer_file_from_upload request path upload_data sha1 None return _filer_file_from_upload model File request request path path upload_data upload_data sha1 sha1
def write_timeseries_value client project_resource custom_metric_type instance_id metric_kind now get_now_rfc3339 timeseries_data {'metric' {'type' custom_metric_type 'labels' {'environment' 'STAGING'}} 'resource' {'type' 'gce_instance' 'labels' {'instance_id' instance_id 'zone' 'us-central1-f'}} 'points' [{'interval' {'startTime' now 'endTime' now} 'value' {'int64Value' get_custom_data_point }}]}request client projects timeSeries create name project_resource body {'timeSeries' [timeseries_data]} request execute
def write_timeseries_value client project_resource custom_metric_type instance_id metric_kind now get_now_rfc3339 timeseries_data {'metric' {'type' custom_metric_type 'labels' {'environment' 'STAGING'}} 'resource' {'type' 'gce_instance' 'labels' {'instance_id' instance_id 'zone' 'us-central1-f'}} 'points' [{'interval' {'startTime' now 'endTime' now} 'value' {'int64Value' get_custom_data_point }}]}request client projects timeSeries create name project_resource body {'timeSeries' [timeseries_data]} request execute
def update cyg_arch 'x86_64' mirrors None args []args append '--upgrade-also' if not _check_cygwin_installed cyg_arch LOG debug 'Cygwin {0} notinstalled couldnotupdate' format cyg_arch return Falsereturn _run_silent_cygwin cyg_arch cyg_arch args args mirrors mirrors
def messy_split long_line new_list []old_list long_line split ' ' for line in old_list if len line 0 line + ' ' * 4 - len line % 4 % 4 new_list append line return new_list
def cancelRepository repository getReadRepository repository for setting in repository displayEntities if setting in repository preferences setting setStateToValue
def load_ptb_dataset path 'data/ptb/' print 'LoadorDownloadPennTreeBank PTB dataset>{}' format path filename 'simple-examples tgz'url 'http //www fit vutbr cz/~imikolov/rnnlm/'maybe_download_and_extract filename path url extract True data_path os path join path 'simple-examples' 'data' train_path os path join data_path 'ptb train txt' valid_path os path join data_path 'ptb valid txt' test_path os path join data_path 'ptb test txt' word_to_id nlp build_vocab nlp read_words train_path train_data nlp words_to_word_ids nlp read_words train_path word_to_id valid_data nlp words_to_word_ids nlp read_words valid_path word_to_id test_data nlp words_to_word_ids nlp read_words test_path word_to_id vocabulary len word_to_id return train_data valid_data test_data vocabulary
def load_ptb_dataset path 'data/ptb/' print 'LoadorDownloadPennTreeBank PTB dataset>{}' format path filename 'simple-examples tgz'url 'http //www fit vutbr cz/~imikolov/rnnlm/'maybe_download_and_extract filename path url extract True data_path os path join path 'simple-examples' 'data' train_path os path join data_path 'ptb train txt' valid_path os path join data_path 'ptb valid txt' test_path os path join data_path 'ptb test txt' word_to_id nlp build_vocab nlp read_words train_path train_data nlp words_to_word_ids nlp read_words train_path word_to_id valid_data nlp words_to_word_ids nlp read_words valid_path word_to_id test_data nlp words_to_word_ids nlp read_words test_path word_to_id vocabulary len word_to_id return train_data valid_data test_data vocabulary
def test_successful_update config_stub basedir download_stub data_tmpdir tmpdir win_registry caplog config_stub data {'content' {'host-block-lists' generic_blocklists tmpdir 'host-blocking-enabled' True 'host-blocking-whitelist' None}}host_blocker adblock HostBlocker host_blocker adblock_update while host_blocker _in_progress current_download host_blocker _in_progress[0]with caplog at_level logging ERROR current_download finished emit host_blocker read_hosts assert_urls host_blocker whitelisted []
def stat filename retry_params None _account_id None common validate_file_path filename api storage_api _get_storage_api retry_params retry_params account_id _account_id status headers content api head_object api_utils _quote_filename filename errors check_status status [200] filename resp_headers headers body content file_stat common GCSFileStat filename filename st_size common get_stored_content_length headers st_ctime common http_time_to_posix headers get 'last-modified' etag headers get 'etag' content_type headers get 'content-type' metadata common get_metadata headers return file_stat
def create_router name ext_network None admin_state_up True profile None conn _auth profile return conn create_router name ext_network admin_state_up
def shells shells_fn '/etc/shells'ret []if os path exists shells_fn try with salt utils fopen shells_fn 'r' as shell_fp lines shell_fp read splitlines for line in lines line line strip if line startswith '#' continueelif not line continueelse ret append line except OSError log error "File'{0}'wasnotfound" format shells_fn return ret
def shells shells_fn '/etc/shells'ret []if os path exists shells_fn try with salt utils fopen shells_fn 'r' as shell_fp lines shell_fp read splitlines for line in lines line line strip if line startswith '#' continueelif not line continueelse ret append line except OSError log error "File'{0}'wasnotfound" format shells_fn return ret
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME resource config get CONF_RESOURCE method 'GET'payload auth headers Noneverify_ssl config get CONF_VERIFY_SSL select config get CONF_SELECT unit config get CONF_UNIT_OF_MEASUREMENT value_template config get CONF_VALUE_TEMPLATE if value_template is not None value_template hass hassrest RestData method resource auth headers payload verify_ssl rest update if rest data is None _LOGGER error 'Unabletofetchdatafrom%s' resource return Falseadd_devices [ScrapeSensor hass rest name select value_template unit ]
def cap_alert_is_template alert_id if not alert_id return Falsetable current s3db cap_alertquery table id alert_id r current db query select table is_template limitby 0 1 first return r and r is_template
def salt_ssh import salt cli sshif '' in sys path sys path remove '' try client salt cli ssh SaltSSH _install_signal_handlers client client run except SaltClientError as err trace traceback format_exc try hardcrash client options hard_crashexcept AttributeError KeyError hardcrash False_handle_interrupt SystemExit err err hardcrash trace trace
def get_status_code_from_code_response code last_valid_line_from_code [line for line in code split u'\n' if line][ -1 ]status_code_from_last_line int last_valid_line_from_code split [0] status_code_from_first_digits int code[ 3] if status_code_from_last_line status_code_from_first_digits log warning u'FTPresponsestatuscodeseemstobeinconsistent \nCodereceived %s extracted %sand%s' code status_code_from_last_line status_code_from_first_digits return status_code_from_last_line
def quota_get_per_project_resources return IMPL quota_get_per_project_resources
def node_region patched_ast_node return patched_ast_node region
@verbosedef lookup_by_userid_demo oauth credsfromfile client Query **oauth user_info client user_info_from_id USERIDS for info in user_info name info['screen_name']followers info['followers_count']following info['friends_count']print '{0} followers {1} following {2}' format name followers following
def get_module user request usage_key field_data_cache position None log_if_not_found True wrap_xmodule_display True grade_bucket_type None depth 0 static_asset_path '' course None try descriptor modulestore get_item usage_key depth depth return get_module_for_descriptor user request descriptor field_data_cache usage_key course_key position position wrap_xmodule_display wrap_xmodule_display grade_bucket_type grade_bucket_type static_asset_path static_asset_path course course except ItemNotFoundError if log_if_not_found log debug 'Erroringet_module ItemNotFoundError' return Noneexcept log exception 'Erroringet_module' return None
def get_module user request usage_key field_data_cache position None log_if_not_found True wrap_xmodule_display True grade_bucket_type None depth 0 static_asset_path '' course None try descriptor modulestore get_item usage_key depth depth return get_module_for_descriptor user request descriptor field_data_cache usage_key course_key position position wrap_xmodule_display wrap_xmodule_display grade_bucket_type grade_bucket_type static_asset_path static_asset_path course course except ItemNotFoundError if log_if_not_found log debug 'Erroringet_module ItemNotFoundError' return Noneexcept log exception 'Erroringet_module' return None
def pnio_get_config pkt ether _get_ethernet pkt config Noneif ether is not None and ether src ether dst in conf contribs['PNIO_RTC'] config conf contribs['PNIO_RTC'][ ether src ether dst ]return config
def test_override_column_class_names class MyTable tables Table population tables Column verbose_name u'Population' def get_column_class_names self classes_set bound_column classes_set add u'prefix-%s' % bound_column name return classes_setTEST_DATA [{u'name' u'Belgium' u'population' 11200000} {u'name' u'Luxembourgh' u'population' 540000} {u'name' u'France' u'population' 66000000}]html MyTable TEST_DATA as_html build_request assert u'<tdclass "prefix-population">11200000</td>' in html
def test_override_column_class_names class MyTable tables Table population tables Column verbose_name u'Population' def get_column_class_names self classes_set bound_column classes_set add u'prefix-%s' % bound_column name return classes_setTEST_DATA [{u'name' u'Belgium' u'population' 11200000} {u'name' u'Luxembourgh' u'population' 540000} {u'name' u'France' u'population' 66000000}]html MyTable TEST_DATA as_html build_request assert u'<tdclass "prefix-population">11200000</td>' in html
def matching_details field our_args []our_kwargs {}for classes args kwargs in introspection_details if any [isinstance field x for x in classes] our_args extend args our_kwargs update kwargs return our_args our_kwargs
def _maybe_add_read_preference spec read_preference mode read_preference modetag_sets read_preference tag_setsmax_staleness read_preference max_stalenessif mode and mode ReadPreference SECONDARY_PREFERRED mode or tag_sets [{}] or max_staleness -1 if '$query' not in spec spec SON [ '$query' spec ] spec['$readPreference'] read_preference documentreturn spec
def _maybe_add_read_preference spec read_preference mode read_preference modetag_sets read_preference tag_setsmax_staleness read_preference max_stalenessif mode and mode ReadPreference SECONDARY_PREFERRED mode or tag_sets [{}] or max_staleness -1 if '$query' not in spec spec SON [ '$query' spec ] spec['$readPreference'] read_preference documentreturn spec
def _yield_clusters max_days_ago None now None **runner_kwargs if now is None now datetime utcnow emr_conn EMRJobRunner **runner_kwargs make_emr_conn created_after Noneif max_days_ago is not None created_after now - timedelta days max_days_ago for cluster_summary in _yield_all_clusters emr_conn created_after created_after _delay _DELAY cluster_id cluster_summary idsleep _DELAY cluster _patched_describe_cluster emr_conn cluster_id cluster steps _list_all_steps emr_conn cluster_id _delay _DELAY cluster bootstrapactions list _yield_all_bootstrap_actions emr_conn cluster_id _delay _DELAY yield cluster
@pytest yield_fixturedef dir_with_hooks tmpdir hooks_dir tmpdir mkdir 'hooks' pre_hook_content textwrap dedent u"\n# /usr/bin/envpython\n#-*-coding utf-8-*-\nprint 'pre_gen_project py~' \n" pre_gen_hook_file hooks_dir / 'pre_gen_project py~' pre_gen_hook_file write_text pre_hook_content encoding 'utf8' post_hook_content textwrap dedent u"\n# /usr/bin/envpython\n#-*-coding utf-8-*-\nprint 'post_gen_project py~' \n" post_gen_hook_file hooks_dir / 'post_gen_project py~' post_gen_hook_file write_text post_hook_content encoding 'utf8' yield str tmpdir pre_gen_hook_file remove post_gen_hook_file remove
def get_power **kwargs with _IpmiCommand **kwargs as s return s get_power ['powerstate']
def get_timestamp_from_url url obj urllib2 urlopen url return time strptime obj info ['Last-Modified'] '%a %d%b%Y%H %M %SGMT'
def ssh ip_address keyname cmd method subprocess check_call key_file '{}/{} key' format KEY_DIRECTORY keyname ssh_cmd ['ssh' '-i' key_file '-o' 'StrictHostKeyChecking no' ip_address cmd]return method ssh_cmd
def delete_tags filesystemid tags keyid None key None profile None region None **kwargs client _get_conn key key keyid keyid profile profile region region client delete_tags FileSystemId filesystemid Tags tags
@declareddef down obj output set_value obj output None 1
def set_ key value profile None if not profile return False conn cur table _connect profile value buffer msgpack packb value q profile get 'set_query' 'INSERTORREPLACEINTO{0}VALUES key value ' format table conn execute q {'key' key 'value' value} conn commit return True
def fetch_pack_index index_url None logger None allow_empty False logger logger or LOG index_urls _build_index_list index_url index status _fetch_and_compile_index index_urls logger if not index and not allow_empty raise ValueError 'Noresultsfromthe%s tried%s \nStatus %s' % 'index' if len index_urls 1 else 'indexes' ' ' join index_urls json dumps status indent 4 return index status
def ckan_after_request response response check_session_cookie response response set_cors_headers_for_response response return response
def setup hass config def handle_receive event 'CallbackallsubscribersforRFXtrxgateway 'if not event device id_string return_LOGGER debug 'ReceiveRFXCOMeventfrom Device_id %sClass %sSub %s Pkt_id %s ' slugify event device id_string lower event device __class__ __name__ event device subtype '' join '{0 02x}' format x for x in event data for subscriber in RECEIVED_EVT_SUBSCRIBERS subscriber event import RFXtrx as rfxtrxmodglobal RFXOBJECTdevice config[DOMAIN][ATTR_DEVICE]debug config[DOMAIN][ATTR_DEBUG]dummy_connection config[DOMAIN][ATTR_DUMMY]if dummy_connection RFXOBJECT rfxtrxmod Connect device handle_receive debug debug transport_protocol rfxtrxmod DummyTransport2 else RFXOBJECT rfxtrxmod Connect device handle_receive debug debug def _shutdown_rfxtrx event 'CloseconnectionwithRFXtrx 'RFXOBJECT close_connection hass bus listen_once EVENT_HOMEASSISTANT_STOP _shutdown_rfxtrx return True
def auth_backends request return {u'auth_backends' get_enabled_auth_backends }
def claModelControlDisableSPLearningCb claModel assert isinstance claModel CLAModel claModel _getSPRegion setParameter 'learningMode' False return
def push_mirrors config git_dir log logging getLogger 'gitosis mirror push_mirrors' repository_dir os path abspath util getRepositoryDir config git_dir os path abspath git_dir git_name get_git_name repository_dir git_dir log info "Updating%s'smirrors " % git_name for remote in get_mirrors config git_name log info 'Updating%s ' % remote repository mirror git_dir remote
def push_mirrors config git_dir log logging getLogger 'gitosis mirror push_mirrors' repository_dir os path abspath util getRepositoryDir config git_dir os path abspath git_dir git_name get_git_name repository_dir git_dir log info "Updating%s'smirrors " % git_name for remote in get_mirrors config git_name log info 'Updating%s ' % remote repository mirror git_dir remote
def push_mirrors config git_dir log logging getLogger 'gitosis mirror push_mirrors' repository_dir os path abspath util getRepositoryDir config git_dir os path abspath git_dir git_name get_git_name repository_dir git_dir log info "Updating%s'smirrors " % git_name for remote in get_mirrors config git_name log info 'Updating%s ' % remote repository mirror git_dir remote
def push_mirrors config git_dir log logging getLogger 'gitosis mirror push_mirrors' repository_dir os path abspath util getRepositoryDir config git_dir os path abspath git_dir git_name get_git_name repository_dir git_dir log info "Updating%s'smirrors " % git_name for remote in get_mirrors config git_name log info 'Updating%s ' % remote repository mirror git_dir remote
def mock_streams which both which 'both' stdout which 'stdout' or both stderr which 'stderr' or both def mocked_streams_decorator func @wraps func def inner_wrapper *args **kwargs if both sys stdall StringIO fake_stdout CarbonCopy cc sys stdall fake_stderr CarbonCopy cc sys stdall else fake_stdout fake_stderr StringIO StringIO if stdout my_stdout sys stdout sys stdout fake_stdout if stderr my_stderr sys stderr sys stderr fake_stderr try func *args **kwargs finally if stdout sys stdout my_stdoutif stderr sys stderr my_stderrif both del sys stdallreturn inner_wrapperreturn mocked_streams_decorator
def _prepare_trans_tar name mods None saltenv 'base' pillar None chunks _compile_state mods saltenv refs salt client ssh state lowstate_file_refs chunks _mk_fileclient trans_tar salt client ssh state prep_trans_tar __opts__ __context__['cp fileclient'] chunks refs pillar name return trans_tar
def _prepare_trans_tar name mods None saltenv 'base' pillar None chunks _compile_state mods saltenv refs salt client ssh state lowstate_file_refs chunks _mk_fileclient trans_tar salt client ssh state prep_trans_tar __opts__ __context__['cp fileclient'] chunks refs pillar name return trans_tar
def _prepare_trans_tar name mods None saltenv 'base' pillar None chunks _compile_state mods saltenv refs salt client ssh state lowstate_file_refs chunks _mk_fileclient trans_tar salt client ssh state prep_trans_tar __opts__ __context__['cp fileclient'] chunks refs pillar name return trans_tar
@contextmanagerdef assert_produces_warning expected_warning Warning filter_level u'always' clear None with warnings catch_warnings record True as w if clear is not None if not _is_list_like clear clear [clear]for m in clear getattr m u'__warningregistry__' {} clear saw_warning Falsewarnings simplefilter filter_level yield w extra_warnings []for actual_warning in w if expected_warning and issubclass actual_warning category expected_warning saw_warning Trueelse extra_warnings append actual_warning category __name__ if expected_warning assert saw_warning u'Didnotseeexpectedwarningofclass%r ' % expected_warning __name__ assert not extra_warnings u'Causedunexpectedwarning s %r ' % extra_warnings
@contextmanagerdef assert_produces_warning expected_warning Warning filter_level u'always' clear None with warnings catch_warnings record True as w if clear is not None if not _is_list_like clear clear [clear]for m in clear getattr m u'__warningregistry__' {} clear saw_warning Falsewarnings simplefilter filter_level yield w extra_warnings []for actual_warning in w if expected_warning and issubclass actual_warning category expected_warning saw_warning Trueelse extra_warnings append actual_warning category __name__ if expected_warning assert saw_warning u'Didnotseeexpectedwarningofclass%r ' % expected_warning __name__ assert not extra_warnings u'Causedunexpectedwarning s %r ' % extra_warnings
def setup_test_episode_file if not os path exists FILE_DIR os makedirs FILE_DIR try with open FILE_PATH 'wb' as ep_file ep_file write 'foobar' ep_file flush except Exception print 'Unabletosetuptestepisode'raise
def discriminant a b c return math sqrt b ** 2 - 4 * a * c
def discriminant a b c return math sqrt b ** 2 - 4 * a * c
def loadImage filename path GUI_DATA_PATH im gtk Image filename os path join path filename im set_from_file filename im show return im
def _convert_seconds seconds return u'{0 0f} {1 02 0f}' format *divmod float seconds 60
def get_session conf requests_session None group None group group or DEFAULT_GROUP auth_plugin ka_loading load_auth_from_conf_options conf group session ka_loading load_session_from_conf_options conf group auth auth_plugin session requests_session return session
def getProfileBaseNameSynonym repository if repository getProfileDirectory None return repository baseNameSynonymreturn os path join repository getProfileDirectory repository baseNameSynonym
def configure_logging logging_config **kwargs LoggingManager logging_config_object logging_configlogging_config configure_logging **kwargs
def is_readable_gs_handle gs_handle try with files open gs_handle as bak_file bak_file read 1 except files PermissionDeniedError return Falsereturn True
def cpu_usage_for_process results process process_results [r for r in results if r['metric']['type'] 'cputime' and r['process'] process ]cpu_values sum r['value'] for r in process_results wallclock_values sum r['wallclock'] for r in process_results if wallclock_values > 0 return float cpu_values / wallclock_values return None
def test_match assert match Command u'ps-ef \xa0grepfoo' stderr u'-bash \xa0grep commandnotfound' assert not match Command 'ps-ef grepfoo' assert not match Command
def test_register client rv register client 'user1' 'default' assert 'Youweresuccessfullyregisteredandcanloginnow' in rv data rv register client 'user1' 'default' assert 'Theusernameisalreadytaken' in rv data rv register client '' 'default' assert 'Youhavetoenterausername' in rv data rv register client 'meh' '' assert 'Youhavetoenterapassword' in rv data rv register client 'meh' 'x' 'y' assert 'Thetwopasswordsdonotmatch' in rv data rv register client 'meh' 'foo' email 'broken' assert 'Youhavetoenteravalidemailaddress' in rv data
def test_unknown enum with pytest raises AttributeError _ enum three
def on_join session print 'sessionconnected {}' format session def on_leave details print 'on_leave' details session on_leave on_leave session leave
def on_join session print 'sessionconnected {}' format session def on_leave details print 'on_leave' details session on_leave on_leave session leave
def generate_conflicting_plot_options_with_json_writes_of_config def gen_test plot_options def test self config _json load open CONFIG_FILE with open CONFIG_FILE 'w' as f config update plot_options f write _json dumps config self assertRaises PlotlyError py _plot_option_logic {} return testfor i plot_options in enumerate TestPlotOptionLogic conflicting_option_set setattr TestPlotOptionLogic 'test_conflicting_plot_options_with_json_writes_of_config{}' format i gen_test plot_options
def generate_conflicting_plot_options_with_json_writes_of_config def gen_test plot_options def test self config _json load open CONFIG_FILE with open CONFIG_FILE 'w' as f config update plot_options f write _json dumps config self assertRaises PlotlyError py _plot_option_logic {} return testfor i plot_options in enumerate TestPlotOptionLogic conflicting_option_set setattr TestPlotOptionLogic 'test_conflicting_plot_options_with_json_writes_of_config{}' format i gen_test plot_options
def prefix_to_attr attr_id attr_by_prefix {'fsmt-' 'MountTargetId' 'subnet-' 'SubnetId' 'eni-' 'NetworkInterfaceId' 'sg-' 'SecurityGroups'}prefix first_or_default filter lambda pref str attr_id startswith pref attr_by_prefix keys if prefix return attr_by_prefix[prefix]return 'IpAddress'
def prefix_to_attr attr_id attr_by_prefix {'fsmt-' 'MountTargetId' 'subnet-' 'SubnetId' 'eni-' 'NetworkInterfaceId' 'sg-' 'SecurityGroups'}prefix first_or_default filter lambda pref str attr_id startswith pref attr_by_prefix keys if prefix return attr_by_prefix[prefix]return 'IpAddress'
def new_test_client cls **kwargs client cls debug_logging True client login **kwargs return client
def _create_ansi_color_dict color_cls return {u'ansidefault' color_cls BLACK u'ansiblack' color_cls BLACK u'ansidarkgray' color_cls BLACK color_cls INTENSITY u'ansilightgray' color_cls GRAY u'ansiwhite' color_cls GRAY color_cls INTENSITY u'ansidarkred' color_cls RED u'ansidarkgreen' color_cls GREEN u'ansibrown' color_cls YELLOW u'ansidarkblue' color_cls BLUE u'ansipurple' color_cls MAGENTA u'ansiteal' color_cls CYAN u'ansired' color_cls RED color_cls INTENSITY u'ansigreen' color_cls GREEN color_cls INTENSITY u'ansiyellow' color_cls YELLOW color_cls INTENSITY u'ansiblue' color_cls BLUE color_cls INTENSITY u'ansifuchsia' color_cls MAGENTA color_cls INTENSITY u'ansiturquoise' color_cls CYAN color_cls INTENSITY }
def _create_ansi_color_dict color_cls return {u'ansidefault' color_cls BLACK u'ansiblack' color_cls BLACK u'ansidarkgray' color_cls BLACK color_cls INTENSITY u'ansilightgray' color_cls GRAY u'ansiwhite' color_cls GRAY color_cls INTENSITY u'ansidarkred' color_cls RED u'ansidarkgreen' color_cls GREEN u'ansibrown' color_cls YELLOW u'ansidarkblue' color_cls BLUE u'ansipurple' color_cls MAGENTA u'ansiteal' color_cls CYAN u'ansired' color_cls RED color_cls INTENSITY u'ansigreen' color_cls GREEN color_cls INTENSITY u'ansiyellow' color_cls YELLOW color_cls INTENSITY u'ansiblue' color_cls BLUE color_cls INTENSITY u'ansifuchsia' color_cls MAGENTA color_cls INTENSITY u'ansiturquoise' color_cls CYAN color_cls INTENSITY }
def NullController *_args **_kwargs return None
def find_interface resource class_or_interface if IInterface providedBy class_or_interface test class_or_interface providedByelse test lambda arg isinstance arg class_or_interface for location in lineage resource if test location return location
def find_interface resource class_or_interface if IInterface providedBy class_or_interface test class_or_interface providedByelse test lambda arg isinstance arg class_or_interface for location in lineage resource if test location return location
def custom_url generator metadata global global_siteurlglobal_siteurl generator settings['SITEURL']
def _kname obj if isinstance obj dict return [obj get 'metadata' {} get 'name' '' ]elif isinstance obj list tuple names []for i in obj names append i get 'metadata' {} get 'name' '' return nameselse return 'Unknowntype'
@importorskip 'PIL' @importorskip modname_tkinter @xfail is_darwin reason 'Issue#1895 Knowntofailwithmacpython-python orgbinary ' def test_pil_tkinter pyi_builder pyi_builder test_source '\nimportPIL Image\n\n#StaticallyimportingtheTkinterpackageshouldsucceed implyingthis\n#importationsuccessfullyoverrodetheexclusionofthispackage\n#requestedby"PIL"packagehooks ToensurePyInstallerparsesthis\n#importandfreezesthispackagewiththistest thisimportisstatic \ntry \nimport{modname_tkinter}\nexceptImportError \nraiseSystemExit \'ERROR Module{modname_tkinter}isNOTbundled \' \n' format modname_tkinter modname_tkinter
@importorskip 'PIL' @importorskip modname_tkinter @xfail is_darwin reason 'Issue#1895 Knowntofailwithmacpython-python orgbinary ' def test_pil_tkinter pyi_builder pyi_builder test_source '\nimportPIL Image\n\n#StaticallyimportingtheTkinterpackageshouldsucceed implyingthis\n#importationsuccessfullyoverrodetheexclusionofthispackage\n#requestedby"PIL"packagehooks ToensurePyInstallerparsesthis\n#importandfreezesthispackagewiththistest thisimportisstatic \ntry \nimport{modname_tkinter}\nexceptImportError \nraiseSystemExit \'ERROR Module{modname_tkinter}isNOTbundled \' \n' format modname_tkinter modname_tkinter
def pr_api_url_from_web_url url path '/' join map partial replace 'pull' 'pulls' url_path_parts url return API_BASE_URL + REPOS_API_PATH + path
def _write_proj fid projs if len projs 0 returnstart_block fid FIFF FIFFB_PROJ for proj in projs start_block fid FIFF FIFFB_PROJ_ITEM write_int fid FIFF FIFF_NCHAN proj['data']['ncol'] write_name_list fid FIFF FIFF_PROJ_ITEM_CH_NAME_LIST proj['data']['col_names'] write_string fid FIFF FIFF_NAME proj['desc'] write_int fid FIFF FIFF_PROJ_ITEM_KIND proj['kind'] if proj['kind'] FIFF FIFFV_PROJ_ITEM_FIELD write_float fid FIFF FIFF_PROJ_ITEM_TIME 0 0 write_int fid FIFF FIFF_PROJ_ITEM_NVEC proj['data']['nrow'] write_int fid FIFF FIFF_MNE_PROJ_ITEM_ACTIVE proj['active'] write_float_matrix fid FIFF FIFF_PROJ_ITEM_VECTORS proj['data']['data'] if proj['explained_var'] is not None write_float fid FIFF FIFF_MNE_ICA_PCA_EXPLAINED_VAR proj['explained_var'] end_block fid FIFF FIFFB_PROJ_ITEM end_block fid FIFF FIFFB_PROJ
def parse_backend_conf backend **kwargs conf settings CACHES get backend None if conf is not None args conf copy args update kwargs backend args pop 'BACKEND' location args pop 'LOCATION' '' return backend location args else try mod_path cls_name backend rsplit ' ' 1 mod importlib import_module mod_path backend_cls getattr mod cls_name except AttributeError ImportError ValueError raise InvalidCacheBackendError "Couldnotfindbackend'%s'" % backend location kwargs pop 'LOCATION' '' return backend location kwargs raise InvalidCacheBackendError "Couldn'tfindacachebackendnamed'%s'" % backend
def parse_backend_conf backend **kwargs conf settings CACHES get backend None if conf is not None args conf copy args update kwargs backend args pop 'BACKEND' location args pop 'LOCATION' '' return backend location args else try mod_path cls_name backend rsplit ' ' 1 mod importlib import_module mod_path backend_cls getattr mod cls_name except AttributeError ImportError ValueError raise InvalidCacheBackendError "Couldnotfindbackend'%s'" % backend location kwargs pop 'LOCATION' '' return backend location kwargs raise InvalidCacheBackendError "Couldn'tfindacachebackendnamed'%s'" % backend
def parse_backend_conf backend **kwargs conf settings CACHES get backend None if conf is not None args conf copy args update kwargs backend args pop 'BACKEND' location args pop 'LOCATION' '' return backend location args else try mod_path cls_name backend rsplit ' ' 1 mod importlib import_module mod_path backend_cls getattr mod cls_name except AttributeError ImportError ValueError raise InvalidCacheBackendError "Couldnotfindbackend'%s'" % backend location kwargs pop 'LOCATION' '' return backend location kwargs raise InvalidCacheBackendError "Couldn'tfindacachebackendnamed'%s'" % backend
def regions from boto machinelearning layer1 import MachineLearningConnectionreturn get_regions 'machinelearning' connection_cls MachineLearningConnection
def _depth_limited_walk top max_depth None for root dirs files in os walk top if max_depth is not None rel_depth root count os sep - top count os sep if rel_depth > max_depth del dirs[ ] yield str root list dirs list files
def _depth_limited_walk top max_depth None for root dirs files in os walk top if max_depth is not None rel_depth root count os sep - top count os sep if rel_depth > max_depth del dirs[ ] yield str root list dirs list files
def _depth_limited_walk top max_depth None for root dirs files in os walk top if max_depth is not None rel_depth root count os sep - top count os sep if rel_depth > max_depth del dirs[ ] yield str root list dirs list files
def parse_name_and_version p m NAME_VERSION_RE match p if not m raise DistlibException "Ill-formedname/versionstring '%s'" % p d m groupdict return d['name'] strip lower d['ver']
def _initial_image_sum width height channels if channels 1 return np zeros height width np float64 else return np zeros height width channels np float64
@require_POST@csrf_protectdef reposync request if not test_user_authenticated request return login request next '/cobbler_web/reposync' expired True remote background_reposync {'names' '' 'tries' 3} request session['token'] return HttpResponseRedirect '/cobbler_web/task_created'
def js_to_url_function converter if hasattr converter 'js_to_url_function' data converter js_to_url_function else for cls in getmro type converter if cls in js_to_url_functions data js_to_url_functions[cls] converter breakelse return 'encodeURIComponent'return ' function value {%s} ' % data
def GetTensorOpName x t x name rsplit ' ' 1 if len t 1 return x nameelse return t[0]
def get_changectx_for_changeset repo changeset_revision **kwd for changeset in repo changelog ctx repo changectx changeset if str ctx changeset_revision return ctxreturn None
def main input output offset 0bytes_per_line 16bytes_per_sentence 2input_chunk bytes_per_line * 10 while True data input read bytes_per_line if data '' returnfor off ordinals printable in xxd offset data bytes_per_line bytes_per_sentence def ashex ord return '%02x' % ord hex '' join ['' join map ashex sentence for sentence in ordinals] hex hex ljust bytes_per_line * 2 + bytes_per_line / bytes_per_sentence - 1 output write '%07x %s%s\n' % off hex printable offset + len data
def main input output offset 0bytes_per_line 16bytes_per_sentence 2input_chunk bytes_per_line * 10 while True data input read bytes_per_line if data '' returnfor off ordinals printable in xxd offset data bytes_per_line bytes_per_sentence def ashex ord return '%02x' % ord hex '' join ['' join map ashex sentence for sentence in ordinals] hex hex ljust bytes_per_line * 2 + bytes_per_line / bytes_per_sentence - 1 output write '%07x %s%s\n' % off hex printable offset + len data
def minute_frame_to_session_frame minute_frame calendar how OrderedDict c _MINUTE_TO_SESSION_OHCLV_HOW[c] for c in minute_frame columns return minute_frame groupby calendar minute_to_session_label agg how
def register_sentry client worker def send_to_sentry job *exc_info client captureException exc_info exc_info extra {u'job_id' job id u'func' job func_name u'args' job args u'kwargs' job kwargs u'description' job description} worker push_exc_handler send_to_sentry
def is_matching G matching if isinstance matching dict matching matching_dict_to_set matching return all len set e1 & set e2 0 for e1 e2 in combinations matching 2
def progressbar iterable None length None label None show_eta True show_percent None show_pos False item_show_func None fill_char '#' empty_char '-' bar_template '% label s[% bar s]% info s' info_sep '' width 36 file None color None from _termui_impl import ProgressBarcolor resolve_color_default color return ProgressBar iterable iterable length length show_eta show_eta show_percent show_percent show_pos show_pos item_show_func item_show_func fill_char fill_char empty_char empty_char bar_template bar_template info_sep info_sep file file label label width width color color
def progressbar iterable None length None label None show_eta True show_percent None show_pos False item_show_func None fill_char '#' empty_char '-' bar_template '% label s[% bar s]% info s' info_sep '' width 36 file None color None from _termui_impl import ProgressBarcolor resolve_color_default color return ProgressBar iterable iterable length length show_eta show_eta show_percent show_percent show_pos show_pos item_show_func item_show_func fill_char fill_char empty_char empty_char bar_template bar_template info_sep info_sep file file label label width width color color
def progressbar iterable None length None label None show_eta True show_percent None show_pos False item_show_func None fill_char '#' empty_char '-' bar_template '% label s[% bar s]% info s' info_sep '' width 36 file None color None from _termui_impl import ProgressBarcolor resolve_color_default color return ProgressBar iterable iterable length length show_eta show_eta show_percent show_percent show_pos show_pos item_show_func item_show_func fill_char fill_char empty_char empty_char bar_template bar_template info_sep info_sep file file label label width width color color
def progressbar iterable None length None label None show_eta True show_percent None show_pos False item_show_func None fill_char '#' empty_char '-' bar_template '% label s[% bar s]% info s' info_sep '' width 36 file None color None from _termui_impl import ProgressBarcolor resolve_color_default color return ProgressBar iterable iterable length length show_eta show_eta show_percent show_percent show_pos show_pos item_show_func item_show_func fill_char fill_char empty_char empty_char bar_template bar_template info_sep info_sep file file label label width width color color
def adv_index_broadcastable_pattern a idx def replace_slice v if isinstance v gof Apply if len v outputs 1 raise ValueError 'Itisambiguouswhichoutputofamulti-outputOphastobefetched ' v else v v outputs[0]if NoneConst equals v return Noneif isinstance v type SliceType return slice None None return numpy zeros 2 * v ndim int newidx tuple map replace_slice idx fakeshape [ 2 - bc for bc in a broadcastable]retshape numpy empty fakeshape [newidx] shapereturn tuple [ dim 1 for dim in retshape]
def user_has_passed_entrance_exam request course if not course_has_entrance_exam course return Trueif not request user is_authenticated return Falseentrance_exam_score get_entrance_exam_score request course if entrance_exam_score > course entrance_exam_minimum_score_pct return Truereturn False
def user_has_passed_entrance_exam request course if not course_has_entrance_exam course return Trueif not request user is_authenticated return Falseentrance_exam_score get_entrance_exam_score request course if entrance_exam_score > course entrance_exam_minimum_score_pct return Truereturn False
def user_has_passed_entrance_exam request course if not course_has_entrance_exam course return Trueif not request user is_authenticated return Falseentrance_exam_score get_entrance_exam_score request course if entrance_exam_score > course entrance_exam_minimum_score_pct return Truereturn False
def user_has_passed_entrance_exam request course if not course_has_entrance_exam course return Trueif not request user is_authenticated return Falseentrance_exam_score get_entrance_exam_score request course if entrance_exam_score > course entrance_exam_minimum_score_pct return Truereturn False
def user_has_passed_entrance_exam request course if not course_has_entrance_exam course return Trueif not request user is_authenticated return Falseentrance_exam_score get_entrance_exam_score request course if entrance_exam_score > course entrance_exam_minimum_score_pct return Truereturn False
def create_sink sink_name destination_bucket filter_ logging_client logging Client destination 'storage googleapis com/{bucket}' format bucket destination_bucket sink logging_client sink sink_name filter_ destination if sink exists print 'Sink{}alreadyexists ' format sink name returnsink create print 'Createdsink{}' format sink name
def create_sink sink_name destination_bucket filter_ logging_client logging Client destination 'storage googleapis com/{bucket}' format bucket destination_bucket sink logging_client sink sink_name filter_ destination if sink exists print 'Sink{}alreadyexists ' format sink name returnsink create print 'Createdsink{}' format sink name
def setup hass config mqtt loader get_component 'mqtt' topic config[DOMAIN] get 'topic' DEFAULT_TOPIC entity_id 'mqtt_example last_message'def message_received topic payload qos 'AnewMQTTmessagehasbeenreceived 'hass states set entity_id payload mqtt subscribe hass topic message_received hass states set entity_id 'Nomessages' def set_state_service call 'Servicetosendamessage 'mqtt publish hass topic call data get 'new_state' hass services register DOMAIN 'set_state' set_state_service return True
def getPointsFromFile numPoints file points []for pointIndex in xrange numPoints x getLittleEndianFloatGivenFile file y getLittleEndianFloatGivenFile file points append complex x y return points
def get_tile filename coord db _connect filename db text_factory bytesformats {'png' 'image/png' 'jpg' 'image/jpeg' 'json' 'application/json' None None}format db execute "SELECTvalueFROMmetadataWHEREname 'format'" fetchone format format and format[0] or None mime_type formats[format]tile_row 2 ** coord zoom - 1 - coord row q 'SELECTtile_dataFROMtilesWHEREzoom_level ?ANDtile_column ?ANDtile_row ?'content db execute q coord zoom coord column tile_row fetchone content content and content[0] or None return mime_type content
def absent name profile 'splunk' ret {'name' name 'changes' {} 'result' True 'comment' '{0}isabsent ' format name }target __salt__['splunk_search get'] name profile profile if target if __opts__['test'] ret {}ret['name'] nameret['comment'] 'Woulddelete{0}' format name ret['result'] Nonereturn retresult __salt__['splunk_search delete'] name profile profile if result ret['comment'] '{0}wasdeleted' format name else ret['comment'] 'Failedtodelete{0}' format name ret['result'] Falsereturn ret
def indent elem level 0 i '\n' + level * '' if len elem if not elem text or not elem text strip elem text i + '' if not elem tail or not elem tail strip elem tail ifor child in elem indent child level + 1 if not child tail or not child tail strip child tail iif not elem tail or not elem tail strip elem tail ielif level and not elem tail or not elem tail strip elem tail i
def safe_update dict_to dict_from for key val in dict dict_from iteritems if key in dict_to raise KeyError key dict_to[key] valreturn dict_to
def locate_prefix_by_name ctx name if name ROOT_ENV_NAME return ctx root_dirfor envs_dir in chain ctx envs_dirs + os getcwd prefix join envs_dir name if isdir prefix return prefixraise CondaEnvironmentNotFoundError name
@control_command def enable_events state dispatcher state consumer event_dispatcherif dispatcher groups and u'task' not in dispatcher groups dispatcher groups add u'task' logger info u'Eventsofgroup{task}enabledbyremote ' return ok u'taskeventsenabled' return ok u'taskeventsalreadyenabled'
def setup_platform hass config add_devices discovery_info None from heatmiserV3 import heatmiser connectionipaddress config get CONF_IPADDRESS port str config get CONF_PORT tstats config get CONF_TSTATS serport connection connection ipaddress port serport open for thermostat tstat in tstats items add_devices [HeatmiserV3Thermostat heatmiser tstat get CONF_ID tstat get CONF_NAME serport ] return
def add_git_host_key module url accept_hostkey True create_dir True if is_ssh_url url fqdn get_fqdn url if fqdn known_host check_hostkey module fqdn if not known_host if accept_hostkey rc out err add_host_key module fqdn create_dir create_dir if rc 0 module fail_json msg 'failedtoadd%shostkey %s' % fqdn out + err else module fail_json msg '%shasanunknownhostkey Setaccept_hostkeytoTrueormanuallyaddthehostkeypriortorunningthegitmodule' % fqdn
def set_lang request profile if profile language request session[LANGUAGE_SESSION_KEY] profile language
def _get_storage_path path app_id _ _ app_id app_id replace ' ' '_' rpartition '~' if path is None for path in _generate_storage_paths app_id try os mkdir path 448 except OSError as e if e errno errno EEXIST if sys platform 'win32' or os stat path st_mode & 511 448 and os path isdir path return pathelse continueraiseelse return pathelif not os path exists path os mkdir path return pathelif not os path isdir path raise IOError 'thegivenstoragepath%risafile adirectorywasexpected' % path else return path
@declareddef ok obj output set_value obj output None 0
def notice_send self print 'SendingLocalNotification'growl Growl GrowlNotifier applicationName self headers['Application-Name'] notifications [self headers['Notification-Name']] noticeIcon get_resource self 'Notification-Icon' growl notify noteType self headers['Notification-Name'] title self headers['Notification-Title'] description self headers get 'Notification-Text' '' icon noticeIcon return self encode
def ip_for_request request meta request METAreturn meta get u'HTTP_X_FORWARDED_FOR' meta[u'REMOTE_ADDR'] split u' ' [0]
def addGridRow diameter gridPath loopsComplex maximumComplex rowIndex x y zigzag row []while x < maximumComplex real point complex x y if euclidean getIsInFilledRegion loopsComplex point row append point x + diameter realif zigzag and rowIndex % 2 1 row reverse gridPath + row
def list2hexstr intlist intsize 4 result ''for value in intlist if isinstance value str result + valueelse result + int2hexstr value intsize return result
def list2hexstr intlist intsize 4 result ''for value in intlist if isinstance value str result + valueelse result + int2hexstr value intsize return result
def find_intermediate_color lowcolor highcolor intermed diff_0 float highcolor[0] - lowcolor[0] diff_1 float highcolor[1] - lowcolor[1] diff_2 float highcolor[2] - lowcolor[2] return lowcolor[0] + intermed * diff_0 lowcolor[1] + intermed * diff_1 lowcolor[2] + intermed * diff_2
def get_context context host get_request_site_address links []for route page in get_pages iteritems if not page no_sitemap links append {u'loc' urllib basejoin host urllib quote page name encode u'utf-8' u'lastmod' nowdate } for route data in get_all_page_context_from_doctypes iteritems links append {u'loc' urllib basejoin host urllib quote route or u'' encode u'utf-8' u'lastmod' get_datetime data get u'modified' strftime u'%Y-%m-%d' } return {u'links' links}
def translate sequence table 'Standard' stop_symbol '*' to_stop False cds False gap None if isinstance sequence Seq return sequence translate table stop_symbol to_stop cds elif isinstance sequence MutableSeq return sequence toseq translate table stop_symbol to_stop cds else try codon_table CodonTable ambiguous_generic_by_id[int table ]except ValueError codon_table CodonTable ambiguous_generic_by_name[table]except AttributeError TypeError if isinstance table CodonTable CodonTable codon_table tableelse raise ValueError 'Badtableargument' return _translate_str sequence codon_table stop_symbol to_stop cds gap gap
def dehydrate_content_ratings content_ratings for body in content_ratings or {} content_ratings[body] dehydrate_content_rating content_ratings[body] return content_ratings
def make_local_path s return s replace '/' os sep
def bayesian_info_criterion log_likelihood n_params n_samples return n_params * np log n_samples - 2 0 * log_likelihood
def bayesian_info_criterion log_likelihood n_params n_samples return n_params * np log n_samples - 2 0 * log_likelihood
def bayesian_info_criterion log_likelihood n_params n_samples return n_params * np log n_samples - 2 0 * log_likelihood
def find_cover_page container ver container opf_version_parsedif ver major < 3 mm container mime_mapguide_type_map container guide_type_mapfor ref_type name in guide_type_map iteritems if ref_type lower u'cover' and mm get name u'' lower in OEB_DOCS return nameelse for name in container manifest_items_with_property u'calibre title-page' return name
def get_valid_user user None if user is None theuser get_default_user elif isinstance user basestring theuser get_user_model objects get username user elif user user get_anonymous raise GeoNodeException 'Theuseruploadingfilesmustnotbeanonymous' else theuser userassert isinstance theuser get_user_model return theuser
def add_application_with_volume node_state manifestation list node_state manifestations values [0]return node_state set 'applications' {Application name u'myapplication' image DockerImage from_string u'image' volume AttachedVolume manifestation manifestation mountpoint FilePath '/data' }
def add_application_with_volume node_state manifestation list node_state manifestations values [0]return node_state set 'applications' {Application name u'myapplication' image DockerImage from_string u'image' volume AttachedVolume manifestation manifestation mountpoint FilePath '/data' }
def add_application_with_volume node_state manifestation list node_state manifestations values [0]return node_state set 'applications' {Application name u'myapplication' image DockerImage from_string u'image' volume AttachedVolume manifestation manifestation mountpoint FilePath '/data' }
def add_application_with_volume node_state manifestation list node_state manifestations values [0]return node_state set 'applications' {Application name u'myapplication' image DockerImage from_string u'image' volume AttachedVolume manifestation manifestation mountpoint FilePath '/data' }
@pytest fixture scope u'session' def celery_worker_pool return u'solo'
@pytest fixture scope u'session' def celery_worker_pool return u'solo'
def export cwd remote target None user None username None password None revision 'HEAD' *opts opts + remote if target opts + target revision_args '-r'opts + revision_args str revision return _run_svn 'export' cwd user username password opts
def polynomial_reduce_mod poly polymod p assert polymod[ -1 ] 1 assert len polymod > 1 while len poly > len polymod if poly[ -1 ] 0 for i in range 2 len polymod + 1 poly[ - i ] poly[ - i ] - poly[ -1 ] * polymod[ - i ] % p poly poly[0 -1 ]return poly
def cache_global name generate try result read_global name except CacheMiss result generate write_global name result return result
def restrict_forward_to_stc fwd stc fwd_out deepcopy fwd src_sel _stc_src_sel fwd['src'] stc fwd_out['source_rr'] fwd['source_rr'][src_sel]fwd_out['nsource'] len src_sel if is_fixed_orient fwd idx src_selelse idx 3 * src_sel[ None] + np arange 3 ravel fwd_out['source_nn'] fwd['source_nn'][idx]fwd_out['sol']['data'] fwd['sol']['data'][ idx]fwd_out['sol']['ncol'] len idx for i in range 2 fwd_out['src'][i]['vertno'] stc vertices[i]fwd_out['src'][i]['nuse'] len stc vertices[i] fwd_out['src'][i]['inuse'] fwd['src'][i]['inuse'] copy fwd_out['src'][i]['inuse'] fill 0 fwd_out['src'][i]['inuse'][stc vertices[i]] 1fwd_out['src'][i]['use_tris'] np array [] int fwd_out['src'][i]['nuse_tri'] np array [0] return fwd_out
def restrict_forward_to_stc fwd stc fwd_out deepcopy fwd src_sel _stc_src_sel fwd['src'] stc fwd_out['source_rr'] fwd['source_rr'][src_sel]fwd_out['nsource'] len src_sel if is_fixed_orient fwd idx src_selelse idx 3 * src_sel[ None] + np arange 3 ravel fwd_out['source_nn'] fwd['source_nn'][idx]fwd_out['sol']['data'] fwd['sol']['data'][ idx]fwd_out['sol']['ncol'] len idx for i in range 2 fwd_out['src'][i]['vertno'] stc vertices[i]fwd_out['src'][i]['nuse'] len stc vertices[i] fwd_out['src'][i]['inuse'] fwd['src'][i]['inuse'] copy fwd_out['src'][i]['inuse'] fill 0 fwd_out['src'][i]['inuse'][stc vertices[i]] 1fwd_out['src'][i]['use_tris'] np array [] int fwd_out['src'][i]['nuse_tri'] np array [0] return fwd_out
def critical_pair f g ring domain ring domainltf Polyn f LTltg Polyn g LTlt monomial_lcm ltf[0] ltg[0] domain one um term_div lt ltf domain vm term_div lt ltg domain fr lbp_mul_term lbp Sign f Polyn f leading_term Num f um gr lbp_mul_term lbp Sign g Polyn g leading_term Num g vm if lbp_cmp fr gr -1 return Sign gr vm g Sign fr um f else return Sign fr um f Sign gr vm g
def get_namespace_choices return NAMESPACE_CHOICES
def test_description_on_big_sentenced_steps feature Feature from_string FEATURE4 assert_equals feature description 'Asacleverguy\nIwanttodescribethisFeature\nSothatIcantakecareofmyScenario'
def add_handler app handler_name func key None handler_adder getattr app handler_name handler_funcs_name '{0}_funcs' format handler_name handler_funcs getattr app handler_funcs_name if func not in handler_funcs get key [] handler_adder func
def OutRbrace DedentLevel Output '}'
def multiplexer conditions def multiplexer_rl expr for key rule in conditions items if key expr return rule expr return multiplexer_rl
def stop_server port 7000 conn httplib HTTPConnection 'localhost %d' % port conn request 'QUIT' '/' conn getresponse
def stop_server port 7000 conn httplib HTTPConnection 'localhost %d' % port conn request 'QUIT' '/' conn getresponse
def invhilbert n exact False from scipy special import combif exact if n > 14 dtype objectelse dtype np int64else dtype np float64invh np empty n n dtype dtype for i in xrange n for j in xrange 0 i + 1 s i + j invh[ i j ] -1 ** s * s + 1 * comb n + i n - j - 1 exact * comb n + j n - i - 1 exact * comb s i exact ** 2 if i j invh[ j i ] invh[ i j ]return invh
def shared_cluster conf False cluster shared_cluster_internal closers []if conf closers extend [hadoop conf HDFS_CLUSTERS['default'] NN_HOST set_for_testing 'localhost' hadoop conf HDFS_CLUSTERS['default'] NN_HDFS_PORT set_for_testing cluster namenode_port hadoop conf MR_CLUSTERS['default'] HOST set_for_testing 'localhost' hadoop conf MR_CLUSTERS['default'] JT_THRIFT_PORT set_for_testing cluster jt thrift_port ] old_caches clear_sys_caches def finish if conf restore_sys_caches old_caches for x in closers x cluster shutdown finishreturn cluster
def _filetime_from_timestamp timestamp moment datetime fromtimestamp timestamp delta_from_utc moment - datetime utcfromtimestamp timestamp return dt_to_filetime moment delta_from_utc
def setup_platform hass config add_devices discovery_info None channels config get CONF_CHANNELS [] add_devices [TwitchSensor channel for channel in channels]
@_docstring 'release-groups' browse True def browse_release_groups artist None release None release_type [] includes [] limit None offset None valid_includes VALID_BROWSE_INCLUDES['release-groups']params {'artist' artist 'release' release}return _browse_impl 'release-group' includes valid_includes limit offset params [] release_type
def MomentumAdjustor final_momentum start saturate warnings warn 'sgd MomentumAdjustorinterfaceisdeprecatedandwillbecomeofficiallyunsupportedasofMay9 2014 Pleaseuse`learning_rule MomentumAdjustor`instead ' return LRMomentumAdjustor final_momentum start saturate
def _safe_quote val SAFE_QUOTE_CHARS '/ ?& 'try ret urllib parse quote val safe SAFE_QUOTE_CHARS except KeyError ret urllib parse quote val encode 'utf-8' safe SAFE_QUOTE_CHARS return ret
def fakeTargetFunction pass
def build_article url '' config None **kwargs config config or Configuration config extend_config config kwargs url url or '' a Article url config config return a
def uncache_zipdir path from zipimport import _zip_directory_cache as zdc_uncache path zdc _uncache path sys path_importer_cache
def uncache_zipdir path from zipimport import _zip_directory_cache as zdc_uncache path zdc _uncache path sys path_importer_cache
def uncache_zipdir path from zipimport import _zip_directory_cache as zdc_uncache path zdc _uncache path sys path_importer_cache
def uncache_zipdir path from zipimport import _zip_directory_cache as zdc_uncache path zdc _uncache path sys path_importer_cache
def beacon config ret []with salt utils fopen WTMP 'rb' as fp_ loc __context__ get LOC_KEY 0 if loc 0 fp_ seek 0 2 __context__[LOC_KEY] fp_ tell return retelse fp_ seek loc while True raw fp_ read SIZE if len raw SIZE return ret__context__[LOC_KEY] fp_ tell pack struct unpack FMT raw event {}for ind field in enumerate FIELDS event[field] pack[ind]if isinstance event[field] str event[field] event[field] strip '\x00' ret append event return ret
def beacon config ret []with salt utils fopen WTMP 'rb' as fp_ loc __context__ get LOC_KEY 0 if loc 0 fp_ seek 0 2 __context__[LOC_KEY] fp_ tell return retelse fp_ seek loc while True raw fp_ read SIZE if len raw SIZE return ret__context__[LOC_KEY] fp_ tell pack struct unpack FMT raw event {}for ind field in enumerate FIELDS event[field] pack[ind]if isinstance event[field] str event[field] event[field] strip '\x00' ret append event return ret
def expose func None alias None def expose_ func func exposed Trueif alias is not None if isinstance alias text_or_bytes parents[alias replace ' ' '_' ] funcelse for a in alias parents[a replace ' ' '_' ] funcreturn funcimport sysimport typesdecoratable_types types FunctionType types MethodType type if six PY2 decoratable_types + types ClassType if isinstance func decoratable_types if alias is None func exposed Truereturn funcelse parents sys _getframe 1 f_localsreturn expose_ func elif func is None if alias is None parents sys _getframe 1 f_localsreturn expose_else parents sys _getframe 1 f_localsreturn expose_else parents sys _getframe 1 f_localsalias funcreturn expose_
def unicode_sorter input key1 input lower key1 key1 replace u'\xe4' u'a' key1 key1 replace u'\xf6' u'o' key1 key1 replace u'\xfc' u'u' key1 key1 replace u'\xdf' u'ss' return key1
def unicode_sorter input key1 input lower key1 key1 replace u'\xe4' u'a' key1 key1 replace u'\xf6' u'o' key1 key1 replace u'\xfc' u'u' key1 key1 replace u'\xdf' u'ss' return key1
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME sink_name config get CONF_SINK_NAME source_name config get CONF_SOURCE_NAME host config get CONF_HOST port config get CONF_PORT buffer_size config get CONF_BUFFER_SIZE tcp_timeout config get CONF_TCP_TIMEOUT server_id str format '{0} {1}' host port if server_id in _PULSEAUDIO_SERVERS server _PULSEAUDIO_SERVERS[server_id]else server PAServer host port buffer_size tcp_timeout _PULSEAUDIO_SERVERS[server_id] serveradd_devices [PALoopbackSwitch hass name server sink_name source_name ]
def wrap_exceptions fun @functools wraps fun def wrapper self *args **kwargs try return fun self *args **kwargs except OSError as err if err errno in ACCESS_DENIED_SET raise AccessDenied self pid self _name if err errno errno ESRCH raise NoSuchProcess self pid self _name raisereturn wrapper
def get_file_subs_from_folder addon user kind path name folder dict kind kind path path name name file_tree addon _get_file_tree filenode folder user user version 'latest-published' return list_of_files file_tree
def get_file_subs_from_folder addon user kind path name folder dict kind kind path path name name file_tree addon _get_file_tree filenode folder user user version 'latest-published' return list_of_files file_tree
def task_package_install package_name distribution package_source PackageSource base_url installer _get_base_url_and_installer_for_distro distribution package_source build_server package_source branch return installer package_name distribution package_source base_url
def quote x if istask x or type x is list return literal x return x
def quote x if istask x or type x is list return literal x return x
def quote x if istask x or type x is list return literal x return x
def quote x if istask x or type x is list return literal x return x
def _fsync_files filenames touched_directories set mode os O_RDONLYif hasattr os 'O_BINARY' mode os O_BINARYfor filename in filenames fd os open filename mode os fsync fd os close fd touched_directories add os path dirname filename if hasattr os 'O_DIRECTORY' for dirname in touched_directories fd os open dirname os O_RDONLY os O_DIRECTORY os fsync fd os close fd
def _fsync_files filenames touched_directories set mode os O_RDONLYif hasattr os 'O_BINARY' mode os O_BINARYfor filename in filenames fd os open filename mode os fsync fd os close fd touched_directories add os path dirname filename if hasattr os 'O_DIRECTORY' for dirname in touched_directories fd os open dirname os O_RDONLY os O_DIRECTORY os fsync fd os close fd
def validate_is_document_type option value if not isinstance value collections MutableMapping RawBSONDocument raise TypeError '%smustbeaninstanceofdict bson son SON bson raw_bson RawBSONDocument oratypethatinheritsfromcollections MutableMapping' % option
def validate_is_document_type option value if not isinstance value collections MutableMapping RawBSONDocument raise TypeError '%smustbeaninstanceofdict bson son SON bson raw_bson RawBSONDocument oratypethatinheritsfromcollections MutableMapping' % option
def get_port_mapper return search_upnp_device addCallback lambda x UPnPMapper x
def upgrade migrate_engine meta MetaData bind migrate_engine key_pairs Table 'key_pairs' meta autoload True shadow_key_pairs Table 'shadow_key_pairs' meta autoload True enum Enum 'ssh' 'x509' metadata meta name 'keypair_types' enum create keypair_type Column 'type' enum nullable False server_default keypair KEYPAIR_TYPE_SSH if hasattr key_pairs c 'type' key_pairs c type drop if hasattr shadow_key_pairs c 'type' shadow_key_pairs c type drop key_pairs create_column keypair_type shadow_key_pairs create_column keypair_type copy
def suffix handlers default None error 'Therequestedsuffixdoesnotmatchanyofthoseallowed' def output_type data request response path request pathhandler defaultfor suffix_test suffix_handler in handlers items if path endswith suffix_test handler suffix_handlerbreakif not handler raise falcon HTTPNotAcceptable error response content_type handler content_typereturn handler data request request response response output_type __doc__ 'Supportsanyofthefollowingformats {0}' format ' ' join function __doc__ for function in handlers values output_type content_type ' ' join handlers keys return output_type
def suffix handlers default None error 'Therequestedsuffixdoesnotmatchanyofthoseallowed' def output_type data request response path request pathhandler defaultfor suffix_test suffix_handler in handlers items if path endswith suffix_test handler suffix_handlerbreakif not handler raise falcon HTTPNotAcceptable error response content_type handler content_typereturn handler data request request response response output_type __doc__ 'Supportsanyofthefollowingformats {0}' format ' ' join function __doc__ for function in handlers values output_type content_type ' ' join handlers keys return output_type
def get_best_unit unit_a unit_b a DATETIME_UNITS[unit_a]b DATETIME_UNITS[unit_b]if a 14 return unit_bif b 14 return unit_aif b > a return unit_breturn unit_a
def to_base85 x islong False size 10 if islong else 5 rems ''for i in xrange size rems b85chars[ x % 85 ] + rems x // 85return rems
def to_base85 x islong False size 10 if islong else 5 rems ''for i in xrange size rems b85chars[ x % 85 ] + rems x // 85return rems
@verbosedef load_data condition 'visual' data_format 'raw' data_type 'experimental' path None force_update False update_path None verbose None if not condition lower in valid_conditions raise ValueError 'Unknowncondition"%s"' % condition if data_format not in valid_data_formats raise ValueError 'Unknowndata_format"%s"' % data_format if data_type not in valid_data_types raise ValueError 'Unknowndata_type"%s"' % data_type urls url_match condition data_format data_type data_paths list for url in urls data_paths extend data_path url path force_update update_path return data_paths
@nottestdef subtest iterator *_names def dec f @wraps f def wrapped *args **kwargs names _namesfailures []for scope in iterator scope tuple scope try f * args + scope **kwargs except Exception as e if not names names count failures append dict zip names scope e if failures raise SubTestFailures *failures return wrappedreturn dec
@nottestdef subtest iterator *_names def dec f @wraps f def wrapped *args **kwargs names _namesfailures []for scope in iterator scope tuple scope try f * args + scope **kwargs except Exception as e if not names names count failures append dict zip names scope e if failures raise SubTestFailures *failures return wrappedreturn dec
def match_coordinates_sky matchcoord catalogcoord nthneighbor 1 storekdtree u'kdtree_sky' if catalogcoord isscalar or len catalogcoord < 1 raise ValueError u'Thecatalogforcoordinatematchingcannotbeascalarorlength-0 ' newmatch matchcoord transform_to catalogcoord match_urepr newmatch data represent_as UnitSphericalRepresentation newmatch_u newmatch realize_frame match_urepr cat_urepr catalogcoord data represent_as UnitSphericalRepresentation newcat_u catalogcoord realize_frame cat_urepr storekdtree catalogcoord cache get storekdtree storekdtree idx sep2d sep3d match_coordinates_3d newmatch_u newcat_u nthneighbor storekdtree if not isinstance catalogcoord data UnitSphericalRepresentation or isinstance newmatch data UnitSphericalRepresentation sep3d catalogcoord[idx] separation_3d newmatch if isinstance storekdtree six string_types catalogcoord cache[storekdtree] newcat_u cache[storekdtree]elif storekdtree is True catalogcoord cache[u'kdtree'] newcat_u cache[u'kdtree']return idx sep2d sep3d
def copy_cache obj funcname cacheobj cacheattr get_cache_impl obj funcname cacheattrtry setattr obj cacheattr cacheobj __dict__[cacheattr] except KeyError pass
def get_more_info_for_log more_info []site getattr frappe local u'site' None if site more_info append u'Site {0}' format site form_dict getattr frappe local u'form_dict' None if form_dict more_info append u'FormDict {0}' format frappe as_json form_dict if more_info more_info more_info + [u''] return u'\n' join more_info
def get_max_denom tup return max Fraction f denominator for f in tup
def update_and_define_min_max config minimum_default maximum_default minimum_value minimum_defaultmaximum_value maximum_defaultif config get CONF_MINIMUM minimum_value config get CONF_MINIMUM if config get CONF_MAXIMUM maximum_value config get CONF_MAXIMUM return minimum_value maximum_value
def update_and_define_min_max config minimum_default maximum_default minimum_value minimum_defaultmaximum_value maximum_defaultif config get CONF_MINIMUM minimum_value config get CONF_MINIMUM if config get CONF_MAXIMUM maximum_value config get CONF_MAXIMUM return minimum_value maximum_value
def test settings start_date datetime datetime now for single_date in start_date + datetime timedelta n for n in range 370 print single_dates SimpleScheduler settings s set_trigger single_date
def polar a side 'right' if side not in ['right' 'left'] raise ValueError "`side`mustbeeither'right'or'left'" a np asarray a if a ndim 2 raise ValueError '`a`mustbea2-Darray ' w s vh svd a full_matrices False u w dot vh if side 'right' p vh T conj * s dot vh else p w * s dot w T conj return u p
def MakeExpiredResponse reference json loads kVerifyResponseRenewedExpired return json dumps {'status' reference['status'] 'receipt' reference['receipt']}
def truncatechars value arg try length int arg except ValueError return valueif len value > length return value[ length - 3 ] + ' ' return value
def NamesOfDefinedFlags return ['tmod_bar_x' 'tmod_bar_y' 'tmod_bar_z' 'tmod_bar_t' 'tmod_bar_u' 'tmod_bar_v']
def lod_sort_by_key _list indexkey _list sort lambda a b a[indexkey] < b[indexkey] return _list
def lod_sort_by_key _list indexkey _list sort lambda a b a[indexkey] < b[indexkey] return _list
def _reshape_2D X if hasattr X u'shape' if len X shape 1 if hasattr X[0] u'shape' X list X else X [X]elif len X shape 2 nrows ncols X shapeif nrows 1 X [X]elif ncols 1 X [X ravel ]else X [X[ i] for i in xrange ncols ]else raise ValueError u'input`X`musthave2orfewerdimensions' if not hasattr X[0] u'__len__' X [X]else X [np ravel x for x in X]return X
def _reshape_2D X if hasattr X u'shape' if len X shape 1 if hasattr X[0] u'shape' X list X else X [X]elif len X shape 2 nrows ncols X shapeif nrows 1 X [X]elif ncols 1 X [X ravel ]else X [X[ i] for i in xrange ncols ]else raise ValueError u'input`X`musthave2orfewerdimensions' if not hasattr X[0] u'__len__' X [X]else X [np ravel x for x in X]return X
def _reshape_2D X if hasattr X u'shape' if len X shape 1 if hasattr X[0] u'shape' X list X else X [X]elif len X shape 2 nrows ncols X shapeif nrows 1 X [X]elif ncols 1 X [X ravel ]else X [X[ i] for i in xrange ncols ]else raise ValueError u'input`X`musthave2orfewerdimensions' if not hasattr X[0] u'__len__' X [X]else X [np ravel x for x in X]return X
def _extra_config user_defined_config base_dir for root_dir _ files in os walk base_dir for name in files if name endswith ' yml' ' yaml' with open os path join root_dir name 'rb' as f du merge_dict user_defined_config yaml safe_load f read or {} logger debug 'Mergedoverridesfromfile{}' format name
def _extra_config user_defined_config base_dir for root_dir _ files in os walk base_dir for name in files if name endswith ' yml' ' yaml' with open os path join root_dir name 'rb' as f du merge_dict user_defined_config yaml safe_load f read or {} logger debug 'Mergedoverridesfromfile{}' format name
def rand_infiniband_guid_address guid []for i in range 8 guid append '%02x' % random randint 0 255 return ' ' join guid
def page_not_found request page_name return page_missing request page_name True
def page_not_found request page_name return page_missing request page_name True
def email_outbox if not auth s3_logged_in session error T 'RequiresLogin ' redirect URL c 'default' f 'user' args 'login' tablename 'msg_email'table s3db msg_emails3 filter table inbound False table inbound readable Falses3 crud_strings[tablename] Storage title_display T 'EmailDetails' title_list T 'SentEmails' label_list_button T 'ViewSentEmails' label_delete_button T 'DeleteEmail' msg_record_deleted T 'Emaildeleted' msg_list_empty T 'NoEmailscurrentlyinOutbox' def postp r output if isinstance output dict add_btn A T 'Compose' _class 'action-btn' _href URL f 'compose' output['rheader'] add_btnreturn outputs3 postp postps3db configure tablename editable False insertable False listadd False list_fields ['id' 'date' 'to_address' 'subject' 'body'] return s3_rest_controller module 'email'
@app route '/' def resize app_path os path dirname os path realpath __file__ image_path os path join app_path 'assets/google_logo jpg' img scipy misc imread image_path img_tinted scipy misc imresize img 300 300 output_image_path os path join app_path 'assets/resized_google_logo jpg' scipy misc imsave output_image_path img_tinted return 'Imageresized '
@app route '/' def resize app_path os path dirname os path realpath __file__ image_path os path join app_path 'assets/google_logo jpg' img scipy misc imread image_path img_tinted scipy misc imresize img 300 300 output_image_path os path join app_path 'assets/resized_google_logo jpg' scipy misc imsave output_image_path img_tinted return 'Imageresized '
def compute_node_update context compute_id values return IMPL compute_node_update context compute_id values
@transaction non_atomic_requests@require_POST@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @require_level 'staff' def get_proctored_exam_results request course_id query_features ['user_email' 'exam_name' 'attempt_code' 'allowed_time_limit_mins' 'is_sample_attempt' 'started_at' 'completed_at' 'status']course_key CourseKey from_string course_id try lms djangoapps instructor_task api submit_proctored_exam_results_report request course_key query_features status_response _ 'Theproctoredexamresultsreportisbeingcreated Toviewthestatusofthereport seePendingTasksbelow ' except AlreadyRunningError status_response _ 'Theproctoredexamresultsreportiscurrentlybeingcreated Toviewthestatusofthereport seePendingTasksbelow Youwillbeabletodownloadthereportwhenitiscomplete ' return JsonResponse {'status' status_response}
def get_tempest_default_config_dir global_conf_dir '/etc/tempest'xdg_config os environ get 'XDG_CONFIG_HOME' os path expanduser '~/ config' user_xdg_global_path os path join xdg_config 'tempest' user_global_path os path join os path expanduser '~' ' tempest/etc' if os path isdir global_conf_dir return global_conf_direlif os path isdir user_xdg_global_path return user_xdg_global_pathelif os path isdir user_global_path return user_global_pathelse os makedirs user_global_path return user_global_path
def get_tempest_default_config_dir global_conf_dir '/etc/tempest'xdg_config os environ get 'XDG_CONFIG_HOME' os path expanduser '~/ config' user_xdg_global_path os path join xdg_config 'tempest' user_global_path os path join os path expanduser '~' ' tempest/etc' if os path isdir global_conf_dir return global_conf_direlif os path isdir user_xdg_global_path return user_xdg_global_pathelif os path isdir user_global_path return user_global_pathelse os makedirs user_global_path return user_global_path
@task@log_calldef remove if exists env venv_path run u'rm-rf%s' % env venv_path if exists env proj_path run u'rm-rf%s' % env proj_path for template in get_templates values remote_path template[u'remote_path']if exists remote_path sudo u'rm%s' % remote_path if exists env repo_path run u'rm-rf%s' % env repo_path sudo u'supervisorctlupdate' psql u'DROPDATABASEIFEXISTS%s ' % env proj_name psql u'DROPUSERIFEXISTS%s ' % env proj_name
def create_cover title authors series None series_index 1 prefs None as_qimage False u'templatesareignored toensurethatthespecifiedmetadataisused 'mi Metadata title authors if series mi series mi series_index series series_index d cprefs defaultsprefs override_prefs prefs or cprefs title_template d[u'title_template'] subtitle_template d[u'subtitle_template'] footer_template d[u'footer_template'] return generate_cover mi prefs prefs as_qimage as_qimage
def _default_loader name code '\nfrompackage_controlimportsys_path\nsys_path add_dependency %s \n' % repr name return dedent code lstrip
@handle_db_data_error@require_contextdef attachment_specs_update_or_create context attachment_id specs session get_session with session begin spec_ref Nonefor key value in specs items try spec_ref _attachment_specs_get_item context attachment_id key session except exception AttachmentSpecsNotFound spec_ref models AttachmentSpecs spec_ref update {'key' key 'value' value 'attachment_id' attachment_id 'deleted' False} spec_ref save session session return specs
def array_repr_oneline array r np array2string array separator u' ' suppress_small True return u'' join l strip for l in r splitlines
def group if auth permission format 'popup' return ''def prep r if r method 'create' return Falsereturn Trues3 prep prepoutput s3_rest_controller 'pr' 'group' return output
def test_g0 from import g0assert g0 value 9 80665 assert g0 si value 9 80665 assert g0 cgs value 980 665 assert g0 uncertainty 0 assert g0 nameassert g0 referenceassert g0 unitassert g0 unit physical_type u'acceleration'
def test_g0 from import g0assert g0 value 9 80665 assert g0 si value 9 80665 assert g0 cgs value 980 665 assert g0 uncertainty 0 assert g0 nameassert g0 referenceassert g0 unitassert g0 unit physical_type u'acceleration'
def find_igw vpc_conn vpc_id igw vpc_conn get_all_internet_gateways filters {'attachment vpc-id' vpc_id} if not igw raise AnsibleIgwSearchException 'NoIGWfoundforVPC{0}' format vpc_id elif len igw 1 return igw[0] idelse raise AnsibleIgwSearchException 'MultipleIGWsfoundforVPC{0}' format vpc_id
def _retrieve_discovery_doc url http cache_discovery cache None if cache_discovery from import discovery_cachefrom discovery_cache import baseif cache is None cache discovery_cache autodetect if cache content cache get url if content return contentactual_url urlif 'REMOTE_ADDR' in os environ actual_url _add_query_parameter url 'userIp' os environ['REMOTE_ADDR'] logger info 'URLbeingrequested GET%s' actual_url resp content http request actual_url if resp status > 400 raise HttpError resp content uri actual_url try content content decode 'utf-8' except AttributeError passtry service json loads content except ValueError as e logger error 'FailedtoparseasJSON ' + content raise InvalidJsonError if cache_discovery and cache cache set url content return content
def generate_password_hash password method 'sha1' salt_length 8 salt method 'plain' and gen_salt salt_length or '' h _hash_internal method salt password if h is None raise TypeError 'invalidmethod%r' % method return '%s$%s$%s' % method salt h
def _cmidrule colindex dataset_width rule '\\cmidrule %s {%d-%d}'if colindex 1 return rule % 'r' colindex colindex if colindex dataset_width return rule % 'l' colindex colindex return rule % 'lr' colindex colindex
def _cmidrule colindex dataset_width rule '\\cmidrule %s {%d-%d}'if colindex 1 return rule % 'r' colindex colindex if colindex dataset_width return rule % 'l' colindex colindex return rule % 'lr' colindex colindex
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def adjustments_from_deltas_no_sids dense_dates sparse_dates column_idx column_name asset_idx deltas ad_series deltas[AD_FIELD_NAME]idx 0 0 return {dense_dates get_loc kd overwrite_from_dates ad_series loc[kd] dense_dates sparse_dates idx v for kd v in deltas[column_name] iteritems }
def test_handshake_protocol_unsupported log message transport proto 'chat'message headers extend gen_ws_headers 'test' [0] with log 'aiohttp websocket' as ctx _ _ _ _ protocol do_handshake message method message headers transport protocols [proto] assert protocol is None assert ctx records[ -1 ] msg 'Clientprotocols%rdon\xe2\x80\x99toverlapserver-knownones%r'
def create_account directory_id email password givenName surname **kwargs items {'email' email 'password' password 'givenName' givenName 'surname' surname}items update **kwargs status result _query action 'directories' command '{0}/accounts' format directory_id data json dumps items header_dict {'Content-Type' 'application/json charset UTF-8'} method 'POST' comps result['href'] split '/' return show_account comps[ -1 ]
def gis_update_location_tree feature user_id None if user_id auth s3_impersonate user_id feature json loads feature path gis update_location_tree feature db commit return path
def gis_update_location_tree feature user_id None if user_id auth s3_impersonate user_id feature json loads feature path gis update_location_tree feature db commit return path
def _fill_defaults context builder sig args defaults ty sig return_typellty context get_data_type ty args tuple args + tuple ir Constant llty d for d in defaults[len args ] sig signature * ty * len args + 1 return sig args
def unicode_code code try if code isdigit return unichr int code else match unicode_pattern match code if match value match group 1 or match group 2 return unichr int value 16 else return codeexcept OverflowError as detail raise ValueError 'codetoolarge %s ' % detail
def _generateCategory filename 'simple csv' numSequences 2 elementsPerSeq 1 numRepeats 10 scriptDir os path dirname __file__ pathname os path join scriptDir 'datasets' filename print 'Creating%s ' % pathname fields [ 'classification' 'string' '' 'field1' 'string' '' ]outFile FileRecordStream pathname write True fields fields sequences []for i in range numSequences seq [x for x in range i * elementsPerSeq i + 1 * elementsPerSeq ]sequences append seq seqIdxs []for i in range numRepeats seqIdxs + range numSequences random shuffle seqIdxs for seqIdx in seqIdxs seq sequences[seqIdx]for x in seq outFile appendRecord [str seqIdx str x ] outFile close
def CurrentAuditLog now_sec rdfvalue RDFDatetime Now AsSecondsFromEpoch rollover config_lib CONFIG['Logging aff4_audit_log_rollover']current_log now_sec // rollover * rollover return ROOT_URN Add 'audit' Add 'logs' Add str current_log
def toint number if isinstance number float if number > 1 number round number 0 else number round math ceil number 0 return int number
def toint number if isinstance number float if number > 1 number round number 0 else number round math ceil number 0 return int number
def identify_landmark gcs_uri max_results 4 batch_request [{'image' {'source' {'gcs_image_uri' gcs_uri}} 'features' [{'type' 'LANDMARK_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service images annotate body {'requests' batch_request} response request execute return response['responses'][0] get 'landmarkAnnotations' None
def identify_landmark gcs_uri max_results 4 batch_request [{'image' {'source' {'gcs_image_uri' gcs_uri}} 'features' [{'type' 'LANDMARK_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service images annotate body {'requests' batch_request} response request execute return response['responses'][0] get 'landmarkAnnotations' None
@pytest mark django_dbdef test_save_store_fs_change_pootle_path_or_store po_directory tp0_store_fs fs_store tp0_store_fsstore fs_store storeother_path '/en/project0/other po'fs_store pootle_path other_pathwith pytest raises ValidationError fs_store save fs_store store Nonefs_store save assert fs_store store is None assert fs_store pootle_path other_path fs_store store storewith pytest raises ValidationError fs_store save fs_store pootle_path store pootle_pathfs_store save assert fs_store store store assert fs_store pootle_path store pootle_path
@pytest mark django_dbdef test_save_store_fs_change_pootle_path_or_store po_directory tp0_store_fs fs_store tp0_store_fsstore fs_store storeother_path '/en/project0/other po'fs_store pootle_path other_pathwith pytest raises ValidationError fs_store save fs_store store Nonefs_store save assert fs_store store is None assert fs_store pootle_path other_path fs_store store storewith pytest raises ValidationError fs_store save fs_store pootle_path store pootle_pathfs_store save assert fs_store store store assert fs_store pootle_path store pootle_path
@pytest mark django_dbdef test_save_store_fs_change_pootle_path_or_store po_directory tp0_store_fs fs_store tp0_store_fsstore fs_store storeother_path '/en/project0/other po'fs_store pootle_path other_pathwith pytest raises ValidationError fs_store save fs_store store Nonefs_store save assert fs_store store is None assert fs_store pootle_path other_path fs_store store storewith pytest raises ValidationError fs_store save fs_store pootle_path store pootle_pathfs_store save assert fs_store store store assert fs_store pootle_path store pootle_path
@register inclusion_tag u'breadcrumbs html' def feincms_breadcrumbs page include_self True ancs page get_ancestors bc [ anc get_absolute_url anc short_title for anc in ancs]if include_self bc append None page short_title return {u'trail' bc}
def _convert_to_example filename image_buffer label text height width colorspace 'RGB'channels 3image_format 'JPEG'example tf train Example features tf train Features feature {'image/height' _int64_feature height 'image/width' _int64_feature width 'image/colorspace' _bytes_feature tf compat as_bytes colorspace 'image/channels' _int64_feature channels 'image/class/label' _int64_feature label 'image/class/text' _bytes_feature tf compat as_bytes text 'image/format' _bytes_feature tf compat as_bytes image_format 'image/filename' _bytes_feature tf compat as_bytes os path basename filename 'image/encoded' _bytes_feature tf compat as_bytes image_buffer } return example
def create_addon name icon_type application **extra_kwargs kwargs {'status' STATUS_PUBLIC 'name' name 'slug' slugify name 'bayesian_rating' random uniform 1 5 'average_daily_users' random randint 200 2000 'weekly_downloads' random randint 200 2000 'created' datetime now 'last_updated' datetime now 'icon_type' icon_type}kwargs update extra_kwargs addon Addon objects create type ADDON_EXTENSION **kwargs generate_version addon addon app application addon update_version addon status STATUS_PUBLICaddon save return addon
def rundeck registry xml_parent data p XML SubElement xml_parent 'org jenkinsci plugins rundeck RundeckNotifier' mappings [ 'job-id' 'jobId' None 'options' 'options' '' 'node-filters' 'nodeFilters' '' 'tag' 'tag' '' 'wait-for-rundeck' 'shouldWaitForRundeckJob' False 'fail-the-build' 'shouldFailTheBuild' False ]helpers convert_mapping_to_xml p data mappings fail_required True
def rundeck registry xml_parent data p XML SubElement xml_parent 'org jenkinsci plugins rundeck RundeckNotifier' mappings [ 'job-id' 'jobId' None 'options' 'options' '' 'node-filters' 'nodeFilters' '' 'tag' 'tag' '' 'wait-for-rundeck' 'shouldWaitForRundeckJob' False 'fail-the-build' 'shouldFailTheBuild' False ]helpers convert_mapping_to_xml p data mappings fail_required True
def rundeck registry xml_parent data p XML SubElement xml_parent 'org jenkinsci plugins rundeck RundeckNotifier' mappings [ 'job-id' 'jobId' None 'options' 'options' '' 'node-filters' 'nodeFilters' '' 'tag' 'tag' '' 'wait-for-rundeck' 'shouldWaitForRundeckJob' False 'fail-the-build' 'shouldFailTheBuild' False ]helpers convert_mapping_to_xml p data mappings fail_required True
def write_file_list_cache opts data list_cache w_lock serial salt payload Serial opts with salt utils fopen list_cache 'w+b' as fp_ fp_ write serial dumps data _unlock_cache w_lock log trace 'Lockfile{0}removed' format w_lock
def _normalize_proj info _make_projector info['projs'] info get 'ch_names' info get 'names' info['bads'] include_active True inplace True
def _normalize_proj info _make_projector info['projs'] info get 'ch_names' info get 'names' info['bads'] include_active True inplace True
def GetRequestContext global _threadLocalContextreturn _threadLocalContext __dict__ setdefault 'reqCtx' StringDict
def get_bufsize iface if __grains__['kernel'] 'Linux' if os path exists '/sbin/ethtool' return _get_bufsize_linux iface return {}
def squeeze value return re sub '[\\x00-\\x20]+' '' value strip
def install p PollReactor from twisted internet main import installReactorinstallReactor p
def run_background_process cmd out_log None err_log None cwd None kwargs {'shell' True 'cwd' cwd}if out_log out_log_file open out_log 'w' kwargs['stdout'] out_log_fileif err_log err_log_file open err_log 'w' kwargs['stderr'] err_log_fileproc subprocess Popen cmd **kwargs def exit_handler "\nSendSIGINTtotheprocess'schildren Thisisimportant\nforrunningcommandsundercoverage ascoveragewillnot\nproducethecorrectartifactsifthechildprocessisn't\nkilledproperly \n"p1_group psutil Process proc pid child_pids p1_group get_children recursive True for child_pid in child_pids os kill child_pid pid signal SIGINT proc wait atexit register exit_handler
def address_ ret {}cmd 'hciconfig'out __salt__['cmd run'] cmd splitlines dev ''for line in out if line startswith 'hci' comps line split ' ' dev comps[0]ret[dev] {'device' dev 'path' '/sys/class/bluetooth/{0}' format dev }if 'BDAddress' in line comps line split ret[dev]['address'] comps[2]if 'DOWN' in line ret[dev]['power'] 'off'if 'UPRUNNING' in line ret[dev]['power'] 'on'return ret
def _zconfint_generic mean std_mean alpha alternative if alternative in ['two-sided' '2-sided' '2s'] zcrit stats norm ppf 1 - alpha / 2 0 lower mean - zcrit * std_mean upper mean + zcrit * std_mean elif alternative in ['larger' 'l'] zcrit stats norm ppf alpha lower mean + zcrit * std_mean upper np infelif alternative in ['smaller' 's'] zcrit stats norm ppf 1 - alpha lower - np inf upper mean + zcrit * std_mean else raise ValueError 'invalidalternative' return lower upper
def interp net layers for l in layers m k h w net params[l][0] data shapeif m k and k 1 print 'input+outputchannelsneedtobethesameor output 1'raiseif h w print 'filtersneedtobesquare'raisefilt upsample_filt h net params[l][0] data[range m range k ] filt
def formset *args **kw prefix kw pop 'prefix' 'form' total_count kw pop 'total_count' len args initial_count kw pop 'initial_count' len args data { prefix + '-TOTAL_FORMS' total_count prefix + '-INITIAL_FORMS' initial_count}for idx d in enumerate args data update '%s-%s-%s' % prefix idx k v for k v in d items data update kw return data
@register_specialize@gof local_optimizer [T mul] def local_mul_to_sqr node if node op T mul if len node inputs 2 if node inputs[0] is node inputs[1] return [T sqr node inputs[0] ]
@pytest mark django_dbdef test_get_path_obj rf po_directory default tp0 language_code tp0 language codeproject_code tp0 project codelanguage_code_fake 'faf'project_code_fake 'fake-tutorial'request rf get '/' request user defaultfunc get_path_obj lambda x y x y func request project_code project_code assert isinstance request ctx_obj Project with pytest raises Http404 func request project_code project_code_fake func request language_code language_code assert isinstance request ctx_obj Language with pytest raises Http404 func request language_code language_code_fake func request language_code language_code project_code project_code assert isinstance request ctx_obj TranslationProject with pytest raises Http404 func request language_code language_code_fake project_code project_code
def log_sum_exp input_tensor reduction_indices None keep_dims False input_tensor tf convert_to_tensor input_tensor dependencies [tf verify_tensor_all_finite input_tensor msg '' ]input_tensor control_flow_ops with_dependencies dependencies input_tensor x_max tf reduce_max input_tensor reduction_indices keep_dims True return tf squeeze x_max + tf log tf reduce_sum tf exp input_tensor - x_max reduction_indices keep_dims
def start_new_background_thread target args kwargs None if kwargs is None kwargs {}request system_service_pb StartBackgroundRequestRequest response system_service_pb StartBackgroundRequestResponse try apiproxy_stub_map MakeSyncCall 'system' 'StartBackgroundRequest' request response except apiproxy_errors ApplicationError as error raise ERROR_MAP[error application_error] error error_detail else return background EnqueueBackgroundThread response request_id target args kwargs
def _get_data x ch_idx if isinstance x BaseRaw return x[ch_idx][0]elif isinstance x Evoked return x data[ch_idx]
def __virtual__ if __grains__['kernel'] 'SunOS' and salt utils which 'profiles' return __virtualname__return False '{0}modulecanonlybeloadedonasolarislikesystem' format __virtualname__
def __virtual__ if __grains__['kernel'] 'SunOS' and salt utils which 'profiles' return __virtualname__return False '{0}modulecanonlybeloadedonasolarislikesystem' format __virtualname__
def plot_occlusion net X target square_length 7 figsize 9 None return _plot_heat_map net X figsize lambda net X n occlusion_heatmap net X target[n] square_length
def cleanup_files patterns dry_run False workdir ' ' current_dir Path workdir python_basedir Path Path sys executable dirname joinpath ' ' abspath error_message Noneerror_count 0for file_pattern in patterns for file_ in path_glob file_pattern current_dir if file_ abspath startswith python_basedir continueif dry_run print 'REMOVE %s dry-run ' % file_ else print 'REMOVE %s' % file_ try file_ remove_p except os error as e message '%s %s' % e __class__ __name__ e print message + 'basedir ' + python_basedir error_count + 1if not error_message error_message messageif False and error_message class CleanupError RuntimeError passraise CleanupError error_message
def _rfe_single_fit rfe estimator X y train test scorer X_train y_train _safe_split estimator X y train X_test y_test _safe_split estimator X y test train return rfe _fit X_train y_train lambda estimator features _score estimator X_test[ features] y_test scorer scores_
def lineage resource while resource is not None yield resource try resource resource __parent__except AttributeError resource None
def _RecAnnotate tree annotate_name annotate_value for child in tree children _RecAnnotate child annotate_name annotate_value if isinstance tree pytree Leaf cur_annotate pytree_utils GetNodeAnnotation tree annotate_name default 0 if cur_annotate < annotate_value pytree_utils SetNodeAnnotation tree annotate_name annotate_value
def _RecAnnotate tree annotate_name annotate_value for child in tree children _RecAnnotate child annotate_name annotate_value if isinstance tree pytree Leaf cur_annotate pytree_utils GetNodeAnnotation tree annotate_name default 0 if cur_annotate < annotate_value pytree_utils SetNodeAnnotation tree annotate_name annotate_value
def chain *brules def chain_brl expr if not brules yield expr return head tail brules[0] brules[1 ] for nexpr in head expr for nnexpr in chain *tail nexpr yield nnexpr return chain_brl
def unicodise_safe string encoding None return unicodise deunicodise string encoding encoding replace u'\ufffd' '?'
@dispatch object basestring list tuple def create_index t column_name_or_names name None raise NotImplementedError 'create_indexnotimplementedfortype%r' % type t __name__
def handle_errors errors format_error_func filename errors list sorted errors key str if not errors returnerror_msg u'\n' join format_error_func error for error in errors raise ConfigurationError u'TheComposefile{file_msg}isinvalidbecause \n{error_msg}' format file_msg u"'{}'" format filename if filename else u'' error_msg error_msg
def handle_errors errors format_error_func filename errors list sorted errors key str if not errors returnerror_msg u'\n' join format_error_func error for error in errors raise ConfigurationError u'TheComposefile{file_msg}isinvalidbecause \n{error_msg}' format file_msg u"'{}'" format filename if filename else u'' error_msg error_msg
def _validate_min_score min_score if min_score message _ '% min_score sisnotavalidgradepercentage' % {'min_score' min_score} try min_score int min_score except ValueError raise GatingValidationError message if min_score < 0 or min_score > 100 raise GatingValidationError message
def _read_pyc source pyc trace lambda x None try fp open pyc 'rb' except IOError return Nonewith fp try mtime int source mtime size source size data fp read 12 except EnvironmentError as e trace '_read_pyc %s EnvironmentError%s' % source e return Noneif len data 12 or data[ 4] imp get_magic or struct unpack '<ll' data[4 ] mtime size trace '_read_pyc %s invalidoroutofdatepyc' % source return Nonetry co marshal load fp except Exception as e trace '_read_pyc %s marshal loaderror%s' % source e return Noneif not isinstance co types CodeType trace '_read_pyc %s notacodeobject' % source return Nonereturn co
def _read_pyc source pyc trace lambda x None try fp open pyc 'rb' except IOError return Nonewith fp try mtime int source mtime size source size data fp read 12 except EnvironmentError as e trace '_read_pyc %s EnvironmentError%s' % source e return Noneif len data 12 or data[ 4] imp get_magic or struct unpack '<ll' data[4 ] mtime size trace '_read_pyc %s invalidoroutofdatepyc' % source return Nonetry co marshal load fp except Exception as e trace '_read_pyc %s marshal loaderror%s' % source e return Noneif not isinstance co types CodeType trace '_read_pyc %s notacodeobject' % source return Nonereturn co
def _find_predicates expr if not isinstance expr BooleanFunction return {expr}return set union * _find_predicates i for i in expr args
def _find_predicates expr if not isinstance expr BooleanFunction return {expr}return set union * _find_predicates i for i in expr args
def join_host_strings user host port None if port template '%s@[%s] %s' if host count ' ' > 1 else '%s@%s %s' return template % user host port else return '%s@%s' % user host
def join_host_strings user host port None if port template '%s@[%s] %s' if host count ' ' > 1 else '%s@%s %s' return template % user host port else return '%s@%s' % user host
def spawnd path args pidfile None daemonize no_close True pidfile pidfile _os execv path args
def get_course_date_blocks course user block_classes CourseEndDate CourseStartDate TodaysDate VerificationDeadlineDate VerifiedUpgradeDeadlineDate blocks cls course user for cls in block_classes def block_key_fn block "\nIftheblock'sdateisNone returnthemaximumdatetimeinorder\ntoforceittotheendofthelistofdisplayedblocks \n"if block date is None return datetime max replace tzinfo pytz UTC return block datereturn sorted b for b in blocks if b is_enabled key block_key_fn
def parse_graftpoints graftpoints grafts {}for l in graftpoints raw_graft l split None 1 commit raw_graft[0]if len raw_graft 2 parents raw_graft[1] split else parents []for sha in [commit] + parents check_hexsha sha 'Invalidgraftpoint' grafts[commit] parentsreturn grafts
@contextlib contextmanagerdef record_audio rate chunk buff queue Queue audio_interface pyaudio PyAudio audio_stream audio_interface open format pyaudio paInt16 channels 1 rate rate input True frames_per_buffer chunk stream_callback functools partial _fill_buffer buff yield _audio_data_generator buff audio_stream stop_stream audio_stream close buff put None audio_interface terminate
@contextlib contextmanagerdef record_audio rate chunk buff queue Queue audio_interface pyaudio PyAudio audio_stream audio_interface open format pyaudio paInt16 channels 1 rate rate input True frames_per_buffer chunk stream_callback functools partial _fill_buffer buff yield _audio_data_generator buff audio_stream stop_stream audio_stream close buff put None audio_interface terminate
def bind_row_anchor_column column_name def decorator method @functools wraps method def wrapper table row cell row cells[column_name]action_element cell find_element by By CSS_SELECTOR 'td %s>a' % NORMAL_COLUMN_CLASS return method table action_element row return wrapperreturn decorator
def getProcessResults cmd timeLimit 20 output ''startTime time time child pexpect spawn cmd timeout 10 child logfile sys stdoutwhile 1 try output + child read_nonblocking timeout timeLimit replace '\r' '' except pexpect EOF as e print str e breakexcept pexpect TIMEOUT as e print str e output + '\nProcessabortedbyFlashTestafter%sseconds \n' % timeLimit print child isalive child kill 9 breakendTime time time child close force True duration endTime - startTime exitStatus child exitstatusreturn output duration exitStatus
def _take_time iter secs album out []total_time 0 0for obj in iter length _length obj album if total_time + length < secs out append obj total_time + lengthreturn out
@bdd when bdd parsers parse 'Ispawnanewwindow' def invoke_with quteproc quteproc log_summary 'Createanewwindow' quteproc send_ipc [] target_arg 'window' quteproc wait_for category 'init' module 'app' function '_open_startpage' message 'Openingstartpage'
def preserve_torrent_directory albumpath from headphones import loggernew_folder os path join albumpath 'headphones-modified' encode headphones SYS_ENCODING 'replace' logger info "Copyingfilesto'headphones-modified'subfoldertopreservedownloadedfilesforseeding" try shutil copytree albumpath new_folder return new_folderexcept Exception as e logger warn 'Cannotcopy/movefilestotempfolder ' + new_folder decode headphones SYS_ENCODING 'replace' + ' Notcontinuing Error ' + str e return None
def download_api_data filename coord api_base projection s host path p q f urlparse api_base bbox coordinate_latlon_bbox coord projection path join path 'api/0 6/map?bbox % 6f % 6f % 6f % 6f' % bbox conn HTTPConnection host conn request 'GET' path headers {'Accept-Encoding' 'compress gzip'} resp conn getresponse assert resp status 200 resp status resp read if resp getheader 'Content-Encoding' 'gzip' disk open filename 'w' else raise Exception host path disk GzipFile filename 'w' bytes resp read disk write bytes disk close return len bytes / 1024 0
def top **kwargs url __opts__['cobbler url']user __opts__['cobbler user']password __opts__['cobbler password']minion_id kwargs['opts']['id']log info 'Queryingcobblerforinformationfor%r' minion_id try server salt ext six moves xmlrpc_client Server url allow_none True if user server login user password data server get_blended_data None minion_id except Exception log exception 'Couldnotconnecttocobbler ' return {}return {data['status'] data['mgmt_classes']}
def init_journalist is_admin False username crypto_util genrandomid user_pw crypto_util genrandomid user db Journalist username user_pw is_admin db db_session add user db db_session commit return user user_pw
def num_answers user return Answer objects filter creator user count
def keep_lazy_text func return keep_lazy str func
def pluralize num 0 text '' return '{ }{}{}' format num text 's'[ num 1 ]
def MultiArgMax x m x max return i for i v in enumerate x if v m
def check filenames select None ignore None if select and ignore raise ValueError 'Cannotpassbothselectandignore Theyaremutuallyexclusive ' elif select or ignore checked_codes select or set ErrorRegistry get_error_codes - set ignore else checked_codes Conventions pep257for filename in filenames log info 'Checkingfile%s ' filename try with tokenize_open filename as file source file read for error in PEP257Checker check_source source filename code getattr error 'code' None if code in checked_codes yield error except EnvironmentError AllError yield sys exc_info [1] except tk TokenError yield SyntaxError 'invalidsyntaxinfile%s' % filename
def check filenames select None ignore None if select and ignore raise ValueError 'Cannotpassbothselectandignore Theyaremutuallyexclusive ' elif select or ignore checked_codes select or set ErrorRegistry get_error_codes - set ignore else checked_codes Conventions pep257for filename in filenames log info 'Checkingfile%s ' filename try with tokenize_open filename as file source file read for error in PEP257Checker check_source source filename code getattr error 'code' None if code in checked_codes yield error except EnvironmentError AllError yield sys exc_info [1] except tk TokenError yield SyntaxError 'invalidsyntaxinfile%s' % filename
def nonzero_features data combine None if combine is None combine functools partial reduce numpy logical_and masks numpy asarray [subset sum axis 0 for subset in data] squeeze nz_feats combine masks nonzero [0]return nz_feats
def symmetric n for perm in variations list range n n yield Permutation perm
def install runas None installer 'https //raw githubusercontent com/rvm/rvm/master/binscripts/rvm-installer'ret __salt__['cmd run_all'] 'curl-Ls{installer} bash-sstable' format installer installer runas runas python_shell True if ret['retcode'] > 0 msg 'ErrorencounteredwhiledownloadingtheRVMinstaller'if ret['stderr'] msg + ' stderrfollows \n\n' + ret['stderr'] raise CommandExecutionError msg return True
def gci return gcf _gci
def insert_enterprise_fields request form_desc if not enterprise_enabled returnadd_data_sharing_consent_field request form_desc
def insert_enterprise_fields request form_desc if not enterprise_enabled returnadd_data_sharing_consent_field request form_desc
def message_url_path course_key access_point return RestrictedCourse message_url_path course_key access_point
def _credentials_from_request request if oauth2_settings storage_model is None or request user is_authenticated return get_storage request get else return None
def has_filename_filter module return getattr module 'filename' None is not None
def has_filename_filter module return getattr module 'filename' None is not None
def has_filename_filter module return getattr module 'filename' None is not None
def run_gevent from gevent import monkeymonkey patch_all
@_refresh_mine_cache@_ensure_existsdef kill name return _change_state name 'kill' 'stopped'
def libvlc_video_get_track p_mi f _Cfunctions get 'libvlc_video_get_track' None or _Cfunction 'libvlc_video_get_track' 1 None ctypes c_int MediaPlayer return f p_mi
def DiscreteUniform name items return rv name DiscreteUniformDistribution *items
def DiscreteUniform name items return rv name DiscreteUniformDistribution *items
def quotify_list words wordout []for word in words qtype qif word and not re search '[\\s\\"\\\']' word qtype ''elif q in word and qq not in word qtype qqwordout append quotify qtype word True return '' join wordout
def setup_platform hass config add_devices discover_info None from pycmus import exceptionshost config get CONF_HOST password config get CONF_PASSWORD port config get CONF_PORT name config get CONF_NAME try cmus_remote CmusDevice host password port name except exceptions InvalidPassword _LOGGER error 'Theprovidedpasswordwasrejectedbycmus' return Falseadd_devices [cmus_remote]
def _save_rev_and_notify rev_form creator document based_on_id None base_rev None new_rev rev_form save creator document based_on_id base_rev statsd incr 'wiki revision' ReviewableRevisionInLocaleEvent new_rev fire exclude new_rev creator EditDocumentEvent new_rev fire exclude new_rev creator
def _save_rev_and_notify rev_form creator document based_on_id None base_rev None new_rev rev_form save creator document based_on_id base_rev statsd incr 'wiki revision' ReviewableRevisionInLocaleEvent new_rev fire exclude new_rev creator EditDocumentEvent new_rev fire exclude new_rev creator
def dump data stream None **kwargs kwargs['Dumper'] AstropyDumperreturn yaml dump data stream stream **kwargs
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def auth_disallow_anonymous_access action @functools wraps action def wrapper context data_dict return action context data_dict wrapper auth_allow_anonymous_access Falsereturn wrapper
def is_valid_endpoint_url endpoint_url parts urlsplit endpoint_url hostname parts hostnameif hostname is None return Falseif len hostname > 255 return Falseif hostname[ -1 ] ' ' hostname hostname[ -1 ]allowed re compile '^ ? - [A-Z\\d-]{1 63} ?< - \\ * ? - [A-Z\\d-]{1 63} ?< - $' re IGNORECASE return allowed match hostname
def getGeometryUtilitiesPath subName '' return getJoinedPath getGeometryPath 'geometry_utilities' subName
def get_view_id_list user site check_global True use_cache True page_ids _get_page_ids_for_action user user site site action 'view_page' check_global check_global use_cache use_cache return page_ids
def ssl_wrap_socket sock utils validate_key_cert CONF key_file CONF cert_file ssl_kwargs {'server_side' True 'certfile' CONF cert_file 'keyfile' CONF key_file 'cert_reqs' ssl CERT_NONE}if CONF ca_file ssl_kwargs['ca_certs'] CONF ca_filessl_kwargs['cert_reqs'] ssl CERT_REQUIREDreturn ssl wrap_socket sock **ssl_kwargs
def status return _statuscmd
def _cleanup es elasticsearch Elasticsearch connection_class Urllib3HttpConnection host HOST port PORT http_auth HTTP_AUTH if es indices exists MARKER_INDEX es indices delete MARKER_INDEX if es indices exists INDEX es indices delete INDEX
def change_music new_music repeat False if music and new_music is not current_music if new_music new_playlist PlayList [new_music] repeat repeat else new_playlist Nonechange_playlist new_playlist
def metadef_tag_get context namespace_name name session None session session or get_session return metadef_tag_api get context namespace_name name session
def get_type atype size None res TYPE_DESCRIPTOR get atype if res is None if atype[0] 'L' if atype startswith 'Ljava/lang' res atype[1 -1 ] lstrip 'java/lang/' replace '/' ' ' else res atype[1 -1 ] replace '/' ' ' elif atype[0] '[' if size is None res '%s[]' % get_type atype[1 ] else res '%s[%s]' % get_type atype[1 ] size else res atypelogger debug 'Unknowndescriptor "%s" ' atype return res
@dispatch Join Sequence Sequence def compute_up t lhs rhs **kwargs if lhs rhs lhs rhs itertools tee lhs 2 on_left [t lhs fields index col for col in listpack t on_left ]on_right [t rhs fields index col for col in listpack t on_right ]left_default None if t how in 'right' 'outer' else toolz itertoolz no_default right_default None if t how in 'left' 'outer' else toolz itertoolz no_default pairs toolz join on_left lhs on_right rhs left_default left_default right_default right_default assemble pair_assemble t on_left on_right return map assemble pairs
@dispatch Join Sequence Sequence def compute_up t lhs rhs **kwargs if lhs rhs lhs rhs itertools tee lhs 2 on_left [t lhs fields index col for col in listpack t on_left ]on_right [t rhs fields index col for col in listpack t on_right ]left_default None if t how in 'right' 'outer' else toolz itertoolz no_default right_default None if t how in 'left' 'outer' else toolz itertoolz no_default pairs toolz join on_left lhs on_right rhs left_default left_default right_default right_default assemble pair_assemble t on_left on_right return map assemble pairs
def _fix_region region region region or '' lower return _ALIAS_TO_REGION get region or region
def regions from boto ec2containerservice layer1 import EC2ContainerServiceConnectionreturn get_regions 'ec2containerservice' connection_cls EC2ContainerServiceConnection
def getMemoryLimit return None
def cleanedUpGenericNetwork original_network network caffe_pb2 NetParameter network CopyFrom original_network for i layer in enumerate network layer if 'Data' in layer type assert layer type in ['Data'] 'Unsupporteddatalayertype%s' % layer type elif layer type 'Input' del network layer[i]elif layer type 'InnerProduct' assert layer inner_product_param HasField 'num_output' "Don'tleaveinner_product_param num_outputunsetforgenericnetworks layer%s " % layer name return network
def test_feature_finder_finds_all_feature_files_within_a_dir ff FeatureLoader cjoin files ff find_feature_files assert_equals sorted files sorted [cjoin '1st_feature_dir' 'one_more feature' cjoin '1st_feature_dir' 'some feature' cjoin '1st_feature_dir' 'more_features_here' 'another feature' cjoin '2nd_feature_dir' 'before_and_after_all feature' cjoin '2nd_feature_dir' 'with_defined_steps feature' cjoin '3rd_feature_dir' 'my_steps_are_anywhere feature' ]
def test_feature_finder_finds_all_feature_files_within_a_dir ff FeatureLoader cjoin files ff find_feature_files assert_equals sorted files sorted [cjoin '1st_feature_dir' 'one_more feature' cjoin '1st_feature_dir' 'some feature' cjoin '1st_feature_dir' 'more_features_here' 'another feature' cjoin '2nd_feature_dir' 'before_and_after_all feature' cjoin '2nd_feature_dir' 'with_defined_steps feature' cjoin '3rd_feature_dir' 'my_steps_are_anywhere feature' ]
def corr_nearest corr threshold 1e-15 n_fact 100 k_vars corr shape[0]if k_vars corr shape[1] raise ValueError 'matrixisnotsquare' diff np zeros corr shape x_new corr copy diag_idx np arange k_vars for ii in range int len corr * n_fact x_adj x_new - diff x_psd clipped clip_evals x_adj value threshold if not clipped x_new x_psdbreakdiff x_psd - x_adj x_new x_psd copy x_new[ diag_idx diag_idx ] 1else import warningswarnings warn iteration_limit_doc IterationLimitWarning return x_new
def serialize_query_with_map_builtin_function test serial fcn t symbol 't' discover iris expr t species map fcn 'int' query {'expr' to_tree expr }response test post '/compute' data serial dumps query headers mimetype serial assert 'OK' in response status respdata serial loads response data result serial data_loads respdata['data'] exp_res compute expr {t iris} return_type list return exp_res result
def serialize_query_with_map_builtin_function test serial fcn t symbol 't' discover iris expr t species map fcn 'int' query {'expr' to_tree expr }response test post '/compute' data serial dumps query headers mimetype serial assert 'OK' in response status respdata serial loads response data result serial data_loads respdata['data'] exp_res compute expr {t iris} return_type list return exp_res result
def serialize_query_with_map_builtin_function test serial fcn t symbol 't' discover iris expr t species map fcn 'int' query {'expr' to_tree expr }response test post '/compute' data serial dumps query headers mimetype serial assert 'OK' in response status respdata serial loads response data result serial data_loads respdata['data'] exp_res compute expr {t iris} return_type list return exp_res result
def get_signature signature_data try signature base64 decode_as_bytes signature_data except TypeError binascii Error raise exception SignatureVerificationError reason _ 'Thesignaturedatawasnotproperlyencodedusingbase64' return signature
def site request return {'site' Site objects get id settings SITE_ID }
def has_access f if hasattr f '_permission_name' permission_str f _permission_nameelse permission_str f __name__def wraps self *args **kwargs permission_str PERMISSION_PREFIX + f _permission_name if self appbuilder sm has_access permission_str self __class__ __name__ return f self *args **kwargs else log warning LOGMSG_ERR_SEC_ACCESS_DENIED format permission_str self __class__ __name__ flash as_unicode FLAMSG_ERR_SEC_ACCESS_DENIED 'danger' return redirect url_for self appbuilder sm auth_view __class__ __name__ + ' login' f _permission_name permission_strreturn functools update_wrapper wraps f
def YamlLoader string representation yaml load string result_cls aff4 FACTORY AFF4Object representation['aff4_class'] aff4_attributes {}for predicate values in representation['attributes'] items attribute aff4 Attribute PREDICATES[predicate]tmp aff4_attributes[attribute] []for rdfvalue_cls_name value age in values rdfvalue_cls aff4 FACTORY RDFValue rdfvalue_cls_name value rdfvalue_cls value age rdfvalue RDFDatetime age tmp append value result result_cls urn representation['_urn'] clone aff4_attributes mode 'rw' age representation['age_policy'] result new_attributes result synced_attributes result synced_attributes {} result _dirty Truereturn result
def YamlLoader string representation yaml load string result_cls aff4 FACTORY AFF4Object representation['aff4_class'] aff4_attributes {}for predicate values in representation['attributes'] items attribute aff4 Attribute PREDICATES[predicate]tmp aff4_attributes[attribute] []for rdfvalue_cls_name value age in values rdfvalue_cls aff4 FACTORY RDFValue rdfvalue_cls_name value rdfvalue_cls value age rdfvalue RDFDatetime age tmp append value result result_cls urn representation['_urn'] clone aff4_attributes mode 'rw' age representation['age_policy'] result new_attributes result synced_attributes result synced_attributes {} result _dirty Truereturn result
def download_and_extract URL if URL None logger warning 'PleaseprovideURL' return Nonetmpdir tempfile mkdtemp filename os path basename URL path tmpdir + '/' + filename zdata urllib2 urlopen URL print 'Savingfiletodiskpleasewait 'with open path 'wb' as local_file local_file write zdata read zfile zipfile ZipFile path print 'Extractingzipfile'try zfile extractall tmpdir except logger warning "Couldn'textractzipfile" return Nonereturn tmpdir
def reload_ jboss_config host None log debug ' MODULEFUNCTION jboss7 reload' if host is None operation ' reload'else operation '/host "{host}"/ reload' format host host reload_result __salt__['jboss7_cli run_operation'] jboss_config operation fail_on_error False if reload_result['success'] or not reload_result['success'] and 'Operationfailed Channelclosed' in reload_result['stdout'] or 'Communicationerror java util concurrent ExecutionException Operationfailed' in reload_result['stdout'] return reload_resultelse raise Exception "Cannothandleerror returncode {retcode} stdout '{stdout}' stderr '{stderr}'" format **reload_result
def make_flat_dict name selector None subselector None ns None if ns is None elemname nametagname Selector 0 else elemname '{%s}%s' % ns name tagname lambda obj do_raise False '{%s}%s' % ns obj[0] if selector is None selector nameroot TemplateElement elemname selector selector subselector subselector elem SubTemplateElement root tagname selector get_items elem text 1return root
def make_flat_dict name selector None subselector None ns None if ns is None elemname nametagname Selector 0 else elemname '{%s}%s' % ns name tagname lambda obj do_raise False '{%s}%s' % ns obj[0] if selector is None selector nameroot TemplateElement elemname selector selector subselector subselector elem SubTemplateElement root tagname selector get_items elem text 1return root
def put_acquire_memoryviewslice lhs_cname lhs_type lhs_pos rhs code have_gil False first_assignment True assert rhs type is_memoryviewslicepretty_rhs rhs result_in_temp or rhs is_simple if pretty_rhs rhstmp rhs result else rhstmp code funcstate allocate_temp lhs_type manage_ref False code putln '%s %s ' % rhstmp rhs result_as lhs_type put_assign_to_memviewslice lhs_cname rhs rhstmp lhs_type code have_gil have_gil first_assignment first_assignment if not pretty_rhs code funcstate release_temp rhstmp
def put_acquire_memoryviewslice lhs_cname lhs_type lhs_pos rhs code have_gil False first_assignment True assert rhs type is_memoryviewslicepretty_rhs rhs result_in_temp or rhs is_simple if pretty_rhs rhstmp rhs result else rhstmp code funcstate allocate_temp lhs_type manage_ref False code putln '%s %s ' % rhstmp rhs result_as lhs_type put_assign_to_memviewslice lhs_cname rhs rhstmp lhs_type code have_gil have_gil first_assignment first_assignment if not pretty_rhs code funcstate release_temp rhstmp
def put_acquire_memoryviewslice lhs_cname lhs_type lhs_pos rhs code have_gil False first_assignment True assert rhs type is_memoryviewslicepretty_rhs rhs result_in_temp or rhs is_simple if pretty_rhs rhstmp rhs result else rhstmp code funcstate allocate_temp lhs_type manage_ref False code putln '%s %s ' % rhstmp rhs result_as lhs_type put_assign_to_memviewslice lhs_cname rhs rhstmp lhs_type code have_gil have_gil first_assignment first_assignment if not pretty_rhs code funcstate release_temp rhstmp
def make_chunk_iter stream separator limit None buffer_size 10 * 1024 stream make_limited_stream stream limit _read stream read_split re compile ' %s ' % re escape separator splitbuffer []while 1 new_data _read buffer_size if not new_data breakchunks _split new_data new_buf []for item in chain buffer chunks if item separator yield '' join new_buf new_buf []else new_buf append item buffer new_bufif buffer yield '' join buffer
def _categories_level keys res []for i in zip *keys tuplefied _tuplify i res append list OrderedDict [ j None for j in tuplefied] return res
def _categories_level keys res []for i in zip *keys tuplefied _tuplify i res append list OrderedDict [ j None for j in tuplefied] return res
def gemset_copy source destination runas None return _rvm ['gemset' 'copy' source destination] runas runas
def find_unit course url def find node url '\nFindnodeincoursetreeforurl \n'if node location to_deprecated_string url return nodefor child in node get_children found find child url if found return foundreturn Noneunit find course url if unit is None raise DashboardError _ "Couldn'tfindmoduleforurl {0}" format url return unit
def find_unit course url def find node url '\nFindnodeincoursetreeforurl \n'if node location to_deprecated_string url return nodefor child in node get_children found find child url if found return foundreturn Noneunit find course url if unit is None raise DashboardError _ "Couldn'tfindmoduleforurl {0}" format url return unit
def build_product_order arg gens gens2idx {}for i g in enumerate gens gens2idx[g] iorder []for expr in arg name expr[0]var expr[1 ]def makelambda var return _ItemGetter gens2idx[g] for g in var order append monomial_key name makelambda var return ProductOrder *order
def toposort_rules rules graph {}class_dict {}for rule in rules if rule __class__ in class_dict raise ValueError 'Duplicateclassrulesarenotallowed %s' % rule __class__ class_dict[rule __class__] rulefor rule in rules if not is_iterable rule dependency and rule dependency rule_dependencies [rule dependency]else rule_dependencies rule dependencydependencies set if rule_dependencies for dependency in rule_dependencies if inspect isclass dependency dependency class_dict get dependency if dependency dependencies add dependency graph[rule] dependenciesreturn toposort graph
def requires_app_credentials func @wraps func def auth_wrapper self *args **kwargs client_id client_secret self session retrieve_client_credentials if client_id and client_secret return func self *args **kwargs else from exceptions import error_forr generate_fake_error_response '{"message" "Requiresusername/passwordauthentication"}' raise error_for r return auth_wrapper
def error_query msg q None if q is None q _NullQuery q error msgreturn q
def error_query msg q None if q is None q _NullQuery q error msgreturn q
def error_query msg q None if q is None q _NullQuery q error msgreturn q
@commands u'announce' @example u' announceSomeimportantmessagehere' def announce bot trigger if not trigger admin bot reply u"Sorry Ican'tletyoudothat" returnfor channel in bot channels bot msg channel u'[ANNOUNCEMENT]%s' % trigger group 2 bot reply u'Announcecomplete '
def find_folders_under root db add_root True follow_links False cancel_callback lambda False lp db library_pathif lp lp os path abspath lp root os path abspath root ans set [] for dirpath dirnames __ in os walk root topdown True followlinks follow_links if cancel_callback breakfor x in list dirnames path os path join dirpath x if lp and path startswith lp dirnames remove x if lp and dirpath startswith lp continueans add dirpath if not add_root ans remove root return ans
def zrange key start stop host None port None db None password None server _connect host port db password return server zrange key start stop
def zrange key start stop host None port None db None password None server _connect host port db password return server zrange key start stop
def extract_mentions txt return re findall u' ? [^\\w] ^ @ [\\w]* ' txt
def read_cz_lsm_info fh byteorder dtype count assert byteorder '<' magic_number structure_size struct unpack '<II' fh read 8 if magic_number not in 50350412 67127628 raise ValueError 'notavalidCS_LSM_INFOstructure' fh seek -8 1 if structure_size < numpy dtype CZ_LSM_INFO itemsize cz_lsm_info []size 0for name dtype in CZ_LSM_INFO size + numpy dtype dtype itemsizeif size > structure_size breakcz_lsm_info append name dtype else cz_lsm_info CZ_LSM_INFOreturn fh read_record cz_lsm_info byteorder byteorder
def fmin func x0 args xtol 0 0001 ftol 0 0001 maxiter None maxfun None full_output 0 disp 1 retall 0 callback None initial_simplex None opts {'xatol' xtol 'fatol' ftol 'maxiter' maxiter 'maxfev' maxfun 'disp' disp 'return_all' retall 'initial_simplex' initial_simplex}res _minimize_neldermead func x0 args callback callback **opts if full_output retlist res['x'] res['fun'] res['nit'] res['nfev'] res['status'] if retall retlist + res['allvecs'] return retlistelif retall return res['x'] res['allvecs'] else return res['x']
def print_environ_usage print '\n<H3>Theseenvironmentvariablescouldhavebeenset </H3>\n<UL>\n<LI>AUTH_TYPE\n<LI>CONTENT_LENGTH\n<LI>CONTENT_TYPE\n<LI>DATE_GMT\n<LI>DATE_LOCAL\n<LI>DOCUMENT_NAME\n<LI>DOCUMENT_ROOT\n<LI>DOCUMENT_URI\n<LI>GATEWAY_INTERFACE\n<LI>LAST_MODIFIED\n<LI>PATH\n<LI>PATH_INFO\n<LI>PATH_TRANSLATED\n<LI>QUERY_STRING\n<LI>REMOTE_ADDR\n<LI>REMOTE_HOST\n<LI>REMOTE_IDENT\n<LI>REMOTE_USER\n<LI>REQUEST_METHOD\n<LI>SCRIPT_NAME\n<LI>SERVER_NAME\n<LI>SERVER_PORT\n<LI>SERVER_PROTOCOL\n<LI>SERVER_ROOT\n<LI>SERVER_SOFTWARE\n</UL>\nInaddition HTTPheaderssentbytheservermaybepassedinthe\nenvironmentaswell Herearesomecommonvariablenames \n<UL>\n<LI>HTTP_ACCEPT\n<LI>HTTP_CONNECTION\n<LI>HTTP_HOST\n<LI>HTTP_PRAGMA\n<LI>HTTP_REFERER\n<LI>HTTP_USER_AGENT\n</UL>\n'
def create_lock name lock_path get_lock_path name if not check_lock lock_path return touch_file lock_path else return False
def create_lock name lock_path get_lock_path name if not check_lock lock_path return touch_file lock_path else return False
def setTexIfNoShaders obj if hasattr obj 'useShaders' and not obj useShaders if hasattr obj '_needTextureUpdate' obj _needTextureUpdate True
def setTexIfNoShaders obj if hasattr obj 'useShaders' and not obj useShaders if hasattr obj '_needTextureUpdate' obj _needTextureUpdate True
def setTexIfNoShaders obj if hasattr obj 'useShaders' and not obj useShaders if hasattr obj '_needTextureUpdate' obj _needTextureUpdate True
def slug_validator s ok SLUG_OK lower True spaces False delimiter '-' message validate_slug message code validate_slug code if not s and slugify s ok lower spaces delimiter s raise ValidationError message code code
def with_metaclass meta *bases class metaclass meta __call__ type __call____init__ type __init__def __new__ cls name this_bases d if this_bases is None return type __new__ cls name d return meta name bases d return metaclass 'temporary_class' None {}
def with_metaclass meta *bases class metaclass meta __call__ type __call____init__ type __init__def __new__ cls name this_bases d if this_bases is None return type __new__ cls name d return meta name bases d return metaclass 'temporary_class' None {}
def check_permission permission_codename request if request user is_superuser return Trueif permission_codename 'view' path_obj Noneif hasattr request 'translation_project' path_obj request translation_projectelif hasattr request 'project' path_obj request projectif path_obj is None return Truereturn path_obj is_accessible_by request user return 'administrate' in request permissions or permission_codename in request permissions
def train yaml_file_path save_path yaml open '{0}/gae_random yaml' format yaml_file_path 'r' read data os path join save_path 'train_preprocessed pkl' params {'save_path' save_path 'region' 13 'nvisX' 169 'nvisY' 169 'max_epochs' 3 'batch_size' 100 'train_data' data 'nfac' 196 'nmap' 50 'lr' 0 01}yaml yaml % params train_yaml yaml
def pack_shards used_images num_shards sorted_images sorted used_images key lambda x x[1] reverse True shards []for i in range 0 num_shards shards append {'images' [] 'sum' 0} for image in sorted_images shard min shards key lambda x x['sum'] shard['images'] append image shard['sum'] + image[1]return shards
def pack_shards used_images num_shards sorted_images sorted used_images key lambda x x[1] reverse True shards []for i in range 0 num_shards shards append {'images' [] 'sum' 0} for image in sorted_images shard min shards key lambda x x['sum'] shard['images'] append image shard['sum'] + image[1]return shards
def pack_shards used_images num_shards sorted_images sorted used_images key lambda x x[1] reverse True shards []for i in range 0 num_shards shards append {'images' [] 'sum' 0} for image in sorted_images shard min shards key lambda x x['sum'] shard['images'] append image shard['sum'] + image[1]return shards
def find_common_parent a b a_parents list a iterancestors b_parents list b iterancestors a_parents_set set a_parents b_parents_set set b_parents if a b return aif b in a_parents_set return bif a in b_parents_set return aif len a_parents < len b_parents for elem in a_parents if elem b or elem in b_parents_set return elemelse for elem in b_parents if elem a or elem in a_parents_set return elem
def testing_suite unittest_suite unittest TestSuite test_loader unittest TestLoader test_loader testMethodPrefix 'test_'tests [TestPSW]for test in tests cur_suite test_loader loadTestsFromTestCase test unittest_suite addTest cur_suite doctest_suite doctest DocTestSuite psw big_suite unittest TestSuite unittest_suite doctest_suite return big_suite
def get_disk_timeout scheme None return _get_powercfg_minute_values scheme 'SUB_DISK' 'DISKIDLE' 'Turnoffharddiskafter'
def notify doc print_html None print_format None attachments None recipients None cc None fetched_from_email_account False recipients cc get_recipients_and_cc doc recipients cc fetched_from_email_account fetched_from_email_account if not recipients returndoc emails_not_sent_to set doc all_email_addresses - set doc sent_email_addresses if frappe flags in_test doc _notify print_html print_html print_format print_format attachments attachments recipients recipients cc cc else check_email_limit list set doc sent_email_addresses enqueue sendmail queue u'default' timeout 300 event u'sendmail' communication_name doc name print_html print_html print_format print_format attachments attachments recipients recipients cc cc lang frappe local lang session frappe local session
def concat bags name 'concat-' + tokenize *bags counter itertools count 0 dsk dict name next counter key for bag in bags for key in sorted bag _keys return Bag merge dsk *[b dask for b in bags] name len dsk
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op cuda GpuElemwise assert topo[ -1 ] op cuda host_from_gpu
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op cuda GpuElemwise assert topo[ -1 ] op cuda host_from_gpu
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op cuda GpuElemwise assert topo[ -1 ] op cuda host_from_gpu
@pytest fixturedef mozilla_user db return amo tests user_factory id settings TASK_USER_ID
@pytest fixturedef mozilla_user db return amo tests user_factory id settings TASK_USER_ID
@core_helper@maintain deprecated 'h time_ago_in_words_from_strisdeprecatedin2 2andwillberemoved Pleaseuseh time_ago_from_timestampinstead' def time_ago_in_words_from_str date_str granularity 'month' if date_str return date time_ago_in_words date_str_to_datetime date_str granularity granularity else return _ 'Unknown'
def create_sample_bookstore store bookstore Bookstore shelf bookstore_pb2 Shelf shelf theme 'Fiction' _ fiction store create_shelf shelf book bookstore_pb2 Book book title 'README'book author 'NealStephenson'store create_book fiction book shelf bookstore_pb2 Shelf shelf theme 'Fantasy' _ fantasy store create_shelf shelf book bookstore_pb2 Book book title 'AGameofThrones'book author 'GeorgeR R Martin'store create_book fantasy book return store
def linereader f while 1 line f readline if not line break yield line[ -1 ]
def data_sharing_consent_requirement_at_login request if not enterprise_enabled return Noneif data_sharing_consent_required_at_login request return 'required'if data_sharing_consent_requested request return 'optional'return None
def _fix_list_encoding var if isinstance var list tuple return filter lambda x x is not None map _to_unicode var return var
def submit_facility_form context facility_form find_id_with_wait context 'facility_form' name_field find_id_with_wait context 'id_name' name_field send_keys 'TheFortressofSolitude' facility_form submit
def not26 func @wraps func def errfunc *args **kwargs raise NotImplementedErrorif hexversion < 34013184 return errfuncelse return func
def not26 func @wraps func def errfunc *args **kwargs raise NotImplementedErrorif hexversion < 34013184 return errfuncelse return func
def not26 func @wraps func def errfunc *args **kwargs raise NotImplementedErrorif hexversion < 34013184 return errfuncelse return func
def get_user_role user course_id if auth user_has_role user CourseInstructorRole course_id return 'instructor'else return 'staff'
def get_random_sequence length exclude None seen set def add_seen kmer seen add kmer seen add revcomp kmer if exclude is not None for pos in range 0 len exclude - K add_seen exclude[pos pos + K - 1 ] seq [random choice 'ACGT' for _ in range K - 1 ]add_seen '' join seq while len seq < length next_base random choice 'ACGT' next_kmer '' join seq[ - K + 2 ] + [next_base] assert len next_kmer K - 1 if next_kmer not in seen seq append next_base add_seen next_kmer else continuereturn '' join seq
def remove_whitespace tokens return [token for token in tokens if token type u'S' ]
def remove_whitespace tokens return [token for token in tokens if token type u'S' ]
def radio text u'' tooltip u'' checked None return _checkbox QtWidgets QRadioButton text tooltip checked
def row *args **kwargs responsive kwargs pop 'responsive' None sizing_mode kwargs pop 'sizing_mode' 'fixed' children kwargs pop 'children' None if responsive sizing_mode _convert_responsive responsive _verify_sizing_mode sizing_mode children _handle_children children children *args row_children []for item in children if isinstance item LayoutDOM item sizing_mode sizing_moderow_children append item else raise ValueError 'OnlyLayoutDOMitemscanbeinsertedintoarow \nTriedtoinsert %softype%s' % item type item return Row children row_children sizing_mode sizing_mode **kwargs
def _create_record_with_sa engine resource_type attributes sa_table db_utils get_table engine 'standardattributes' sa_record engine execute sa_table insert values {'resource_type' resource_type} attributes['standard_attr_id'] sa_record inserted_primary_key[0]resource_table db_utils get_table engine resource_type engine execute resource_table insert values attributes
def zero_mul_simp l index while index > 0 and index < len l - 1 and l[index][0] is l[ index + 1 ][0] exp l[index][1] + l[ index + 1 ][1] base l[index][0]l[index] base exp del l[ index + 1 ]if l[index][1] 0 del l[index]index - 1
def pearsonr x y x np asarray x y np asarray y n len x mx x mean my y mean xm ym x - mx y - my r_num np add reduce xm * ym r_den np sqrt _sum_of_squares xm * _sum_of_squares ym r r_num / r_den r max min r 1 0 -1 0 df n - 2 if abs r 1 0 prob 0 0else t_squared r ** 2 * df / 1 0 - r * 1 0 + r prob _betai 0 5 * df 0 5 df / df + t_squared return r prob
def split_line_endings data lines NEWLINE_RE split data if not lines[ -1 ] lines lines[ -1 ]return lines
def _extract_war_version war basename os path basename war war_package os path splitext basename [0]version re findall '- [\\d -]+ $' war_package return version[0] if version and len version 1 else None
def get_option file_name section option separator ' ' inifile _Ini get_ini_file file_name separator separator return inifile get section {} get option None
def check_for_external_modification fileName old_mtime new_modification_time get_last_modification fileName if new_modification_time > old_mtime return Truereturn False
def _GetCallingModule return _GetCallingModuleObjectAndName [1]
def process_queue queue quantity 1 backend 'sqlite' event salt utils event get_event 'master' __opts__['sock_dir'] __opts__['transport'] opts __opts__ listen False try items pop queue queue quantity quantity backend backend except SaltInvocationError as exc error_txt '{0}' format exc __jid_event__ fire_event {'errors' error_txt} 'progress' return Falsedata {'items' items 'backend' backend 'queue' queue}event fire_event data tagify [queue 'process'] prefix 'queue'
def process_queue queue quantity 1 backend 'sqlite' event salt utils event get_event 'master' __opts__['sock_dir'] __opts__['transport'] opts __opts__ listen False try items pop queue queue quantity quantity backend backend except SaltInvocationError as exc error_txt '{0}' format exc __jid_event__ fire_event {'errors' error_txt} 'progress' return Falsedata {'items' items 'backend' backend 'queue' queue}event fire_event data tagify [queue 'process'] prefix 'queue'
def get_selinux_context path out __salt__['cmd run'] ['ls' '-Z' path] python_shell False try ret re search '\\w+ \\w+ \\w+ \\w+' out group 0 except AttributeError ret 'Noselinuxcontextinformationisavailablefor{0}' format path return ret
def _read_uint16 f return np uint16 struct unpack '>H' f read 4 [2 4] [0]
def adam_consensus trees clades [tree root for tree in trees]return BaseTree Tree root _part clades rooted True
@pytest fixturedef numbered_po test_fs project0 tp TranslationProjectFactory project project0 language LanguageDBFactory store StoreDBFactory name 'numbered po' translation_project tp parent tp directory with test_fs open 'data/po/1234 po' as src store update store deserialize src read return store
def do_merge pr_url pr session response session put pr_url + '/merge' data json dumps dict sha pr['head']['sha'] if response status_code 200 print 'PRfailedtomerge {}' format response json ['message'] return Falseelse print '{}at{}' format response json ['message'] response json ['sha'] del_resp delete_branch pr session if del_resp status_code 204 print 'Branchdeletionfailed {}' format del_resp content return Falseprint 'Branchdeleted' return True
def do_merge pr_url pr session response session put pr_url + '/merge' data json dumps dict sha pr['head']['sha'] if response status_code 200 print 'PRfailedtomerge {}' format response json ['message'] return Falseelse print '{}at{}' format response json ['message'] response json ['sha'] del_resp delete_branch pr session if del_resp status_code 204 print 'Branchdeletionfailed {}' format del_resp content return Falseprint 'Branchdeleted' return True
def do_merge pr_url pr session response session put pr_url + '/merge' data json dumps dict sha pr['head']['sha'] if response status_code 200 print 'PRfailedtomerge {}' format response json ['message'] return Falseelse print '{}at{}' format response json ['message'] response json ['sha'] del_resp delete_branch pr session if del_resp status_code 204 print 'Branchdeletionfailed {}' format del_resp content return Falseprint 'Branchdeleted' return True
def _psed text before after limit flags atext textif limit limit re compile limit comps text split limit atext '' join comps[1 ] count 1if 'g' in flags count 0flags flags replace 'g' '' aflags 0for flag in flags aflags RE_FLAG_TABLE[flag]before re compile before flags aflags text re sub before after atext count count return text
def yield_fixture scope 'function' params None autouse False ids None name None if callable scope and params is None and not autouse return FixtureFunctionMarker 'function' params autouse ids ids name name scope else return FixtureFunctionMarker scope params autouse ids ids name name
def dirents buf d []while buf try ent linux_dirent buf except ValueError breakd append ent d_name buf buf[len ent ]return sorted d
def randslice_from_slicelen slicelen listlen maxstart listlen - slicelen start randrange maxstart + 1 maxstep listlen - start // slicelen if slicelen else 1 step randrange 1 maxstep + 1 stop start + slicelen * step s slice start stop step _ _ _ control slice_indices s listlen if control slicelen raise RuntimeErrorreturn s
def get_group_info_for_cohort cohort use_cached False request_cache RequestCache get_request_cache cache_key u'cohorts get_group_info_for_cohort {}' format cohort id if use_cached and cache_key in request_cache data return request_cache data[cache_key]request_cache data pop cache_key None try partition_group CourseUserGroupPartitionGroup objects get course_user_group cohort return request_cache data setdefault cache_key partition_group group_id partition_group partition_id except CourseUserGroupPartitionGroup DoesNotExist passreturn request_cache data setdefault cache_key None None
def clean_path root path subdir False if not os path isabs root return ''if not os path isabs path path os path join root path path os path normpath path if subdir if path startswith root return pathelif os path dirname path os path normpath root return pathreturn ''
def clean_path root path subdir False if not os path isabs root return ''if not os path isabs path path os path join root path path os path normpath path if subdir if path startswith root return pathelif os path dirname path os path normpath root return pathreturn ''
def change_smb_enum_shares table if not table return tableresult {}for field in ['account_used' 'note'] if field in table result[field] table pop field result['shares'] []for key value in table iteritems value update {'Share' key} result['shares'] append value return result
def write_descriptor_js output_root return _write_js output_root _list_descriptors
def encode_multipart values boundary None charset 'utf-8' stream length boundary stream_encode_multipart values use_tempfile False boundary boundary charset charset return boundary stream read
def celery_settings request capital re compile '^[A-Z]' settings [key for key in dir current_app conf if capital match key ]sorted_settings [{'key' key 'value' '*****' if 'password' in key lower else getattr current_app conf key } for key in sorted settings ]return render_to_response 'kadmin/settings html' {'settings' sorted_settings 'title' 'CelerySettings'} RequestContext request {}
def test_transform_path_pri frame_transform_graph invalidate_cache tpath td frame_transform_graph find_shortest_path ICRS Galactic assert tpath [ICRS FK5 Galactic] assert td 2 tpath td frame_transform_graph find_shortest_path FK4 Galactic assert tpath [FK4 FK4NoETerms Galactic] assert td 2
def RANGE value if u' ' in value start stop value split u' ' 1 start UINT start if stop strip stop UINT stop if start > stop raise ValueError u'Endmustbelargerthanstart' else stop Noneelse start UINT value stop start + 1 return slice start stop
def test_inverse np random seed 3285 for link in Links for k in range 10 p np random uniform 0 1 d link inverse link p assert_allclose d p atol 1e-08 err_msg str link z get_domainvalue link d link link inverse z assert_allclose d z atol 1e-08 err_msg str link
def _contains_cycle fgraph orderings outputs fgraph outputsassert isinstance outputs tuple list deque parent_counts {}node_to_children {}visitable deque for var in fgraph variables owner var ownerif owner node_to_children setdefault owner [] append var parent_counts[var] 1else visitable append var parent_counts[var] 0for a_n in fgraph apply_nodes parents list a_n inputs parents extend orderings get a_n [] if parents for parent in parents node_to_children setdefault parent [] append a_n parent_counts[a_n] len parents else visitable append a_n parent_counts[a_n] 0visited 0while visitable node visitable popleft visited + 1for client in node_to_children get node [] parent_counts[client] - 1if not parent_counts[client] visitable append client return visited len parent_counts
def _contains_cycle fgraph orderings outputs fgraph outputsassert isinstance outputs tuple list deque parent_counts {}node_to_children {}visitable deque for var in fgraph variables owner var ownerif owner node_to_children setdefault owner [] append var parent_counts[var] 1else visitable append var parent_counts[var] 0for a_n in fgraph apply_nodes parents list a_n inputs parents extend orderings get a_n [] if parents for parent in parents node_to_children setdefault parent [] append a_n parent_counts[a_n] len parents else visitable append a_n parent_counts[a_n] 0visited 0while visitable node visitable popleft visited + 1for client in node_to_children get node [] parent_counts[client] - 1if not parent_counts[client] visitable append client return visited len parent_counts
def _contains_cycle fgraph orderings outputs fgraph outputsassert isinstance outputs tuple list deque parent_counts {}node_to_children {}visitable deque for var in fgraph variables owner var ownerif owner node_to_children setdefault owner [] append var parent_counts[var] 1else visitable append var parent_counts[var] 0for a_n in fgraph apply_nodes parents list a_n inputs parents extend orderings get a_n [] if parents for parent in parents node_to_children setdefault parent [] append a_n parent_counts[a_n] len parents else visitable append a_n parent_counts[a_n] 0visited 0while visitable node visitable popleft visited + 1for client in node_to_children get node [] parent_counts[client] - 1if not parent_counts[client] visitable append client return visited len parent_counts
def get_jid jid options _get_options ret None _response _request 'GET' options['url'] + options['db'] + '/' + jid if 'error' in _response log error 'UnabletogetJID"{0}" "{1}"' format jid _response return {}return {_response['id'] _response}
@pytest mark hasgpudef test_hist nbin_offset_dim_dtype_inp backend_pair nbins offset dim dtype name inp_gen nbin_offset_dim_dtype_inpgpuflag check_gpu get_compute_capability 0 > 3 0 if gpuflag is False raise RuntimeError 'DevicedoesnothaveCUDAcomputecapability3 0orgreater' ng nc backend_pairng set_hist_buffers nbins offset nc set_hist_buffers nbins offset np_inp inp_gen dim astype dtype np_hist ref_hist np_inp nbins nbins offset offset for be in [ng nc] be_inp be array np_inp dtype dtype be_hist be_inp hist name assert tensors_allclose np_hist be_hist
def test_options_from_venv_config script virtualenv from pip locations import config_basenameconf '[global]\nno-index true'ini virtualenv location / config_basename with open ini 'w' as f f write conf result script pip 'install' '-vvv' 'INITools' expect_error True assert 'Ignoringindexes ' in result stdout str result assert 'DistributionNotFound NomatchingdistributionfoundforINITools' in result stdout
def _computeDigestResponse auth_map password method 'GET' A1 None **kwargs params auth_mapalgorithm params get 'algorithm' MD5 H DIGEST_AUTH_ENCODERS[algorithm]KD lambda secret data H secret + ' ' + data qop params get 'qop' None H_A2 H _A2 params method kwargs if algorithm MD5_SESS and A1 is not None H_A1 H A1 else H_A1 H _A1 params password if qop in 'auth' 'auth-int' request '%s %s %s %s %s' % params['nonce'] params['nc'] params['cnonce'] params['qop'] H_A2 elif qop is None request '%s %s' % params['nonce'] H_A2 return KD H_A1 request
def _computeDigestResponse auth_map password method 'GET' A1 None **kwargs params auth_mapalgorithm params get 'algorithm' MD5 H DIGEST_AUTH_ENCODERS[algorithm]KD lambda secret data H secret + ' ' + data qop params get 'qop' None H_A2 H _A2 params method kwargs if algorithm MD5_SESS and A1 is not None H_A1 H A1 else H_A1 H _A1 params password if qop in 'auth' 'auth-int' request '%s %s %s %s %s' % params['nonce'] params['nc'] params['cnonce'] params['qop'] H_A2 elif qop is None request '%s %s' % params['nonce'] H_A2 return KD H_A1 request
def get_default_persistent_db_instance return get_default_temp_db_instance
def get_default_persistent_db_instance return get_default_temp_db_instance
def getKeyMap myMap 'wsrep_last_committed' 'wsrep_replicated' 'wsrep_repl_keys' 'wsrep_local_commits' 'wsrep_received' 'wsrep_local_send_queue_avg' 'wsrep_local_recv_queue_avg' return myMap
def getKeyMap myMap 'wsrep_last_committed' 'wsrep_replicated' 'wsrep_repl_keys' 'wsrep_local_commits' 'wsrep_received' 'wsrep_local_send_queue_avg' 'wsrep_local_recv_queue_avg' return myMap
def getKeyMap myMap 'wsrep_last_committed' 'wsrep_replicated' 'wsrep_repl_keys' 'wsrep_local_commits' 'wsrep_received' 'wsrep_local_send_queue_avg' 'wsrep_local_recv_queue_avg' return myMap
def test_file class FakeResponse object passlogo_path os path join BASE_DIRECTORY 'artwork' 'logo png' fake_response FakeResponse assert hasattr hug output_format file logo_path fake_response 'read' assert fake_response content_type 'image/png' with open logo_path 'rb' as image_file hasattr hug output_format file image_file fake_response 'read' assert not hasattr hug output_format file 'NONEXISTENTFILE' fake_response 'read'
def batch_norm_dnn layer **kwargs nonlinearity getattr layer 'nonlinearity' None if nonlinearity is not None layer nonlinearity nonlinearities identityif hasattr layer 'b' and layer b is not None del layer params[layer b]layer b Nonebn_name kwargs pop 'name' None or getattr layer 'name' None and layer name + '_bn' layer BatchNormDNNLayer layer name bn_name **kwargs if nonlinearity is not None from special import NonlinearityLayernonlin_name bn_name and bn_name + '_nonlin' layer NonlinearityLayer layer nonlinearity name nonlin_name return layer
def get_func_list stats sel_list if stats fcn_list list stats fcn_list[ ]order_message 'Orderedby ' + stats sort_type else list stats stats keys order_message 'Randomlistingorderwasused'select_message ''for selection in sel_list list select_message stats eval_print_amount selection list select_message return list order_message select_message
def get_func_list stats sel_list if stats fcn_list list stats fcn_list[ ]order_message 'Orderedby ' + stats sort_type else list stats stats keys order_message 'Randomlistingorderwasused'select_message ''for selection in sel_list list select_message stats eval_print_amount selection list select_message return list order_message select_message
def cyclen n iterable return chain from_iterable repeat tuple iterable n
def cyclen n iterable return chain from_iterable repeat tuple iterable n
def _mask_non_positives a mask a < 0 0 if mask any return ma MaskedArray a mask mask return a
def _mask_non_positives a mask a < 0 0 if mask any return ma MaskedArray a mask mask return a
def isarray a try validity isinstance a ndarray except validity Falsereturn validity
def encode data marker passphrase None randfunc None if randfunc is None randfunc get_random_bytesout '-----BEGIN%s-----\n' % marker if passphrase salt randfunc 8 key PBKDF1 passphrase salt 16 1 MD5 key + PBKDF1 key + passphrase salt 8 1 MD5 objenc DES3 new key DES3 MODE_CBC salt out + 'Proc-Type 4 ENCRYPTED\nDEK-Info DES-EDE3-CBC %s\n\n' % tostr hexlify salt upper data objenc encrypt pad data objenc block_size chunks [tostr b2a_base64 data[i i + 48 ] for i in range 0 len data 48 ]out + '' join chunks out + '-----END%s-----' % marker return out
def is_sphinx_markup docstring return '`' in docstring or ' ' in docstring
def setup options **kwargs params dict kwargs params update level options log_level logging basicConfig **params
def findLocalPort ports retVal Nonefor port in ports try try s socket _orig_socket socket AF_INET socket SOCK_STREAM except AttributeError s socket socket socket AF_INET socket SOCK_STREAM s connect LOCALHOST port retVal portbreakexcept socket error passfinally try s close except socket error passreturn retVal
def add_credential username password proxy T411Proxy is_new proxy add_credential username username password password if is_new console u'Credentialsuccessfullyadded' else console u'Credentialsuccessfullyupdated'
def _os_bootstrap names sys builtin_module_namesjoin Noneif 'posix' in names sep '/'from posix import statelif 'nt' in names sep '\\'from nt import statelif 'dos' in names sep '\\'from dos import statelif 'os2' in names sep '\\'from os2 import statelse raise ImportError 'noosspecificmodulefound'if join is None def join a b sep sep if a '' return blastchar a[ -1 ]if lastchar '/' or lastchar sep return a + b return a + sep + b global _os_stat_os_stat statglobal _os_path_join_os_path_join join
def get_all_sharing_strategies return _all_sharing_strategies
def get_all_sharing_strategies return _all_sharing_strategies
def pci_device_get_by_addr context node_id dev_addr return IMPL pci_device_get_by_addr context node_id dev_addr
def test_download_wheel script data result script pip 'download' '--no-index' '-f' data packages '-d' ' ' 'meta' assert Path 'scratch' / 'meta-1 0-py2 py3-none-any whl' in result files_created assert script site_packages / 'piptestpackage' not in result files_created
def weekend_to_monday dt if dt weekday 6 return dt + timedelta 1 elif dt weekday 5 return dt + timedelta 2 return dt
def _check_reg_match sss_py sss_mf comp_tol info_py sss_py info['proc_history'][0]['max_info']['sss_info']assert_true info_py is not None assert_true len info_py > 0 info_mf sss_mf info['proc_history'][0]['max_info']['sss_info']n_in Nonefor inf in info_py info_mf if n_in is None n_in _get_n_moments inf['in_order'] else assert_equal n_in _get_n_moments inf['in_order'] assert_equal inf['components'][ n_in] sum inf['nfree'] assert_allclose info_py['nfree'] info_mf['nfree'] atol comp_tol err_msg sss_py _filenames[0]
def application_init args update False setup_environment process_args args app new_application args model new_model app args repo prompt args prompt settings args settings if update model update_status cfg gitcfg current return ApplicationContext args app cfg model
def application_init args update False setup_environment process_args args app new_application args model new_model app args repo prompt args prompt settings args settings if update model update_status cfg gitcfg current return ApplicationContext args app cfg model
def test_get_debug_values_exc prev_value config compute_test_valuetry config compute_test_value 'raise'x T vector try for x_val in op get_debug_values x assert Falseraised Falseexcept AttributeError raised Trueassert raisedfinally config compute_test_value prev_value
def test_get_debug_values_exc prev_value config compute_test_valuetry config compute_test_value 'raise'x T vector try for x_val in op get_debug_values x assert Falseraised Falseexcept AttributeError raised Trueassert raisedfinally config compute_test_value prev_value
def test_get_debug_values_exc prev_value config compute_test_valuetry config compute_test_value 'raise'x T vector try for x_val in op get_debug_values x assert Falseraised Falseexcept AttributeError raised Trueassert raisedfinally config compute_test_value prev_value
def test_get_debug_values_exc prev_value config compute_test_valuetry config compute_test_value 'raise'x T vector try for x_val in op get_debug_values x assert Falseraised Falseexcept AttributeError raised Trueassert raisedfinally config compute_test_value prev_value
def _dataset_version path name ver_fname op join path 'version txt' if op exists ver_fname with open ver_fname 'r' as fid version fid readline strip else version '0 3' if name 'sample' else '0 7' return version
def parse_xmlsec_output output for line in output split '\n' if line 'OK' return Trueelif line 'FAIL' raise XmlsecError output raise XmlsecError output
def vb_stop_vm name None timeout 10000 **kwargs vbox vb_get_box machine vbox findMachine name log info 'Stoppingmachine%s' name session _virtualboxManager openMachineSession machine try console session consoleprogress console powerDown progress waitForCompletion timeout finally _virtualboxManager closeMachineSession session vb_wait_for_session_state session log info 'Stoppedmachine%sisnow%s' name vb_machinestate_to_str machine state return vb_xpcom_to_attribute_dict machine 'IMachine'
def getFourSignificantFigures number if number None return NoneabsoluteNumber abs number if absoluteNumber > 100 0 return getRoundedToPlacesString 2 number if absoluteNumber < 1e-09 return getRoundedToPlacesString 13 number return getRoundedToPlacesString 3 - math floor math log10 absoluteNumber number
def getFourSignificantFigures number if number None return NoneabsoluteNumber abs number if absoluteNumber > 100 0 return getRoundedToPlacesString 2 number if absoluteNumber < 1e-09 return getRoundedToPlacesString 13 number return getRoundedToPlacesString 3 - math floor math log10 absoluteNumber number
@skip_if_not_win32@with_environmentdef test_get_home_dir_8 os name 'nt'for key in ['HOME' 'HOMESHARE' 'HOMEDRIVE' 'HOMEPATH' 'USERPROFILE'] env pop key None class key def Close self passwith patch object wreg 'OpenKey' return_value key with patch object wreg 'QueryValueEx' return_value [abspath HOME_TEST_DIR ] home_dir path get_home_dir nt assert_equal home_dir abspath HOME_TEST_DIR
def GenerateOutput target_list target_dicts data params if params['options'] generator_output raise NotImplementedError '--generator_outputnotimplementedforeclipse' user_config params get 'generator_flags' {} get 'config' None if user_config GenerateOutputForConfig target_list target_dicts data params user_config else config_names target_dicts[target_list[0]]['configurations'] keys for config_name in config_names GenerateOutputForConfig target_list target_dicts data params config_name
def get_arch run_function run arch run_function '/bin/uname-m' stdout rstrip if re match 'i\\d86$' arch arch 'i386'return arch
def _plot_option_logic plot_options_from_call_signature default_plot_options copy deepcopy DEFAULT_PLOT_OPTIONS file_options tools get_config_file session_options session get_session_plot_options plot_options_from_call_signature copy deepcopy plot_options_from_call_signature for option_set in [plot_options_from_call_signature session_options file_options] utils validate_world_readable_and_sharing_settings option_set utils set_sharing_and_world_readable option_set if 'filename' in option_set and 'fileopt' not in option_set option_set['fileopt'] 'overwrite'user_plot_options {}user_plot_options update default_plot_options user_plot_options update file_options user_plot_options update session_options user_plot_options update plot_options_from_call_signature user_plot_options {k v for k v in user_plot_options items if k in default_plot_options }return user_plot_options
def _plot_option_logic plot_options_from_call_signature default_plot_options copy deepcopy DEFAULT_PLOT_OPTIONS file_options tools get_config_file session_options session get_session_plot_options plot_options_from_call_signature copy deepcopy plot_options_from_call_signature for option_set in [plot_options_from_call_signature session_options file_options] utils validate_world_readable_and_sharing_settings option_set utils set_sharing_and_world_readable option_set if 'filename' in option_set and 'fileopt' not in option_set option_set['fileopt'] 'overwrite'user_plot_options {}user_plot_options update default_plot_options user_plot_options update file_options user_plot_options update session_options user_plot_options update plot_options_from_call_signature user_plot_options {k v for k v in user_plot_options items if k in default_plot_options }return user_plot_options
def update_hash_dict filehash filename try with open file_path + '/hash_dict pickle' 'rb' as f hash_dict cPickle load f except IOError hash_dict {}hash_dict update {filename filehash} with open os path join file_path 'hash_dict pickle' 'wb' as f cPickle dump hash_dict f
def _manageRoles mo firstHalf mo group 1 secondHalf mo group 2 newRoles []roles secondHalf split '/' for role in roles role role strip if not role continueroleID analyze_imdbid role if roleID is None roleID u'/'else roleID + u'/'newRoles append u'<divclass "_imdbpyrole"roleid "%s">%s</div>' % roleID role strip return firstHalf + u'/' join newRoles + mo group 3
def _manageRoles mo firstHalf mo group 1 secondHalf mo group 2 newRoles []roles secondHalf split '/' for role in roles role role strip if not role continueroleID analyze_imdbid role if roleID is None roleID u'/'else roleID + u'/'newRoles append u'<divclass "_imdbpyrole"roleid "%s">%s</div>' % roleID role strip return firstHalf + u'/' join newRoles + mo group 3
def list_option option opt value parser if value lower 'true' dest Trueelse dest [s for s in value split ' ' ]setattr parser values option dest dest
def list_option option opt value parser if value lower 'true' dest Trueelse dest [s for s in value split ' ' ]setattr parser values option dest dest
def render hjson_data saltenv 'base' sls '' **kws if not isinstance hjson_data string_types hjson_data hjson_data read if hjson_data startswith '# ' hjson_data hjson_data[ hjson_data find '\n' + 1 ]if not hjson_data strip return {}return hjson loads hjson_data
def test_scenarios_parsed_by_feature_has_feature feature Feature from_string FEATURE2 for scenario in feature scenarios assert_equals scenario feature feature
def test_scenarios_parsed_by_feature_has_feature feature Feature from_string FEATURE2 for scenario in feature scenarios assert_equals scenario feature feature
def _validate_keys key_file ret {}linere re compile '^ *? \\s? ? ssh\\- ecds [\\w-]+\\s + $' try with salt utils fopen key_file 'r' as _fh for line in _fh if line startswith '#' continuesearch re search linere line if not search continueopts search group 1 comps search group 2 split if len comps < 2 continueif opts options opts split ' ' else options []enc comps[0]key comps[1]comment '' join comps[2 ] fingerprint _fingerprint key if fingerprint is None continueret[key] {'enc' enc 'comment' comment 'options' options 'fingerprint' fingerprint}except IOError OSError raise CommandExecutionError 'Problemreadingsshkeyfile{0}' format key_file return ret
@contextmanagerdef pushd path cwd os getcwd os chdir os path abspath path try yield finally os chdir cwd
@contextmanagerdef pushd path cwd os getcwd os chdir os path abspath path try yield finally os chdir cwd
def date year None month None day None obj False today dt datetime utcnow if year is None year today yearif month is None month today monthif day is None day today dayvalue dt date year month day if obj return valuereturn format_date value
def getall return _load copy
def getall return _load copy
def oo_haproxy_backend_masters hosts port servers []for idx host_info in enumerate hosts server dict name 'master%s' % idx server_ip host_info['openshift']['common']['ip']server['address'] '%s %s' % server_ip port server['opts'] 'check'servers append server return servers
def _fix_up_private_attr clsname spec out OrderedDict for k v in spec items if k startswith '__' and not k endswith '__' k '_' + clsname + k out[k] vreturn out
def test_grouped_item_access T1 for masked in False True t1 Table T1 masked masked tg t1 group_by 'a' tgs tg[ 'a' 'c' 'd' ]assert np all tgs groups keys tg groups keys assert np all tgs groups indices tg groups indices tgsa tgs groups aggregate np sum assert tgsa pformat ['acd' '----------' '00 04' '16 018' '222 06'] tgs tg[ 'c' 'd' ]assert np all tgs groups keys tg groups keys assert np all tgs groups indices tg groups indices tgsa tgs groups aggregate np sum assert tgsa pformat ['cd' '-------' '0 04' '6 018' '22 06']
def test_grouped_item_access T1 for masked in False True t1 Table T1 masked masked tg t1 group_by 'a' tgs tg[ 'a' 'c' 'd' ]assert np all tgs groups keys tg groups keys assert np all tgs groups indices tg groups indices tgsa tgs groups aggregate np sum assert tgsa pformat ['acd' '----------' '00 04' '16 018' '222 06'] tgs tg[ 'c' 'd' ]assert np all tgs groups keys tg groups keys assert np all tgs groups indices tg groups indices tgsa tgs groups aggregate np sum assert tgsa pformat ['cd' '-------' '0 04' '6 018' '22 06']
def dict_dir obj ns {}for key in dir2 obj try ns[key] getattr obj key except AttributeError passreturn ns
def elu x alpha 1 return tensor switch x > 0 x alpha * tensor exp x - 1
def _csrtodok csr smat {} A JA IA shape csrfor i in range len IA - 1 indices slice IA[i] IA[ i + 1 ] for l m in zip A[indices] JA[indices] smat[ i m ] lreturn SparseMatrix * shape + [smat]
def _csrtodok csr smat {} A JA IA shape csrfor i in range len IA - 1 indices slice IA[i] IA[ i + 1 ] for l m in zip A[indices] JA[indices] smat[ i m ] lreturn SparseMatrix * shape + [smat]
def _has_catalog_visibility course visibility_type return ACCESS_GRANTED if course catalog_visibility visibility_type else ACCESS_DENIED
def selRandom individuals k return [random choice individuals for i in xrange k ]
def selRandom individuals k return [random choice individuals for i in xrange k ]
def ensure_local_plotly_files if check_file_permissions for fn in [CREDENTIALS_FILE CONFIG_FILE] utils ensure_file_exists fn contents utils load_json_dict fn for key val in list FILE_CONTENT[fn] items if key not in contents contents[key] valcontents_keys list contents keys for key in contents_keys if key not in FILE_CONTENT[fn] del contents[key]utils save_json_dict fn contents else warnings warn "Lookslikeyoudon'thave'read-write'permissiontoyour'home' '~' directoryortoour'~/ plotly'directory Thatmeansplotly'spythonapican'tsetuplocalconfigurationfiles Noproblemthough You'lljusthavetosign-inusing'plotly plotly sign_in ' Forhelpwiththat 'help plotly plotly sign_in ' \nQuestions?Visitcommunity plot lyorupgradetoaProplanfor1-1help https //goo gl/1YUVu9"
def ensure_local_plotly_files if check_file_permissions for fn in [CREDENTIALS_FILE CONFIG_FILE] utils ensure_file_exists fn contents utils load_json_dict fn for key val in list FILE_CONTENT[fn] items if key not in contents contents[key] valcontents_keys list contents keys for key in contents_keys if key not in FILE_CONTENT[fn] del contents[key]utils save_json_dict fn contents else warnings warn "Lookslikeyoudon'thave'read-write'permissiontoyour'home' '~' directoryortoour'~/ plotly'directory Thatmeansplotly'spythonapican'tsetuplocalconfigurationfiles Noproblemthough You'lljusthavetosign-inusing'plotly plotly sign_in ' Forhelpwiththat 'help plotly plotly sign_in ' \nQuestions?Visitcommunity plot lyorupgradetoaProplanfor1-1help https //goo gl/1YUVu9"
def notes document notes domhelpers findElementsWithAttribute document 'class' 'note' notePrefix dom parseString '<strong>Note </strong>' documentElementfor note in notes note childNodes insert 0 notePrefix
def function1 individual position height width value 0 0for x p in zip individual position value + x - p ** 2 return height / 1 + width * value
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME add_devices [CpuSpeedSensor name ]
def all_from_module module mod mod_import module if not mod return {}members getmembers mod predicate lambda obj getmodule obj in mod None return dict key val for key val in members if not key startswith '_'
@contextmanagerdef args **kwargs kwargs_str ' ' join [ '%s %r' % k v for k v in kwargs items ] raise DeprecationWarning '\n\nsh args hasbeendeprecatedbecauseitwasneverthreadsafe usethe\nfollowinginstead \n\nsh2 sh {kwargs} \nsh2 your_command \n\nor\n\nsh2 sh {kwargs} \nfromsh2importyour_command\nyour_command \n\n' format kwargs kwargs_str
@contextmanagerdef args **kwargs kwargs_str ' ' join [ '%s %r' % k v for k v in kwargs items ] raise DeprecationWarning '\n\nsh args hasbeendeprecatedbecauseitwasneverthreadsafe usethe\nfollowinginstead \n\nsh2 sh {kwargs} \nsh2 your_command \n\nor\n\nsh2 sh {kwargs} \nfromsh2importyour_command\nyour_command \n\n' format kwargs kwargs_str
def add_handlers handler_list subparsers command_handlers [ListArtifactsHandler 'screenboard' None 'list_datadog_screenboards' 'GetthelistofScreenboardsfromDatadog ' ListArtifactsHandler 'timeboard' None 'list_datadog_timeboards' 'GetthelistofTimeboardsfromDatadog ' GetArtifactHandler 'screenboard' None 'get_datadog_screenboard' 'GettheaDatadogScreenboard ' GetArtifactHandler 'timeboard' None 'get_datadog_timeboard' 'GettheaDatadogTimeboard ' ]for handler in command_handlers handler add_argparser subparsers handler_list append handler
@pytest mark parametrize u'poly' [Chebyshev2D 1 2 Polynomial2D 2 Legendre2D 1 2 Chebyshev1D 5 Legendre1D 5 Polynomial1D 5 ] def test_compound_with_polynomials poly poly parameters [1 2 3 4 1 2]shift Shift 3 model poly shift x y np mgrid[ 20 37]result_compound model x y result shift poly x y assert_allclose result result_compound
@pytest mark parametrize u'poly' [Chebyshev2D 1 2 Polynomial2D 2 Legendre2D 1 2 Chebyshev1D 5 Legendre1D 5 Polynomial1D 5 ] def test_compound_with_polynomials poly poly parameters [1 2 3 4 1 2]shift Shift 3 model poly shift x y np mgrid[ 20 37]result_compound model x y result shift poly x y assert_allclose result result_compound
@pytest mark parametrize u'poly' [Chebyshev2D 1 2 Polynomial2D 2 Legendre2D 1 2 Chebyshev1D 5 Legendre1D 5 Polynomial1D 5 ] def test_compound_with_polynomials poly poly parameters [1 2 3 4 1 2]shift Shift 3 model poly shift x y np mgrid[ 20 37]result_compound model x y result shift poly x y assert_allclose result result_compound
def add_lease mac ip_address api network_rpcapi NetworkAPI api lease_fixed_ip context get_admin_context ip_address CONF host
def _ReadUrlContents url req urllib2 Request url return urllib2 urlopen req read
def get_power_command power_type if power_type power_path1 '/sbin/fence_%s' % power_type power_path2 '/usr/sbin/fence_%s' % power_type for power_path in power_path1 power_path2 if os path isfile power_path and os access power_path os X_OK return power_pathreturn None
def getDataProvider dataset assert dataset in ['flickr8k' 'flickr30k' 'coco'] 'dataset%sunknown' % dataset return BasicDataProvider dataset
def getDataProvider dataset assert dataset in ['flickr8k' 'flickr30k' 'coco'] 'dataset%sunknown' % dataset return BasicDataProvider dataset
def _validate_name name name str name name_length len name regex re compile '^[a-zA-Z0-9][A-Za-z0-9_-]*[a-zA-Z0-9]$' if name_length < 3 or name_length > 48 ret Falseelif not re match regex name ret Falseelse ret Trueif ret is False log warning 'ALinodelabelmayonlycontainASCIIlettersornumbers dashes andunderscores mustbeginandendwithlettersornumbers andbeatleastthreecharactersinlength ' return ret
def _validate_name name name str name name_length len name regex re compile '^[a-zA-Z0-9][A-Za-z0-9_-]*[a-zA-Z0-9]$' if name_length < 3 or name_length > 48 ret Falseelif not re match regex name ret Falseelse ret Trueif ret is False log warning 'ALinodelabelmayonlycontainASCIIlettersornumbers dashes andunderscores mustbeginandendwithlettersornumbers andbeatleastthreecharactersinlength ' return ret
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
@xframe_options_sameorigin@login_required@process_document_pathdef edit_attachment request document_slug document_locale document get_object_or_404 Document locale document_locale slug document_slug if request method 'POST' return redirect document get_edit_url if not allow_add_attachment_by request user raise PermissionDeniedform AttachmentRevisionForm data request POST files request FILES if form is_valid revision form save commit False revision creator request userattachment Attachment objects create title revision title revision attachment attachmentrevision save attachment attach document request user revision return redirect document get_edit_url else context {'form' form 'document' document}return render request 'attachments/edit_attachment html' context
def twitter_outbox if not auth s3_logged_in session error T 'RequiresLogin ' redirect URL c 'default' f 'user' args 'login' tablename 'msg_twitter'table s3db msg_twitters3 filter table inbound False table inbound readable Falses3 crud_strings[tablename] Storage title_display T 'TweetDetails' title_list T 'SentTweets' label_list_button T 'ViewSentTweets' label_delete_button T 'DeleteTweet' msg_record_deleted T 'Tweetdeleted' msg_list_empty T 'NoTweetscurrentlyinOutbox' def postp r output if isinstance output dict add_btn A T 'Compose' _class 'action-btn' _href URL f 'compose' output['rheader'] add_btnreturn outputs3 postp postps3db configure tablename editable False insertable False listadd False list_fields ['id' 'date' 'to_address' 'body'] return s3_rest_controller module 'twitter'
def get_localzone global _cache_tzif _cache_tz is None _cache_tz _get_localzone return _cache_tz
def get_localzone global _cache_tzif _cache_tz is None _cache_tz _get_localzone return _cache_tz
def _in_encoding return _stream_encoding sys stdin
def _check_update_montage info montage path None update_ch_names False if montage is not None if not isinstance montage string_types Montage err 'Montagemustbestr None orinstanceofMontage %swasprovided' % type montage raise TypeError err if montage is not None if isinstance montage string_types montage read_montage montage path path _set_montage info montage update_ch_names update_ch_names missing_positions []exclude FIFF FIFFV_EOG_CH FIFF FIFFV_MISC_CH FIFF FIFFV_STIM_CH for ch in info['chs'] if not ch['kind'] in exclude if np unique ch['loc'] size 1 missing_positions append ch['ch_name'] if missing_positions raise KeyError 'Thefollowingpositionsaremissingfromthemontagedefinitions %s IfthosechannelslackpositionsbecausetheyareEOGchannelsusetheeogparameter ' % str missing_positions
def _check_update_montage info montage path None update_ch_names False if montage is not None if not isinstance montage string_types Montage err 'Montagemustbestr None orinstanceofMontage %swasprovided' % type montage raise TypeError err if montage is not None if isinstance montage string_types montage read_montage montage path path _set_montage info montage update_ch_names update_ch_names missing_positions []exclude FIFF FIFFV_EOG_CH FIFF FIFFV_MISC_CH FIFF FIFFV_STIM_CH for ch in info['chs'] if not ch['kind'] in exclude if np unique ch['loc'] size 1 missing_positions append ch['ch_name'] if missing_positions raise KeyError 'Thefollowingpositionsaremissingfromthemontagedefinitions %s IfthosechannelslackpositionsbecausetheyareEOGchannelsusetheeogparameter ' % str missing_positions
def libvlc_media_list_lock p_ml f _Cfunctions get 'libvlc_media_list_lock' None or _Cfunction 'libvlc_media_list_lock' 1 None None MediaList return f p_ml
@register_opt 'low_memory' @local_optimizer [GpuCAReduceCuda] def local_gpu_elemwise_careduce node if isinstance node op GpuCAReduceCuda and node op pre_scalar_op is None and node inputs[0] owner and isinstance node inputs[0] owner op GpuElemwise and isinstance node inputs[0] owner op scalar_op scalar basic Sqr op node opinp node inputs[0] owner inputs[0]return [gpu_ca_reduce_cuda scalar_op op scalar_op axis op axis reduce_mask op reduce_mask pre_scalar_op scalar basic sqr inp ]
def save_obj base_mapper states uowtransaction single False if not single and not base_mapper batch for state in _sort_states states save_obj base_mapper [state] uowtransaction single True return states_to_insert states_to_update _organize_states_for_save base_mapper states uowtransaction cached_connections _cached_connection_dict base_mapper for table mapper in base_mapper _sorted_tables items insert _collect_insert_commands base_mapper uowtransaction table states_to_insert update _collect_update_commands base_mapper uowtransaction table states_to_update if update _emit_update_statements base_mapper uowtransaction cached_connections mapper table update if insert _emit_insert_statements base_mapper uowtransaction cached_connections mapper table insert _finalize_insert_update_commands base_mapper uowtransaction states_to_insert states_to_update
def mpl_runner safe_execfile def mpl_execfile fname *where **kw 'matplotlib-awarewrapperaroundsafe_execfile \n\nItsinterfaceisidenticaltothatofthe func `execfile`builtin \n\nThisisultimatelyacalltoexecfile butwrappedinsafetiesto\nproperlyhandleinteractiverendering 'import matplotlibimport matplotlib pyplot as pltis_interactive matplotlib rcParams['interactive']matplotlib interactive False safe_execfile fname *where **kw matplotlib interactive is_interactive if plt draw_if_interactive called plt draw plt draw_if_interactive called Falsetry da plt draw_allexcept AttributeError passelse da return mpl_execfile
def cloudnetwork vm_ return config get_cloud_config_value 'cloudnetwork' vm_ __opts__ default False search_global False
def cloudnetwork vm_ return config get_cloud_config_value 'cloudnetwork' vm_ __opts__ default False search_global False
def cloudnetwork vm_ return config get_cloud_config_value 'cloudnetwork' vm_ __opts__ default False search_global False
def test_grouping_identifier_list_subquery p sqlparse parse 'select*from selecta b+casdfromtable sub' [0]subquery p tokens[ -1 ] tokens[0] idx iden_list subquery token_next_by i sql IdentifierList assert iden_list is not None _ ilist subquery token_next_by i sql Identifier idx idx assert ilist is None
def test_grouping_identifier_list_subquery p sqlparse parse 'select*from selecta b+casdfromtable sub' [0]subquery p tokens[ -1 ] tokens[0] idx iden_list subquery token_next_by i sql IdentifierList assert iden_list is not None _ ilist subquery token_next_by i sql Identifier idx idx assert ilist is None
def test_grouping_identifier_list_subquery p sqlparse parse 'select*from selecta b+casdfromtable sub' [0]subquery p tokens[ -1 ] tokens[0] idx iden_list subquery token_next_by i sql IdentifierList assert iden_list is not None _ ilist subquery token_next_by i sql Identifier idx idx assert ilist is None
def test_ast_bad_except cant_compile u' except1 ' cant_compile u' try1 except1 ' cant_compile u' try1 except[13] ' cant_compile u' try1 except[x[FooBar]BarBar] '
def _get_default_profile_image_urls return _get_profile_image_urls configuration_helpers get_value 'PROFILE_IMAGE_DEFAULT_FILENAME' settings PROFILE_IMAGE_DEFAULT_FILENAME staticfiles_storage file_extension settings PROFILE_IMAGE_DEFAULT_FILE_EXTENSION
def _GetConnection connection Noneif os getenv _ENV_KEY try connection _thread_local connectionexcept AttributeError passif connection is None connection datastore_rpc Connection adapter _adapter _SetConnection connection return connection
def run_hive_script script if not os path isfile script raise RuntimeError 'Hivescript {0}doesnotexist ' format script return run_hive ['-f' script]
def run_hive_script script if not os path isfile script raise RuntimeError 'Hivescript {0}doesnotexist ' format script return run_hive ['-f' script]
def rsync_upload excludes [u'* pyc' u'* pyo' u'* db' u' DS_Store' u' coverage' u'local_settings py' u'/static' u'/ git' u'/ hg']local_dir os getcwd + os sep return rsync_project remote_dir env proj_path local_dir local_dir exclude excludes
def rsync_upload excludes [u'* pyc' u'* pyo' u'* db' u' DS_Store' u' coverage' u'local_settings py' u'/static' u'/ git' u'/ hg']local_dir os getcwd + os sep return rsync_project remote_dir env proj_path local_dir local_dir exclude excludes
def rsync_upload excludes [u'* pyc' u'* pyo' u'* db' u' DS_Store' u' coverage' u'local_settings py' u'/static' u'/ git' u'/ hg']local_dir os getcwd + os sep return rsync_project remote_dir env proj_path local_dir local_dir exclude excludes
def get_gdp_year rdint vs random request Request vs MACRO_URL % vs P_TYPE['http'] vs DOMAINS['sina'] rdint vs MACRO_TYPE[0] 0 70 rdint text urlopen request timeout 10 read text text decode 'gbk' if ct PY3 else text regSym re compile '\\ count *? \\}' datastr regSym findall text datastr datastr[0]datastr datastr split 'data ' [1]datastr datastr replace '"' '' replace 'null' '0' js json loads datastr df pd DataFrame js columns vs GDP_YEAR_COLS df[ df 0 ] np NaNreturn df
def test_keypoints_censure_moon_image_dob detector CENSURE detector detect img expected_keypoints np array [[21 497] [36 46] [119 350] [185 177] [287 250] [357 239] [463 116] [464 132] [467 260]] expected_scales np array [3 4 4 2 2 3 2 2 2] assert_array_equal expected_keypoints detector keypoints assert_array_equal expected_scales detector scales
def filter_displayed_blocks block unused_view frag unused_context if getattr block 'show_in_read_only_mode' False return fragreturn Fragment _ u'Thistypeofcomponentcannotbeshownwhileviewingthecourseasaspecificstudent '
def filter_displayed_blocks block unused_view frag unused_context if getattr block 'show_in_read_only_mode' False return fragreturn Fragment _ u'Thistypeofcomponentcannotbeshownwhileviewingthecourseasaspecificstudent '
def delete_router router profile None conn _auth profile return conn delete_router router
def _is_protected_type obj return isinstance obj types NoneType int long datetime datetime datetime date datetime time float Decimal basestring
def _is_protected_type obj return isinstance obj types NoneType int long datetime datetime datetime date datetime time float Decimal basestring
def _is_protected_type obj return isinstance obj types NoneType int long datetime datetime datetime date datetime time float Decimal basestring
def _is_protected_type obj return isinstance obj types NoneType int long datetime datetime datetime date datetime time float Decimal basestring
def find_tag fid node findkind if node['directory'] is not None for subnode in node['directory'] if subnode kind findkind return read_tag fid subnode pos return None
def add_parse_callback callback options add_parse_callback callback
@mock_streams 'stderr' @with_patched_object output 'aborts' True def test_abort_message try abort 'Test' except SystemExit passresult sys stderr getvalue eq_ '\nFatalerror Test\n\nAborting \n' result
@app route '/drip' def drip args CaseInsensitiveDict request args items duration float args get 'duration' 2 numbytes min int args get 'numbytes' 10 10 * 1024 * 1024 code int args get 'code' 200 pause duration / numbytes delay float args get 'delay' 0 if delay > 0 time sleep delay def generate_bytes for i in xrange numbytes yield u'*' encode 'utf-8' time sleep pause response Response generate_bytes headers {'Content-Type' 'application/octet-stream' 'Content-Length' str numbytes } response status_code codereturn response
def _set_cache_version version from django core cache import cachecache set CMS_PAGE_CACHE_VERSION_KEY version get_cms_setting 'CACHE_DURATIONS' ['content']
def attachment_destroy context attachment_id return IMPL attachment_destroy context attachment_id
def add_team name description None repo_names None privacy None permission None profile 'github' try client _get_client profile organization client get_organization _get_config_value profile 'org_name' parameters {}parameters['name'] nameif description is not None parameters['description'] descriptionif repo_names is not None parameters['repo_names'] repo_namesif permission is not None parameters['permission'] permissionif privacy is not None parameters['privacy'] privacyorganization _requester requestJsonAndCheck 'POST' organization url + '/teams' input parameters list_teams ignore_cache True return Trueexcept github GithubException as e log exception 'Errorcreatingateam {0}' format str e return False
def add_team name description None repo_names None privacy None permission None profile 'github' try client _get_client profile organization client get_organization _get_config_value profile 'org_name' parameters {}parameters['name'] nameif description is not None parameters['description'] descriptionif repo_names is not None parameters['repo_names'] repo_namesif permission is not None parameters['permission'] permissionif privacy is not None parameters['privacy'] privacyorganization _requester requestJsonAndCheck 'POST' organization url + '/teams' input parameters list_teams ignore_cache True return Trueexcept github GithubException as e log exception 'Errorcreatingateam {0}' format str e return False
def OpenFilename filename options {} command GetVimCommand options get u'command' u'horizontal-split' u'horizontal-split' size options get u'size' u'' if command in [u'split' u'vsplit'] else u'' focus options get u'focus' False if not focus and command u'tabedit' previous_tab GetIntValue u'tabpagenr ' else previous_tab Nonetry vim command u'{0}{1}{2}' format size command filename except vim error as e if u'E325' not in str e raiseif filename GetCurrentBufferFilepath returnexcept KeyboardInterrupt return_SetUpLoadedBuffer command filename options get u'fix' False options get u'position' u'start' options get u'watch' False if not focus if command u'tabedit' JumpToTab previous_tab if command in [u'split' u'vsplit'] JumpToPreviousWindow
def Object theType offset vm name None **kwargs name name or theType offset int offset try if vm profile has_type theType result vm profile types[theType] offset offset vm vm name name **kwargs return resultexcept InvalidOffsetError return NoneObject 'InvalidAddress0x{0 08X} instantiating{1}' format offset name strict vm profile strict debug warning 'Cantfindobject{0}inprofile{1}?' format theType vm profile
def Object theType offset vm name None **kwargs name name or theType offset int offset try if vm profile has_type theType result vm profile types[theType] offset offset vm vm name name **kwargs return resultexcept InvalidOffsetError return NoneObject 'InvalidAddress0x{0 08X} instantiating{1}' format offset name strict vm profile strict debug warning 'Cantfindobject{0}inprofile{1}?' format theType vm profile
@pytest fixturedef xonsh_execer monkeypatch monkeypatch setattr xonsh built_ins 'load_builtins' lambda *args **kwargs None execer Execer login False unload False builtins __xonsh_execer__ execerreturn execer
def deserialize_key_value value secret False if secret KeyValuePairAPI _setup_crypto value symmetric_decrypt KeyValuePairAPI crypto_key value return value
def get_cache conf if conf cache_url return _get_cache_region_for_legacy conf cache_url elif conf cache enabled return _get_cache_region conf else return False
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if not isinstance v six text_type v six text_type v if column type length and column type length < len v raise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if not isinstance v six text_type v six text_type v if column type length and column type length < len v raise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if not isinstance v six text_type v six text_type v if column type length and column type length < len v raise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if not isinstance v six text_type v six text_type v if column type length and column type length < len v raise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
@when u'wedroptable' def step_drop_table context context cli sendline u'droptablea '
def get_cpu_stat key stats []stat_file open '/proc/stat' 'r' line stat_file readline while line if line startswith key stats line split [1 ]breakline stat_file readline return stats
@utils expects_func_args 'image_id' 'instance' def delete_image_on_error function @functools wraps function def decorated_function self context image_id instance *args **kwargs try return function self context image_id instance *args **kwargs except Exception with excutils save_and_reraise_exception LOG debug 'Cleaningupimage%s' image_id exc_info True instance instance try self image_api delete context image_id except exception ImageNotFound passexcept Exception LOG exception _LE 'Errorwhiletryingtocleanupimage%s' image_id instance instance return decorated_function
@utils expects_func_args 'image_id' 'instance' def delete_image_on_error function @functools wraps function def decorated_function self context image_id instance *args **kwargs try return function self context image_id instance *args **kwargs except Exception with excutils save_and_reraise_exception LOG debug 'Cleaningupimage%s' image_id exc_info True instance instance try self image_api delete context image_id except exception ImageNotFound passexcept Exception LOG exception _LE 'Errorwhiletryingtocleanupimage%s' image_id instance instance return decorated_function
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def xframe_options_exempt view_func def wrapped_view *args **kwargs resp view_func *args **kwargs resp xframe_options_exempt Truereturn respreturn wraps view_func assigned available_attrs view_func wrapped_view
def course_context_from_course_id course_id if course_id is None return {'course_id' '' 'org_id' ''}assert isinstance course_id CourseKey return {'course_id' course_id to_deprecated_string 'org_id' course_id org}
def _colspec dataset_width spec 'l'for _ in range 1 dataset_width spec + 'r'return spec
def make_formatters config stream_openers default_stream_opener StreamOpener stream sys stdout formatter_list []for i name in enumerate config format stream_opener default_stream_openerif i < len stream_openers stream_opener stream_openers[i]formatter_class select_formatter_class name formatter_object formatter_class stream_opener config formatter_list append formatter_object return formatter_list
def set_fw_rules subprocess call 'iptables-tnat-APREROUTING-ptcp--dport80-jDNAT--to-destination%s %s' % NETWORK_GW_IP PORT shell True subprocess call 'iptables-tnat-APREROUTING-pudp--dport53-jDNAT--to-destination%s %s' % NETWORK_GW_IP 53 shell True subprocess call 'iptables-tnat-APREROUTING-ptcp--dport53-jDNAT--to-destination%s %s' % NETWORK_GW_IP 53 shell True subprocess call 'iptables-tnat-APREROUTING-ptcp--dport443-jDNAT--to-destination%s %s' % NETWORK_GW_IP SSL_PORT shell True
def setup_database_via_manager engine settings DATABASES['default']['ENGINE']rdbms_type database_manager engine_to_rdbms_type engine manager database_manager get_manager_from_config rdbms_type rdbms_type manager create_instance manager grant_privileges
def backoffPolicy initialDelay 1 0 maxDelay 60 0 factor 1 5 jitter _goodEnoughRandom def policy attempt return min initialDelay * factor ** attempt maxDelay + jitter return policy
def backoffPolicy initialDelay 1 0 maxDelay 60 0 factor 1 5 jitter _goodEnoughRandom def policy attempt return min initialDelay * factor ** attempt maxDelay + jitter return policy
def open_repo_in_new_window dirname qtutils opendir_dialog N_ u'OpenGitRepository ' main model getcwd if not dirname returncmds do cmds OpenNewRepo dirname
def AppLogInit logging debug 'InitializingApplicationLogger ' return GrrApplicationLogger
def normal_ordered_form expr independent False recursive_limit 10 _recursive_depth 0 if _recursive_depth > recursive_limit warnings warn 'Toomanyrecursions aborting' return exprif isinstance expr Add return _normal_ordered_form_terms expr recursive_limit recursive_limit _recursive_depth _recursive_depth independent independent elif isinstance expr Mul return _normal_ordered_form_factor expr recursive_limit recursive_limit _recursive_depth _recursive_depth independent independent else return expr
def date_format date None format '%Y-%m-%d' return date_cast date strftime format
def date_format date None format '%Y-%m-%d' return date_cast date strftime format
def is_site_configuration_enabled configuration get_current_site_configuration if configuration return configuration enabledreturn False
def archive_repository_revision app repository archive_dir changeset_revision repo get_repo_for_repository app repository repository repo_path None create False options_dict get_mercurial_default_options_dict 'archive' options_dict['rev'] changeset_revisionerror_message ''return_code Nonetry return_code commands archive get_configured_ui repo archive_dir **options_dict except Exception as e error_message 'Errorattemptingtoarchiverevision<b>%s</b>ofrepository%s %s\nReturncode %s\n' % str changeset_revision str repository name str e str return_code log exception error_message return return_code error_message
def _cherry_pick_call func *args **dargs p_args p_dargs _cherry_pick_args func args dargs return func *p_args **p_dargs
def _cherry_pick_call func *args **dargs p_args p_dargs _cherry_pick_args func args dargs return func *p_args **p_dargs
def _delAccountRights sidObject user_right try _polHandle win32security LsaOpenPolicy None win32security POLICY_ALL_ACCESS user_rights_list [user_right]_ret win32security LsaRemoveAccountRights _polHandle sidObject False user_rights_list return Trueexcept Exception as e log error 'Errorattemptingtodeleteaccountright exceptionwas{0}' format e return False
def strip_dev device_name return _dev sub '' device_name if device_name else device_name
def establish_connection ip username '' password '' delay 1 remote_conn telnetlib Telnet ip TELNET_PORT TELNET_TIMEOUT output remote_conn read_until 'sername ' READ_TIMEOUT remote_conn write username + '\n' output remote_conn read_until 'ssword ' READ_TIMEOUT remote_conn write password + '\n' time sleep delay return remote_conn
def filter_non_model_columns data model columns [c name for c in model __table__ columns]return dict k v for k v in six iteritems data if k in columns or isinstance getattr model k None associationproxy AssociationProxy
def lfsr_sequence key fill n if not isinstance key list raise TypeError 'keymustbealist' if not isinstance fill list raise TypeError 'fillmustbealist' p key[0] modF FF p s fillk len fill L []for i in range n s0 s[ ]L append s[0] s s[1 k]x sum [int key[i] * s0[i] for i in range k ] s append F x return L
def file_descriptors_used pid try pid int pid if pid < 0 raise IOError "Processpidscan'tbenegative %s" % pid except ValueError TypeError raise IOError 'Processpidwasnon-numeric %s' % pid try return len os listdir '/proc/%i/fd' % pid except Exception as exc raise IOError 'Unabletochecknumberoffiledescriptorsused %s' % exc
def dict_to_xml tag d elem Element tag for key val in d items child Element key child text str val elem append child return elem
def createParser filename real_filename None tags None if not tags tags []stream FileInputStream filename real_filename tags tags return guessParser stream
def f1_score y_true y_pred labels None pos_label 1 average 'binary' sample_weight None return fbeta_score y_true y_pred 1 labels labels pos_label pos_label average average sample_weight sample_weight
def start_request request_id with _request_states_lock _request_states[request_id] RequestState request_id
def testtextextraction document opendocx TEST_FILE paratextlist getdocumenttext document assert len paratextlist > 0
def getdirs dirs [i for i in os listdir dname ]dirs filter lambda x not os path isfile os path join dname x dirs return dirs
def getdirs dirs [i for i in os listdir dname ]dirs filter lambda x not os path isfile os path join dname x dirs return dirs
def enable_ssh _current global_settings if _current['GlobalSettings']['SSH_STATUS']['VALUE'] 'Y' return True_xml '<RIBCLVERSION "2 0">\n<LOGINUSER_LOGIN "adminname"PASSWORD "password">\n<RIB_INFOMODE "write">\n<MOD_GLOBAL_SETTINGS>\n<SSH_STATUSvalue "Yes"/>\n</MOD_GLOBAL_SETTINGS>\n</RIB_INFO>\n</LOGIN>\n</RIBCL>'return __execute_cmd 'Enable_SSH' _xml
@register_uncanonicalize@gof local_optimizer [DimShuffle] def local_dimshuffle_alloc node if isinstance node op DimShuffle and node inputs[0] owner input_ node inputs[0]if isinstance input_ owner op T Alloc new_order node op new_orderexpected_new_order 'x' * len new_order - input_ ndim + tuple range input_ ndim if new_order expected_new_order return Falsenb_new_dims len new_order - input_ ndim new_shape_input 1 * nb_new_dims + tuple input_ owner inputs[1 ] return [T alloc input_ owner inputs[0] *new_shape_input ]return False
@register_uncanonicalize@gof local_optimizer [DimShuffle] def local_dimshuffle_alloc node if isinstance node op DimShuffle and node inputs[0] owner input_ node inputs[0]if isinstance input_ owner op T Alloc new_order node op new_orderexpected_new_order 'x' * len new_order - input_ ndim + tuple range input_ ndim if new_order expected_new_order return Falsenb_new_dims len new_order - input_ ndim new_shape_input 1 * nb_new_dims + tuple input_ owner inputs[1 ] return [T alloc input_ owner inputs[0] *new_shape_input ]return False
def imrotate arr angle interp 'bilinear' arr asarray arr func {'nearest' 0 'lanczos' 1 'bilinear' 2 'bicubic' 3 'cubic' 3}im toimage arr im im rotate angle resample func[interp] return fromimage im
def _covar_mstep_spherical *args cv _covar_mstep_diag *args return np tile cv mean axis 1 [ np newaxis] 1 cv shape[1]
def locale_details request locale_code leader_form None reviewer_form None editor_form None locale get_object_or_404 Locale locale locale_code leaders locale leaders all select_related 'profile' reviewers locale reviewers all select_related 'profile' editors locale editors all select_related 'profile' active active_contributors from_date date today - timedelta days 90 locale locale_code user_can_edit _user_can_edit request user locale return render request 'wiki/locale_details html' {'locale' locale 'leaders' leaders 'reviewers' reviewers 'editors' editors 'active' active 'user_can_edit' user_can_edit 'leader_form' leader_form or AddUserForm 'reviewer_form' reviewer_form or AddUserForm 'editor_form' editor_form or AddUserForm }
@gen coroutinedef UpdateDevice client obj_store user_id device_id request device_dict request['device_dict']if device_dict has_key 'device_id' and device_dict['device_id'] device_id raise web HTTPError 400 'badauthcookie deviceidmismatch%d %d' % device_dict['device_id'] device_id request['user_id'] user_idrequest['device_id'] device_id yield gen Task Operation CreateAndExecute client user_id device_id 'Device UpdateOperation' request logging info 'UPDATEDEVICE user %d device %d' % user_id device_id raise gen Return {}
def _multinomial_loss_grad w X Y alpha sample_weight n_classes Y shape[1]n_features X shape[1]fit_intercept w size n_classes * n_features + 1 grad np zeros n_classes n_features + bool fit_intercept loss p w _multinomial_loss w X Y alpha sample_weight sample_weight sample_weight[ np newaxis]diff sample_weight * p - Y grad[ n_features] safe_sparse_dot diff T X grad[ n_features] + alpha * w if fit_intercept grad[ -1 ] diff sum axis 0 return loss grad ravel p
def _has_access_course_key user action course_key checkers {'staff' lambda _has_staff_access_to_location user None course_key 'instructor' lambda _has_instructor_access_to_location user None course_key }return _dispatch checkers action user course_key
def _has_access_course_key user action course_key checkers {'staff' lambda _has_staff_access_to_location user None course_key 'instructor' lambda _has_instructor_access_to_location user None course_key }return _dispatch checkers action user course_key
def _aggr_mode inList valueCounts dict nonNone 0for elem in inList if elem SENTINEL_VALUE_FOR_MISSING_DATA continuenonNone + 1if elem in valueCounts valueCounts[elem] + 1else valueCounts[elem] 1if nonNone 0 return NonesortedCounts valueCounts items sortedCounts sort cmp lambda x y x[1] - y[1] reverse True return sortedCounts[0][0]
def _aggr_mode inList valueCounts dict nonNone 0for elem in inList if elem SENTINEL_VALUE_FOR_MISSING_DATA continuenonNone + 1if elem in valueCounts valueCounts[elem] + 1else valueCounts[elem] 1if nonNone 0 return NonesortedCounts valueCounts items sortedCounts sort cmp lambda x y x[1] - y[1] reverse True return sortedCounts[0][0]
def make_message command_id arguments tuple return MESSAGE_START + command_id + arguments + midi SYSEX_END
def do_with_python python cmdline runas None if python cmd 'PYENV_VERSION {0}{1}' format python cmdline else cmd cmdlinereturn do cmd runas runas
def save_signal sender instance **kw if not kw get 'raw' save_translations make_key instance
def save_signal sender instance **kw if not kw get 'raw' save_translations make_key instance
def _get_rc_timezone s matplotlib rcParams[u'timezone']if s u'UTC' return UTCimport pytzreturn pytz timezone s
def _get_rc_timezone s matplotlib rcParams[u'timezone']if s u'UTC' return UTCimport pytzreturn pytz timezone s
@log_calldef metadef_object_get_all context namespace_name namespace metadef_namespace_get context namespace_name objects []_check_namespace_visibility context namespace namespace_name for object in DATA['metadef_objects'] if object['namespace_id'] namespace['id'] objects append object return objects
def NormalProbabilityPlot sample fit_color '0 8' **options xs ys NormalProbability sample mean var MeanVar sample std math sqrt var fit FitLine xs mean std thinkplot Plot color fit_color label 'model' *fit xs ys NormalProbability sample thinkplot Plot xs ys **options
def NormalProbabilityPlot sample fit_color '0 8' **options xs ys NormalProbability sample mean var MeanVar sample std math sqrt var fit FitLine xs mean std thinkplot Plot color fit_color label 'model' *fit xs ys NormalProbability sample thinkplot Plot xs ys **options
@slow_test@testing requires_testing_data@requires_mayavi@requires_nibabel def test_render_mri tempdir _TempDir trans_fname_new op join tempdir 'temp-trans fif' for a b in [[trans_fname trans_fname_new]] shutil copyfile a b report Report info_fname raw_fname subject 'sample' subjects_dir subjects_dir with warnings catch_warnings record True warnings simplefilter 'always' report parse_folder data_path tempdir mri_decim 30 pattern '*' n_jobs 2 report save op join tempdir 'report html' open_browser False assert_true repr report
def aggregate label u'' def wrap f f _label labelreturn freturn wrap
def aggregate label u'' def wrap f f _label labelreturn freturn wrap
def aggregate label u'' def wrap f f _label labelreturn freturn wrap
def notebook_div model notebook_comms_target None model _check_one_model model with _ModelInEmptyDocument model docs_json render_items _standalone_docs_json_and_render_items [model] item render_items[0]if notebook_comms_target item['notebook_comms_target'] notebook_comms_targetelse notebook_comms_target ''script _wrap_in_onload DOC_JS render docs_json serialize_json docs_json render_items serialize_json render_items resources EMPTYjs AUTOLOAD_NB_JS render comms_target notebook_comms_target js_urls resources js_files css_urls resources css_files js_raw resources js_raw + [script] css_raw resources css_raw_str elementid item['elementid'] div _div_for_render_item item html NOTEBOOK_DIV render plot_script js plot_div div return encode_utf8 html
def notebook_div model notebook_comms_target None model _check_one_model model with _ModelInEmptyDocument model docs_json render_items _standalone_docs_json_and_render_items [model] item render_items[0]if notebook_comms_target item['notebook_comms_target'] notebook_comms_targetelse notebook_comms_target ''script _wrap_in_onload DOC_JS render docs_json serialize_json docs_json render_items serialize_json render_items resources EMPTYjs AUTOLOAD_NB_JS render comms_target notebook_comms_target js_urls resources js_files css_urls resources css_files js_raw resources js_raw + [script] css_raw resources css_raw_str elementid item['elementid'] div _div_for_render_item item html NOTEBOOK_DIV render plot_script js plot_div div return encode_utf8 html
def notebook_div model notebook_comms_target None model _check_one_model model with _ModelInEmptyDocument model docs_json render_items _standalone_docs_json_and_render_items [model] item render_items[0]if notebook_comms_target item['notebook_comms_target'] notebook_comms_targetelse notebook_comms_target ''script _wrap_in_onload DOC_JS render docs_json serialize_json docs_json render_items serialize_json render_items resources EMPTYjs AUTOLOAD_NB_JS render comms_target notebook_comms_target js_urls resources js_files css_urls resources css_files js_raw resources js_raw + [script] css_raw resources css_raw_str elementid item['elementid'] div _div_for_render_item item html NOTEBOOK_DIV render plot_script js plot_div div return encode_utf8 html
def notebook_div model notebook_comms_target None model _check_one_model model with _ModelInEmptyDocument model docs_json render_items _standalone_docs_json_and_render_items [model] item render_items[0]if notebook_comms_target item['notebook_comms_target'] notebook_comms_targetelse notebook_comms_target ''script _wrap_in_onload DOC_JS render docs_json serialize_json docs_json render_items serialize_json render_items resources EMPTYjs AUTOLOAD_NB_JS render comms_target notebook_comms_target js_urls resources js_files css_urls resources css_files js_raw resources js_raw + [script] css_raw resources css_raw_str elementid item['elementid'] div _div_for_render_item item html NOTEBOOK_DIV render plot_script js plot_div div return encode_utf8 html
def inv_item_packs try item_id request args[0]except raise HTTP 400 current xml json_message False 400 'Novalueprovided ' table s3db inv_inv_itemptable db supply_item_packquery table id item_id & table item_id ptable item_id records db query select ptable id ptable name ptable quantity output records json response headers['Content-Type'] 'application/json'return output
def prevent_recursion default def decorator func name '_calling_%s_' % func __name__ def newfunc self *args **kwds if getattr self name False return default setattr self name True try return func self *args **kwds finally setattr self name False return newfuncreturn decorator
def prevent_recursion default def decorator func name '_calling_%s_' % func __name__ def newfunc self *args **kwds if getattr self name False return default setattr self name True try return func self *args **kwds finally setattr self name False return newfuncreturn decorator
def intToID idnum rid ''while idnum > 0 idnum - 1rid chr idnum % 26 + ord 'a' + rid idnum int idnum / 26 return rid
def get_updated_changeset_revisions app name owner changeset_revision repository tool_shed util repository_util get_repository_by_name_and_owner app name owner repo hg_util get_repo_for_repository app repository repository repo_path None create False upper_bound_changeset_revision get_next_downloadable_changeset_revision repository repo changeset_revision changeset_hashes []for changeset in hg_util reversed_lower_upper_bounded_changelog repo changeset_revision upper_bound_changeset_revision if changeset upper_bound_changeset_revision changeset_hashes append str repo changectx changeset if changeset_hashes changeset_hashes_str ' ' join changeset_hashes return changeset_hashes_strreturn ''
def _read_page_header file_obj tin TFileTransport file_obj pin TCompactProtocolFactory get_protocol tin page_header parquet_thrift PageHeader page_header read pin return page_header
@contextlib contextmanagerdef _get_xapi_session _xenapi _check_xenapi xapi_uri __salt__['config option'] 'xapi uri' xapi_login __salt__['config option'] 'xapi login' xapi_password __salt__['config option'] 'xapi password' if not xapi_uri xapi_uri 'httpu ///var/run/xend/xen-api sock'if not xapi_login xapi_login ''if not xapi_password xapi_password ''try session _xenapi Session xapi_uri session xenapi login_with_password xapi_login xapi_password yield session xenapi except Exception raise CommandExecutionError 'FailedtoconnecttoXenAPIsocket ' finally session xenapi session logout
def _AppendSubtypeRec node subtype force True if isinstance node pytree Leaf _AppendTokenSubtype node subtype returnfor child in node children _AppendSubtypeRec child subtype force force
def _rewrite_sin m_n s a b from sympy import expand_mul pi ceiling gamma m n m_nm expand_mul m / pi n expand_mul n / pi r ceiling - m * a - n as_real_imag [0] return gamma m * s + n + r gamma 1 - n - r - m * s -1 ** r * pi
def add_wsgi_intercept host port app_create_fn script_name '' _wsgi_intercept[ host port ] app_create_fn script_name
def add_wsgi_intercept host port app_create_fn script_name '' _wsgi_intercept[ host port ] app_create_fn script_name
def ceil x np import_module 'numpy' if isinstance x int float return interval np ceil x elif isinstance x interval if x is_valid is False return interval - np inf np inf is_valid False else start np ceil x start end np ceil x end if start end return interval start end is_valid x is_valid else return interval start end is_valid None else return NotImplementedError
def _check_olecf data offset 512if data startswith '\xec\xa5\xc1\x00' offset return 'application/msword'elif 'MicrosoftExcel' in data return 'application/vnd ms-excel'elif _ppt_pattern match data offset return 'application/vnd ms-powerpoint'return False
def _check_olecf data offset 512if data startswith '\xec\xa5\xc1\x00' offset return 'application/msword'elif 'MicrosoftExcel' in data return 'application/vnd ms-excel'elif _ppt_pattern match data offset return 'application/vnd ms-powerpoint'return False
def system_path ca_path Nonepaths [u'/usr/lib/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-bundle crt' u'/etc/pki/tls/certs/ca-bundle crt' u'/etc/ssl/ca-bundle pem' u'/usr/local/share/certs/ca-root-nss crt' u'/etc/ssl/cert pem']if u'SSL_CERT_FILE' in os environ paths insert 0 os environ[u'SSL_CERT_FILE'] for path in paths if os path exists path and os path getsize path > 0 ca_path pathbreakif not ca_path raise OSError pretty_message u'\nUnabletofindaCAcertsbundleincommonlocations-try\nsettingtheSSL_CERT_FILEenvironmentalvariable\n' return ca_path
def system_path ca_path Nonepaths [u'/usr/lib/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-bundle crt' u'/etc/pki/tls/certs/ca-bundle crt' u'/etc/ssl/ca-bundle pem' u'/usr/local/share/certs/ca-root-nss crt' u'/etc/ssl/cert pem']if u'SSL_CERT_FILE' in os environ paths insert 0 os environ[u'SSL_CERT_FILE'] for path in paths if os path exists path and os path getsize path > 0 ca_path pathbreakif not ca_path raise OSError pretty_message u'\nUnabletofindaCAcertsbundleincommonlocations-try\nsettingtheSSL_CERT_FILEenvironmentalvariable\n' return ca_path
def system_path ca_path Nonepaths [u'/usr/lib/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-certificates crt' u'/etc/ssl/certs/ca-bundle crt' u'/etc/pki/tls/certs/ca-bundle crt' u'/etc/ssl/ca-bundle pem' u'/usr/local/share/certs/ca-root-nss crt' u'/etc/ssl/cert pem']if u'SSL_CERT_FILE' in os environ paths insert 0 os environ[u'SSL_CERT_FILE'] for path in paths if os path exists path and os path getsize path > 0 ca_path pathbreakif not ca_path raise OSError pretty_message u'\nUnabletofindaCAcertsbundleincommonlocations-try\nsettingtheSSL_CERT_FILEenvironmentalvariable\n' return ca_path
def _get_signed_query_params credentials expiration string_to_sign if not isinstance credentials google auth credentials Signing auth_uri 'http //google-cloud-python readthedocs io/en/latest/google-cloud-auth html#setting-up-a-service-account'raise AttributeError 'youneedaprivatekeytosigncredentials thecredentialsyouarecurrentlyusing%sjustcontainsatoken see%sformoredetails ' % type credentials auth_uri signature_bytes credentials sign_bytes string_to_sign signature base64 b64encode signature_bytes service_account_name credentials signer_emailreturn {'GoogleAccessId' service_account_name 'Expires' str expiration 'Signature' signature}
def get_score_funcs from scipy import statsfrom scipy spatial import distancescore_funcs Bunch xy_arg_dist_funcs [ n f for n f in vars distance items if isfunction f and not n startswith '_' ]xy_arg_stats_funcs [ n f for n f in vars stats items if isfunction f and not n startswith '_' ]score_funcs update dict n _make_xy_sfunc f for n f in xy_arg_dist_funcs if _get_args f ['u' 'v'] score_funcs update dict n _make_xy_sfunc f ndim_output True for n f in xy_arg_stats_funcs if _get_args f ['x' 'y'] return score_funcs
def zk_group_path key project key app if key name_space namespace key name_space else namespace ' default'first_element key path element 0 kind first_element type if first_element has_id suffix ' {}' format first_element id else suffix ' {}' format first_element name return LOCK_PATH_TEMPLATE format project project namespace namespace group kind + suffix
def create_update_gitdir if not os path exists gitdname retcode subprocess call 'gitclone' + repo shell True stdout sys stdout stderr sys stderr if retcode 0 msg 'Therewasaproblemcloningtherepo'raise Exception msg else shutil rmtree gitdname create_update_gitdir
def pure_nash_brute g return list pure_nash_brute_gen g
def pure_nash_brute g return list pure_nash_brute_gen g
def normalize word if not isinstance word basestring word str word if not isinstance word str try word word encode 'utf-8' 'ignore' except passfor k v in DIACRITICS items for v in v word word replace v k return word
def _ipv4_to_bits ipaddr return '' join [bin int x [2 ] rjust 8 '0' for x in ipaddr split ' ' ]
def l2_norm tensors squared False summed [tensor sqr tensor as_tensor_variable t sum for t in tensors]joined tensor stack summed axis 0 return joined sum if squared else tensor sqrt joined sum
def wait_started name path None timeout 300 if not exists name path path raise CommandExecutionError 'Container{0}doesdoesexists' format name if not state name path path 'running' raise CommandExecutionError 'Container{0}isnotrunning' format name ret Falseif running_systemd name path path test_started test_sd_started_statelogger log errorelse test_started test_bare_started_statelogger log debugnow time time expire now + timeout now time time started test_started name path path while time time < expire and not started time sleep 0 3 started test_started name path path if started is None logger 'Assuming{0}isstarted althoughwefailedtodetectthatisfullystartedcorrectly' format name ret Trueelse ret startedreturn ret
def wait_started name path None timeout 300 if not exists name path path raise CommandExecutionError 'Container{0}doesdoesexists' format name if not state name path path 'running' raise CommandExecutionError 'Container{0}isnotrunning' format name ret Falseif running_systemd name path path test_started test_sd_started_statelogger log errorelse test_started test_bare_started_statelogger log debugnow time time expire now + timeout now time time started test_started name path path while time time < expire and not started time sleep 0 3 started test_started name path path if started is None logger 'Assuming{0}isstarted althoughwefailedtodetectthatisfullystartedcorrectly' format name ret Trueelse ret startedreturn ret
def _moved_global old_name new_module None new_name None assert new_module or new_name if isinstance new_module _MovedGlobals new_module new_module _mg__old_refold_module inspect getmodule inspect stack [1][0] new_module new_module or old_module new_name new_name or old_name _MovedGlobals _mg__moves[ old_module old_name ] new_module new_name
def roles_trans roles {}for role in ROLE_PERMISSIONS roles[role] trans_role role return roles
def create_benefit benefit_class **kwargs if benefit_class description is Benefit description raise RuntimeError "Yourcustombenefitmustimplementitsown'description'property" return Benefit objects create proxy_class _class_path benefit_class **kwargs
def set_key yaml_data yaml_key yaml_value changes []ptr yaml_datafinal_key yaml_key split ' ' [ -1 ]for key in yaml_key split ' ' if key not in ptr and key final_key ptr[key] {}ptr ptr[key]elif key final_key if key in ptr and module safe_eval ptr[key] yaml_value or key not in ptr ptr[key] yaml_valuechanges append yaml_key yaml_value else if ptr[key] is None and key final_key ptr[key] {}ptr ptr[key]return changes
def set_key yaml_data yaml_key yaml_value changes []ptr yaml_datafinal_key yaml_key split ' ' [ -1 ]for key in yaml_key split ' ' if key not in ptr and key final_key ptr[key] {}ptr ptr[key]elif key final_key if key in ptr and module safe_eval ptr[key] yaml_value or key not in ptr ptr[key] yaml_valuechanges append yaml_key yaml_value else if ptr[key] is None and key final_key ptr[key] {}ptr ptr[key]return changes
def set_key yaml_data yaml_key yaml_value changes []ptr yaml_datafinal_key yaml_key split ' ' [ -1 ]for key in yaml_key split ' ' if key not in ptr and key final_key ptr[key] {}ptr ptr[key]elif key final_key if key in ptr and module safe_eval ptr[key] yaml_value or key not in ptr ptr[key] yaml_valuechanges append yaml_key yaml_value else if ptr[key] is None and key final_key ptr[key] {}ptr ptr[key]return changes
@staff_member_requireddef admin_keywords_submit request keyword_ids titles [] [] remove punctuation replace u'-' u'' for title in request POST get u'text_keywords' u'' split u' ' title u'' join [c for c in title if c not in remove ] strip if title kw created Keyword objects get_or_create_iexact title title keyword_id str kw id if keyword_id not in keyword_ids keyword_ids append keyword_id titles append title return HttpResponse u'%s %s' % u' ' join keyword_ids u' ' join titles content_type u'text/plain'
def appendXmlTextNode tag_name text parent el xmlTextNode tag_name text parent append el return el
def _next_device return _select_free_device _find_allocated_devices
def taggedsent_to_conll sentence for i word tag in enumerate sentence start 1 input_str [str i word '_' tag tag '_' '0' 'a' '_' '_']input_str ' DCTB ' join input_str + '\n' yield input_str
def convert_db_torrent_to_json torrent include_rel_score False torrent_name torrent[2]if torrent_name is None or len torrent_name strip 0 torrent_name 'Unnamedtorrent'res_json {'id' torrent[0] 'infohash' torrent[1] encode 'hex' 'name' torrent_name 'size' torrent[3] 'category' torrent[4] 'num_seeders' torrent[5] or 0 'num_leechers' torrent[6] or 0 'last_tracker_check' torrent[7] or 0 }if include_rel_score res_json['relevance_score'] torrent[9]return res_json
def get_tests_stanza tests is_server prepend None append None client_control_file '' assert not client_control_file and is_server if not prepend prepend []if not append append []raw_control_files [read_control_file test for test in tests]return _get_tests_stanza raw_control_files is_server prepend append client_control_file client_control_file
def drag page source_index target_index placeholder_height 0 draggables page q css ' drag-handle' source draggables[source_index]target draggables[target_index]action ActionChains page browser action click_and_hold source move_to_element_with_offset target 0 placeholder_height if placeholder_height 0 action release target perform else action release perform wait_for_notification page
def drag page source_index target_index placeholder_height 0 draggables page q css ' drag-handle' source draggables[source_index]target draggables[target_index]action ActionChains page browser action click_and_hold source move_to_element_with_offset target 0 placeholder_height if placeholder_height 0 action release target perform else action release perform wait_for_notification page
def get_pack_file_abs_path pack_ref file_path pack_base_path get_pack_base_path pack_name pack_ref path_components []path_components append pack_base_path normalized_file_path os path normpath '/' + file_path lstrip '/' if normalized_file_path file_path raise ValueError 'Invalidfilepath %s' % file_path path_components append normalized_file_path result os path join *path_components assert normalized_file_path in result common_prefix os path commonprefix [pack_base_path result] if common_prefix pack_base_path raise ValueError 'Invalidfile_path %s' % file_path return result
def create_candlestick open high low close dates None direction 'both' **kwargs if dates is not None utils validate_equal_length open high low close dates else utils validate_equal_length open high low close validate_ohlc open high low close direction **kwargs if direction is 'increasing' candle_incr_data make_increasing_candle open high low close dates **kwargs data candle_incr_dataelif direction is 'decreasing' candle_decr_data make_decreasing_candle open high low close dates **kwargs data candle_decr_dataelse candle_incr_data make_increasing_candle open high low close dates **kwargs candle_decr_data make_decreasing_candle open high low close dates **kwargs data candle_incr_data + candle_decr_data layout graph_objs Layout return graph_objs Figure data data layout layout
def start_tls_server test port context_factory server_endpoint SSL4ServerEndpoint reactor port context_factory interface '127 0 0 1' server_factory WaitForDisconnectsFactory forProtocol SendingProtocol test addCleanup lambda server_factory wait_for_disconnects d server_endpoint listen server_factory d addCallback lambda port test addCleanup port stopListening return d
def deflood s n 3 if n 0 return s[0 0]return re sub ' \\2{%s } ' % n - 1 lambda m m group 1 [0] * n s
def _bistochastic_normalize X max_iter 1000 tol 1e-05 X make_nonnegative X X_scaled Xdist Nonefor _ in range max_iter X_new _ _ _scale_normalize X_scaled if issparse X dist norm X_scaled data - X data else dist norm X_scaled - X_new X_scaled X_newif dist is not None and dist < tol breakreturn X_scaled
@dispatch Projection def rowfunc t from toolz itertoolz import getterindices [t _child fields index col for col in t fields]return getter indices
@dispatch Projection def rowfunc t from toolz itertoolz import getterindices [t _child fields index col for col in t fields]return getter indices
@dispatch Projection def rowfunc t from toolz itertoolz import getterindices [t _child fields index col for col in t fields]return getter indices
@pytest fixturedef issue_2401_po po_directory settings afrikaans_tutorial return _require_store afrikaans_tutorial settings POOTLE_TRANSLATION_DIRECTORY 'issue_2401 po'
def validate_bucket_name name _validate_path name if not _GCS_BUCKET_REGEX match name raise ValueError 'Bucketshouldbe3-63characterslongusingonlya-z 0-9 underscore dashordotbutgot%s' % name
def get_num_escape_turns x y c complex x y z complex x y num_iterations 0while MIN_MAGNITUDE < np absolute z < ESCAPE_MAGNITUDE and num_iterations < MAX_ITERATIONS z z ** 2 + c num_iterations + 1return float num_iterations / float MAX_ITERATIONS
def waterbutler_url_for route provider path node user None _internal False **kwargs url furl furl website_settings WATERBUTLER_INTERNAL_URL if _internal else website_settings WATERBUTLER_URL url path segments append waterbutler_action_map[route] url args update {'path' path 'nid' node _id 'provider' provider} if user url args['cookie'] user get_or_create_cookie elif website_settings COOKIE_NAME in request cookies url args['cookie'] request cookies[website_settings COOKIE_NAME]view_only Falseif 'view_only' in kwargs view_only kwargs get 'view_only' else view_only request args get 'view_only' url args['view_only'] view_onlyurl args update kwargs return url url
def finite_diff_kauers sum function sum functionfor l in sum limits function function subs l[0] l[ -1 ] + 1 return function
def finite_diff_kauers sum function sum functionfor l in sum limits function function subs l[0] l[ -1 ] + 1 return function
def generate_reset_password_token user password_hash md5 user password if user password else None data [str user id password_hash]return _security reset_serializer dumps data
def send_commit return s3db req_send_commit
def seed seed None get_random_state seed seed
@pytest fixturedef reset_standarddir no_cachedir_tag standarddir init None yield standarddir init None
@pytest fixturedef reset_standarddir no_cachedir_tag standarddir init None yield standarddir init None
def badDecorator fn def nameCollision *args **kwargs return fn *args **kwargs return nameCollision
def mod_run_check_cmd cmd filename **check_cmd_opts log debug 'runningourcheck_cmd' _cmd '{0}{1}' format cmd filename cret __salt__['cmd run_all'] _cmd **check_cmd_opts if cret['retcode'] 0 ret {'comment' 'check_cmdexecutionfailed' 'skip_watch' True 'result' False}if cret get 'stdout' ret['comment'] + '\n' + cret['stdout'] if cret get 'stderr' ret['comment'] + '\n' + cret['stderr'] return retreturn True
def strategy_connected_sequential_dfs G colors return strategy_connected_sequential G colors 'dfs'
def repo_absent name profile 'github' **kwargs ret {'name' name 'changes' {} 'result' None 'comment' ''}try target __salt__['github get_repo_info'] name profile profile **kwargs except CommandExecutionError target Noneif not target ret['comment'] 'Repo{0}doesnotexist' format name ret['result'] Truereturn retelse if __opts__['test'] ret['comment'] 'Repo{0}willbedeleted' format name ret['result'] Nonereturn retresult __salt__['github remove_repo'] name profile profile **kwargs if result ret['comment'] 'Deletedrepo{0}' format name ret['changes'] setdefault 'old' 'Repo{0}exists' format name ret['changes'] setdefault 'new' 'Repo{0}deleted' format name ret['result'] Trueelse ret['comment'] 'Failedtodeleterepo{0} Ensurethedelete_reposcopeisenabledifusingOAuth ' format name ret['result'] Falsereturn ret
def _validate_timedelta_unit arg try return _unit_map[arg]except if arg is None return 'ns'raise ValueError 'invalidtimedeltaunit{0}provided' format arg
def servicegroup_server_add sg_name s_name s_port **connection_args ret Trueserver _servicegroup_get_server sg_name s_name s_port **connection_args if server is not None return Falsenitro _connect **connection_args if nitro is None return Falsesgsb NSServiceGroupServerBinding sgsb set_servicegroupname sg_name sgsb set_servername s_name sgsb set_port s_port try NSServiceGroupServerBinding add nitro sgsb except NSNitroError as error log debug 'netscalermoduleerror-NSServiceGroupServerBinding failed {0}' format error ret False_disconnect nitro return ret
def nonisomorphic_trees order create 'graph' if order < 2 raise ValueErrorlayout list range order // 2 + 1 + list range 1 order + 1 // 2 while layout is not None layout _next_tree layout if layout is not None if create 'graph' yield _layout_to_graph layout elif create 'matrix' yield _layout_to_matrix layout layout _next_rooted_tree layout
def nonisomorphic_trees order create 'graph' if order < 2 raise ValueErrorlayout list range order // 2 + 1 + list range 1 order + 1 // 2 while layout is not None layout _next_tree layout if layout is not None if create 'graph' yield _layout_to_graph layout elif create 'matrix' yield _layout_to_matrix layout layout _next_rooted_tree layout
def _append_domain opts if opts['id'] endswith opts['append_domain'] return opts['id']if opts['id'] endswith ' ' return opts['id']return '{0[id]} {0[append_domain]}' format opts
def is_bare_console if platform system 'Windows' try import ctypesGetConsoleProcessList ctypes windll kernel32 GetConsoleProcessListnum GetConsoleProcessList ctypes byref ctypes c_int 0 ctypes c_int 1 if num 1 return Trueexcept Exception passreturn False
def is_bare_console if platform system 'Windows' try import ctypesGetConsoleProcessList ctypes windll kernel32 GetConsoleProcessListnum GetConsoleProcessList ctypes byref ctypes c_int 0 ctypes c_int 1 if num 1 return Trueexcept Exception passreturn False
def bonferroni_correction pvals return array pvals dtype float * len pvals
def bonferroni_correction pvals return array pvals dtype float * len pvals
def get_integration_service_events events {}for service in frappe get_all u'IntegrationService' filters {u'enabled' 1} fields [u'name'] controller get_integration_controller service name if hasattr controller u'scheduler_events' for key handlers in controller scheduler_events items events setdefault key [] extend handlers return events
def GetAvailableReportPlugins return sorted REGISTRY GetRegisteredPlugins itervalues key lambda cls cls __name__
def determine_is_pv session vdi_ref disk_image_type os_type LOG debug _ 'Lookingupvdi%sforPVkernel' vdi_ref if disk_image_type ImageType DISK_VHD if os_type 'windows' is_pv Falseelse is_pv Trueelif disk_image_type ImageType DISK_RAW with vdi_attached_here session vdi_ref read_only True as dev is_pv _is_vdi_pv dev elif disk_image_type ImageType DISK is_pv Trueelif disk_image_type ImageType DISK_ISO is_pv Falseelif not disk_image_type LOG warning _ 'ImageformatisNone tryingtodeterminePVstatususingpygrub ifinstancewithvdi%sdoesnotbootcorrectly trywithimagemetadata ' % vdi_ref with vdi_attached_here session vdi_ref read_only True as dev is_pv _is_vdi_pv dev else msg _ 'Unknownimageformat% disk_image_type s' % locals raise exception NovaException msg return is_pv
def determine_is_pv session vdi_ref disk_image_type os_type LOG debug _ 'Lookingupvdi%sforPVkernel' vdi_ref if disk_image_type ImageType DISK_VHD if os_type 'windows' is_pv Falseelse is_pv Trueelif disk_image_type ImageType DISK_RAW with vdi_attached_here session vdi_ref read_only True as dev is_pv _is_vdi_pv dev elif disk_image_type ImageType DISK is_pv Trueelif disk_image_type ImageType DISK_ISO is_pv Falseelif not disk_image_type LOG warning _ 'ImageformatisNone tryingtodeterminePVstatususingpygrub ifinstancewithvdi%sdoesnotbootcorrectly trywithimagemetadata ' % vdi_ref with vdi_attached_here session vdi_ref read_only True as dev is_pv _is_vdi_pv dev else msg _ 'Unknownimageformat% disk_image_type s' % locals raise exception NovaException msg return is_pv
def namespaced_function function global_dict defaults None preserve_context False if defaults is None defaults function __defaults__if preserve_context _global_dict function __globals__ copy _global_dict update global_dict global_dict _global_dictnew_namespaced_function types FunctionType function __code__ global_dict name function __name__ argdefs defaults new_namespaced_function __dict__ update function __dict__ return new_namespaced_function
def with_metaclass meta *bases class metaclass meta __call__ type __call____init__ type __init__def __new__ cls name this_bases d if this_bases is None return type __new__ cls name d return meta name bases d return metaclass 'temporary_class' None {}
def equateSphericalDotElevation point returnValue radius abs point if radius < 0 0 returnazimuthComplex point dropAxis azimuthRadius abs azimuthComplex if azimuthRadius < 0 0 returnelevationComplex euclidean getWiddershinsUnitPolar math radians returnValue azimuthComplex * radius / azimuthRadius * elevationComplex real point x azimuthComplex realpoint y azimuthComplex imagpoint z elevationComplex imag * radius
@register simple_tag takes_context True def avatar_urls context user size service_id None service avatar_services for_user user service_id if service is None logging error u'Couldnotgetasuitableavatarserviceforuser%s ' user urls {}else urls {resolution url for resolution url in six iteritems service get_avatar_urls request context[u'request'] user user size size }return mark_safe json dumps urls
def write_custom_metric client project_id now_rfc3339 color size count timeseries_descriptor {'project' project_id 'metric' CUSTOM_METRIC_NAME 'labels' {'{}/color' format CUSTOM_METRIC_DOMAIN color '{}/size' format CUSTOM_METRIC_DOMAIN size}}timeseries_data {'timeseriesDesc' timeseries_descriptor 'point' {'start' now_rfc3339 'end' now_rfc3339 'int64Value' count}}request client timeseries write project project_id body {'timeseries' [timeseries_data]} try request execute except Exception as e print 'Failedtowritedatatocustommetric exception {}' format e raise
def translate_jobconf_dict jobconf hadoop_version None translated_jobconf jobconf copy translation_warnings {}for variable value in jobconf items if hadoop_version variants [translate_jobconf variable hadoop_version ]else variants translate_jobconf_for_all_versions variable for variant in variants if variant in jobconf continuetranslated_jobconf[variant] valueif hadoop_version translation_warnings[variable] variantif translation_warnings log warning 'Detectedhadoopconfigurationpropertynamesthatdonotmatchhadoopversion%s \nThehavebeentranslatedasfollows\n%s' hadoop_version '\n' join [ '%s %s' % variable variant for variable variant in sorted translation_warnings items ] return translated_jobconf
def translate_jobconf_dict jobconf hadoop_version None translated_jobconf jobconf copy translation_warnings {}for variable value in jobconf items if hadoop_version variants [translate_jobconf variable hadoop_version ]else variants translate_jobconf_for_all_versions variable for variant in variants if variant in jobconf continuetranslated_jobconf[variant] valueif hadoop_version translation_warnings[variable] variantif translation_warnings log warning 'Detectedhadoopconfigurationpropertynamesthatdonotmatchhadoopversion%s \nThehavebeentranslatedasfollows\n%s' hadoop_version '\n' join [ '%s %s' % variable variant for variable variant in sorted translation_warnings items ] return translated_jobconf
def translate_jobconf_dict jobconf hadoop_version None translated_jobconf jobconf copy translation_warnings {}for variable value in jobconf items if hadoop_version variants [translate_jobconf variable hadoop_version ]else variants translate_jobconf_for_all_versions variable for variant in variants if variant in jobconf continuetranslated_jobconf[variant] valueif hadoop_version translation_warnings[variable] variantif translation_warnings log warning 'Detectedhadoopconfigurationpropertynamesthatdonotmatchhadoopversion%s \nThehavebeentranslatedasfollows\n%s' hadoop_version '\n' join [ '%s %s' % variable variant for variable variant in sorted translation_warnings items ] return translated_jobconf
def _cmp_by_asn local_asn path1 path2 def get_path_source_asn path asn Noneif path source is None asn local_asnelse asn path source remote_asreturn asnp1_asn get_path_source_asn path1 p2_asn get_path_source_asn path2 if p1_asn local_asn and p2_asn local_asn return path2if p2_asn local_asn and p1_asn local_asn return path1return None
def _model2dataframe model_endog model_exog model_type OLS **kwargs model_result model_type model_endog model_exog **kwargs fit statistics pd Series {'r2' model_result rsquared 'adj_r2' model_result rsquared_adj} result_df pd DataFrame {'params' model_result params 'pvals' model_result pvalues 'std' model_result bse 'statistics' statistics} fisher_df pd DataFrame {'params' {'_f_test' model_result fvalue} 'pvals' {'_f_test' model_result f_pvalue}} res_series pd concat [result_df fisher_df] unstack return res_series dropna
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
def _training_mode_application_calls application_calls from bricks import BatchNormalizationout []for app_call in application_calls assert isinstance app_call application brick BatchNormalization assert app_call application application BatchNormalization apply if app_call metadata get 'training_mode' False out append app_call return out
def getMedian alist tmp list alist tmp sort alen len tmp if alen % 2 1 return tmp[ alen // 2 ]else return tmp[ alen // 2 ] + tmp[ alen // 2 - 1 ] / 2
def _determine_toggles payload toggles for toggle definition in six iteritems toggles if definition['value'] is not None if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'yes_no' payload[toggle] 'yes'elif definition['value'] is False or definition['value'] 'no' and definition['type'] 'yes_no' payload[toggle] 'no'if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'true_false' payload[toggle] Trueelif definition['value'] is False or definition['value'] 'no' and definition['type'] 'true_false' payload[toggle] Falsereturn payload
def _determine_toggles payload toggles for toggle definition in six iteritems toggles if definition['value'] is not None if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'yes_no' payload[toggle] 'yes'elif definition['value'] is False or definition['value'] 'no' and definition['type'] 'yes_no' payload[toggle] 'no'if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'true_false' payload[toggle] Trueelif definition['value'] is False or definition['value'] 'no' and definition['type'] 'true_false' payload[toggle] Falsereturn payload
def _determine_toggles payload toggles for toggle definition in six iteritems toggles if definition['value'] is not None if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'yes_no' payload[toggle] 'yes'elif definition['value'] is False or definition['value'] 'no' and definition['type'] 'yes_no' payload[toggle] 'no'if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'true_false' payload[toggle] Trueelif definition['value'] is False or definition['value'] 'no' and definition['type'] 'true_false' payload[toggle] Falsereturn payload
def _determine_toggles payload toggles for toggle definition in six iteritems toggles if definition['value'] is not None if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'yes_no' payload[toggle] 'yes'elif definition['value'] is False or definition['value'] 'no' and definition['type'] 'yes_no' payload[toggle] 'no'if definition['value'] is True or definition['value'] 'yes' and definition['type'] 'true_false' payload[toggle] Trueelif definition['value'] is False or definition['value'] 'no' and definition['type'] 'true_false' payload[toggle] Falsereturn payload
def _wns_prepare_toast data **kwargs root ET Element 'toast' visual ET SubElement root 'visual' binding ET SubElement visual 'binding' binding attrib['template'] kwargs pop 'template' 'ToastText01' if 'text' in data for count item in enumerate data['text'] start 1 elem ET SubElement binding 'text' elem text itemelem attrib['id'] str count if 'image' in data for count item in enumerate data['image'] start 1 elem ET SubElement binding 'img' elem attrib['src'] itemelem attrib['id'] str count return ET tostring root
def restore_ccx_collection field_value ccx_id None if ccx_id is None return field_valueif isinstance field_value list field_value [restore_ccx fv ccx_id for fv in field_value]elif isinstance field_value dict for key val in field_value iteritems field_value[key] restore_ccx val ccx_id else field_value restore_ccx field_value ccx_id return field_value
def get_owner obj_name security_descriptor win32security GetFileSecurity obj_name win32security OWNER_SECURITY_INFORMATION owner_sid security_descriptor GetSecurityDescriptorOwner return get_name win32security ConvertSidToStringSid owner_sid
def get_tenant_network creds_provider compute_networks_client shared_network_name caller test_utils find_test_caller net_creds creds_provider get_primary_creds network getattr net_creds 'network' None if not network or not network get 'name' if shared_network_name msg 'Novalidnetworkprovidedorcreated defaultingtofixed_network_name'if caller msg ' %s %s' % caller msg LOG debug msg try network get_network_from_name shared_network_name compute_networks_client except exceptions InvalidTestResource network {}msg 'Foundnetwork%savailablefortenant' % network if caller msg ' %s %s' % caller msg LOG info msg return network
def set_peers *peers **options test options pop 'test' False commit options pop 'commit' True return __salt__['net load_template'] 'set_ntp_peers' peers peers test test commit commit
def transform_key key seed rounds cipher AES new seed AES MODE_ECB for n in range 0 rounds key cipher encrypt key return sha256 key
def get_bound_method obj method_name method getattr obj method_name None if method is not None if six get_method_self method is None msg '{0}mustbeaboundmethod' format method raise AttributeError msg return method
def string_from_module module variable None default None val variable_from_module module variable variable default default if val if variable return valelse result [v for v in make_iter val if isinstance v basestring ]return result if result else default return default
def __virtual__ if __grains__ get 'kernel' '' not in 'Linux' return False 'Thevbox_guestexecutionmodulefailedtoload onlyavailableonLinuxsystems ' return __virtualname__
@pytest mark skipif u'notHAS_SCIPY' def test_scipy_poisson_limit assert_allclose funcs _scipy_kraft_burrows_nousek 5 0 2 5 0 99 0 10 67 rtol 0 001 conf funcs poisson_conf_interval [5 0 6 0] u'kraft-burrows-nousek' background [2 5 2 0] conflevel [0 99 0 9] assert_allclose conf[ 0] 0 10 67 rtol 0 001 assert_allclose conf[ 1] 0 81 8 99 rtol 0 005
@pytest mark skipif u'notHAS_SCIPY' def test_scipy_poisson_limit assert_allclose funcs _scipy_kraft_burrows_nousek 5 0 2 5 0 99 0 10 67 rtol 0 001 conf funcs poisson_conf_interval [5 0 6 0] u'kraft-burrows-nousek' background [2 5 2 0] conflevel [0 99 0 9] assert_allclose conf[ 0] 0 10 67 rtol 0 001 assert_allclose conf[ 1] 0 81 8 99 rtol 0 005
def test_changing_timer_with_messages_shown qtbot view config_stub config_stub['ui']['message-timeout'] 900000view show_message usertypes MessageLevel info 'test' with qtbot waitSignal view _clear_timer timeout config_stub set 'ui' 'message-timeout' 100
def _get_options ret None defaults {'color' 'yellow' 'notify' False 'api_url' 'api hipchat com'}attrs {'hipchat_profile' 'profile' 'room_id' 'room_id' 'from_name' 'from_name' 'api_key' 'api_key' 'api_version' 'api_version' 'color' 'color' 'notify' 'notify' 'api_url' 'api_url'}profile_attr 'hipchat_profile'profile_attrs {'from_jid' 'from_jid' 'api_key' 'api_key' 'api_version' 'api_key' 'api_url' 'api_url'}_options salt returners get_returner_options __virtualname__ ret attrs profile_attr profile_attr profile_attrs profile_attrs __salt__ __salt__ __opts__ __opts__ defaults defaults return _options
def previous_current_next items extend itertools chain [None] items [None] prev cur nex itertools tee extend 3 next cur next nex next nex return zip prev cur nex
def _upload param_dict timeout data param_dict['format'] 'json'param_dict['wait'] 'true'param_dict['bucket'] 'audio_summary'result util callm 'track/upload' param_dict POST True socket_timeout 300 data data return _track_from_response result timeout
def _botocore_exception_maybe if HAS_BOTO3 return botocore exceptions ClientErrorreturn type None
def generate_dropout_mask mlp default_include_prob 0 5 input_include_probs None rng 2013 5 17 if input_include_probs is None input_include_probs {}if not hasattr rng 'uniform' rng np random RandomState rng total_units 0mask 0for layer in mlp layers if layer layer_name in input_include_probs p input_include_probs[layer layer_name]else p default_include_probfor _ in xrange layer get_input_space get_total_dimension mask int rng uniform < p << total_units total_units + 1return mask
def _escape_node node result []for i char in enumerate node if char u'\\' if u'' join node[i i + 3 ] in JID_ESCAPE_SEQUENCES result append u'\\5c' continueresult append char for i char in enumerate result if char u'\\' result[i] JID_ESCAPE_TRANSFORMATIONS get char char escaped u'' join result if escaped startswith u'\\20' or escaped endswith u'\\20' raise InvalidJID u'Escapedlocalpartstartsorendswith"\\20"' _validate_node escaped return escaped
def hash_path account container None object None raw_digest False if object and not container raise ValueError 'containerisrequiredifobjectisprovided' paths [account]if container paths append container if object paths append object if raw_digest return md5 HASH_PATH_PREFIX + '/' + '/' join paths + HASH_PATH_SUFFIX digest else return md5 HASH_PATH_PREFIX + '/' + '/' join paths + HASH_PATH_SUFFIX hexdigest
@receiver m2m_changed sender Sale products through def sale_update_products sender instance action *args **kwargs if action u'post_add' instance update_products
@receiver m2m_changed sender Sale products through def sale_update_products sender instance action *args **kwargs if action u'post_add' instance update_products
@receiver m2m_changed sender Sale products through def sale_update_products sender instance action *args **kwargs if action u'post_add' instance update_products
def get_status_from_instructor_task instructor_task status {}if instructor_task is not None status['task_id'] instructor_task task_idstatus['task_state'] instructor_task task_statestatus['in_progress'] instructor_task task_state not in READY_STATES if instructor_task task_output is not None status['task_progress'] json loads instructor_task task_output return status
def _subdivide_interval_by_hour start end start_hour start replace minute 0 second 0 microsecond 0 end_hour end replace minute 0 second 0 microsecond 0 if start_hour end_hour hour_to_secs {start_hour _to_secs end - start }else hour_to_secs {}hour_to_secs[start_hour] _to_secs start_hour + timedelta hours 1 - start hour_to_secs[end_hour] _to_secs end - end_hour cur_hour start_hour + timedelta hours 1 while cur_hour < end_hour hour_to_secs[cur_hour] _to_secs timedelta hours 1 cur_hour + timedelta hours 1 hour_to_secs dict h secs for h secs in hour_to_secs items if secs return hour_to_secs
def attach_cd session vm_ref vdi_ref userdevice vbd_ref create_vbd session vm_ref None userdevice vbd_type 'cd' read_only True bootable True empty True unpluggable False session call_xenapi 'VBD insert' vbd_ref vdi_ref return vbd_ref
def gametime_to_realtime secs 0 mins 0 hrs 0 days 0 weeks 0 months 0 yrs 0 format False realtime secs + mins * MIN + hrs * HOUR + days * DAY + weeks * WEEK + months * MONTH + yrs * YEAR / TIMEFACTOR if format return _format realtime 31536000 2628000 604800 86400 3600 60 return realtime
def gametime_to_realtime secs 0 mins 0 hrs 0 days 0 weeks 0 months 0 yrs 0 format False realtime secs + mins * MIN + hrs * HOUR + days * DAY + weeks * WEEK + months * MONTH + yrs * YEAR / TIMEFACTOR if format return _format realtime 31536000 2628000 604800 86400 3600 60 return realtime
def write_info fname info data_type None reset_range True fid start_file fname start_block fid FIFF FIFFB_MEAS write_meas_info fid info data_type reset_range end_block fid FIFF FIFFB_MEAS end_file fid
def write_info fname info data_type None reset_range True fid start_file fname start_block fid FIFF FIFFB_MEAS write_meas_info fid info data_type reset_range end_block fid FIFF FIFFB_MEAS end_file fid
def pop_context _local stack pop
def getPathCopy path pathCopy []for point in path pathCopy append point copy return pathCopy
def present profile 'pagerduty' subdomain None api_key None **kwargs kwargs['service']['name'] kwargs['name']escalation_policy_id kwargs['service']['escalation_policy_id']escalation_policy __salt__['pagerduty_util get_resource'] 'escalation_policies' escalation_policy_id ['name' 'id'] profile profile subdomain subdomain api_key api_key if escalation_policy kwargs['service']['escalation_policy_id'] escalation_policy['id']r __salt__['pagerduty_util resource_present'] 'services' ['name' 'id'] _diff profile subdomain api_key **kwargs return r
def setup_platform hass config add_devices discovery_info None lights []for address device_config in config[CONF_DEVICES] items device {}device['name'] device_config[CONF_NAME]device['address'] addresslight ZenggeLight device if light is_valid lights append light add_devices lights
def binary_is_text data if not isinstance data bytes raise TypeError "datamustbebytes got'%s'" % type data __name__ return all c not in _BINARYCHARS for c in data
def binary_is_text data if not isinstance data bytes raise TypeError "datamustbebytes got'%s'" % type data __name__ return all c not in _BINARYCHARS for c in data
def binary_is_text data if not isinstance data bytes raise TypeError "datamustbebytes got'%s'" % type data __name__ return all c not in _BINARYCHARS for c in data
def parse description factory default 'tcp' return endpoints _parseServer description factory default
def spline_filter Iin lmbda 5 0 intype Iin dtype charhcol array [1 0 4 0 1 0] 'f' / 6 0 if intype in ['F' 'D'] Iin Iin astype 'F' ckr cspline2d Iin real lmbda cki cspline2d Iin imag lmbda outr sepfir2d ckr hcol hcol outi sepfir2d cki hcol hcol out outr + 1j * outi astype intype elif intype in ['f' 'd'] ckr cspline2d Iin lmbda out sepfir2d ckr hcol hcol out out astype intype else raise TypeError 'InvaliddatatypeforIin' return out
def AlternatingGroup n if n in 1 2 return PermutationGroup [Permutation [0] ] a list range n a[0] a[1] a[2] a[1] a[2] a[0] gen1 aif n % 2 a list range 1 n a append 0 gen2 aelse a list range 2 n a append 1 a insert 0 0 gen2 agens [gen1 gen2]if gen1 gen2 gens gens[ 1]G PermutationGroup [_af_new a for a in gens] dups False if n < 4 G _is_abelian TrueG _is_nilpotent Trueelse G _is_abelian FalseG _is_nilpotent Falseif n < 5 G _is_solvable Trueelse G _is_solvable FalseG _degree nG _is_transitive TrueG _is_alt Truereturn G
def get_global_aliases return {u'shop' [u'store' u'store_id' u'_store'] u'default_price_value' [u'price' u'original_price' u'originalprice' u'default_price'] u'first_name' [u'firstname'] u'last_name' [u'lastname'] u'street' [u'street_address' u'address_street' u'addr_street' u'address[street]'] u'country' [u'country_id'] u'slug' [u'url_key' u'url'] u'phone' [u'telephone'] u'postal_code' [u'postcode' u'postalcode' u'address_postcode' u'address_postalcode' u'address_postal_code' u'address[postcode]' u'address[postalcode]' u'address[postal_code]']}
def enforce_required_arguments module missing_args []for arg in 'min_size' 'max_size' 'launch_config_name' if module params[arg] is None missing_args append arg if missing_args module fail_json msg 'Missingrequiredargumentsforautoscalinggroupcreate/update %s' % ' ' join missing_args
def _grid_out_property field_name docstring def getter self self _ensure_file if field_name 'length' return self _file get field_name 0 return self _file get field_name None docstring + '\n\nThisattributeisread-only 'return property getter doc docstring
def discard_draft exp_id user_id exp_user_data user_models ExplorationUserDataModel get user_id exp_id if exp_user_data exp_user_data draft_change_list Noneexp_user_data draft_change_list_last_updated Noneexp_user_data draft_change_list_exp_version Noneexp_user_data put
def walk children level 0 path None usename True if level 0 path {}if not children yield path copy return head tail children[0] children[1 ] name func headfor child in func if usename path[name] childelse path[level] childfor child_paths in walk tail level + 1 path usename yield child_paths
def walk children level 0 path None usename True if level 0 path {}if not children yield path copy return head tail children[0] children[1 ] name func headfor child in func if usename path[name] childelse path[level] childfor child_paths in walk tail level + 1 path usename yield child_paths
def source_tmux_files pl args tmux_version None source_tmux_file source_tmux_file tmux_version tmux_version or get_tmux_version pl source_tmux_file os path join TMUX_CONFIG_DIRECTORY u'powerline-base conf' for fname priority in sorted get_tmux_configs tmux_version key lambda v v[1] source_tmux_file fname if not os environ get u'POWERLINE_COMMAND' cmd deduce_command if cmd set_tmux_environment u'POWERLINE_COMMAND' deduce_command remove False try run_tmux_command u'refresh-client' except subprocess CalledProcessError pass
def prompt msg title None text u'' if title is None title msgresult QtWidgets QInputDialog getText active_window msg title QtWidgets QLineEdit Normal text return result[0] result[1]
def synchronize_iterables iterables out_list []iterable_items [ field iter fvals for field fvals in sorted iterables items ]while True cur_dict {}for field iter_values in iterable_items try cur_dict[field] next iter_values except StopIteration passif cur_dict out_list append cur_dict else breakreturn out_list
def synchronize_iterables iterables out_list []iterable_items [ field iter fvals for field fvals in sorted iterables items ]while True cur_dict {}for field iter_values in iterable_items try cur_dict[field] next iter_values except StopIteration passif cur_dict out_list append cur_dict else breakreturn out_list
def SubPlot plot_number rows None cols None rows rows or SUBPLOT_ROWS cols cols or SUBPLOT_COLS pyplot subplot rows cols plot_number
def SubPlot plot_number rows None cols None rows rows or SUBPLOT_ROWS cols cols or SUBPLOT_COLS pyplot subplot rows cols plot_number
def _get_client func @functools wraps func def wrapper context *args **kwargs client api get_registry_client context return func client *args **kwargs return wrapper
def DFS_loop digr node_explored set [] finishing_times []for node in digr nodes if node not in node_explored leader_node nodeinner_DFS digr node node_explored finishing_times return finishing_times
def DFS_loop digr node_explored set [] finishing_times []for node in digr nodes if node not in node_explored leader_node nodeinner_DFS digr node node_explored finishing_times return finishing_times
def wildcards2patterns wildcards return [re compile '^' + wc replace ' ' '\\ ' replace '*' ' *' + '$' for wc in wildcards]
def read_user_choice var_name options if not isinstance options list raise TypeErrorif not options raise ValueErrorchoice_map OrderedDict u'{}' format i value for i value in enumerate options 1 choices choice_map keys default u'1'choice_lines [u'{}-{}' format *c for c in choice_map items ]prompt u'\n' join u'Select{} ' format var_name u'\n' join choice_lines u'Choosefrom{}' format u' ' join choices user_choice click prompt prompt type click Choice choices default default return choice_map[user_choice]
def get_full_file_list file_path_glob file_list []for file_name in glob glob file_path_glob full_file_path os path abspath file_name file_list append full_file_path return file_list
def get_num_hosts multiple_labels exclude_only_if_needed_labels False exclude_atomic_group_hosts False valid_only True **filter_data hosts rpc_utils get_host_query multiple_labels exclude_only_if_needed_labels exclude_atomic_group_hosts valid_only filter_data return hosts count
def display_page request virtual_path page Nonefor page_model in AbstractPage __subclasses__ try page page_model objects live request user get virtual_path virtual_path except ObjectDoesNotExist passif page is None raise Http404if page url return redirect page url template_name 'staticpages/page_display html'if request is_ajax template_name 'staticpages/_body html'ctx {'page' page}return render request template_name ctx
def display_page request virtual_path page Nonefor page_model in AbstractPage __subclasses__ try page page_model objects live request user get virtual_path virtual_path except ObjectDoesNotExist passif page is None raise Http404if page url return redirect page url template_name 'staticpages/page_display html'if request is_ajax template_name 'staticpages/_body html'ctx {'page' page}return render request template_name ctx
def l1_l2_regularizer weight_l1 1 0 weight_l2 1 0 scope None def regularizer tensor with tf name_scope scope 'L1L2Regularizer' [tensor] weight_l1_t tf convert_to_tensor weight_l1 dtype tensor dtype base_dtype name 'weight_l1' weight_l2_t tf convert_to_tensor weight_l2 dtype tensor dtype base_dtype name 'weight_l2' reg_l1 tf multiply weight_l1_t tf reduce_sum tf abs tensor name 'value_l1' reg_l2 tf multiply weight_l2_t tf nn l2_loss tensor name 'value_l2' return tf add reg_l1 reg_l2 name 'value' return regularizer
def pysiphash uint64 assert 0 < uint64 < 1 << 64 if uint64 > 1 << 63 - 1 int64 uint64 - 1 << 64 else int64 uint64uint32 uint64 ^ uint64 >> 32 & 4294967295 if uint32 > 1 << 31 - 1 int32 uint32 - 1 << 32 else int32 uint32return int32 int64
def pysiphash uint64 assert 0 < uint64 < 1 << 64 if uint64 > 1 << 63 - 1 int64 uint64 - 1 << 64 else int64 uint64uint32 uint64 ^ uint64 >> 32 & 4294967295 if uint32 > 1 << 31 - 1 int32 uint32 - 1 << 32 else int32 uint32return int32 int64
def create_snapshot volume_id size 1 metadata None ctxt None **kwargs metadata metadata or {} snap objects Snapshot ctxt or context get_admin_context snap volume_size sizesnap user_id fake USER_IDsnap project_id fake PROJECT_IDsnap volume_id volume_idsnap status 'creating'if metadata is not None snap metadata metadatasnap update kwargs snap create return snap
def ObjectSpecification direct cls return Provides cls direct
def ObjectSpecification direct cls return Provides cls direct
def effective_n_jobs n_jobs -1 backend _ get_active_backend return backend effective_n_jobs n_jobs n_jobs
def effective_n_jobs n_jobs -1 backend _ get_active_backend return backend effective_n_jobs n_jobs n_jobs
def test_arg_of_sigmoid_bad X T matrix Y T nnet softmax X try Z arg_of_sigmoid Y except TypeError returnassert False
def test_arg_of_sigmoid_bad X T matrix Y T nnet softmax X try Z arg_of_sigmoid Y except TypeError returnassert False
def getLoopLayerAppend loopLayers z settings printProgress len loopLayers 'slice' loopLayer euclidean LoopLayer z loopLayers append loopLayer return loopLayer
def getLoopLayerAppend loopLayers z settings printProgress len loopLayers 'slice' loopLayer euclidean LoopLayer z loopLayers append loopLayer return loopLayer
def _generate_noise info cov iir_filter random_state n_samples zi None from scipy signal import lfilternoise_cov pick_channels_cov cov include info['ch_names'] exclude [] if set info['ch_names'] set noise_cov ch_names raise ValueError 'Evokedandcovariancechannelnamesarenotidentical Cannotgeneratethenoisematrix Channelsmissingincovariance%s ' % np setdiff1d info['ch_names'] noise_cov ch_names rng check_random_state random_state c np diag noise_cov data if noise_cov['diag'] else noise_cov data mu_channels np zeros len c with warnings catch_warnings record True noise rng multivariate_normal mu_channels c n_samples Tif iir_filter is not None if zi is None zi np zeros len c len iir_filter - 1 noise zf lfilter [1] iir_filter noise axis -1 zi zi else zf Nonereturn noise zf
def build_nodegraph_args descr None epilog None parser None citations None parser build_graph_args descr descr epilog epilog parser parser citations citations return parser
def CAN_CHANGE_PERMISSIONS article user return _is_staff_for_article article user
def CAN_CHANGE_PERMISSIONS article user return _is_staff_for_article article user
def GetModuleForTypelib typelibCLSID lcid major minor modName GetGeneratedFileName typelibCLSID lcid major minor mod _GetModule modName if '_in_gencache_' not in mod __dict__ AddModuleToCache typelibCLSID lcid major minor assert '_in_gencache_' in mod __dict__ return mod
def FilterFixture fixture None regex ' ' result []regex re compile regex if fixture is None fixture client_fixture VFSfor path attributes in fixture if regex match path result append path attributes return result
def _psql_cmd *args **kwargs user host port maintenance_db password _connection_defaults kwargs get 'user' kwargs get 'host' kwargs get 'port' kwargs get 'maintenance_db' kwargs get 'password' _PSQL_BIN _find_pg_binary 'psql' cmd [_PSQL_BIN '--no-align' '--no-readline' '--no-psqlrc' '--no-password']if user cmd + ['--username' user]if host cmd + ['--host' host]if port cmd + ['--port' str port ]if not maintenance_db maintenance_db 'postgres'cmd extend ['--dbname' maintenance_db] cmd extend args return cmd
def console_pool_get_by_host_type context compute_host proxy_host console_type return IMPL console_pool_get_by_host_type context compute_host proxy_host console_type
def add_local_bypass table chain ipv6 run_iptables_cmd '-t%s-A%s-ptcp-msocket-jRETURN' % table chain ipv6 ipv6 v4_addrs v6_addrs get_interface_addresses for addr in v4_addrs run_iptables_cmd '-t%s-A%s-ptcp-d%s-jRETURN' % table chain addr ipv6 False for addr in v6_addrs run_iptables_cmd '-t%s-A%s-ptcp-d%s-jRETURN' % table chain addr ipv4 False ipv6 ipv6
@pytest fixturedef quickmark_manager_stub stubs stub stubs QuickmarkManagerStub objreg register 'quickmark-manager' stub yield stub objreg delete 'quickmark-manager'
def _get_rabbitmq_plugin rabbitmq __context__ get 'rabbitmq-plugins' if rabbitmq is None version __salt__['pkg version'] 'rabbitmq-server' split '-' [0]rabbitmq '/usr/lib/rabbitmq/lib/rabbitmq_server-{0}/sbin/rabbitmq-plugins' format version __context__['rabbitmq-plugins'] rabbitmqreturn rabbitmq
def _get_rabbitmq_plugin rabbitmq __context__ get 'rabbitmq-plugins' if rabbitmq is None version __salt__['pkg version'] 'rabbitmq-server' split '-' [0]rabbitmq '/usr/lib/rabbitmq/lib/rabbitmq_server-{0}/sbin/rabbitmq-plugins' format version __context__['rabbitmq-plugins'] rabbitmqreturn rabbitmq
def _get_rabbitmq_plugin rabbitmq __context__ get 'rabbitmq-plugins' if rabbitmq is None version __salt__['pkg version'] 'rabbitmq-server' split '-' [0]rabbitmq '/usr/lib/rabbitmq/lib/rabbitmq_server-{0}/sbin/rabbitmq-plugins' format version __context__['rabbitmq-plugins'] rabbitmqreturn rabbitmq
def _get_rabbitmq_plugin rabbitmq __context__ get 'rabbitmq-plugins' if rabbitmq is None version __salt__['pkg version'] 'rabbitmq-server' split '-' [0]rabbitmq '/usr/lib/rabbitmq/lib/rabbitmq_server-{0}/sbin/rabbitmq-plugins' format version __context__['rabbitmq-plugins'] rabbitmqreturn rabbitmq
def info dev if 'sys' in dev qtype 'path'else qtype 'name'cmd 'udevadminfo--export--query all--{0} {1}' format qtype dev udev_result __salt__['cmd run_all'] cmd output_loglevel 'quiet' if udev_result['retcode'] 0 raise CommandExecutionError udev_result['stderr'] return _parse_udevadm_info udev_result['stdout'] [0]
def preload_module *modules for m in modules s 'import%sasx x ' % m Script s 1 len s None completions
def preload_module *modules for m in modules s 'import%sasx x ' % m Script s 1 len s None completions
def preload_module *modules for m in modules s 'import%sasx x ' % m Script s 1 len s None completions
def converge service strategy ConvergenceStrategy changed plan service convergence_plan strategy return service execute_convergence_plan plan timeout 1
def converge service strategy ConvergenceStrategy changed plan service convergence_plan strategy return service execute_convergence_plan plan timeout 1
def setting_list request if not test_user_authenticated request return login request next '/cobbler_web/setting/list' expired True settings remote get_settings skeys settings keys skeys sort results []for k in skeys results append [k settings[k]] t get_template 'settings tmpl' html t render RequestContext request {'settings' results 'version' remote extended_version request session['token'] ['version'] 'username' username} return HttpResponse html
def get_keystone_session **config return Session auth _openstack_auth_from_config **config verify _openstack_verify_from_config **config
def splint a b tck full_output 0 if isinstance tck BSpline if tck c ndim > 1 mesg 'Callingsplint withBSplineobjectswithc ndim>1isnotrecommended UseBSpline integrate instead 'warnings warn mesg DeprecationWarning if full_output 0 mesg 'full_output %sisnotsupported Proceedingasiffull_output 0' % full_output return tck integrate a b extrapolate False else return _impl splint a b tck full_output
@cache_returndef may_be_null_is_nullable repo GIRepository repo require 'GLib' '2 0' 0 info repo find_by_name 'GLib' 'spawn_sync' return not info get_arg 8 may_be_null
def apply_momentum updates params None momentum 0 9 if params is None params updates keys updates OrderedDict updates for param in params value param get_value borrow True velocity theano shared np zeros value shape dtype value dtype broadcastable param broadcastable x momentum * velocity + updates[param] updates[velocity] x - param updates[param] xreturn updates
def notification_handler fn notification_handlers add fn return fn
def mod_watch name **kwargs if kwargs['sfun'] in 'wait' 'run' 'watch' if kwargs get 'stateful' kwargs pop 'stateful' return _reinterpreted_state run name **kwargs return run name **kwargs elif kwargs['sfun'] 'wait_script' or kwargs['sfun'] 'script' if kwargs get 'stateful' kwargs pop 'stateful' return _reinterpreted_state script name **kwargs return script name **kwargs elif kwargs['sfun'] 'wait_call' or kwargs['sfun'] 'call' if kwargs get 'func' func kwargs pop 'func' return call name func **kwargs else return {'name' name 'changes' {} 'comment' 'cmd {0[sfun]}needsanamedparameterfunc' format kwargs 'result' False}return {'name' name 'changes' {} 'comment' 'cmd {0[sfun]}doesnotworkwiththewatchrequisite pleaseusecmd waitorcmd wait_script' format kwargs 'result' False}
def create_virtualenv root run_command ['virtualenv' '--python /usr/bin/python2 7' '--quiet' root path] added_env dict PYTHONDONTWRITEBYTECODE '1' for module_name in virtualenv REQUIRED_MODULES py_base root descendant ['lib' 'python2 7' module_name] py py_base siblingExtension ' py' if py exists and py islink pyc py_base siblingExtension ' pyc' py_target py realpath pyc_target FilePath py_target splitext [0] siblingExtension ' pyc' if pyc exists pyc remove if pyc_target exists pyc_target linkTo pyc return VirtualEnv root root
def get_pull_request_files project num auth False url 'https //api github com/repos/{project}/pulls/{num}/files' format project project num num if auth header make_auth_header else header Nonereturn get_paged_request url headers header
def data_path paths environ None return zipline_path ['data'] + list paths environ environ
def make_auth_cookie app global_conf cookie_name 'PASTE_AUTH_COOKIE' scanlist 'REMOTE_USER' 'REMOTE_SESSION' secret None timeout 30 maxlen 4096 if isinstance scanlist six string_types scanlist scanlist split if secret is None and global_conf get 'secret' secret global_conf['secret']try timeout int timeout except ValueError raise ValueError 'Badvaluefortimeout mustbeint %r' % timeout try maxlen int maxlen except ValueError raise ValueError 'Badvalueformaxlen mustbeint %r' % maxlen return AuthCookieHandler app cookie_name cookie_name scanlist scanlist secret secret timeout timeout maxlen maxlen
def get_credential_sets global _credential_set2global _credential_set1if _credential_set1 is None _credential_set1 CredentialSet create _credential_set2 CredentialSet create return _credential_set1 _credential_set2
def OpenDocumentSpreadsheet doc OpenDocument 'application/vnd oasis opendocument spreadsheet' doc spreadsheet Spreadsheet doc body addElement doc spreadsheet return doc
def convert_from_bcd bcd place decimal 1 0 while bcd > 0 nibble bcd & 15 decimal + nibble * place bcd >> 4place * 10return decimal
def convert_from_bcd bcd place decimal 1 0 while bcd > 0 nibble bcd & 15 decimal + nibble * place bcd >> 4place * 10return decimal
def _convert_range_to_list tgt range_server r seco range Range range_server try return r expand tgt except seco range RangeException as err log error 'Rangeserverexception {0}' format err return []
def extract_link_from_link_header http_response header_name header_value re_match LINK_HEADER_RE search header_value if re_match try url_str re_match group 1 except IndexError raise StopIterationif not url_str raise StopIterationtry yield http_response get_url url_join url_str except ValueError msg 'Theapplicationsenta"%s"headerthatw3affailedtocorrectlyparseasanURL theheadervaluewas "%s"'om out debug msg % header_name header_value
def kmap registry xml_parent data kmap XML SubElement xml_parent 'org jenkinsci plugins KmapJenkinsBuilder' kmap set 'plugin' 'kmap-jenkins' publish data get 'publish-optional' False mapping [ 'username' 'username' None 'password' 'password' None 'url' 'kmapClient' None 'categories' 'categories' None 'file-path' 'filePath' None 'app-name' 'appName' None 'bundle' 'bundle' '' 'version' 'version' None 'description' 'description' '' 'icon-path' 'iconPath' '' ]convert_mapping_to_xml kmap data mapping fail_required True if publish is True publish_optional XML SubElement kmap 'publishOptional' publish_mapping [ 'groups' 'teams' '' 'users' 'users' '' 'notify-users' 'sendNotifications' False ]convert_mapping_to_xml publish_optional data publish_mapping fail_required True
def kmap registry xml_parent data kmap XML SubElement xml_parent 'org jenkinsci plugins KmapJenkinsBuilder' kmap set 'plugin' 'kmap-jenkins' publish data get 'publish-optional' False mapping [ 'username' 'username' None 'password' 'password' None 'url' 'kmapClient' None 'categories' 'categories' None 'file-path' 'filePath' None 'app-name' 'appName' None 'bundle' 'bundle' '' 'version' 'version' None 'description' 'description' '' 'icon-path' 'iconPath' '' ]convert_mapping_to_xml kmap data mapping fail_required True if publish is True publish_optional XML SubElement kmap 'publishOptional' publish_mapping [ 'groups' 'teams' '' 'users' 'users' '' 'notify-users' 'sendNotifications' False ]convert_mapping_to_xml publish_optional data publish_mapping fail_required True
def decode txt _nid NameID for part in txt split ' ' if part find ' ' -1 i val part split ' ' try setattr _nid ATTR[int i ] unquote val except passreturn _nid
def decode txt _nid NameID for part in txt split ' ' if part find ' ' -1 i val part split ' ' try setattr _nid ATTR[int i ] unquote val except passreturn _nid
@register inclusion_tag u'generic/includes/disqus_sso html' takes_context True def disqus_sso_script context settings context[u'settings']public_key getattr settings u'COMMENTS_DISQUS_API_PUBLIC_KEY' u'' secret_key getattr settings u'COMMENTS_DISQUS_API_SECRET_KEY' u'' user context[u'request'] userif public_key and secret_key and user is_authenticated context[u'public_key'] public_keycontext[u'sso_data'] _get_disqus_sso user public_key secret_key return context
@register inclusion_tag u'generic/includes/disqus_sso html' takes_context True def disqus_sso_script context settings context[u'settings']public_key getattr settings u'COMMENTS_DISQUS_API_PUBLIC_KEY' u'' secret_key getattr settings u'COMMENTS_DISQUS_API_SECRET_KEY' u'' user context[u'request'] userif public_key and secret_key and user is_authenticated context[u'public_key'] public_keycontext[u'sso_data'] _get_disqus_sso user public_key secret_key return context
@register inclusion_tag u'generic/includes/disqus_sso html' takes_context True def disqus_sso_script context settings context[u'settings']public_key getattr settings u'COMMENTS_DISQUS_API_PUBLIC_KEY' u'' secret_key getattr settings u'COMMENTS_DISQUS_API_SECRET_KEY' u'' user context[u'request'] userif public_key and secret_key and user is_authenticated context[u'public_key'] public_keycontext[u'sso_data'] _get_disqus_sso user public_key secret_key return context
def extract_param_list params prefix '' key_re re compile '%s\\ member\\ [0-9]+ \\ * ' % prefix def get_param_data params for param_name value in params items match key_re match param_name if match try index int match group 1 except ValueError passelse key match group 2 yield index key value def key_func d return d[0]data sorted get_param_data params key key_func members itertools groupby data key_func return [dict kv for di kv in m for mi m in members]
def get_attr data attribute None if not attribute raise errors AnsibleFilterError ' failedexpectsattributetobeset' ptr datafor attr in attribute split ' ' if attr in ptr ptr ptr[attr]else ptr Nonebreakreturn ptr
def test_lex_mangling_hyphen entry tokenize 'foo-bar' assert entry [HySymbol 'foo_bar' ] entry tokenize '-' assert entry [HySymbol '-' ]
def test_lex_mangling_hyphen entry tokenize 'foo-bar' assert entry [HySymbol 'foo_bar' ] entry tokenize '-' assert entry [HySymbol '-' ]
def stub_out_glanceclient_create stubs sent_to_glance orig_add_image glanceclient v1 images ImageManager createdef fake_create context metadata data None sent_to_glance['metadata'] metadatasent_to_glance['data'] datareturn orig_add_image metadata data stubs Set glanceclient v1 images ImageManager 'create' fake_create
def stub_out_glanceclient_create stubs sent_to_glance orig_add_image glanceclient v1 images ImageManager createdef fake_create context metadata data None sent_to_glance['metadata'] metadatasent_to_glance['data'] datareturn orig_add_image metadata data stubs Set glanceclient v1 images ImageManager 'create' fake_create
def populate_filter_properties filter_properties host_state if isinstance host_state dict host host_state['host']nodename host_state['nodename']limits host_state['limits']else host host_state hostnodename host_state nodenamelimits host_state limits_add_retry_host filter_properties host nodename if not filter_properties get 'force_hosts' filter_properties['limits'] limits
def populate_filter_properties filter_properties host_state if isinstance host_state dict host host_state['host']nodename host_state['nodename']limits host_state['limits']else host host_state hostnodename host_state nodenamelimits host_state limits_add_retry_host filter_properties host nodename if not filter_properties get 'force_hosts' filter_properties['limits'] limits
def check_conversion condition message if not condition raise InvalidConversionError message
def _generate_failed_chall_msg failed_achalls error failed_achalls[0] errortyp error typif messages is_acme_error error typ error codemsg ['Thefollowingerrorswerereportedbytheserver ']for achall in failed_achalls msg append '\n\nDomain %s\nType %s\nDetail %s' % achall domain typ achall error detail if typ in _ERROR_HELP msg append '\n\n' msg append _ERROR_HELP[typ] return '' join msg
def get_region service region profile _ region _ _ _get_profile service region None None profile return region
@register inclusion_tag 'downloads/templatetags/os_release_files html' def os_release_files release os_slug return {'release' release 'files' release files_for_os os_slug }
@pytest fixture scope u'session' def celery_worker_parameters return {}
def pack_unit value pack np zeros value shape + 4 dtype np ubyte for i in range 4 value pack[ i] np modf value * 256 0 return pack
def _write_cron_lines user lines path salt utils files mkstemp if _check_instance_uid_match user or __grains__ get 'os_family' in 'Solaris' 'AIX' with salt utils fpopen path 'w+' uid __salt__['file user_to_uid'] user mode 384 as fp_ fp_ writelines lines ret __salt__['cmd run_all'] _get_cron_cmdstr path runas user python_shell False else with salt utils fpopen path 'w+' mode 384 as fp_ fp_ writelines lines ret __salt__['cmd run_all'] _get_cron_cmdstr path user python_shell False os remove path return ret
def test_mixed_newstyle_oldstyle_init class foo def __init__ self self x 3class bar foo def __init__ self self x 4class baz foo passclass ns object passclass full bar baz ns passa full AreEqual a x 4 class full bar baz ns def __init__ self self x 5a full AreEqual a x 5 class ns object def __init__ self self x 6class full bar baz ns passa full AreEqual a x 4
def running return salt utils minion running __opts__
def process_bezout_output poly_seq x L poly_seq[ ]d degree L[1] x i 2while i < len L d_i degree L[i] x if d_i < 0 L remove L[i] i i - 1 if d d_i L remove L[i] i i - 1 if d_i > 0 d d_ii i + 1 return L
def stripFormatting text formatted parseFormattedText text return _textattributes flatten formatted _textattributes DefaultFormattingState
def pytest_addoption parser parser addoption '--all' action 'store_true' help 'runalltests' parser addoption '--device_id' type int default 0 help 'GPUdevicetouse' return
def pytest_addoption parser parser addoption '--all' action 'store_true' help 'runalltests' parser addoption '--device_id' type int default 0 help 'GPUdevicetouse' return
def pytest_addoption parser parser addoption '--all' action 'store_true' help 'runalltests' parser addoption '--device_id' type int default 0 help 'GPUdevicetouse' return
def load_key_bindings get_search_state None enable_abort_and_exit_bindings False enable_system_bindings False enable_search False enable_open_in_editor False enable_extra_page_navigation False enable_auto_suggest_bindings False assert get_search_state is None or callable get_search_state enable_abort_and_exit_bindings to_cli_filter enable_abort_and_exit_bindings enable_system_bindings to_cli_filter enable_system_bindings enable_search to_cli_filter enable_search enable_open_in_editor to_cli_filter enable_open_in_editor enable_extra_page_navigation to_cli_filter enable_extra_page_navigation enable_auto_suggest_bindings to_cli_filter enable_auto_suggest_bindings registry MergedRegistry [load_basic_bindings load_mouse_bindings ConditionalRegistry load_abort_and_exit_bindings enable_abort_and_exit_bindings ConditionalRegistry load_basic_system_bindings enable_system_bindings load_emacs_bindings ConditionalRegistry load_emacs_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_emacs_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_emacs_system_bindings enable_system_bindings ConditionalRegistry load_extra_emacs_page_navigation_bindings enable_extra_page_navigation load_vi_bindings get_search_state get_search_state ConditionalRegistry load_vi_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_vi_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_vi_system_bindings enable_system_bindings ConditionalRegistry load_extra_vi_page_navigation_bindings enable_extra_page_navigation ConditionalRegistry load_auto_suggestion_bindings enable_auto_suggest_bindings ] return registry
def load_key_bindings get_search_state None enable_abort_and_exit_bindings False enable_system_bindings False enable_search False enable_open_in_editor False enable_extra_page_navigation False enable_auto_suggest_bindings False assert get_search_state is None or callable get_search_state enable_abort_and_exit_bindings to_cli_filter enable_abort_and_exit_bindings enable_system_bindings to_cli_filter enable_system_bindings enable_search to_cli_filter enable_search enable_open_in_editor to_cli_filter enable_open_in_editor enable_extra_page_navigation to_cli_filter enable_extra_page_navigation enable_auto_suggest_bindings to_cli_filter enable_auto_suggest_bindings registry MergedRegistry [load_basic_bindings load_mouse_bindings ConditionalRegistry load_abort_and_exit_bindings enable_abort_and_exit_bindings ConditionalRegistry load_basic_system_bindings enable_system_bindings load_emacs_bindings ConditionalRegistry load_emacs_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_emacs_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_emacs_system_bindings enable_system_bindings ConditionalRegistry load_extra_emacs_page_navigation_bindings enable_extra_page_navigation load_vi_bindings get_search_state get_search_state ConditionalRegistry load_vi_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_vi_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_vi_system_bindings enable_system_bindings ConditionalRegistry load_extra_vi_page_navigation_bindings enable_extra_page_navigation ConditionalRegistry load_auto_suggestion_bindings enable_auto_suggest_bindings ] return registry
def load_key_bindings get_search_state None enable_abort_and_exit_bindings False enable_system_bindings False enable_search False enable_open_in_editor False enable_extra_page_navigation False enable_auto_suggest_bindings False assert get_search_state is None or callable get_search_state enable_abort_and_exit_bindings to_cli_filter enable_abort_and_exit_bindings enable_system_bindings to_cli_filter enable_system_bindings enable_search to_cli_filter enable_search enable_open_in_editor to_cli_filter enable_open_in_editor enable_extra_page_navigation to_cli_filter enable_extra_page_navigation enable_auto_suggest_bindings to_cli_filter enable_auto_suggest_bindings registry MergedRegistry [load_basic_bindings load_mouse_bindings ConditionalRegistry load_abort_and_exit_bindings enable_abort_and_exit_bindings ConditionalRegistry load_basic_system_bindings enable_system_bindings load_emacs_bindings ConditionalRegistry load_emacs_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_emacs_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_emacs_system_bindings enable_system_bindings ConditionalRegistry load_extra_emacs_page_navigation_bindings enable_extra_page_navigation load_vi_bindings get_search_state get_search_state ConditionalRegistry load_vi_open_in_editor_bindings enable_open_in_editor ConditionalRegistry load_vi_search_bindings get_search_state get_search_state enable_search ConditionalRegistry load_vi_system_bindings enable_system_bindings ConditionalRegistry load_extra_vi_page_navigation_bindings enable_extra_page_navigation ConditionalRegistry load_auto_suggestion_bindings enable_auto_suggest_bindings ] return registry
def find_tex_file filename format None cmd [str u'kpsewhich' ]if format is not None cmd + [ u'--format ' + format ]cmd + [filename]matplotlib verbose report u'find_tex_file %s %s' % filename cmd u'debug' pipe subprocess Popen cmd stdout subprocess PIPE stderr subprocess PIPE result pipe communicate [0] rstrip matplotlib verbose report u'find_tex_fileresult %s' % result u'debug' return result decode u'ascii'
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def inject_create_tags event_name class_attributes **kwargs class_attributes['create_tags'] create_tags
def dispatch_by_operation entity_type entity operation try index index_for entity_type if operation model domain_object DomainObjectOperation new index insert_dict entity elif operation model domain_object DomainObjectOperation changed index update_dict entity elif operation model domain_object DomainObjectOperation deleted index remove_dict entity else log warn 'Unknownoperation %s' % operation except Exception as ex log exception ex raise
def __virtual__ if HAS_DEPS return Truereturn False
def _insert_header network_str incomings outgoings line_1 deque [] if incomings line_1 append 'In-->' line_1 append 'Layer' if outgoings line_1 append '-->Out' line_1 append 'Description' line_2 deque [] if incomings line_2 append '-------' line_2 append '-----' if outgoings line_2 append '-------' line_2 append '-----------' network_str appendleft line_2 network_str appendleft line_1 return network_str
def save_session l filename with open filename 'w' as fd fd write dumps l -1
def survey_getPriorityQuestionForSeries series_id template_rec survey_getTemplateFromSeries series_id if template_rec None priority_question_code template_rec['priority_qstn']question survey_getQuestionFromCode priority_question_code series_id return questionelse return None
def _label_all rag attr_name node rag nodes [0]new_label rag node[node]['labels'][0]for n d in rag nodes_iter data True d[attr_name] new_label
def _label_all rag attr_name node rag nodes [0]new_label rag node[node]['labels'][0]for n d in rag nodes_iter data True d[attr_name] new_label
def get_server_id if salt utils is_proxy return {}return {'server_id' abs hash __opts__ get 'id' '' % 2 ** 31 }
def gidFromString gidString try return int gidString except ValueError if grp is None raisereturn grp getgrnam gidString [2]
def custom_model *args **kwargs fit_deriv kwargs get u'fit_deriv' None if len args 1 and six callable args[0] return _custom_model_wrapper args[0] fit_deriv fit_deriv elif not args return functools partial _custom_model_wrapper fit_deriv fit_deriv else raise TypeError u'{0}takesatmostonepositionalargument thecallable/functiontobeturnedintoamodel Whenusedasadecoratoritshouldbepassedkeywordargumentsonly ifany ' format __name__
def _audioTimeCallback event movieInstanceRef streamPlayer if movieInstanceRef tm - event u new_time / 1000 0 movieInstanceRef _audio_stream_clock reset tm
def _audioTimeCallback event movieInstanceRef streamPlayer if movieInstanceRef tm - event u new_time / 1000 0 movieInstanceRef _audio_stream_clock reset tm
def nti distmat marginals group iters group_marginals [marginals index i for i in group]mn_y_obs mntd reduce_mtx distmat group_marginals mn_y_n sd_y_n random_mntd distmat len group_marginals iters if abs sd_y_n < 1e-05 raise ValueError 'Thestandarddeviationofthemeansoftherandom' + 'drawsfromthedistancematrixwaslessthan 00001 Thisis' + 'likelydotoaphylogenywithdistancestoalltipsequal ' + 'ThisphylogenyisnotsuitableforNRI/NTIanalysis ' return -1 0 * mn_y_obs - mn_y_n / sd_y_n
def geoexplorer bing_key settings get_gis_api_bing google_key settings get_gis_api_google yahoo_key settings get_gis_api_yahoo print_service settings get_gis_print_service geoserver_url settings get_gis_geoserver_url response title 'GeoExplorer'return dict bing_key bing_key google_key google_key yahoo_key yahoo_key print_service print_service geoserver_url geoserver_url
def master_event type master None event_map {'connected' '__master_connected' 'disconnected' '__master_disconnected' 'failback' '__master_failback' 'alive' '__master_alive'}if type 'alive' and master is not None return '{0}_{1}' format event_map get type master return event_map get type None
def master_event type master None event_map {'connected' '__master_connected' 'disconnected' '__master_disconnected' 'failback' '__master_failback' 'alive' '__master_alive'}if type 'alive' and master is not None return '{0}_{1}' format event_map get type master return event_map get type None
def master_event type master None event_map {'connected' '__master_connected' 'disconnected' '__master_disconnected' 'failback' '__master_failback' 'alive' '__master_alive'}if type 'alive' and master is not None return '{0}_{1}' format event_map get type master return event_map get type None
def migration_get_by_id_and_instance context migration_id instance_uuid return IMPL migration_get_by_id_and_instance context migration_id instance_uuid
def guess_lexer _text **options best_lexer [0 0 None]for lexer in _iter_lexerclasses rv lexer analyse_text _text if rv 1 0 return lexer **options if rv > best_lexer[0] best_lexer[ ] rv lexer if not best_lexer[0] or best_lexer[1] is None raise ClassNotFound 'nolexermatchingthetextfound' return best_lexer[1] **options
def _convert_colors colors to_rgb mpl colors colorConverter to_rgbif isinstance colors pd DataFrame return pd DataFrame {col colors[col] map to_rgb for col in colors} elif isinstance colors pd Series return colors map to_rgb else try to_rgb colors[0] return list map to_rgb colors except ValueError return [list map to_rgb l for l in colors]
@anonymous_csrf@mobile_template 'questions/{mobile/}marketplace_developer_request html' def marketplace_developer_request request template error_message Noneif request method 'GET' form MarketplaceDeveloperRequestForm request user else form MarketplaceDeveloperRequestForm request user request POST if form is_valid try form submit_ticket return HttpResponseRedirect reverse 'questions marketplace_aaq_success' except ZendeskError error_message ZENDESK_ERROR_MESSAGEreturn render request template {'form' form 'error_message' error_message}
def RGS_enum m if m < 1 return 0elif m 1 return 1else return bell m
def RGS_enum m if m < 1 return 0elif m 1 return 1else return bell m
def dnsdomain_get_all context return IMPL dnsdomain_get_all context
def getDocBlockRegion view point start end pointwhile start > 0 and view scope_name start - 1 find 'comment block' > -1 start start - 1 while end < view size and view scope_name end find 'comment block' > -1 end end + 1 return sublime Region start end
def setup hass config hass states set 'hello_world Hello_World' 'Works ' return True
def _tmp_access_rule method ip None ttl None port None direction 'in' port_origin 'd' ip_origin 'd' comment '' if _status_csf if ip is None return {'error' 'YoumustsupplyanipaddressorCIDR '}if ttl is None return {'error' 'Youmustsupplyattl '}args _build_tmp_access_args method ip ttl port direction comment return __csf_cmd args
def compare_medians_ms group_1 group_2 axis None med_1 med_2 ma median group_1 axis axis ma median group_2 axis axis std_1 std_2 mstats stde_median group_1 axis axis mstats stde_median group_2 axis axis W np abs med_1 - med_2 / ma sqrt std_1 ** 2 + std_2 ** 2 return 1 - norm cdf W
def _mkdir newdir if os path isdir newdir passelif os path isfile newdir raise OSError "afilewiththesamenameasthedesireddir '%s' alreadyexists " % newdir else head tail os path split newdir if head and not os path isdir head _mkdir head if tail os mkdir newdir
def get_unique_name check prefix '' suffix '' length None skip None if length _name '_' join [_ for _ in prefix '%s' suffix if _] for _ in xrange 1000 name _name % generate_random_string length if check name return nameelse _name '_' join [_ for _ in prefix '%s' suffix if _] for i in xrange skip skip + 1000 name _name % i if check name return nameraise StopIteration 'Failtogetuniquenamein1000iterations %s ' % _name
def _make_streaming_request sample language_code max_alternatives profanity_filter speech_context single_utterance interim_results config RecognitionConfig encoding sample encoding sample_rate sample sample_rate language_code language_code max_alternatives max_alternatives profanity_filter profanity_filter speech_context speech_context streaming_config StreamingRecognitionConfig config config single_utterance single_utterance interim_results interim_results config_request StreamingRecognizeRequest streaming_config streaming_config return config_request
@_ec_dispatcher dispatch_for ops MigrationScript def _migration_script_ops context directive phase version_path cli _get_version_branch_path context config release cli CURRENT_RELEASE branch phase autogen_kwargs {}cli _check_bootstrap_new_branch phase version_path autogen_kwargs op ops MigrationScript new_rev_id ops UpgradeOps ops [d for d in _assign_directives context directive upgrade_ops ops phase ] ops DowngradeOps ops [] message directive message **autogen_kwargs if not op upgrade_ops is_empty return op
def handshake_in_memory client_conn server_conn client_conn set_connect_state server_conn set_accept_state for conn in [client_conn server_conn] try conn do_handshake except WantReadError passinteract_in_memory client_conn server_conn
def handshake_in_memory client_conn server_conn client_conn set_connect_state server_conn set_accept_state for conn in [client_conn server_conn] try conn do_handshake except WantReadError passinteract_in_memory client_conn server_conn
def median_high name num minimum 0 maximum 0 ref None return calc name num 'median_high' ref
@np deprecate new_name 'expm' def expm2 A A _asarray_square A t A dtype charif t not in ['f' 'F' 'd' 'D'] A A astype 'd' t 'd' s vr eig A vri inv vr r dot dot vr diag exp s vri if t in ['f' 'd'] return r real astype t else return r astype t
def test_cmp a frozenset [1 2] b set [1 2] abig frozenset [1 2 3] bbig set [1 2 3] AreEqual cmp a b 0 AreEqual cmp a bbig -1 AreEqual cmp abig b 1 class sset set passclass fset frozenset passa fset [1 2] b sset [1 2] abig fset [1 2 3] bbig sset [1 2 3] AreEqual cmp a b 0 AreEqual cmp a bbig -1 AreEqual cmp abig b 1
def _do_inf_pots mri_rr bem_rr mri_Q sol bounds np concatenate [np arange 0 len mri_rr 200 [len mri_rr ]] B np empty len mri_rr * 3 sol shape[1] for bi in range len bounds - 1 v0s _bem_inf_pots mri_rr[bounds[bi] bounds[ bi + 1 ]] bem_rr mri_Q v0s shape v0s shape[0] * 3 v0s shape[2] B[ 3 * bounds[bi] 3 * bounds[ bi + 1 ] ] np dot v0s sol return B
def _resolve_document request docid permission 'base change_resourcebase' msg _PERMISSION_MSG_GENERIC **kwargs return resolve_object request Document {'pk' docid} permission permission permission_msg msg **kwargs
def read_json fh byteorder dtype count data fh read count try return json loads unicode stripnull data 'utf-8' except ValueError warnings warn "invalidJSON'%s'" % data
def popup_inputbox title text par_widget h2 1w2 par_widget width * 6 // 7 x par_widget width - w2 // 2 - 1 + par_widget x y par_widget height - h2 // 2 - 1 + par_widget y borders curses newwin h2 + 2 w2 + 2 y x borders border borders addstr 0 w2 - len title // 2 '%s' % title borders refresh return inputbox text x + 1 y + 1 w2 h2
def popup_inputbox title text par_widget h2 1w2 par_widget width * 6 // 7 x par_widget width - w2 // 2 - 1 + par_widget x y par_widget height - h2 // 2 - 1 + par_widget y borders curses newwin h2 + 2 w2 + 2 y x borders border borders addstr 0 w2 - len title // 2 '%s' % title borders refresh return inputbox text x + 1 y + 1 w2 h2
def locate_config apache_ctl try proc subprocess Popen [apache_ctl '-V'] stdout subprocess PIPE stderr subprocess PIPE output _ proc communicate except OSError sys exit _NO_APACHECTL server_root config_file ''for line in output splitlines if 'HTTPD_ROOT' in line server_root line[ line find '"' + 1 -1 ]elif 'SERVER_CONFIG_FILE' in line config_file line[ line find '"' + 1 -1 ]if not server_root and config_file sys exit 'UnabletolocateApacheconfiguration Pleaserunthisscriptagainandspecify--server-rootand--config-file' return server_root config_file
def locate_config apache_ctl try proc subprocess Popen [apache_ctl '-V'] stdout subprocess PIPE stderr subprocess PIPE output _ proc communicate except OSError sys exit _NO_APACHECTL server_root config_file ''for line in output splitlines if 'HTTPD_ROOT' in line server_root line[ line find '"' + 1 -1 ]elif 'SERVER_CONFIG_FILE' in line config_file line[ line find '"' + 1 -1 ]if not server_root and config_file sys exit 'UnabletolocateApacheconfiguration Pleaserunthisscriptagainandspecify--server-rootand--config-file' return server_root config_file
def locate_config apache_ctl try proc subprocess Popen [apache_ctl '-V'] stdout subprocess PIPE stderr subprocess PIPE output _ proc communicate except OSError sys exit _NO_APACHECTL server_root config_file ''for line in output splitlines if 'HTTPD_ROOT' in line server_root line[ line find '"' + 1 -1 ]elif 'SERVER_CONFIG_FILE' in line config_file line[ line find '"' + 1 -1 ]if not server_root and config_file sys exit 'UnabletolocateApacheconfiguration Pleaserunthisscriptagainandspecify--server-rootand--config-file' return server_root config_file
def isBPFSocket obj return isinstance obj L2bpfListenSocket or isinstance obj L2bpfListenSocket or isinstance obj L3bpfSocket
def fake_team db teamowner teamname None isapproved [True False]productorservice ['Product' 'Service']if teamname is None teamname faker first_name + fake_text_id 3 ctime teamowner ctime + datetime timedelta days 7 try teamslug slugize teamname homepage 'http //www example org/' + fake_text_id 3 insert_fake_data db 'teams' slug teamslug slug_lower teamslug lower name teamname homepage homepage ctime ctime product_or_service random sample productorservice 1 [0] onboarding_url homepage + '/contributing' owner teamowner username is_approved random sample isapproved 1 [0] receiving 0 1 nreceiving_from 3 except IntegrityError InvalidTeamName return fake_team db teamowner return Team from_slug teamslug
def pop_from_stack_section args if len args 0 return ''parts []for idx in xrange len args parts append 'self->arg%d self->arguments_stack[self->deeplevel "arg%d"] \n DCTB self->arguments_stack[self->deeplevel "arg%d"] 0 ' % idx idx idx parts append '--self->deeplevel ' return '\n DCTB ' + '\n DCTB ' join parts
@with_config DEBUG True ASSETS_DEBUG True def test_no_output_no_merge bundle_to_joblist Bundle 's1' 's2'
def cat_extract tar member targetpath assert member isreg targetpath targetpath rstrip '/' targetpath targetpath replace '/' os sep upperdirs os path dirname targetpath if upperdirs and not os path exists upperdirs try os makedirs upperdirs except EnvironmentError as e if e errno errno EEXIST passelse raisewith files DeleteOnError targetpath as dest with pipeline get_cat_pipeline pipeline PIPE dest f as pl fp tar extractfile member copyfileobj copyfileobj fp pl stdin if sys version_info < 3 5 tar chown member targetpath else tar chown member targetpath False tar chmod member targetpath tar utime member targetpath
def _url_replace_regex prefix return u'\n ?x #flags re VERBOSE\n ?P<quote>\\\\?[\'"] #theopeningquotes\n ?P<prefix>{prefix} #theprefix\n ?P<rest> *? #everythingelseintheurl\n ?P quote #thefirstmatchingclosingquote\n' format prefix prefix
def _url_replace_regex prefix return u'\n ?x #flags re VERBOSE\n ?P<quote>\\\\?[\'"] #theopeningquotes\n ?P<prefix>{prefix} #theprefix\n ?P<rest> *? #everythingelseintheurl\n ?P quote #thefirstmatchingclosingquote\n' format prefix prefix
def recreate_image codebook labels w h d codebook shape[1]image np zeros w h d label_idx 0for i in range w for j in range h image[i][j] codebook[labels[label_idx]]label_idx + 1return image
def try_using parallel_type def print_number number '\nSimplefunctiontogiveasimpletasktoexecute \n'print numberif parallel_type 'multiprocessing' from multiprocessing import Process as Bucketelif parallel_type 'threading' from threading import Thread as Bucketqueue Queue Queue jobs JobQueue 5 queue jobs _debug Truefor x in range 20 jobs append Bucket target print_number args [x] kwargs {} jobs close jobs run
def dynamic_choice_scriptler_param registry xml_parent data dynamic_scriptler_param_common registry xml_parent data 'ScriptlerChoiceParameterDefinition'
@contextmanagerdef _wrap_ptyprocess_err try yield except ptyprocess PtyProcessError as e raise ExceptionPexpect *e args
@contextmanagerdef _wrap_ptyprocess_err try yield except ptyprocess PtyProcessError as e raise ExceptionPexpect *e args
def write_latest_release_file filename '_latest_release rst'template " orphan \n\n SomecommonreStructuredTextsubstitutions \n\n**Thisfileisautogenerated **Sodon'tedititbyhand \n\nYoucanincludethisfileatthetopofyour``* rst``filewithaline\nlike \n\n include {filename}\n\nThenusethesubstitutionsinthisfile e g \n\n latest_release_version \n\n latest_release_tag replace {latest_tag}\n latest_release_version replace {latest_version}\n latest_package_name_precise replace {package_name_precise}\n latest_package_name_trusty replace {package_name_trusty}\n\n"open filename 'w' write template format filename filename latest_tag latest_release_tag latest_version latest_release_version package_name_precise latest_package_name 'precise' package_name_trusty latest_package_name 'trusty'
def write_latest_release_file filename '_latest_release rst'template " orphan \n\n SomecommonreStructuredTextsubstitutions \n\n**Thisfileisautogenerated **Sodon'tedititbyhand \n\nYoucanincludethisfileatthetopofyour``* rst``filewithaline\nlike \n\n include {filename}\n\nThenusethesubstitutionsinthisfile e g \n\n latest_release_version \n\n latest_release_tag replace {latest_tag}\n latest_release_version replace {latest_version}\n latest_package_name_precise replace {package_name_precise}\n latest_package_name_trusty replace {package_name_trusty}\n\n"open filename 'w' write template format filename filename latest_tag latest_release_tag latest_version latest_release_version package_name_precise latest_package_name 'precise' package_name_trusty latest_package_name 'trusty'
def write_latest_release_file filename '_latest_release rst'template " orphan \n\n SomecommonreStructuredTextsubstitutions \n\n**Thisfileisautogenerated **Sodon'tedititbyhand \n\nYoucanincludethisfileatthetopofyour``* rst``filewithaline\nlike \n\n include {filename}\n\nThenusethesubstitutionsinthisfile e g \n\n latest_release_version \n\n latest_release_tag replace {latest_tag}\n latest_release_version replace {latest_version}\n latest_package_name_precise replace {package_name_precise}\n latest_package_name_trusty replace {package_name_trusty}\n\n"open filename 'w' write template format filename filename latest_tag latest_release_tag latest_version latest_release_version package_name_precise latest_package_name 'precise' package_name_trusty latest_package_name 'trusty'
def connectWS factory contextFactory None timeout 30 bindAddress None if hasattr factory 'reactor' reactor factory reactorelse from twisted internet import reactorif factory isSecure if contextFactory is None from twisted internet import sslcontextFactory ssl ClientContextFactory if factory proxy is not None factory contextFactory contextFactoryconn reactor connectTCP factory proxy[u'host'] factory proxy[u'port'] factory timeout bindAddress elif factory isSecure conn reactor connectSSL factory host factory port factory contextFactory timeout bindAddress else conn reactor connectTCP factory host factory port factory timeout bindAddress return conn
def quantize t quant_scale max_value 1 0 t tf minimum max_value tf maximum t - max_value big quant_scale * t + max_value + 0 5 with tf get_default_graph gradient_override_map {'Floor' 'CustomIdG'} res tf floor big / quant_scale - max_value return res
def delete_table dataset_name table_name project None bigquery_client bigquery Client project project dataset bigquery_client dataset dataset_name table dataset table table_name table delete print 'Table{} {}deleted ' format dataset_name table_name
def survey_getAllWidgetsForTemplate template_id s3db current s3dbqltable s3db survey_question_listqtable s3db survey_questionquery qltable template_id template_id & qltable question_id qtable id rows current db query select qtable id qtable code qtable type qltable posn widgets {}for row in rows sqrow row survey_questionqstn_type sqrow typeqstn_id sqrow idqstn_code sqrow codeqstn_posn row survey_question_list posnwidget_obj survey_question_type[qstn_type] qstn_id widgets[qstn_code] widget_objwidget_obj question['posn'] qstn_posnreturn widgets
def get_docker_client cluster address def get_path name return cluster certificates_path child name pathtls TLSConfig client_cert get_path 'user crt' get_path 'user key' ssl_version ssl PROTOCOL_TLSv1 assert_hostname False verify get_path 'cluster crt' return dockerpy_client base_url 'https //{} {}' format address DOCKER_PORT tls tls timeout 100 version '1 21'
def load_file location with open location as f s f read return load s
@register u'transpose-chars' def transpose_chars event b event current_bufferp b cursor_positionif p 0 returnelif p len b text or b text[p] u'\n' b swap_characters_before_cursor else b cursor_position + b document get_cursor_right_position b swap_characters_before_cursor
def import_image uuid verbose False ret {}imgadm _check_imgadm cmd '{0}import{1}' format imgadm uuid res __salt__['cmd run_all'] cmd python_shell False retcode res['retcode']if retcode 0 ret['Error'] _exit_status retcode return retreturn {uuid _parse_image_meta get uuid verbose }
def clebsch_gordan j_1 j_2 j_3 m_1 m_2 m_3 res -1 ** sympify j_1 - j_2 + m_3 * sqrt 2 * j_3 + 1 * wigner_3j j_1 j_2 j_3 m_1 m_2 - m_3 return res
def parse_host hostname hostname hostname strip if host_is_ipv6 hostname return hostname split '] ' 1 [0] strip '[]' else return hostname split ' ' 1 [0]
def _get_xunit_setup_teardown holder attr_name param_obj None param_obj param_obj if param_obj is not None else holder result _get_xunit_func holder attr_name if result is not None arg_count result __code__ co_argcountif inspect ismethod result arg_count - 1if arg_count return lambda result param_obj else return result
@preloaderPausedef GetUserCredentials try login Nonepassword Noneif login is None login rawInput 'Login ' if password is None password rawInput 'Password ' True except KeyboardInterrupt SystemExit as e if e message tools exit e message else tools exitreturn login password
def cross_entropy_loss logits one_hot_labels label_smoothing 0 weight 1 0 scope None logits get_shape assert_is_compatible_with one_hot_labels get_shape with tf name_scope scope 'CrossEntropyLoss' [logits one_hot_labels] num_classes one_hot_labels get_shape [ -1 ] valueone_hot_labels tf cast one_hot_labels logits dtype if label_smoothing > 0 smooth_positives 1 0 - label_smoothing smooth_negatives label_smoothing / num_classes one_hot_labels one_hot_labels * smooth_positives + smooth_negatives cross_entropy tf contrib nn deprecated_flipped_softmax_cross_entropy_with_logits logits one_hot_labels name 'xentropy' weight tf convert_to_tensor weight dtype logits dtype base_dtype name 'loss_weight' loss tf multiply weight tf reduce_mean cross_entropy name 'value' tf add_to_collection LOSSES_COLLECTION loss return loss
def cross_entropy_loss logits one_hot_labels label_smoothing 0 weight 1 0 scope None logits get_shape assert_is_compatible_with one_hot_labels get_shape with tf name_scope scope 'CrossEntropyLoss' [logits one_hot_labels] num_classes one_hot_labels get_shape [ -1 ] valueone_hot_labels tf cast one_hot_labels logits dtype if label_smoothing > 0 smooth_positives 1 0 - label_smoothing smooth_negatives label_smoothing / num_classes one_hot_labels one_hot_labels * smooth_positives + smooth_negatives cross_entropy tf contrib nn deprecated_flipped_softmax_cross_entropy_with_logits logits one_hot_labels name 'xentropy' weight tf convert_to_tensor weight dtype logits dtype base_dtype name 'loss_weight' loss tf multiply weight tf reduce_mean cross_entropy name 'value' tf add_to_collection LOSSES_COLLECTION loss return loss
def test_timeout from time import sleepsleep 2
def distrib_desc with settings hide 'running' 'stdout' if not is_file '/etc/redhat-release' return run 'lsb_release--desc--short' return run 'cat/etc/redhat-release'
def construct_message labels face_annotations response_text PRETEXTlabel_desc ''pos_labels ['verylikely' 'likely' 'possibly']for i in range len labels label_desc + '\nScoreis%sfor%s' % labels[i]['score'] labels[i]['description'] joy anger sorrow surprise extract_sentiment face_annotations for i in range len pos_labels if joy[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingjoy' % joy[i] pos_labels[i] if anger[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencinganger' % anger[i] pos_labels[i] if sorrow[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingsorrow' % sorrow[i] pos_labels[i] if surprise[i] > 0 label_desc + '\nWefound%speoplewhoare%sexperiencingsurprise' % surprise[i] pos_labels[i] if not label_desc label_desc 'Nolabelsfound 'response_text + label_descresp twilio twiml Response resp message response_text return resp
def graphviz_layout G prog 'neato' root None **kwds return pydot_layout G G prog prog root root **kwds
def arp interface '' ipaddr '' macaddr '' proxy_output __proxy__['napalm call'] 'get_arp_table' **{} if not proxy_output get 'result' return proxy_outputarp_table proxy_output get 'out' if interface arp_table _filter_list arp_table 'interface' interface if ipaddr arp_table _filter_list arp_table 'ip' ipaddr if macaddr arp_table _filter_list arp_table 'mac' macaddr proxy_output update {'out' arp_table} return proxy_output
def arp interface '' ipaddr '' macaddr '' proxy_output __proxy__['napalm call'] 'get_arp_table' **{} if not proxy_output get 'result' return proxy_outputarp_table proxy_output get 'out' if interface arp_table _filter_list arp_table 'interface' interface if ipaddr arp_table _filter_list arp_table 'ip' ipaddr if macaddr arp_table _filter_list arp_table 'mac' macaddr proxy_output update {'out' arp_table} return proxy_output
def mean_absolute_error y_real y_pred y_real y_pred check_arrays y_real y_pred return np sum np abs y_pred - y_real / y_real size
def _Strptime arg strptime_format split_arg arg split ' ' datetime_obj datetime datetime strptime split_arg[0] strptime_format if len split_arg 2 datetime_obj datetime_obj replace microsecond int split_arg[1] return datetime_obj
def instance_system_metadata_get context instance_uuid return IMPL instance_system_metadata_get context instance_uuid
def get_res_pool_ref session cluster res_pool_ref session _call_method vutil 'get_object_property' cluster 'resourcePool' return res_pool_ref
def _get_table_str table table_str ''col_size [max len str val for val in column for column in zip *table ]for line in table table_str + '\n'table_str + '' join '{0 <{1}}' format val col_size[i] for i val in enumerate line return table_str
def convert_regex_to_flask_path url_path for token in [u'$'] url_path url_path replace token u'' def caller reg match_name match_pattern reg groups return u'<regex "{0}" {1}>' format match_pattern match_name url_path re sub u'\\ \\?P< *? > *? \\ ' caller url_path if url_path endswith u'/?' url_path url_path rstrip u'/?' return url_path
def reboot vm force False key 'uuid' ret {}vmadm _check_vmadm if key not in ['uuid' 'alias' 'hostname'] ret['Error'] 'Keymustbeeitheruuid aliasorhostname'return retvm lookup '{0} {1}' format key vm one True if 'Error' in vm return vmcmd '{vmadm}reboot{force}{uuid}' format vmadm vmadm force '-F' if force else '' uuid vm res __salt__['cmd run_all'] cmd retcode res['retcode']if retcode 0 ret['Error'] res['stderr'] if 'stderr' in res else _exit_status retcode return retreturn True
def bytes_to_num bval num 0num + ord bval[0] << 24 num + ord bval[1] << 16 num + ord bval[2] << 8 num + ord bval[3] return num
def PlistValueToPlainValue plist if isinstance plist dict ret_value dict for key value in plist items ret_value[key] PlistValueToPlainValue value return ret_valueelif isinstance plist list return [PlistValueToPlainValue value for value in plist]elif isinstance plist binplist RawValue return plist valueelif isinstance plist binplist CorruptReference or isinstance plist binplist UnknownObject return Noneelif isinstance plist datetime datetime return calendar timegm plist utctimetuple * 1000000 + plist microsecond return plist
def PlistValueToPlainValue plist if isinstance plist dict ret_value dict for key value in plist items ret_value[key] PlistValueToPlainValue value return ret_valueelif isinstance plist list return [PlistValueToPlainValue value for value in plist]elif isinstance plist binplist RawValue return plist valueelif isinstance plist binplist CorruptReference or isinstance plist binplist UnknownObject return Noneelif isinstance plist datetime datetime return calendar timegm plist utctimetuple * 1000000 + plist microsecond return plist
def url_replace_param url name value url_components urlparse force_str url query_params parse_qs url_components query query_params[name] valuequery urlencode query_params doseq True return force_text urlunparse [url_components scheme url_components netloc url_components path url_components params query url_components fragment]
@commands u'title' @example u' titlehttp //google com' u'[Google]-google com' def title_command bot trigger if not trigger group 2 if trigger sender not in bot memory[u'last_seen_url'] returnmatched check_callbacks bot trigger bot memory[u'last_seen_url'][trigger sender] True if matched returnelse urls [bot memory[u'last_seen_url'][trigger sender]]else urls re findall url_finder trigger results process_urls bot trigger urls for title domain in results[ 4] bot reply u'[%s]-%s' % title domain
def highlight code lexer formatter outfile None return format lex code lexer formatter outfile
def MakeEntityForQuery query *path pseudo_pb entity_pb EntityProto pseudo_pb mutable_entity_group pseudo_pk pseudo_pb mutable_key pseudo_pk set_app query app if query has_name_space pseudo_pk set_name_space query name_space for i in xrange 0 len path 2 pseudo_pe pseudo_pk mutable_path add_element pseudo_pe set_type path[i] if isinstance path[ i + 1 ] basestring pseudo_pe set_name path[ i + 1 ] else pseudo_pe set_id path[ i + 1 ] return pseudo_pb
def main print '\nInitializingserialconnection'console serial Serial port 'COM1' baudrate 9600 parity 'N' stopbits 1 bytesize 8 timeout READ_TIMEOUT if not console isOpen sys exit login console print send_command console cmd 'showipintbrief' logout console
def main print '\nInitializingserialconnection'console serial Serial port 'COM1' baudrate 9600 parity 'N' stopbits 1 bytesize 8 timeout READ_TIMEOUT if not console isOpen sys exit login console print send_command console cmd 'showipintbrief' logout console
def is_unedited_config_file content template_content None content content encode u'latin-1' content re sub '\njquery_url\\s* \\s*[^\n]+' '' content buffer io BytesIO content buffer seek 0 raw_cfg configobj ConfigObj buffer interpolation True for v in six itervalues raw_cfg if len v breakelse return Trueknown_configs set [u'7d4b4f1120304b286d71f205975b1286' u'5df7e409425e5bfe7ed041513fda3288' u'8355f99a01b3bdfd8761ef45d5d8b7e5' u'4ea5a84de146dc3fcea2a5b93735e634'] md5 hashlib md5 md5 update content digest md5 hexdigest return digest in known_configs
def is_unedited_config_file content template_content None content content encode u'latin-1' content re sub '\njquery_url\\s* \\s*[^\n]+' '' content buffer io BytesIO content buffer seek 0 raw_cfg configobj ConfigObj buffer interpolation True for v in six itervalues raw_cfg if len v breakelse return Trueknown_configs set [u'7d4b4f1120304b286d71f205975b1286' u'5df7e409425e5bfe7ed041513fda3288' u'8355f99a01b3bdfd8761ef45d5d8b7e5' u'4ea5a84de146dc3fcea2a5b93735e634'] md5 hashlib md5 md5 update content digest md5 hexdigest return digest in known_configs
def is_unedited_config_file content template_content None content content encode u'latin-1' content re sub '\njquery_url\\s* \\s*[^\n]+' '' content buffer io BytesIO content buffer seek 0 raw_cfg configobj ConfigObj buffer interpolation True for v in six itervalues raw_cfg if len v breakelse return Trueknown_configs set [u'7d4b4f1120304b286d71f205975b1286' u'5df7e409425e5bfe7ed041513fda3288' u'8355f99a01b3bdfd8761ef45d5d8b7e5' u'4ea5a84de146dc3fcea2a5b93735e634'] md5 hashlib md5 md5 update content digest md5 hexdigest return digest in known_configs
def is_unedited_config_file content template_content None content content encode u'latin-1' content re sub '\njquery_url\\s* \\s*[^\n]+' '' content buffer io BytesIO content buffer seek 0 raw_cfg configobj ConfigObj buffer interpolation True for v in six itervalues raw_cfg if len v breakelse return Trueknown_configs set [u'7d4b4f1120304b286d71f205975b1286' u'5df7e409425e5bfe7ed041513fda3288' u'8355f99a01b3bdfd8761ef45d5d8b7e5' u'4ea5a84de146dc3fcea2a5b93735e634'] md5 hashlib md5 md5 update content digest md5 hexdigest return digest in known_configs
def split_by array group_size filler args [iter array ] * group_size return list map list zip_longest fillvalue filler *args
def split_by array group_size filler args [iter array ] * group_size return list map list zip_longest fillvalue filler *args
def reachable stepFunction start destinations _alreadyseen None if len start 0 or len destinations 0 return {}if _alreadyseen is None _alreadyseen []_alreadyseen extend start res {}for s in start if s in destinations res[s] 0start remove s new set for s in start new update stepFunction s new difference_update _alreadyseen ndestinations list destinations for s in list new if s in destinations res[s] 1new remove s ndestinations remove s _alreadyseen append s deeper reachable stepFunction new ndestinations _alreadyseen for k val in list deeper items res[k] val + 1 return res
def http_request method url session requests **kwargs kwargs setdefault 'timeout' 30 0 kwargs setdefault 'verify' False try return getattr session method lower url **kwargs except requests exceptions MissingSchema requests exceptions InvalidSchema print_error 'InvalidURLformat {}' format url returnexcept requests exceptions ConnectionError print_error 'Connectionerror {}' format url returnexcept requests RequestException as error print_error error returnexcept socket error as err print_error err returnexcept KeyboardInterrupt print_info print_status 'Modulehasbeenstopped'
def mb_parser_xml resp try return mbxml parse_message resp except UnicodeError as exc raise ResponseError cause exc except Exception as exc if isinstance exc ETREE_EXCEPTIONS raise ResponseError cause exc else raise
def mb_parser_xml resp try return mbxml parse_message resp except UnicodeError as exc raise ResponseError cause exc except Exception as exc if isinstance exc ETREE_EXCEPTIONS raise ResponseError cause exc else raise
def upgrade migrate_engine meta MetaData meta bind migrate_engineworkers Table 'workers' meta autoload True if migrate_engine name startswith 'mysql' try workers c updated_at alter mysql DATETIME fsp 6 except Exception passwi workers insert now timeutils utcnow replace microsecond 123 wi execute {'created_at' now 'updated_at' now 'deleted' False 'resource_type' 'SENTINEL' 'resource_id' 'SUB-SECOND' 'status' 'OK'}
def upgrade migrate_engine meta MetaData meta bind migrate_engineworkers Table 'workers' meta autoload True if migrate_engine name startswith 'mysql' try workers c updated_at alter mysql DATETIME fsp 6 except Exception passwi workers insert now timeutils utcnow replace microsecond 123 wi execute {'created_at' now 'updated_at' now 'deleted' False 'resource_type' 'SENTINEL' 'resource_id' 'SUB-SECOND' 'status' 'OK'}
@snippetdef client_run_sync_query_paged client _ TIMEOUT_MS 1000PAGE_SIZE 100LIMIT 1000LIMITED '%sLIMIT%d' % QUERY LIMIT all_rows []def do_something_with rows all_rows extend rows query client run_sync_query LIMITED query timeout_ms TIMEOUT_MSquery max_results PAGE_SIZEquery run assert query completeassert query page_token is not None assert len query rows PAGE_SIZE assert [field name for field in query schema] ['name'] rows query rowstoken query page_tokenwhile True do_something_with rows if token is None break rows total_count token query fetch_data page_token token assert total_count LIMIT assert len all_rows LIMIT
def set_le_script_version venv_dir version with open join venv_dir 'letsencrypt' 'bin' 'letsencrypt' 'w' as script script write "# /usr/bin/envpython\nfromsysimportstderr\nstderr write 'letsencrypt%s\\n' " % version
def set_le_script_version venv_dir version with open join venv_dir 'letsencrypt' 'bin' 'letsencrypt' 'w' as script script write "# /usr/bin/envpython\nfromsysimportstderr\nstderr write 'letsencrypt%s\\n' " % version
def pypackable name pytype format size items _formatinfo format return type Packable name pytype Packable {'_format_' format '_size_' size '_items_' items}
def Authenticate opener host user pwd otp_entry request_dict {'username' user 'password' pwd 'otp' otp_entry}req _MakeRequest host '/otp' request_dict return _HandleResponse 'authentication' opener open req
def apply_template_on_contents contents template context defaults saltenv if template in salt utils templates TEMPLATE_REGISTRY context_dict defaults if defaults else {} if context context_dict update context contents salt utils templates TEMPLATE_REGISTRY[template] contents from_str True to_str True context context_dict saltenv saltenv grains __opts__['grains'] pillar __pillar__ salt __salt__ opts __opts__ ['data'] encode 'utf-8' else ret {}ret['result'] Falseret['comment'] 'Specifiedtemplateformat{0}isnotsupported' format template return retreturn contents
def _SkipFixed32 buffer pos end pos + 4if pos > end raise _DecodeError 'Truncatedmessage ' return pos
def check_stats_permission request addon for_contributions False if addon public_stats and not for_contributions returnif not request user is_authenticated raise PermissionDeniedif not for_contributions if addon has_author request user or acl action_allowed request 'Stats' 'View' returnelif addon has_author request user or acl action_allowed request 'RevenueStats' 'View' returnraise PermissionDenied
def largest interface instance return _superlative interface 1 instance
def largest interface instance return _superlative interface 1 instance
def versionize app pagename templatename context doctree if not app config canonical_root and app config versions returncontext['versions'] [ vs _build_url app config canonical_root vs pagename for vs in app config versions split ' ' if vs app config version ]
def versionize app pagename templatename context doctree if not app config canonical_root and app config versions returncontext['versions'] [ vs _build_url app config canonical_root vs pagename for vs in app config versions split ' ' if vs app config version ]
def sweepB best worst front stairs fstairs [] [] iter_best iter best next_best next iter_best False for h in worst while next_best and h[ 2] < next_best[ 2] insert Truefor i fstair in enumerate fstairs if front[fstair] front[next_best] if fstair[1] > next_best[1] insert Falseelse del stairs[i] fstairs[i]breakif insert idx bisect bisect_right stairs - next_best[1] stairs insert idx - next_best[1] fstairs insert idx next_best next_best next iter_best False idx bisect bisect_right stairs - h[1] if 0 < idx < len stairs fstair max fstairs[ idx] key front __getitem__ front[h] max front[h] front[fstair] + 1
def mb_call func *args **kwargs try return func *args **kwargs except musicbrainzngs AuthenticationError raise ui UserError u'authenticationwithMusicBrainzfailed' except musicbrainzngs ResponseError musicbrainzngs NetworkError as exc raise ui UserError u'MusicBrainzAPIerror {0}' format exc except musicbrainzngs UsageError raise ui UserError u'MusicBrainzcredentialsmissing'
def complete y return linkage y method 'complete' metric 'euclidean'
def complete y return linkage y method 'complete' metric 'euclidean'
def run_tests argv None defaultTest None topleveldir None xmloutput None verbosity 1 nomultiproc False if xmloutput is not None import xmlrunnerrunner xmlrunner XMLTestRunner output xmloutput else runner Noneprog NumbaTestProgram argv argv module None defaultTest defaultTest topleveldir topleveldir testRunner runner exit False verbosity verbosity nomultiproc nomultiproc return prog result
def run_tests argv None defaultTest None topleveldir None xmloutput None verbosity 1 nomultiproc False if xmloutput is not None import xmlrunnerrunner xmlrunner XMLTestRunner output xmloutput else runner Noneprog NumbaTestProgram argv argv module None defaultTest defaultTest topleveldir topleveldir testRunner runner exit False verbosity verbosity nomultiproc nomultiproc return prog result
def run_tests argv None defaultTest None topleveldir None xmloutput None verbosity 1 nomultiproc False if xmloutput is not None import xmlrunnerrunner xmlrunner XMLTestRunner output xmloutput else runner Noneprog NumbaTestProgram argv argv module None defaultTest defaultTest topleveldir topleveldir testRunner runner exit False verbosity verbosity nomultiproc nomultiproc return prog result
def dmp_eval_tail f A u K if not A return fif dmp_zero_p f u return dmp_zero u - len A e _rec_eval_tail f 0 A u K if u len A - 1 return eelse return dmp_strip e u - len A
def handle_wallclock_metric common_props sample wallclock_samples []wallclock_sample dict common_props wallclock_sample['value'] sample['value']wallclock_samples append wallclock_sample return wallclock_samples
def _exception_traceback exc_info excout StringIO exc_type exc_val exc_tb exc_infotraceback print_exception exc_type exc_val exc_tb file excout return excout getvalue
def strip_course_id path course_id unicode FAKE_COURSE_KEY return path split course_id [0]
def strip_course_id path course_id unicode FAKE_COURSE_KEY return path split course_id [0]
def CheckLocation for url in config_lib CONFIG['Client server_urls'] + config_lib CONFIG['Client control_urls'] if 'staging' in url or 'localhost' in url returnlogging error 'Poolclientshouldonlyberunagainsttestorstaging ' exit
def member_with_tags_server_selector tag_sets selection return apply_tag_sets tag_sets readable_server_selector selection
def multiEvaluate repeat def decorator func def inner *args **kwargs result 0 0for dummy in range repeat result + func *args **kwargs return result / repeat return innerreturn decorator
def logout if current_user is_authenticated logout_user return redirect request args get 'next' None or get_url _security post_logout_view
def set_gpu_fraction sess None gpu_fraction 0 3 print 'tensorlayer GPUMEMFraction%f' % gpu_fraction gpu_options tf GPUOptions per_process_gpu_memory_fraction gpu_fraction sess tf Session config tf ConfigProto gpu_options gpu_options return sess
def add_uids doctree condition for node in doctree traverse condition node uid uuid4 hex yield node
def snapshot_from_bdm snapshot_id template copy_from_template 'disk_bus' 'device_type' 'boot_index' 'delete_on_termination' 'volume_size' 'device_name' snapshot_dict {'source_type' 'snapshot' 'destination_type' 'volume' 'snapshot_id' snapshot_id}for key in copy_from_template snapshot_dict[key] template get key return BlockDeviceDict snapshot_dict
def mark_negation document double_neg_flip False shallow False if not shallow document deepcopy document labeled document and isinstance document[0] tuple list if labeled doc document[0]else doc documentneg_scope Falsefor i word in enumerate doc if NEGATION_RE search word if not neg_scope or neg_scope and double_neg_flip neg_scope not neg_scope continueelse doc[i] + '_NEG'elif neg_scope and CLAUSE_PUNCT_RE search word neg_scope not neg_scope elif neg_scope and not CLAUSE_PUNCT_RE search word doc[i] + '_NEG'return document
def make_ip_network port network ip_address netaddr IPAddress port['fixed_ips'][0]['ip_address'] return netaddr IPNetwork ip_address value network prefixlen
def make_ip_network port network ip_address netaddr IPAddress port['fixed_ips'][0]['ip_address'] return netaddr IPNetwork ip_address value network prefixlen
def instance_group_get_by_instance context instance_uuid return IMPL instance_group_get_by_instance context instance_uuid
def fListToString a_list a_precision 3 from numpy import arounds_list ' ' join '%g' % around x a_precision ljust a_precision + 3 for x in a_list return '[%s]' % s_list
def test_enhancements plugin domains supported plugin supported_enhancements if 'redirect' not in supported logger error 'Thepluginandthisprogramsupportnocommonenhancements' return Falsefor domain in domains try plugin enhance domain 'redirect' plugin save except le_errors PluginError as error logger warning 'Pluginfailedtoenableredirectfor%s ' domain logger warning '%s' error except le_errors Error as error logger error 'Anerroroccurredwhileenablingredirectfor%s ' domain logger exception error if not _save_and_restart plugin 'enhanced' return Falsesuccess Truefor domain in domains verify functools partial validator Validator redirect 'localhost' plugin http_port headers {'Host' domain} if not _try_until_true verify logger error 'Improperredirectfordomain%s' domain success Falseif success logger info 'Enhancmentstestsucceeded' return success
def loss y_hat y return T sqr y_hat - y mean
def loss y_hat y return T sqr y_hat - y mean
def _AddPropertiesForField field cls assert _FieldDescriptor MAX_CPPTYPE 10 constant_name field name upper + '_FIELD_NUMBER' setattr cls constant_name field number if field label _FieldDescriptor LABEL_REPEATED _AddPropertiesForRepeatedField field cls elif field cpp_type _FieldDescriptor CPPTYPE_MESSAGE _AddPropertiesForNonRepeatedCompositeField field cls else _AddPropertiesForNonRepeatedScalarField field cls
@strategy_options loader_option def baked_lazyload loadopt attr return loadopt set_relationship_strategy attr {'lazy' 'baked_select'}
def _GetModuleObjectAndName globals_dict for name module in sys modules items if getattr module '__dict__' None is globals_dict if name '__main__' name sys argv[0]return module name return None None
def no_freesurfer if Info version is None return Trueelse return False
def no_freesurfer if Info version is None return Trueelse return False
def no_freesurfer if Info version is None return Trueelse return False
def set_scroll_commands widget hbar vbar if vbar widget['yscrollcommand'] vbar 'set' vbar['command'] widget 'yview' if hbar widget['xscrollcommand'] hbar 'set' hbar['command'] widget 'xview' widget vbar vbarwidget hbar hbar
def make_double_frame master None class_ None name None relief RAISED borderwidth 1 if name if class_ frame Frame master class_ class_ name name else frame Frame master name name elif class_ frame Frame master class_ class_ else frame Frame master top Frame frame name 'topframe' relief relief borderwidth borderwidth bottom Frame frame name 'bottomframe' bottom pack fill X padx '1m' pady '1m' side BOTTOM top pack expand 1 fill BOTH padx '1m' pady '1m' frame pack expand 1 fill BOTH top Frame top top pack expand 1 fill BOTH padx '2m' pady '2m' return frame top bottom
def _check_caller_authority caller role if not caller is_authenticated and caller is_active raise PermissionDeniedif GlobalStaff has_user caller returnif isinstance role GlobalStaff CourseCreatorRole raise PermissionDeniedelif isinstance role CourseRole if not user_has_role caller CourseInstructorRole role course_key raise PermissionDenied
def _check_caller_authority caller role if not caller is_authenticated and caller is_active raise PermissionDeniedif GlobalStaff has_user caller returnif isinstance role GlobalStaff CourseCreatorRole raise PermissionDeniedelif isinstance role CourseRole if not user_has_role caller CourseInstructorRole role course_key raise PermissionDenied
@taskdef bootstrap try import virtualenvexcept ImportError raise RuntimeError 'virtualenvisneededforbootstrap' bdir options bootstrap_dirif not os path exists bdir os makedirs bdir bscript 'boostrap py'options virtualenv script_name os path join options bootstrap_dir bscript options bootstrap no_site_packages Falsecall_task 'paver virtual bootstrap' sh 'cd%s %s%s' % bdir sys executable bscript
def set_log_level_for_all_loggers level logging DEBUG root_logger logging getLogger loggers logging Logger manager loggerDict values loggers + [root_logger]for logger in loggers if not isinstance logger logging Logger continueset_log_level_for_all_handlers logger logger
def get_class lookup_view if isinstance lookup_view str mod_name func_name get_mod_func lookup_view if func_name '' lookup_view getattr __import__ mod_name {} {} ['*'] func_name if not callable lookup_view raise AttributeError "'%s %s'isnotacallable " % mod_name func_name return lookup_view
def co_findloadednames co names {}names update co_code_findloadednames co for c in co co_consts if isinstance c type co names update co_findloadednames c return names
def create_table dataset_name table_name project None bigquery_client bigquery Client project project dataset bigquery_client dataset dataset_name if not dataset exists print 'Dataset{}doesnotexist ' format dataset_name returntable dataset table table_name table schema bigquery SchemaField 'Name' 'STRING' bigquery SchemaField 'Age' 'INTEGER' bigquery SchemaField 'Weight' 'FLOAT' table create print 'Createdtable{}indataset{} ' format table_name dataset_name
def create_table dataset_name table_name project None bigquery_client bigquery Client project project dataset bigquery_client dataset dataset_name if not dataset exists print 'Dataset{}doesnotexist ' format dataset_name returntable dataset table table_name table schema bigquery SchemaField 'Name' 'STRING' bigquery SchemaField 'Age' 'INTEGER' bigquery SchemaField 'Weight' 'FLOAT' table create print 'Createdtable{}indataset{} ' format table_name dataset_name
def npz_to_W_pdf path None regx 'w1pre_[0-9]+\\ npz ' file_list load_file_list path path regx regx for f in file_list W load_npz path f [0]print '%s-->%s' % f f split ' ' [0] + ' pdf' visualize W W second 10 saveable True name f split ' ' [0] fig_idx 2012
def add_build_arguments parser parser add_argument '--involucro-path' dest 'involucro_path' default None help 'Pathtoinvolucro ifnotsetwilllookinworkingdirectoryandonPATH ' parser add_argument '--force-rebuild' dest 'force_rebuild' action 'store_true' help 'Rebuildpackageevenifalreadypublished ' parser add_argument '--dry-run' dest 'dry_run' action 'store_true' help 'Justprintcommandsinsteadofexecutingthem ' parser add_argument '-n' '--namespace' dest 'namespace' default 'mulled' help 'quay ionamespace ' parser add_argument '-r' '--repository_template' dest 'repository_template' default DEFAULT_REPOSITORY_TEMPLATE help 'Dockerrepositorytargetforpublication onlyquay ioorcompat APIiscurrentlysupported ' parser add_argument '-c' '--channel' dest 'channel' default DEFAULT_CHANNEL help 'Targetcondachannel' parser add_argument '--extra-channels' dest 'extra_channels' default ' ' join DEFAULT_EXTRA_CHANNELS help 'Dependentcondachannels '
def add_build_arguments parser parser add_argument '--involucro-path' dest 'involucro_path' default None help 'Pathtoinvolucro ifnotsetwilllookinworkingdirectoryandonPATH ' parser add_argument '--force-rebuild' dest 'force_rebuild' action 'store_true' help 'Rebuildpackageevenifalreadypublished ' parser add_argument '--dry-run' dest 'dry_run' action 'store_true' help 'Justprintcommandsinsteadofexecutingthem ' parser add_argument '-n' '--namespace' dest 'namespace' default 'mulled' help 'quay ionamespace ' parser add_argument '-r' '--repository_template' dest 'repository_template' default DEFAULT_REPOSITORY_TEMPLATE help 'Dockerrepositorytargetforpublication onlyquay ioorcompat APIiscurrentlysupported ' parser add_argument '-c' '--channel' dest 'channel' default DEFAULT_CHANNEL help 'Targetcondachannel' parser add_argument '--extra-channels' dest 'extra_channels' default ' ' join DEFAULT_EXTRA_CHANNELS help 'Dependentcondachannels '
def loop_template_list loop_positions instance instance_type default_template registery {} templates []local_loop_position loop_positions[1]global_loop_position loop_positions[0]instance_string slugify str instance for key in [ '%s-%s' % instance_type instance_string instance_string instance_type 'default'] try templates append registery[key][global_loop_position] except KeyError passtemplates append append_position default_template global_loop_position '-' templates append append_position default_template local_loop_position '_' templates append default_template return templates
def loop_template_list loop_positions instance instance_type default_template registery {} templates []local_loop_position loop_positions[1]global_loop_position loop_positions[0]instance_string slugify str instance for key in [ '%s-%s' % instance_type instance_string instance_string instance_type 'default'] try templates append registery[key][global_loop_position] except KeyError passtemplates append append_position default_template global_loop_position '-' templates append append_position default_template local_loop_position '_' templates append default_template return templates
def pathlist2filename pathlist fullpath ''for elem in pathlist fullpath os path join fullpath elem try return fullpath decode 'utf-8' except UnicodeDecodeError charenc chardet detect fullpath ['encoding']return fullpath decode charenc
def load_entry_point dist group name return get_distribution dist load_entry_point group name
def builds_chain_fingerprinter registry xml_parent data fingerprinter XML SubElement xml_parent 'org jenkinsci plugins buildschainfingerprinter AutomaticFingerprintJobProperty' XML SubElement fingerprinter 'isPerBuildsChainEnabled' text str data get 'per-builds-chain' False lower XML SubElement fingerprinter 'isPerJobsChainEnabled' text str data get 'per-job-chain' False lower
def builds_chain_fingerprinter registry xml_parent data fingerprinter XML SubElement xml_parent 'org jenkinsci plugins buildschainfingerprinter AutomaticFingerprintJobProperty' XML SubElement fingerprinter 'isPerBuildsChainEnabled' text str data get 'per-builds-chain' False lower XML SubElement fingerprinter 'isPerJobsChainEnabled' text str data get 'per-job-chain' False lower
def get_credit_requirement_status course_key username namespace None name None requirements CreditRequirement get_course_requirements course_key namespace namespace name name requirement_statuses CreditRequirementStatus get_statuses requirements username requirement_statuses dict o requirement o for o in requirement_statuses statuses []for requirement in requirements requirement_status requirement_statuses get requirement statuses append {'namespace' requirement namespace 'name' requirement name 'display_name' requirement display_name 'criteria' requirement criteria 'reason' requirement_status reason if requirement_status else None 'status' requirement_status status if requirement_status else None 'status_date' requirement_status modified if requirement_status else None 'order' requirement order} return statuses
def project_activity_year_options db current dbtable current s3db project_activityquery table deleted False min_field table date min start_date_min db query select min_field orderby min_field limitby 0 1 first [min_field]if start_date_min start_year start_date_min yearelse start_year Nonemax_field table end_date max end_date_max db query select max_field orderby max_field limitby 0 1 first [max_field]if end_date_max end_year end_date_max yearelse end_year Noneif not start_year or not end_year return {start_year start_year} or {end_year end_year} years {}for year in xrange start_year end_year + 1 years[year] yearreturn years
def test_root_normalized_mean_absolute_error max_rating 5 0min_rating 1 0y_real np array [0 0 1 0 0 0 2 0 3 0] y_pred np array [0 0 1 0 0 0 2 0 3 0] assert_equals 0 0 normalized_mean_absolute_error y_real y_pred max_rating min_rating y_real np array [3 0 1 0 2 0 1 0 1 0] y_pred np array [0 0 1 0 0 0 2 0 3 0] assert_almost_equals 0 4 normalized_mean_absolute_error y_real y_pred max_rating min_rating
def _init_externals if __version__ 'git' sys path insert 0 osp join osp dirname __file__ 'ext' 'gitdb' try import gitdbexcept ImportError raise ImportError "'gitdb'couldnotbefoundinyourPYTHONPATH"
def _init_externals if __version__ 'git' sys path insert 0 osp join osp dirname __file__ 'ext' 'gitdb' try import gitdbexcept ImportError raise ImportError "'gitdb'couldnotbefoundinyourPYTHONPATH"
@register filterdef thumbnailer_passive obj thumbnailer get_thumbnailer obj thumbnailer generate Falsereturn thumbnailer
@register filterdef thumbnailer_passive obj thumbnailer get_thumbnailer obj thumbnailer generate Falsereturn thumbnailer
@register filterdef thumbnailer_passive obj thumbnailer get_thumbnailer obj thumbnailer generate Falsereturn thumbnailer
@register filterdef thumbnailer_passive obj thumbnailer get_thumbnailer obj thumbnailer generate Falsereturn thumbnailer
def generate_signing_key args if os path exists args keyfile raise esptool FatalError 'ERROR Keyfile%salreadyexists' % args keyfile sk ecdsa SigningKey generate curve ecdsa NIST256p with open args keyfile 'wb' as f f write sk to_pem print 'ECDSANIST256pprivatekeyinPEMformatwrittento%s' % args keyfile
def concat series axis 0 allow_mix False is_pandas np r_[[_is_using_pandas s None for s in series]]if np all is_pandas concatenated pd concat series axis axis elif np all ~ is_pandas or allow_mix concatenated np concatenate series axis axis else raise ValueError 'AttemptedtoconcatenatePandasobjectswithnon-Pandasobjectswith`allow_mix False` ' return concatenated
def scale x y pt None rv eye 3 rv[ 0 0 ] xrv[ 1 1 ] yif pt from sympy geometry point import Pointpt Point pt dim 2 tr1 translate * - pt args tr2 translate *pt args return tr1 * rv * tr2 return rv
@task_failure connectdef process_failure_signal exception traceback sender task_id signal args kwargs einfo **kw exc_info type exception exception traceback log error u'CeleryTASKexception {0 __name__} {1}' format *exc_info exc_info exc_info extra {'data' {'task_id' task_id 'sender' sender 'args' args 'kwargs' kwargs}}
def display_bitmask kind bitmap value col1_width max map len list bitmap keys + [kind] col2_width 7FMT '{name >{col1_width}}{value >{col2_width}}{description}'print FMT format name kind value 'Value' description 'Description' col1_width col1_width col2_width col2_width print '{0}{1}{2}' format '-' * col1_width '-' * col2_width '-' * max map len bitmap values for flag_name description in bitmap items try bitmask getattr termios flag_name bit_val 'on' if bool value & bitmask else 'off' except AttributeError bit_val 'undef'print FMT format name flag_name value bit_val description description col1_width col1_width col2_width col2_width print
def make_linear_colorscale colors scale 1 0 / len colors - 1 return [[ i * scale color] for i color in enumerate colors ]
def _get_current_inventory_resources conn rp cur_res_sel sa select [_INV_TBL c resource_class_id] where _INV_TBL c resource_provider_id rp id existing_resources conn execute cur_res_sel fetchall return set [r[0] for r in existing_resources]
def _get_current_inventory_resources conn rp cur_res_sel sa select [_INV_TBL c resource_class_id] where _INV_TBL c resource_provider_id rp id existing_resources conn execute cur_res_sel fetchall return set [r[0] for r in existing_resources]
def _get_current_inventory_resources conn rp cur_res_sel sa select [_INV_TBL c resource_class_id] where _INV_TBL c resource_provider_id rp id existing_resources conn execute cur_res_sel fetchall return set [r[0] for r in existing_resources]
def setup_platform hass config add_devices discovery_info None add_devices [DemoSensor 'OutsideTemperature' 15 6 TEMP_CELSIUS 12 DemoSensor 'OutsideHumidity' 54 '%' None ]
def is_possible_short_number_for_region short_number region_dialing_from if isinstance short_number PhoneNumber short_number national_significant_number short_number metadata PhoneMetadata short_metadata_for_region region_dialing_from if metadata is None return Falsegeneral_desc metadata general_descreturn _is_number_possible_for_desc short_number general_desc
def pagebreak type 'page' orient 'portrait' validtypes ['page' 'section']if type not in validtypes tmpl 'Pagebreakstyle"%s"notimplemented Validstyles %s 'raise ValueError tmpl % type validtypes pagebreak makeelement 'p' if type 'page' run makeelement 'r' br makeelement 'br' attributes {'type' type} run append br pagebreak append run elif type 'section' pPr makeelement 'pPr' sectPr makeelement 'sectPr' if orient 'portrait' pgSz makeelement 'pgSz' attributes {'w' '12240' 'h' '15840'} elif orient 'landscape' pgSz makeelement 'pgSz' attributes {'h' '12240' 'w' '15840' 'orient' 'landscape'} sectPr append pgSz pPr append sectPr pagebreak append pPr return pagebreak
def get_timezone zone None if zone is None return LOCALTZif not isinstance zone string_types return zonetry return _pytz timezone zone except _pytz UnknownTimeZoneError raise LookupError 'Unknowntimezone%s' % zone
def _get_filter_query args query Q for arg in args if hasattr ChangeSet arg and args[arg] kwargs {str arg + '__id' long args[arg] }query query & Q **kwargs if 'status' not in args query query & Q status__hidden False return query
def proxy_info_from_environment method 'http' if method not in ['http' 'https'] returnenv_var method + '_proxy' url os environ get env_var os environ get env_var upper if not url returnpi proxy_info_from_url url method no_proxy os environ get 'no_proxy' os environ get 'NO_PROXY' '' bypass_hosts []if no_proxy bypass_hosts no_proxy split ' ' if no_proxy '*' bypass_hosts AllHostspi bypass_hosts bypass_hostsreturn pi
def load_notebook resources None verbose False hide_banner False load_timeout 5000 html js _load_notebook_html resources verbose hide_banner load_timeout publish_display_data {'text/html' html} publish_display_data {'application/javascript' js}
def host_memory_size obj s e host_memory_extents obj assert e > s 'memoryextendofnegativesize'return e - s
def sample_count value len_uris len value if len_uris 1 return 'ten'if len_uris > 10 return 'ten'else return human_number len_uris
def sample_count value len_uris len value if len_uris 1 return 'ten'if len_uris > 10 return 'ten'else return human_number len_uris
def _add_billed_ops_to_map billed_ops_map billed_ops_list for billed_op in billed_ops_list if billed_op op not in billed_ops_map update_me datamodel_pb BilledOpProto update_me set_op billed_op op update_me set_num_ops 0 billed_ops_map[billed_op op ] update_meupdate_me billed_ops_map[billed_op op ]update_me set_num_ops update_me num_ops + billed_op num_ops
def warns expected_warning *args **kwargs wcheck WarningsChecker expected_warning if not args return wcheckelif isinstance args[0] str code argsassert isinstance code str frame sys _getframe 1 loc frame f_locals copy loc update kwargs with wcheck code _pytest _code Source code compile py builtin exec_ code frame f_globals loc else func args[0]with wcheck return func *args[1 ] **kwargs
def warns expected_warning *args **kwargs wcheck WarningsChecker expected_warning if not args return wcheckelif isinstance args[0] str code argsassert isinstance code str frame sys _getframe 1 loc frame f_locals copy loc update kwargs with wcheck code _pytest _code Source code compile py builtin exec_ code frame f_globals loc else func args[0]with wcheck return func *args[1 ] **kwargs
def take a indices axis None out None return a take indices axis out
def tunnel_write_and_run remote_write_fn remote_cmd_fn with tempfile NamedTemporaryFile as tmp_fh rando_text str uuid uuid4 tmp_fh write rando_text encode tmp_fh flush remote_tmp_file '/tmp/' + str uuid uuid4 remote_write_fn src tmp_fh name dst remote_tmp_file returned_text remote_cmd_fn cmd ['cat' remote_tmp_file] decode 'utf-8' strip '\n' assert returned_text rando_text
def tunnel_write_and_run remote_write_fn remote_cmd_fn with tempfile NamedTemporaryFile as tmp_fh rando_text str uuid uuid4 tmp_fh write rando_text encode tmp_fh flush remote_tmp_file '/tmp/' + str uuid uuid4 remote_write_fn src tmp_fh name dst remote_tmp_file returned_text remote_cmd_fn cmd ['cat' remote_tmp_file] decode 'utf-8' strip '\n' assert returned_text rando_text
def pre_order_list node filter_func no_filter l stack [] [] poped index 0 0 while node if filter_func node if not poped l append node if node children and not poped stack append node index index 0node node children[0]else index + 1try node stack[ -1 ][0] children[index]except IndexError node Noneelse node Nonepoped 0if node is None and len stack > 1 node index stack pop poped 1return l
def pre_order_list node filter_func no_filter l stack [] [] poped index 0 0 while node if filter_func node if not poped l append node if node children and not poped stack append node index index 0node node children[0]else index + 1try node stack[ -1 ][0] children[index]except IndexError node Noneelse node Nonepoped 0if node is None and len stack > 1 node index stack pop poped 1return l
def corner_peaks image min_distance 1 threshold_abs None threshold_rel 0 1 exclude_border True indices True num_peaks np inf footprint None labels None peaks peak_local_max image min_distance min_distance threshold_abs threshold_abs threshold_rel threshold_rel exclude_border exclude_border indices False num_peaks num_peaks footprint footprint labels labels if min_distance > 0 coords np transpose peaks nonzero for r c in coords if peaks[ r c ] peaks[ r - min_distance r + min_distance + 1 c - min_distance c + min_distance + 1 ] Falsepeaks[ r c ] Trueif indices is True return np transpose peaks nonzero else return peaks
@register filterdef external_url url return urlresolvers get_outgoing_url unicode url
def create_gs_key_async filename rpc None if not isinstance filename basestring raise TypeError 'filenamemustbestr %s' % filename if not filename startswith GS_PREFIX raise ValueError 'filenamemuststartwith"/gs/" %s' % filename if not '/' in filename[4 ] raise ValueError 'filenamemusthavetheformat"/gs/bucket_name/object_name" %s' % filename request blobstore_service_pb CreateEncodedGoogleStorageKeyRequest response blobstore_service_pb CreateEncodedGoogleStorageKeyResponse request set_filename filename return _make_async_call rpc 'CreateEncodedGoogleStorageKey' request response _get_result_hook lambda rpc rpc response blob_key
def test_credentials_in_url_auth_flag_has_priority httpbin_both url add_auth httpbin_both url + '/basic-auth/user/password' auth 'user wrong' r http '--auth user password' 'GET' url assert HTTP_OK in r assert r json {'authenticated' True 'user' 'user'}
@with_setup prepare_stdout def test_background_with_header from lettuce import step world@step u'thevariable" \\w+ "holds \\d+ ' def set_variable step name value setattr world name int value @step u'thevariable" \\w+ "isequalto \\d+ ' def check_variable step name expected expected int expected expect world to have property name being equal expected @step u'thevariable" \\w+ "times \\d+ isequalto \\d+ ' def multiply_and_verify step name times expected times int times expected int expected getattr world name * times should equal expected filename bg_feature_name 'header' runner Runner filename verbosity 1 runner run assert_stdout_lines ' \n1feature 1passed \n2scenarios 2passed \n7steps 7passed \n'
@with_setup prepare_stdout def test_background_with_header from lettuce import step world@step u'thevariable" \\w+ "holds \\d+ ' def set_variable step name value setattr world name int value @step u'thevariable" \\w+ "isequalto \\d+ ' def check_variable step name expected expected int expected expect world to have property name being equal expected @step u'thevariable" \\w+ "times \\d+ isequalto \\d+ ' def multiply_and_verify step name times expected times int times expected int expected getattr world name * times should equal expected filename bg_feature_name 'header' runner Runner filename verbosity 1 runner run assert_stdout_lines ' \n1feature 1passed \n2scenarios 2passed \n7steps 7passed \n'
@task@use_masterdef fetch_icon pk version_pk None **kw from mkt extensions models import Extensionextension Extension objects get pk pk if version_pk version extension versions get pk version_pk else version extension latest_public_versionicon_path version manifest get 'icons' {} get '128' '' lstrip '/' if not icon_path returnwith private_storage open version file_path as fd with ZipFile fd as zfd icon_contents zfd read icon_path save_icon extension icon_contents
def attach_userstory_statuses queryset as_field 'userstory_statuses_attr' model queryset modelsql '\nSELECTjson_agg \nrow_to_json projects_userstorystatus \nORDERBYprojects_userstorystatus order\n \nFROMprojects_userstorystatus\nWHEREprojects_userstorystatus project_id {tbl} id\n'sql sql format tbl model _meta db_table queryset queryset extra select {as_field sql} return queryset
def server_security_groups request instance_id security_groups []nclient novaclient request resp body nclient client get '/servers/%s/os-security-groups' % instance_id if body sg_objs [NovaSecurityGroup nclient security_groups sg loaded True for sg in body get 'security_groups' [] ]security_groups [SecurityGroup sg for sg in sg_objs]for sg in security_groups rule_objects [SecurityGroupRule rule for rule in sg rules]sg rules rule_objectsreturn security_groups
def reader_macroexpand char tree compiler load_macros compiler module_name reader_macro _hy_reader[compiler module_name] get char if reader_macro is None try reader_macro _hy_reader[None][char]except KeyError raise HyTypeError char "`{0}'isnotadefinedreadermacro " format char expr reader_macro tree return replace_hy_obj wrap_value expr tree
def test_system_threading_tasks temp_list range 10000 temp_list_output []Parallel For Overloads[ int int System Action[int] ] 0 len temp_list lambda x temp_list_output append x AreEqual len temp_list len temp_list_output temp_list_output sort AreEqual temp_list temp_list_output temp_list range 10000 temp_list_output []Parallel ForEach xrange 10000 lambda x temp_list_output append x AreEqual len temp_list len temp_list_output temp_list_output sort AreEqual temp_list temp_list_output
def _create_cache_timestamp cache_path access_path os path join cache_path _CACHE_TIMESTAMP_FILE if not os path exists access_path print u'Writingcachecreationtimestamp'created long time time try with open access_path 'w' as f f write str created except Exception as e print u'Erroroccuredwritingcachecreationtimestamp'print e
@verbosedef make_ad_hoc_cov info verbose None info pick_info info pick_types info meg True eeg True exclude [] info _check_consistency grad_std 5e-13mag_std 2e-14eeg_std 2e-07logger info 'Usingstandardnoisevalues MEGgrad %6 1ffT/cmMEGmag %6 1ffTEEG %6 1fuV ' % 10000000000000 0 * grad_std 1000000000000000 0 * mag_std 1000000 0 * eeg_std data np zeros len info['ch_names'] for meg eeg val in zip 'grad' 'mag' False False False True grad_std mag_std eeg_std data[pick_types info meg meg eeg eeg ] val * val return Covariance data info['ch_names'] info['bads'] info['projs'] nfree 0
def parse_params params ignore_keys None parsed {}for key in params if ignore_keys and key in ignore_keys continuevalue params getall key if not value value ''if len value 1 value value[0]parsed[key] valuereturn parsed
def generate_replace_result_xml result_sourcedid score elem ElementMaker nsmap {None 'http //www imsglobal org/services/ltiv1p1/xsd/imsoms_v1p0'} xml elem imsx_POXEnvelopeRequest elem imsx_POXHeader elem imsx_POXRequestHeaderInfo elem imsx_version 'V1 0' elem imsx_messageIdentifier str uuid uuid4 elem imsx_POXBody elem replaceResultRequest elem resultRecord elem sourcedGUID elem sourcedId result_sourcedid elem result elem resultScore elem language 'en' elem textString str score return etree tostring xml xml_declaration True encoding 'UTF-8'
def generate_replace_result_xml result_sourcedid score elem ElementMaker nsmap {None 'http //www imsglobal org/services/ltiv1p1/xsd/imsoms_v1p0'} xml elem imsx_POXEnvelopeRequest elem imsx_POXHeader elem imsx_POXRequestHeaderInfo elem imsx_version 'V1 0' elem imsx_messageIdentifier str uuid uuid4 elem imsx_POXBody elem replaceResultRequest elem resultRecord elem sourcedGUID elem sourcedId result_sourcedid elem result elem resultScore elem language 'en' elem textString str score return etree tostring xml xml_declaration True encoding 'UTF-8'
def filter sum_dict align_dict filter_attribute low_bound high_bound new_sum_dict FSSP FSSPSumDict new_align_dict copy deepcopy align_dict for prot_num in sum_dict attr_value getattr sum_dict[prot_num] filter_attribute if attr_value > low_bound and attr_value < high_bound new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict abs_res_dict new_align_dict abs pos_num pos_align_dict {}for prot_num in prot_numbers new_align_dict abs pos_num pos_align_dict[prot_num] align_dict abs pos_num pos_align_dict[prot_num]return new_sum_dict new_align_dict
def filter sum_dict align_dict filter_attribute low_bound high_bound new_sum_dict FSSP FSSPSumDict new_align_dict copy deepcopy align_dict for prot_num in sum_dict attr_value getattr sum_dict[prot_num] filter_attribute if attr_value > low_bound and attr_value < high_bound new_sum_dict[prot_num] sum_dict[prot_num]prot_numbers sorted new_sum_dict for pos_num in new_align_dict abs_res_dict new_align_dict abs pos_num pos_align_dict {}for prot_num in prot_numbers new_align_dict abs pos_num pos_align_dict[prot_num] align_dict abs pos_num pos_align_dict[prot_num]return new_sum_dict new_align_dict
def get_account_for_tenant test_auth tenant_id return '%s%s' % test_auth reseller_prefixes[0] tenant_id
def _get_params mapper_spec allowed_keys None if 'input_reader' not in mapper_spec params message "Inputreader'sparametersshouldbespecifiedininput_readersubdictionary "if allowed_keys raise errors BadReaderParamsError message params mapper_spec paramsparams dict str n v for n v in params iteritems else if not isinstance mapper_spec params get 'input_reader' dict raise errors BadReaderParamsError 'Inputreaderparametersshouldbeadictionary' params mapper_spec params get 'input_reader' params dict str n v for n v in params iteritems if allowed_keys params_diff set params keys - allowed_keys if params_diff raise errors BadReaderParamsError 'Invalidinput_readerparameters %s' % ' ' join params_diff return params
def check_if_doc_is_linked doc method u'Delete' from frappe model rename_doc import get_link_fieldslink_fields get_link_fields doc doctype link_fields [[lf[u'parent'] lf[u'fieldname'] lf[u'issingle']] for lf in link_fields]for link_dt link_field issingle in link_fields if not issingle for item in frappe db get_values link_dt {link_field doc name} [u'name' u'parent' u'parenttype' u'docstatus'] as_dict True if item and item parent or item name doc name and method u'Delete' and item docstatus < 2 or method u'Cancel' and item docstatus 1 frappe throw _ u'Cannotdeleteorcancelbecause{0}<ahref "#Form/{0}/{1}">{1}</a>islinkedwith{2}<ahref "#Form/{2}/{3}">{3}</a>' format doc doctype doc name item parenttype if item parent else link_dt item parent or item name frappe LinkExistsError
def _oauth_signature consumer_token method url parameters {} token None parts urlparse urlparse url scheme netloc path parts[ 3]normalized_url scheme lower + ' //' + netloc lower + path base_elems []base_elems append method upper base_elems append normalized_url base_elems append '&' join '%s %s' % k _oauth_escape str v for k v in sorted parameters items base_string '&' join _oauth_escape e for e in base_elems key_elems [escape utf8 consumer_token['secret'] ]key_elems append escape utf8 token['secret'] if token else '' key '&' join key_elems hash hmac new key escape utf8 base_string hashlib sha1 return binascii b2a_base64 hash digest [ -1 ]
def is_option_value_selected browser_query value select Select browser_query first results[0] ddl_selected_value select first_selected_option get_attribute 'value' return ddl_selected_value value
def _ExpandDirectories filenames expanded set for filename in filenames if not os path isdir filename expanded add filename continuefor root _ files in os walk filename for loopfile in files fullname os path join root loopfile if fullname startswith ' ' + os path sep fullname fullname[len ' ' + os path sep ]expanded add fullname filtered []for filename in expanded if os path splitext filename [1][1 ] in GetAllExtensions filtered append filename return filtered
def _ExpandDirectories filenames expanded set for filename in filenames if not os path isdir filename expanded add filename continuefor root _ files in os walk filename for loopfile in files fullname os path join root loopfile if fullname startswith ' ' + os path sep fullname fullname[len ' ' + os path sep ]expanded add fullname filtered []for filename in expanded if os path splitext filename [1][1 ] in GetAllExtensions filtered append filename return filtered
def lstrip s chars None return s lstrip chars
def _quantile data quantile index quantile * len data - 1 bottom_index int floor index top_index int ceil index difference index - bottom_index output 1 - difference * data[bottom_index] + difference * data[top_index] return output
def _quantile data quantile index quantile * len data - 1 bottom_index int floor index top_index int ceil index difference index - bottom_index output 1 - difference * data[bottom_index] + difference * data[top_index] return output
def set_global_registry registry entry_point_group '_default' global __GLOBAL_REGISTRYlog debug "'set_global_registry '-settingregistry " __GLOBAL_REGISTRY[entry_point_group] registry
def getInterpretPluginsPath subName '' return getJoinedPath getFabmetheusToolsPath 'interpret_plugins' subName
def stat_mode_to_index_mode mode if S_ISLNK mode return S_IFLNKif S_ISDIR mode or S_IFMT mode S_IFGITLINK return S_IFGITLINKreturn S_IFREG 420 mode & 73
def jclouds registry xml_parent data deployer XML SubElement xml_parent 'jenkins plugins jclouds blobstore BlobStorePublisher' if 'profile' not in data raise JenkinsJobsException 'profileparameterismissing' XML SubElement deployer 'profileName' text data get 'profile' entries XML SubElement deployer 'entries' deployer_entry XML SubElement entries 'jenkins plugins jclouds blobstore BlobStoreEntry' try XML SubElement deployer_entry 'container' text data['container']XML SubElement deployer_entry 'path' text data get 'basedir' '' XML SubElement deployer_entry 'sourceFile' text data['files']except KeyError as e raise JenkinsJobsException "blobstorerequires'%s'tobeset" % e args[0] XML SubElement deployer_entry 'keepHierarchy' text str data get 'hierarchy' False lower
def jclouds registry xml_parent data deployer XML SubElement xml_parent 'jenkins plugins jclouds blobstore BlobStorePublisher' if 'profile' not in data raise JenkinsJobsException 'profileparameterismissing' XML SubElement deployer 'profileName' text data get 'profile' entries XML SubElement deployer 'entries' deployer_entry XML SubElement entries 'jenkins plugins jclouds blobstore BlobStoreEntry' try XML SubElement deployer_entry 'container' text data['container']XML SubElement deployer_entry 'path' text data get 'basedir' '' XML SubElement deployer_entry 'sourceFile' text data['files']except KeyError as e raise JenkinsJobsException "blobstorerequires'%s'tobeset" % e args[0] XML SubElement deployer_entry 'keepHierarchy' text str data get 'hierarchy' False lower
def OpenPathWithStub path stub from six moves import http_clientif not hasattr stub 'scheme' raise vmodl fault NotSupported elif stub scheme http_client HTTPConnection protocol 'http'elif stub scheme http_client HTTPSConnection protocol 'https'else raise vmodl fault NotSupported hostPort stub hosturl '%s //%s%s' % protocol hostPort path headers {}if stub cookie headers['Cookie'] stub cookiereturn requests get url headers headers verify False
def OpenPathWithStub path stub from six moves import http_clientif not hasattr stub 'scheme' raise vmodl fault NotSupported elif stub scheme http_client HTTPConnection protocol 'http'elif stub scheme http_client HTTPSConnection protocol 'https'else raise vmodl fault NotSupported hostPort stub hosturl '%s //%s%s' % protocol hostPort path headers {}if stub cookie headers['Cookie'] stub cookiereturn requests get url headers headers verify False
def __virtual__ if HAS_HEAT and HAS_OSLO return 'heat'return False 'Theheatexecutionmodulecannotbeloaded theheatclientandoslo_serializationpythonlibraryisnotavailable '
def add_existing_tag tag_name tag_manager tag Tag objects get name__iexact tag_name tag_manager add tag return tag name
def optimal_mode data if data isdigit return MODE_NUMBERif RE_ALPHA_NUM match data return MODE_ALPHA_NUMreturn MODE_8BIT_BYTE
def check_classification_targets y y_type type_of_target y if y_type not in ['binary' 'multiclass' 'multiclass-multioutput' 'multilabel-indicator' 'multilabel-sequences'] raise ValueError 'Unknownlabeltype %r' % y_type
def _unwrap_dict dictionary index_string index index_string split ' ' for k in index dictionary dictionary[k]return dictionary
def libvlc_audio_get_track p_mi f _Cfunctions get 'libvlc_audio_get_track' None or _Cfunction 'libvlc_audio_get_track' 1 None ctypes c_int MediaPlayer return f p_mi
def build_narrow_filter narrow check_supported_events_narrow_filter narrow def narrow_filter event message event['message']flags event['flags']for element in narrow operator element[0]operand element[1]if operator 'stream' if message['type'] 'stream' return Falseif operand lower message['display_recipient'] lower return Falseelif operator 'topic' if message['type'] 'stream' return Falseif operand lower message['subject'] lower return Falseelif operator 'sender' if operand lower message['sender_email'] lower return Falseelif operator 'is' and operand 'private' if message['type'] 'private' return Falseelif operator 'is' and operand in ['starred'] if operand not in flags return Falseelif operator 'is' and operand in ['alerted' 'mentioned'] if 'mentioned' not in flags return Falsereturn Truereturn narrow_filter
def create_program_action parent text name icon None nt_name None if is_text_string icon icon get_icon icon if os name 'nt' and nt_name is not None name nt_namepath programs find_program name if path is not None return create_action parent text icon icon triggered lambda programs run_program name
def test_find_number_0 r find_number 'sss' assert r is None
def test_find_number_0 r find_number 'sss' assert r is None
@register simple_tag takes_context True def avatar context user size service_id None service avatar_services for_user user service_id if service is None logging error u'Couldnotgetasuitableavatarserviceforuser%s ' user return mark_safe u'' return service render request context[u'request'] user user size size
def disabled name **kwargs ret {'name' name 'changes' {} 'result' True 'comment' ''}ret update _disable name None **kwargs return ret
def alternatives *rules def _alternatives integral alts []for rule in rules result rule integral if result and not isinstance result DontKnowRule and result integral and result not in alts alts append result if len alts 1 return alts[0]elif alts doable [rule for rule in alts if not contains_dont_know rule ]if doable return AlternativeRule doable *integral else return AlternativeRule alts *integral return _alternatives
@XFAILdef test_bounded_xfail assert ask Q finite sin x ** x is True assert ask Q finite cos x ** x is True
@XFAILdef test_bounded_xfail assert ask Q finite sin x ** x is True assert ask Q finite cos x ** x is True
def force_drop_names *names from import configfrom sqlalchemy import inspect@decoratordef go fn *args **kw try return fn *args **kw finally drop_all_tables config db inspect config db include_names names return go
def force_drop_names *names from import configfrom sqlalchemy import inspect@decoratordef go fn *args **kw try return fn *args **kw finally drop_all_tables config db inspect config db include_names names return go
def challenge crap ''for x in range random randrange 15 25 crap crap + chr random randint 65 90 crap md5 crap digest return crap
def extract_link_from_header_simple http_response header_name header_value if not header_value raise StopIterationtry yield http_response get_url url_join header_value except ValueError msg 'Theapplicationsenta"%s"headerthatw3affailedtocorrectlyparseasanURL theheadervaluewas "%s"'om out debug msg % header_name header_value
def get_file path dest saltenv 'base' makedirs False template None gzip None if gzip is not None log warning 'Thegzipargumenttocp get_fileinsalt-sshisunsupported' if template is not None path dest _render_filenames path dest saltenv template src __context__['fileclient'] cache_file path saltenv cachedir os path join 'salt-ssh' __salt__ kwargs['id_'] single salt client ssh Single __opts__ '' **__salt__ kwargs ret single shell send src dest makedirs return not ret[2]
def ImgtIterator handle return _ImgtScanner debug 0 parse_records handle
def multiple_file_DA_fitZIG input_dir output_dir mapping_fp mapping_category subcategory_1 subcategory_2 if not exists output_dir makedirs output_dir file_names [fname for fname in listdir input_dir if not fname startswith ' ' or isdir fname ]for fname in file_names base_fname ext splitext fname original_fname base_fname + ' biom' hdf5_infile join input_dir original_fname tmp_bt load_table hdf5_infile tmp_pmf _ parse_mapping_file_to_dict mapping_fp check_mapping_file_category tmp_bt mapping_fp mapping_category subcategory_1 subcategory_2 tmp_bt add_metadata tmp_pmf 'sample' outfile join output_dir 'fitZIG_DA_' + base_fname + ' txt' with tempfile NamedTemporaryFile dir get_qiime_temp_dir prefix 'QIIME-differential-abundance-temp-table-' suffix ' biom' as temp_fh temp_fh write tmp_bt to_json 'forR' temp_fh flush run_fitZIG temp_fh name outfile mapping_category subcategory_1 subcategory_2
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1 5 b -3 x np arange 100 y m_real x m MyModel f fitting LevMarLSQFitter fitted_1 f m x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 m2 MyModel m2 a bounds -2 2 f2 fitting LevMarLSQFitter fitted_2 f2 m2 x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 assert np any f2 fit_info[u'fjac'] 0
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1 5 b -3 x np arange 100 y m_real x m MyModel f fitting LevMarLSQFitter fitted_1 f m x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 m2 MyModel m2 a bounds -2 2 f2 fitting LevMarLSQFitter fitted_2 f2 m2 x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 assert np any f2 fit_info[u'fjac'] 0
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1 5 b -3 x np arange 100 y m_real x m MyModel f fitting LevMarLSQFitter fitted_1 f m x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 m2 MyModel m2 a bounds -2 2 f2 fitting LevMarLSQFitter fitted_2 f2 m2 x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 assert np any f2 fit_info[u'fjac'] 0
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1 5 b -3 x np arange 100 y m_real x m MyModel f fitting LevMarLSQFitter fitted_1 f m x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 m2 MyModel m2 a bounds -2 2 f2 fitting LevMarLSQFitter fitted_2 f2 m2 x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 assert np any f2 fit_info[u'fjac'] 0
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_bound_constraints_estimate_jacobian class MyModel Fittable1DModel a Parameter default 1 b Parameter default 2 @staticmethoddef evaluate x a b return a * x + b m_real MyModel a 1 5 b -3 x np arange 100 y m_real x m MyModel f fitting LevMarLSQFitter fitted_1 f m x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 m2 MyModel m2 a bounds -2 2 f2 fitting LevMarLSQFitter fitted_2 f2 m2 x y assert np allclose fitted_1 a 1 5 assert np allclose fitted_1 b -3 assert np any f2 fit_info[u'fjac'] 0
@world absorbdef css_has_text css_selector text index 0 strip False if text wait_for lambda _ css_text css_selector index index actual_text css_text css_selector index index if strip actual_text actual_text strip text text strip return actual_text text
def make_colorizer color def inner text return colorizer colorize color text return inner
def my_kernel X Y M np array [[2 0] [0 1 0]] return np dot np dot X M Y T
def FindNextMatchingAngleBracket clean_lines linenum init_suffix line init_suffixnesting_stack ['<']while True match Search '^[^<> \\[\\]]* [<> \\[\\]] * $' line if match operator match group 1 line match group 2 if nesting_stack[ -1 ] '<' if operator in '<' ' ' '[' nesting_stack append operator elif operator '>' nesting_stack pop if not nesting_stack return Trueelif operator ' ' return Trueelse return Falseelif operator in '<' ' ' '[' nesting_stack append operator elif operator in ' ' ']' nesting_stack pop else linenum + 1if linenum > len clean_lines elided breakline clean_lines elided[linenum]return True
def sdm_LM f return f[0][0]
def is_comprehensive_theming_enabled if settings ENABLE_COMPREHENSIVE_THEMING and current_request_has_associated_site_theme return Trueif microsite is_request_in_microsite return Falsereturn settings ENABLE_COMPREHENSIVE_THEMING
def main args parse_args client NSoTInventory if args list_ print client do_list elif args host print client do_host args host
def make_next_param login_url current_url l urlparse login_url c urlparse current_url if not l scheme or l scheme c scheme and not l netloc or l netloc c netloc return urlunparse '' '' c path c params c query '' return current_url
def make_next_param login_url current_url l urlparse login_url c urlparse current_url if not l scheme or l scheme c scheme and not l netloc or l netloc c netloc return urlunparse '' '' c path c params c query '' return current_url
def _allow_new_attributes f def decorated self *args **kw 'Thedecoratedfunctionthatreplaces__init__ or__setstate__ \n\n'if not hasattr self '_canAddAttributes' self __dict__['_canAddAttributes'] 1else self _canAddAttributes + 1assert self _canAddAttributes > 1 count self _canAddAttributesf self *args **kw if hasattr self '_canAddAttributes' self _canAddAttributes - 1else self _canAddAttributes count - 1 assert self _canAddAttributes > 0 if self _canAddAttributes 0 del self _canAddAttributesdecorated __doc__ f __doc__decorated __name__ f __name__return decorated
def _allow_new_attributes f def decorated self *args **kw 'Thedecoratedfunctionthatreplaces__init__ or__setstate__ \n\n'if not hasattr self '_canAddAttributes' self __dict__['_canAddAttributes'] 1else self _canAddAttributes + 1assert self _canAddAttributes > 1 count self _canAddAttributesf self *args **kw if hasattr self '_canAddAttributes' self _canAddAttributes - 1else self _canAddAttributes count - 1 assert self _canAddAttributes > 0 if self _canAddAttributes 0 del self _canAddAttributesdecorated __doc__ f __doc__decorated __name__ f __name__return decorated
def _allow_new_attributes f def decorated self *args **kw 'Thedecoratedfunctionthatreplaces__init__ or__setstate__ \n\n'if not hasattr self '_canAddAttributes' self __dict__['_canAddAttributes'] 1else self _canAddAttributes + 1assert self _canAddAttributes > 1 count self _canAddAttributesf self *args **kw if hasattr self '_canAddAttributes' self _canAddAttributes - 1else self _canAddAttributes count - 1 assert self _canAddAttributes > 0 if self _canAddAttributes 0 del self _canAddAttributesdecorated __doc__ f __doc__decorated __name__ f __name__return decorated
def get_data_for_unfinished_jobs unfinished_job_models job_models JobModel get_all_unfinished_jobs NUM_JOBS_IN_DASHBOARD_LIMIT return [_get_job_dict_from_job_model model for model in unfinished_job_models]
def get_data_for_unfinished_jobs unfinished_job_models job_models JobModel get_all_unfinished_jobs NUM_JOBS_IN_DASHBOARD_LIMIT return [_get_job_dict_from_job_model model for model in unfinished_job_models]
def core from fabtools require deb import package as require_deb_packagefrom fabtools require rpm import package as require_rpm_packagefamily distrib_family if not files exists '/usr/bin/sudo' raise Exception 'Pleaseinstallthesudopackageandexecuteadduser%ssudo' % env user if not files exists '/usr/bin/docker' if family 'debian' require_deb_package 'curl' elif family 'redhat' require_rpm_package 'curl' else raise UnsupportedFamily supported ['debian' 'redhat'] run_as_root 'curl-sSLhttps //get docker com/ sh'
def show_highstate __opts__['grains'] __grains__st_ salt client ssh state SSHHighState __opts__ __pillar__ __salt__ __context__['fileclient'] return st_ compile_highstate
def _abbreviate text threshold if text is not None and len text > threshold text text[ threshold] + ' ' return text
def _abbreviate text threshold if text is not None and len text > threshold text text[ threshold] + ' ' return text
def _abbreviate text threshold if text is not None and len text > threshold text text[ threshold] + ' ' return text
def mac_str_to_bytes mac_str if len mac_str 12 passelif len mac_str 17 sep mac_str[2]mac_str mac_str replace sep '' else raise ValueError 'InvalidMACaddress' if six PY3 mac_bytes bytes int mac_str[s s + 2 ] 16 for s in range 0 12 2 else mac_bytes '' join chr int mac_str[s s + 2 ] 16 for s in range 0 12 2 return mac_bytes
def _convert_asset_timestamp_fields dict_ for key in _asset_timestamp_fields & viewkeys dict_ value pd Timestamp dict_[key] tz 'UTC' dict_[key] None if isnull value else value return dict_
def check_freezing_date posting_date adv_adj False if not adv_adj acc_frozen_upto frappe db get_value u'AccountsSettings' None u'acc_frozen_upto' if acc_frozen_upto frozen_accounts_modifier frappe db get_value u'AccountsSettings' None u'frozen_accounts_modifier' if getdate posting_date < getdate acc_frozen_upto and not frozen_accounts_modifier in frappe get_roles frappe throw _ u'Youarenotauthorizedtoaddorupdateentriesbefore{0}' format formatdate acc_frozen_upto
def check_freezing_date posting_date adv_adj False if not adv_adj acc_frozen_upto frappe db get_value u'AccountsSettings' None u'acc_frozen_upto' if acc_frozen_upto frozen_accounts_modifier frappe db get_value u'AccountsSettings' None u'frozen_accounts_modifier' if getdate posting_date < getdate acc_frozen_upto and not frozen_accounts_modifier in frappe get_roles frappe throw _ u'Youarenotauthorizedtoaddorupdateentriesbefore{0}' format formatdate acc_frozen_upto
def check_freezing_date posting_date adv_adj False if not adv_adj acc_frozen_upto frappe db get_value u'AccountsSettings' None u'acc_frozen_upto' if acc_frozen_upto frozen_accounts_modifier frappe db get_value u'AccountsSettings' None u'frozen_accounts_modifier' if getdate posting_date < getdate acc_frozen_upto and not frozen_accounts_modifier in frappe get_roles frappe throw _ u'Youarenotauthorizedtoaddorupdateentriesbefore{0}' format formatdate acc_frozen_upto
def read_token_file filename f open filename return f readline strip f readline strip
def determine_timestamp item for key in ['creationTimestamp' 'timeCreated'] if key in item return item[key]raise ValueError 'Couldnotdeterminetimestampkeyfor{0}' format item get 'kind' item
def optional_args decorator @wraps decorator def wrapper *args **kwargs def dec f return decorator f *args **kwargs is_decorating not kwargs and len args 1 and callable args[0] if is_decorating f args[0]args []return dec f else return decreturn wrapper
def optional_args decorator @wraps decorator def wrapper *args **kwargs def dec f return decorator f *args **kwargs is_decorating not kwargs and len args 1 and callable args[0] if is_decorating f args[0]args []return dec f else return decreturn wrapper
def _open cgi params None get 1 from Bio _py3k import urlopen urlencodeif params is None params {}options urlencode params if get if options cgi + '?' + options handle urlopen cgi else handle urlopen cgi data options return handle
def _open cgi params None get 1 from Bio _py3k import urlopen urlencodeif params is None params {}options urlencode params if get if options cgi + '?' + options handle urlopen cgi else handle urlopen cgi data options return handle
def check_marshalled_restart_policy test_case policy_type **attributes expected_name FLOCKER_RESTART_POLICY_POLICY_TO_NAME[policy_type]test_case assertEqual dict name expected_name **attributes marshalled_restart_policy policy_type **attributes
def find_duplicative_certs config domains def update_certs_for_domain_matches candidate_lineage rv 'Returncertasidentical_names_certifitmatches \norsubset_names_certifitmatchesassubset\n' identical_names_cert subset_names_cert rvcandidate_names set candidate_lineage names if candidate_names set domains identical_names_cert candidate_lineageelif candidate_names issubset set domains if subset_names_cert is None subset_names_cert candidate_lineageelif len candidate_names > len subset_names_cert names subset_names_cert candidate_lineagereturn identical_names_cert subset_names_cert return _search_lineages config update_certs_for_domain_matches None None
def find_duplicative_certs config domains def update_certs_for_domain_matches candidate_lineage rv 'Returncertasidentical_names_certifitmatches \norsubset_names_certifitmatchesassubset\n' identical_names_cert subset_names_cert rvcandidate_names set candidate_lineage names if candidate_names set domains identical_names_cert candidate_lineageelif candidate_names issubset set domains if subset_names_cert is None subset_names_cert candidate_lineageelif len candidate_names > len subset_names_cert names subset_names_cert candidate_lineagereturn identical_names_cert subset_names_cert return _search_lineages config update_certs_for_domain_matches None None
def map_int_to_tour num_nodes i start_node nodes_remaining range 0 start_node + range start_node + 1 num_nodes tour []while len nodes_remaining > 0 num_nodes len nodes_remaining next_step nodes_remaining[ i % num_nodes ]nodes_remaining remove next_step tour append next_step i i / num_nodes tour [start_node] + tour + [start_node] return tour
def map_int_to_tour num_nodes i start_node nodes_remaining range 0 start_node + range start_node + 1 num_nodes tour []while len nodes_remaining > 0 num_nodes len nodes_remaining next_step nodes_remaining[ i % num_nodes ]nodes_remaining remove next_step tour append next_step i i / num_nodes tour [start_node] + tour + [start_node] return tour
def pkcs_ilen n i 0while n > 0 n >> 8i + 1return i
def pkcs_ilen n i 0while n > 0 n >> 8i + 1return i
def open filename buffer builtins open filename 'rb' encoding lines detect_encoding buffer readline buffer seek 0 text TextIOWrapper buffer encoding line_buffering True text mode 'r'return text
def open filename buffer builtins open filename 'rb' encoding lines detect_encoding buffer readline buffer seek 0 text TextIOWrapper buffer encoding line_buffering True text mode 'r'return text
def getClippedSimplifiedLoopPath clip loopPath radius return getSimplifiedPath getClippedLoopPath clip loopPath radius
def assemble block return [ '\n' join sub_block + '\n' for sub_block in block]
def _simple_cmd cmd app url 'http //localhost 8080/manager' timeout 180 try opts {'path' app 'version' ls url [app]['version']}return '\n' join _wget cmd opts url timeout timeout ['msg'] except Exception return 'FAIL-Nocontextexistsforpath{0}' format app
def from_units val val str val strip upper if val '-1' return valm RE_UNITS search val if m if m group 2 val float m group 1 unit m group 2 n 0while unit TAB_UNITS[n] val val * 1024 0 n n + 1 else val m group 1 try return float val except return 0 0else return 0 0
def get_uid path follow_symlinks True return stats os path expanduser path follow_symlinks follow_symlinks get 'uid' -1
def _autoregister admin model follow None if model _meta proxy raise RegistrationError 'Proxymodelscannotbeusedwithdjango-reversion registertheparentclassinstead' if not is_registered model follow follow or [] for parent_cls field in model _meta parents items follow append field name _autoregister admin parent_cls register model follow follow format admin reversion_format
@snippetdef client_list_entries client to_delete for entry in client list_entries do_something_with entry FILTER 'logName log_nameANDtextPayload simple'for entry in client list_entries filter_ FILTER do_something_with entry from google cloud logging import DESCENDINGfor entry in client list_entries order_by DESCENDING do_something_with entry iterator client list_entries pages iterator pagespage1 next pages for entry in page1 do_something_with entry page2 next pages for entry in page2 do_something_with entry
def weighted_score raw_earned raw_possible weight assert raw_possible is not None cannot_compute_with_weight weight is None or raw_possible 0 if cannot_compute_with_weight return raw_earned raw_possible else return float raw_earned * weight / raw_possible float weight
def register_draft_only model_class fields follow format if revision_manager is_registered model_class raise RegistrationError '%rhasalreadybeenregisteredwithReversion ' % model_class if model_class _meta proxy and not revision_manager is_registered list model_class _meta parents keys [0] raise RegistrationError '%risaproxymodel anditsparenthasnotbeenregisteredwithReversion ' % model_class opts model_class _metalocal_fields opts local_fields + opts local_many_to_many if fields is None fields [field name for field in local_fields]fields tuple fields follow tuple follow try registration_info VersionAdapter fields fields follow follow format format for_concrete_model True ignore_duplicates False except TypeError registration_info VersionAdapter model_class registration_info fields fieldsregistration_info follow followregistration_info format formatif hasattr revision_manager '_registration_key_for_model' model_key revision_manager _registration_key_for_model model_class else model_key model_classrevision_manager _registered_models[model_key] registration_info
def register_draft_only model_class fields follow format if revision_manager is_registered model_class raise RegistrationError '%rhasalreadybeenregisteredwithReversion ' % model_class if model_class _meta proxy and not revision_manager is_registered list model_class _meta parents keys [0] raise RegistrationError '%risaproxymodel anditsparenthasnotbeenregisteredwithReversion ' % model_class opts model_class _metalocal_fields opts local_fields + opts local_many_to_many if fields is None fields [field name for field in local_fields]fields tuple fields follow tuple follow try registration_info VersionAdapter fields fields follow follow format format for_concrete_model True ignore_duplicates False except TypeError registration_info VersionAdapter model_class registration_info fields fieldsregistration_info follow followregistration_info format formatif hasattr revision_manager '_registration_key_for_model' model_key revision_manager _registration_key_for_model model_class else model_key model_classrevision_manager _registered_models[model_key] registration_info
def doc_checksum docstr import hashlibconverted hashlib sha1 docstr hexdigest return converted
def _check_orphans_no_tips cursor orphans_with_tips cursor all '\nWITHvalid_tipsAS SELECT*FROMcurrent_tipsWHEREamount>0 \nSELECTusername\nFROM SELECTtipperASusernameFROMvalid_tips\nUNION\nSELECTtippeeASusernameFROMvalid_tips foo\nWHERENOTEXISTS SELECT1FROMelsewhereWHEREparticipant username \n' assert len orphans_with_tips 0 orphans_with_tips
def _check_orphans_no_tips cursor orphans_with_tips cursor all '\nWITHvalid_tipsAS SELECT*FROMcurrent_tipsWHEREamount>0 \nSELECTusername\nFROM SELECTtipperASusernameFROMvalid_tips\nUNION\nSELECTtippeeASusernameFROMvalid_tips foo\nWHERENOTEXISTS SELECT1FROMelsewhereWHEREparticipant username \n' assert len orphans_with_tips 0 orphans_with_tips
def _check_orphans_no_tips cursor orphans_with_tips cursor all '\nWITHvalid_tipsAS SELECT*FROMcurrent_tipsWHEREamount>0 \nSELECTusername\nFROM SELECTtipperASusernameFROMvalid_tips\nUNION\nSELECTtippeeASusernameFROMvalid_tips foo\nWHERENOTEXISTS SELECT1FROMelsewhereWHEREparticipant username \n' assert len orphans_with_tips 0 orphans_with_tips
def search_channel_tag key None category None return Channel objects get_by_tag key key category category
def instantiateShootErrback d defer Deferred try 1 / 0 except d errback d addErrback lambda x None
def parse_sample_id_map sample_id_map_f result {}new_samp_id_counts defaultdict int for line in sample_id_map_f line line strip if line samp_id mapped_id line split ' DCTB ' if samp_id in result raise ValueError "ThefirstcolumnofthesampleIDmapmustcontainuniquesampleIDs '%s'isrepeated Thesecondcolumn however maycontainrepeats " % samp_id elif new_samp_id_counts[mapped_id] > 2 raise ValueError "OnlytwooriginalsampleIDsmaymaptothesamenewsampleID ThenewsampleID'%s'hasmorethantwosampleIDsmappingtoit " % mapped_id else result[samp_id] mapped_idnew_samp_id_counts[mapped_id] + 1return result
def rgrids *args **kwargs ax gca if not isinstance ax PolarAxes raise RuntimeError 'rgridsonlydefinedforpolaraxes' if len args 0 lines ax yaxis get_ticklines labels ax yaxis get_ticklabels else lines labels ax set_rgrids *args **kwargs draw_if_interactive return silent_list 'Line2Drgridline' lines silent_list 'Textrgridlabel' labels
def verify_checksums filename errors 0try hdulist fits open filename checksum OPTIONS checksum_kind except UserWarning as w remainder ' ' + '' join str w split '' [1 ] strip log warning 'BAD{ r}{}' format filename remainder return 1if not OPTIONS ignore_missing for i hdu in enumerate hdulist if not hdu _checksum log warning 'MISSING{ r} ChecksumnotfoundinHDU#{}' format filename i return 1if not hdu _datasum log warning 'MISSING{ r} DatasumnotfoundinHDU#{}' format filename i return 1if not errors log info 'OK{ r}' format filename return errors
def verify_checksums filename errors 0try hdulist fits open filename checksum OPTIONS checksum_kind except UserWarning as w remainder ' ' + '' join str w split '' [1 ] strip log warning 'BAD{ r}{}' format filename remainder return 1if not OPTIONS ignore_missing for i hdu in enumerate hdulist if not hdu _checksum log warning 'MISSING{ r} ChecksumnotfoundinHDU#{}' format filename i return 1if not hdu _datasum log warning 'MISSING{ r} DatasumnotfoundinHDU#{}' format filename i return 1if not errors log info 'OK{ r}' format filename return errors
def SetThreadName thread name thread setName '[%s %s]' % GlobalProcess Type name
def set_ key value profile None db _get_db profile return db save {'_id' uuid4 hex key value}
def IdToCounter k if k > _MAX_SCATTERED_ID return 0 SCATTERED elif k > _MAX_SEQUENTIAL_ID and k < _MAX_SCATTERED_ID return long ReverseBitsInt64 k >> _SCATTER_SHIFT SCATTERED elif k > 0 return long k SEQUENTIAL else raise datastore_errors BadArgumentError 'invalidid %d ' % k
def IdToCounter k if k > _MAX_SCATTERED_ID return 0 SCATTERED elif k > _MAX_SEQUENTIAL_ID and k < _MAX_SCATTERED_ID return long ReverseBitsInt64 k >> _SCATTER_SHIFT SCATTERED elif k > 0 return long k SEQUENTIAL else raise datastore_errors BadArgumentError 'invalidid %d ' % k
def ensure_pr_fetch modified Falseremotes git remote splitlines if u'edx' not in remotes git remote u'add' u'edx' u'https //github com/edx/edx-platform git' modified Trueedx_fetches git config u'remote edx fetch' get_all True splitlines pr_fetch u'+refs/pull/*/head refs/remotes/edx/pr/*'if pr_fetch not in edx_fetches git config u'remote edx fetch' pr_fetch add True modified Truegit fetch u'edx' return modified
def ensure_pr_fetch modified Falseremotes git remote splitlines if u'edx' not in remotes git remote u'add' u'edx' u'https //github com/edx/edx-platform git' modified Trueedx_fetches git config u'remote edx fetch' get_all True splitlines pr_fetch u'+refs/pull/*/head refs/remotes/edx/pr/*'if pr_fetch not in edx_fetches git config u'remote edx fetch' pr_fetch add True modified Truegit fetch u'edx' return modified
def ensure_pr_fetch modified Falseremotes git remote splitlines if u'edx' not in remotes git remote u'add' u'edx' u'https //github com/edx/edx-platform git' modified Trueedx_fetches git config u'remote edx fetch' get_all True splitlines pr_fetch u'+refs/pull/*/head refs/remotes/edx/pr/*'if pr_fetch not in edx_fetches git config u'remote edx fetch' pr_fetch add True modified Truegit fetch u'edx' return modified
def ensure_pr_fetch modified Falseremotes git remote splitlines if u'edx' not in remotes git remote u'add' u'edx' u'https //github com/edx/edx-platform git' modified Trueedx_fetches git config u'remote edx fetch' get_all True splitlines pr_fetch u'+refs/pull/*/head refs/remotes/edx/pr/*'if pr_fetch not in edx_fetches git config u'remote edx fetch' pr_fetch add True modified Truegit fetch u'edx' return modified
def _idnaBytes text try import idnaexcept ImportError return text encode 'idna' else return idna encode text
def dvi_match_query body_id ptable s3db pr_personntable s3db pr_notebtable s3db dvi_bodyquery ptable deleted False & ptable missing True & ntable pe_id ptable pe_id & ntable status 1 body btable[body_id]if not body return queryif body date_of_recovery q ntable timestmp < body date_of_recovery ntable timestmp None query query & q if body age_group and body age_group 1 q ptable age_group None ptable age_group 1 ptable age_group body age_group query query & q if body gender and body gender 1 q ptable gender None ptable gender 1 ptable gender body gender return query
def getInterpretPlugin fileName importPluginFileNames getImportPluginFileNames for importPluginFileName in importPluginFileNames fileTypeDot ' ' + importPluginFileName if fileName[ - len fileTypeDot ] lower fileTypeDot importPluginsDirectoryPath getPluginsDirectoryPath pluginModule archive getModuleWithDirectoryPath importPluginsDirectoryPath importPluginFileName if pluginModule None return pluginModuleprint 'Couldnotfindplugintohandle' + fileName return None
def fromXMLname string retval sub '_xFFFF_' '' string def fun matchobj return _fromUnicodeHex matchobj group 0 retval sub '_x[0-9A-Za-z]+_' fun retval return retval
def main ip_addr raw_input 'IPaddress ' ip_addr ip_addr strip username 'pyclass'password getpass getpass remote_conn telnet_connect ip_addr output login remote_conn username password time sleep 1 remote_conn read_very_eager disable_paging remote_conn output send_command remote_conn 'showipintbrief' print '\n\n'print outputprint '\n\n'remote_conn close
def remove_job_submit_sidebar_box apps schema_editor Box apps get_model u'boxes' u'Box' try submit_box Box objects get label u'jobs-submitajob' submit_box delete except Box DoesNotExist pass
def _keygen_callback return
def _keygen_callback return
def xticks *args **kwargs ax gca if len args 0 locs ax get_xticks labels ax get_xticklabels elif len args 1 locs ax set_xticks args[0] labels ax get_xticklabels elif len args 2 locs ax set_xticks args[0] labels ax set_xticklabels args[1] **kwargs else raise TypeError 'Illegalnumberofargumentstoxticks' if len kwargs for l in labels l update kwargs draw_if_interactive return locs silent_list 'Textxticklabel' labels
def namedObject name classSplit name split ' ' module namedModule ' ' join classSplit[ -1 ] return getattr module classSplit[ -1 ]
def chain_transports *args if len args < 2 raise ValueError 'chain_transportsneedsatleast2transports ' class WrappedTransport TransportWrapper cls_chain list args return WrappedTransport
def chain_transports *args if len args < 2 raise ValueError 'chain_transportsneedsatleast2transports ' class WrappedTransport TransportWrapper cls_chain list args return WrappedTransport
def get_sprot_raw id return _urlopen 'http //www uniprot org/uniprot/%s txt' % id
def mofile mofile **kwargs return _pofile_or_mofile mofile 'mofile' **kwargs
def _build_regex_range ws True invert False exclude None if exclude is None exclude []regex ''in_range Falselast Nonelast_added Nonedef valid_char char if char in exclude result Falseelif ws result _is_printable char else result _is_printable char and unicodedata category char 'Zs' if invert is True return not result return resultfor c in _get_all_chars if valid_char c if not in_range regex + re escape c last_added cin_range Trueelse if in_range and last last_added regex + '-' + re escape last in_range Falselast celse if in_range regex + '-' + re escape c return regex
def submit_jobs commands prefix qiime_config load_qiime_config CLUSTER_JOBS_SCRIPT qiime_config['cluster_jobs_fp']if not CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotsetinconfigfile ' if not exists CLUSTER_JOBS_SCRIPT or which CLUSTER_JOBS_SCRIPT raise ApplicationNotFoundError 'cluster_jobs_fpnotin$PATHorprovidedasfullpath ' outfilename join get_qiime_temp_dir '%s_commands txt' % prefix fh open outfilename 'w' fh write '\n' join commands fh close cmd '%s-ms%s%s' % CLUSTER_JOBS_SCRIPT outfilename prefix system cmd remove outfilename
def gemset_list ruby 'default' runas None gemsets []output _rvm_do ruby ['rvm' 'gemset' 'list'] runas runas if output regex re compile '^ [^]+ ' for line in output splitlines match regex match line if match gemsets append match group 1 return gemsets
def merge a b _check_steps a b return range min a start b start max a stop b stop
def get_all_eip_addresses addresses None allocation_ids None region None key None keyid None profile None return [x public_ip for x in _get_all_eip_addresses addresses allocation_ids region key keyid profile ]
def find_first_level_groups_span string enclosing opening closing enclosingdepth []result []for i c in enumerate string if c opening depth append i elif c closing try start depth pop end iif not depth result append start end + 1 except IndexError passreturn result
def process bundle force False allow_debug True joblist bundle_to_joblist bundle allow_debug allow_debug simplify_jobs joblist result []for output_path work in joblist iteritems if isinstance work tuple list build output_path work force force result append make_url output_path else result append make_url output_path return result
def smartsplit code strings []pos 0while pos < len code if code[pos] '"' word ''pos + 1while pos < len code if code[pos] '"' breakif code[pos] '\\' word + '\\'pos + 1word + code[pos]pos + 1strings append '"%s"' % word pos + 1return strings
@app route '/hello' def say_hello return 'StaticFileServersayshello '
def cartesian arrays out None arrays [np asarray x for x in arrays]shape len x for x in arrays dtype arrays[0] dtypeix np indices shape ix ix reshape len arrays -1 Tif out is None out np empty_like ix dtype dtype for n arr in enumerate arrays out[ n] arrays[n][ix[ n]]return out
def get_module module number mod mod_inst get_mod_num module number if not mod is None and not mod_inst is None return HOUSE[mod][mod_inst]return None
def override_system_resolver resolver None if resolver is None resolver get_default_resolver global _resolver_resolver resolversocket getaddrinfo _getaddrinfosocket getnameinfo _getnameinfosocket getfqdn _getfqdnsocket gethostbyname _gethostbynamesocket gethostbyname_ex _gethostbyname_exsocket gethostbyaddr _gethostbyaddr
def override_system_resolver resolver None if resolver is None resolver get_default_resolver global _resolver_resolver resolversocket getaddrinfo _getaddrinfosocket getnameinfo _getnameinfosocket getfqdn _getfqdnsocket gethostbyname _gethostbynamesocket gethostbyname_ex _gethostbyname_exsocket gethostbyaddr _gethostbyaddr
def override_system_resolver resolver None if resolver is None resolver get_default_resolver global _resolver_resolver resolversocket getaddrinfo _getaddrinfosocket getnameinfo _getnameinfosocket getfqdn _getfqdnsocket gethostbyname _gethostbynamesocket gethostbyname_ex _gethostbyname_exsocket gethostbyaddr _gethostbyaddr
def override_system_resolver resolver None if resolver is None resolver get_default_resolver global _resolver_resolver resolversocket getaddrinfo _getaddrinfosocket getnameinfo _getnameinfosocket getfqdn _getfqdnsocket gethostbyname _gethostbynamesocket gethostbyname_ex _gethostbyname_exsocket gethostbyaddr _gethostbyaddr
def bfs_successors G source parent sourcechildren []for p c in bfs_edges G source if p parent children append c continue yield parent children children [c]parent p yield parent children
def diff x n 1 axis -1 return DiffOp n n axis axis x
def diff x n 1 axis -1 return DiffOp n n axis axis x
def list_repos repos {}out __salt__['cmd run'] 'xbps-query-L' output_loglevel 'trace' for line in out splitlines repo {}if not line continuetry nb url rsa line strip split '' 2 except ValueError log error 'Problemparsingxbps-query Unexpectedformattinginline "{0}"' format line repo['nbpkg'] int nb if nb isdigit else 0 repo['url'] urlrepo['rsasigned'] True if rsa ' RSAsigned ' else False repos[repo['url']] reporeturn repos
def _dict_from_path path val delimiter DEFAULT_TARGET_DELIM nested_dict _infinitedict keys path rsplit delimiter lastplace reduce operator getitem keys[ -1 ] nested_dict lastplace[keys[ -1 ]] valreturn nested_dict
def _dict_from_path path val delimiter DEFAULT_TARGET_DELIM nested_dict _infinitedict keys path rsplit delimiter lastplace reduce operator getitem keys[ -1 ] nested_dict lastplace[keys[ -1 ]] valreturn nested_dict
@taskdef clean ctx dry_run False basedir ctx sphinx destdir or 'build/docs' cleanup_dirs [basedir] dry_run dry_run
def randomDeterministic Ts numA len Ts dim len Ts[0] choices rand dim * numA astype int policy zeros dim numA for si a in choices policy[ si a ] 1return policy collapsedTransitions Ts policy
def read_chunks file size io DEFAULT_BUFFER_SIZE while True chunk file read size if not chunk break yield chunk
def iscsi_get_nodes cmd 'iscsiadm--modenode'output utils system_output cmd pattern ' \\d+\\ \\d+\\ \\d+\\ \\d+ \\W {2}\\d\\W \\d+ \\d+\\s+ [\\w\\ \\- \\d]+ 'nodes []if 'Norecordsfound' not in output nodes re findall pattern output return nodes
def _options_dir name _check_portname name _root '/var/db/ports'new_dir os path join _root name replace '/' '_' old_dir os path join _root name split '/' [ -1 ] if os path isdir old_dir return old_dirreturn new_dir
def fileList paths relative False folders False if not isinstance paths list paths [paths]files []def append directory name if not name startswith ' ' path os path join directory name files append path for path in paths for directory dirnames filenames in os walk path followlinks True if folders for dirname in dirnames append directory dirname for filename in filenames append directory filename if relative files map_apply lambda x x[ len path + 1 ] files return files
def fileList paths relative False folders False if not isinstance paths list paths [paths]files []def append directory name if not name startswith ' ' path os path join directory name files append path for path in paths for directory dirnames filenames in os walk path followlinks True if folders for dirname in dirnames append directory dirname for filename in filenames append directory filename if relative files map_apply lambda x x[ len path + 1 ] files return files
def test_sets objs tokenize '#{12}' assert objs [HySet [HyInteger 1 HyInteger 2 ] ] objs tokenize ' bar#{foobarbaz} ' assert objs [HyExpression [HySymbol 'bar' HySet ['foo' 'bar' 'baz'] ] ] objs tokenize '#{ foobar bazquux }' assert objs [HySet [HyExpression [HySymbol 'foo' HySymbol 'bar' ] HyExpression [HySymbol 'baz' HySymbol 'quux' ] ] ] objs tokenize '#{121121}' assert objs [HySet [HyInteger n for n in [1 2 1 1 2 1]] ] assert len objs[0] 6 objs tokenize '#{a1}' assert objs [HySet [HySymbol 'a' HyInteger 1 ] ]
@hook command 'validate' 'w3c' def validate text text text strip if not urllib parse urlparse text scheme text 'http //' + text params {'uri' text}request requests get 'http //validator w3 org/check' params params info request headersurl web try_shorten request url status info['x-w3c-validator-status'] lower print statusif status in 'valid' 'invalid' error_count info['x-w3c-validator-errors']warning_count info['x-w3c-validator-warnings']return '{}wasfoundtobe{}with{}error{}and{}warning{}-{}' format text status error_count 's'[ error_count 1 ] warning_count 's'[ warning_count 1 ] url elif status 'abort' return 'Invalidinput '
def with_server_span name def with_server_span_decorator fn @functools wraps fn def with_server_span_wrapper *args **kwargs assert not c trace 'calledwhilealreadyinaserverspan'try with make_server_span name return fn *args **kwargs finally g stats flush return with_server_span_wrapperreturn with_server_span_decorator
def rm_id isid new new def ident_remove expr 'Removeidentities'ids list map isid expr args if sum ids 0 return exprelif sum ids len ids return new expr __class__ *[arg for arg x in zip expr args ids if not x ] else return new expr __class__ expr args[0] return ident_remove
def SplitByKind freqdict kinds {}for kind_fullname freq in freqdict items kind fullname kind_fullname split ' ' if not kind in kinds kinds[kind] []kinds[kind] append fullname freq['read'] freq['write'] freq['miss'] for kind in kinds kinds[kind] sort key lambda ent ent[1] + ent[2] reverse True kinds_bycount sorted kinds iteritems key lambda pair len pair[1] reverse True maxcount 0for kind in kinds maxcount max maxcount kinds[kind][0][1] + kinds[kind][0][2] return kinds_bycount maxcount
@pytest mark django_dbdef test_save_store_fs_bad_lang_with_store po_directory tp0_store tp0_store_fs tp0_store_fs store tp0_storetp0_store_fs pootle_path '/language1/project0/example po'with pytest raises ValidationError tp0_store_fs save
def run_shell_command cmdstr **subprocess_kwargs if 'shell' in subprocess_kwargs and not subprocess_kwargs['shell'] raise ProgramError 'The"shell"kwargmaybeomitted butifprovideditmustbeTrue ' else subprocess_kwargs['shell'] Trueif 'executable' not in subprocess_kwargs subprocess_kwargs['executable'] os getenv 'SHELL' for stream in ['stdin' 'stdout' 'stderr'] subprocess_kwargs setdefault stream subprocess PIPE subprocess_kwargs alter_subprocess_kwargs_by_platform **subprocess_kwargs return subprocess Popen cmdstr **subprocess_kwargs
def launch_server app webapp_factory kwargs prefix 'GALAXY' config_object None name prefix lower host_env_key '%s_TEST_HOST' % prefix port_env_key '%s_TEST_PORT' % prefix default_web_host getattr config_object 'default_web_host' DEFAULT_WEB_HOST host os environ get host_env_key default_web_host port os environ get port_env_key None webapp webapp_factory kwargs['global_conf'] app app use_translogger False static_enabled True server port serve_webapp webapp host host port port os environ[host_env_key] hostos environ[port_env_key] portwait_for_http_server host port log info 'Embeddedwebserverfor%sstarted' % name return ServerWrapper app server name host port
def launch_server app webapp_factory kwargs prefix 'GALAXY' config_object None name prefix lower host_env_key '%s_TEST_HOST' % prefix port_env_key '%s_TEST_PORT' % prefix default_web_host getattr config_object 'default_web_host' DEFAULT_WEB_HOST host os environ get host_env_key default_web_host port os environ get port_env_key None webapp webapp_factory kwargs['global_conf'] app app use_translogger False static_enabled True server port serve_webapp webapp host host port port os environ[host_env_key] hostos environ[port_env_key] portwait_for_http_server host port log info 'Embeddedwebserverfor%sstarted' % name return ServerWrapper app server name host port
def scale_matrix factor origin None direction None if direction is None M numpy diag [factor factor factor 1 0] if origin is not None M[ 3 3] origin[ 3]M[ 3 3] * 1 0 - factor else direction unit_vector direction[ 3] factor 1 0 - factor M numpy identity 4 M[ 3 3] - factor * numpy outer direction direction if origin is not None M[ 3 3] factor * numpy dot origin[ 3] direction * direction return M
@declareddef allperfs obj_ref obj get_object obj_ref p PerfDatas obj perf_data logger debug '[trigger]Igetallperfdatas' return dict [ metric name p[metric name] for metric in p]
def get_current_timezone_name return _get_timezone_name get_current_timezone
def float_compare value1 value2 precision_digits None precision_rounding None rounding_factor _float_check_precision precision_digits precision_digits precision_rounding precision_rounding value1 float_round value1 precision_rounding rounding_factor value2 float_round value2 precision_rounding rounding_factor delta value1 - value2 if float_is_zero delta precision_rounding rounding_factor return 0return -1 if delta < 0 0 else 1
def float_compare value1 value2 precision_digits None precision_rounding None rounding_factor _float_check_precision precision_digits precision_digits precision_rounding precision_rounding value1 float_round value1 precision_rounding rounding_factor value2 float_round value2 precision_rounding rounding_factor delta value1 - value2 if float_is_zero delta precision_rounding rounding_factor return 0return -1 if delta < 0 0 else 1
def auth_sub_string_from_url url scopes_param_prefix 'auth_sub_scopes' if isinstance url str unicode url atom http_core Uri parse_uri url if 'token' not in url query return None None token url query['token']scopes Noneif scopes_param_prefix in url query scopes tuple url query[scopes_param_prefix] split '' return token scopes
def auth_sub_string_from_url url scopes_param_prefix 'auth_sub_scopes' if isinstance url str unicode url atom http_core Uri parse_uri url if 'token' not in url query return None None token url query['token']scopes Noneif scopes_param_prefix in url query scopes tuple url query[scopes_param_prefix] split '' return token scopes
def save_on_signal obj trans signal models signals pre_savedef cb sender instance **kw if instance is obj is_new trans autoid is None trans save force_insert is_new force_update not is_new signal disconnect cb signal connect cb sender obj __class__ weak False
@require_http_methods ['POST'] def upload_archive request response {'status' -1 'data' ''}try resp _upload_archive request response update resp except Exception as ex response['data'] str ex finally hdfs_file request FILES get 'hdfs_file' if hdfs_file hdfs_file remove return JsonResponse response
@require_http_methods ['POST'] def upload_archive request response {'status' -1 'data' ''}try resp _upload_archive request response update resp except Exception as ex response['data'] str ex finally hdfs_file request FILES get 'hdfs_file' if hdfs_file hdfs_file remove return JsonResponse response
def _rewrite_assign tok toknum tokval tokreturn toknum ' ' if tokval ' ' else tokval
def _rewrite_assign tok toknum tokval tokreturn toknum ' ' if tokval ' ' else tokval
def _rewrite_assign tok toknum tokval tokreturn toknum ' ' if tokval ' ' else tokval
def application *args **kwargs if not args and not kwargs or not args and kwargs raise ValueErrorif args application_function argsapplication Application application_function return applicationelse def wrap_application application_function application Application application_function for key value in kwargs items setattr application key value return applicationreturn wrap_application
def execute_section section global_bear_list local_bear_list print_results cache log_printer console_printer try running_processes int section['jobs'] except ValueError log_printer warn "Unabletoconvertsetting'jobs'intoanumber FallingbacktoCPUcount " running_processes get_cpu_count except IndexError running_processes get_cpu_count processes arg_dict instantiate_processes section local_bear_list global_bear_list running_processes cache log_printer console_printer console_printer logger_thread LogPrinterThread arg_dict['message_queue'] log_printer processes append logger_thread for runner in processes runner start try return process_queues processes arg_dict['control_queue'] arg_dict['local_result_dict'] arg_dict['global_result_dict'] arg_dict['file_dict'] print_results section cache log_printer console_printer console_printer arg_dict['local_result_dict'] arg_dict['global_result_dict'] arg_dict['file_dict'] finally logger_thread running Falsefor runner in processes runner join
def test_fk5_galactic fk5 FK5 ra 1 * u deg dec 2 * u deg direct fk5 transform_to Galactic indirect fk5 transform_to FK4 transform_to Galactic assert direct separation indirect degree < 1e-10 direct fk5 transform_to Galactic indirect fk5 transform_to FK4NoETerms transform_to Galactic assert direct separation indirect degree < 1e-10
def test_fk5_galactic fk5 FK5 ra 1 * u deg dec 2 * u deg direct fk5 transform_to Galactic indirect fk5 transform_to FK4 transform_to Galactic assert direct separation indirect degree < 1e-10 direct fk5 transform_to Galactic indirect fk5 transform_to FK4NoETerms transform_to Galactic assert direct separation indirect degree < 1e-10
def wavread filename if os path isfile filename False raise ValueError 'Inputfileiswrong' fs x read filename if len x shape 1 raise ValueError 'Audiofileshouldbemono' if fs 44100 raise ValueError 'Samplingrateofinputsoundshouldbe44100' x np float32 x / norm_fact[x dtype name] return fs x
def filter_re_replace val pattern repl return re sub pattern repl str val
def get_course_syllabus_section course section_key if section_key in ['syllabus' 'guest_syllabus'] try filesys course system resources_fsdirs [ path 'syllabus' / course url_name path 'syllabus' ]filepath find_file filesys dirs section_key + ' html' with filesys open filepath as html_file return replace_static_urls html_file read decode 'utf-8' getattr course 'data_dir' None course_id course id static_asset_path course static_asset_path except ResourceNotFoundError log exception u'Missingsyllabussection%sincourse%s' section_key course location to_deprecated_string return ' Syllabusmissing 'raise KeyError 'Invalidaboutkey' + str section_key
def get_course_syllabus_section course section_key if section_key in ['syllabus' 'guest_syllabus'] try filesys course system resources_fsdirs [ path 'syllabus' / course url_name path 'syllabus' ]filepath find_file filesys dirs section_key + ' html' with filesys open filepath as html_file return replace_static_urls html_file read decode 'utf-8' getattr course 'data_dir' None course_id course id static_asset_path course static_asset_path except ResourceNotFoundError log exception u'Missingsyllabussection%sincourse%s' section_key course location to_deprecated_string return ' Syllabusmissing 'raise KeyError 'Invalidaboutkey' + str section_key
@cli command name u'json' @click option u'-c' u'--clean/--dirty' is_flag True default True help clean_help @click option u'-f' u'--config-file' type click File u'rb' help config_help @click option u'-s' u'--strict' is_flag True help strict_help @click option u'-d' u'--site-dir' type click Path help site_dir_help @common_optionsdef json_command clean config_file strict site_dir log warning u'ThejsoncommandisdeprecatedandwillberemovedinafutureMkDocsrelease Fordetailsonupdating http //www mkdocs org/about/release-notes/' strict strict or None try build build config load_config config_file config_file strict strict site_dir site_dir dump_json True dirty not clean except exceptions ConfigurationError as e raise SystemExit u'\n' + str e
def libvlc_video_get_marquee_string p_mi option f _Cfunctions get 'libvlc_video_get_marquee_string' None or _Cfunction 'libvlc_video_get_marquee_string' 1 1 string_result ctypes c_void_p MediaPlayer ctypes c_uint return f p_mi option
def _get_layer_initializers initializers layer_name fields if initializers is None return Noneif isinstance initializers dict and layer_name in initializers return _get_initializers initializers[layer_name] fields return _get_initializers initializers fields
def depth_first_search gr s path if s in path return Falsepath add s for each in gr neighbors s if each not in path depth_first_search gr each path
def circle screensize center radius col1 1 0 col2 0 blur 1 return color_gradient screensize p1 center r radius col1 col1 col2 col2 shape 'radial' offset 0 if radius 0 else 1 0 * radius - blur / radius
def which_bin cmds return salt utils which_bin cmds
def which_bin cmds return salt utils which_bin cmds
def _patch_cmdutils monkeypatch stubs symbol cmd_utils stubs FakeCmdUtils {'stop' stubs FakeCommand name 'stop' desc 'stopqutebrowser' 'drop' stubs FakeCommand name 'drop' desc 'dropalluserdata' 'roll' stubs FakeCommand name 'roll' desc 'nevergonnagiveyouup' 'hide' stubs FakeCommand name 'hide' hide True 'depr' stubs FakeCommand name 'depr' deprecated True } monkeypatch setattr symbol cmd_utils
def _patch_cmdutils monkeypatch stubs symbol cmd_utils stubs FakeCmdUtils {'stop' stubs FakeCommand name 'stop' desc 'stopqutebrowser' 'drop' stubs FakeCommand name 'drop' desc 'dropalluserdata' 'roll' stubs FakeCommand name 'roll' desc 'nevergonnagiveyouup' 'hide' stubs FakeCommand name 'hide' hide True 'depr' stubs FakeCommand name 'depr' deprecated True } monkeypatch setattr symbol cmd_utils
def _patch_cmdutils monkeypatch stubs symbol cmd_utils stubs FakeCmdUtils {'stop' stubs FakeCommand name 'stop' desc 'stopqutebrowser' 'drop' stubs FakeCommand name 'drop' desc 'dropalluserdata' 'roll' stubs FakeCommand name 'roll' desc 'nevergonnagiveyouup' 'hide' stubs FakeCommand name 'hide' hide True 'depr' stubs FakeCommand name 'depr' deprecated True } monkeypatch setattr symbol cmd_utils
def transformation_to_normal eq var coeff diop_type classify_diop eq _dict False if diop_type in 'homogeneous_ternary_quadratic' 'homogeneous_ternary_quadratic_normal' return _transformation_to_normal var coeff
def transformation_to_normal eq var coeff diop_type classify_diop eq _dict False if diop_type in 'homogeneous_ternary_quadratic' 'homogeneous_ternary_quadratic_normal' return _transformation_to_normal var coeff
def write_to_file path contents umask None if umask saved_umask os umask umask try with open path 'w' as f f write contents finally if umask os umask saved_umask
def _serialize_allocations_for_resource_provider allocations resource_provider return _allocations_dict allocations lambda x x consumer_id resource_provider resource_provider
def _dumx_remove dumx dumx_flat p0 res []for dx in dumx if p0 not in dx res append dx continuek dx index p0 if k % 2 0 p0_paired dx[ k + 1 ]else p0_paired dx[ k - 1 ]dx remove p0 dx remove p0_paired dumx_flat remove p0 dumx_flat remove p0_paired res append dx
def get_host_name name ''try name eval 'os uname [1]' except try name eval "os getenv 'HOSTNAME' os getenv 'COMPUTERNAME' or'' lower " except name ''return name
def build_audit_info parent_audit_id None audit_id random_urlsafe_str if parent_audit_id is not None return [audit_id parent_audit_id]return [audit_id]
def build_audit_info parent_audit_id None audit_id random_urlsafe_str if parent_audit_id is not None return [audit_id parent_audit_id]return [audit_id]
def get_connection_ip_list as_wmi_format False server _DEFAULT_SERVER ret dict setting 'IPGrant'reg_separator ' \\s*'if as_wmi_format ret list addresses _get_wmi_setting 'IIsIPSecuritySetting' setting server for unnormalized_address in addresses ip_address subnet re split reg_separator unnormalized_address if as_wmi_format ret append '{0} {1}' format ip_address subnet else ret[ip_address] subnetif not ret _LOG debug '%sisempty ' setting return ret
def NodeName node if node type < 256 return token tok_name[node type]else return pygram python_grammar number2symbol[node type]
def _estimate_gaussian_covariances_full resp X nk means reg_covar n_components n_features means shapecovariances np empty n_components n_features n_features for k in range n_components diff X - means[k] covariances[k] np dot resp[ k] * diff T diff / nk[k] covariances[k] flat[ n_features + 1 ] + reg_covarreturn covariances
def _apply_exif_orientation image try exif_tags image _getexif or {} except AttributeError return imageORIENTATION_TAG_ID 274orientation exif_tags get ORIENTATION_TAG_ID if orientation 1 passelif orientation 2 image image transpose Image FLIP_LEFT_RIGHT elif orientation 3 image image transpose Image ROTATE_180 elif orientation 4 image image transpose Image FLIP_TOP_BOTTOM elif orientation 5 image image transpose Image FLIP_LEFT_RIGHT image image transpose Image ROTATE_90 elif orientation 6 image image transpose Image ROTATE_270 elif orientation 7 image image transpose Image FLIP_LEFT_RIGHT image image transpose Image ROTATE_270 elif orientation 8 image image transpose Image ROTATE_90 return image
def _apply_exif_orientation image try exif_tags image _getexif or {} except AttributeError return imageORIENTATION_TAG_ID 274orientation exif_tags get ORIENTATION_TAG_ID if orientation 1 passelif orientation 2 image image transpose Image FLIP_LEFT_RIGHT elif orientation 3 image image transpose Image ROTATE_180 elif orientation 4 image image transpose Image FLIP_TOP_BOTTOM elif orientation 5 image image transpose Image FLIP_LEFT_RIGHT image image transpose Image ROTATE_90 elif orientation 6 image image transpose Image ROTATE_270 elif orientation 7 image image transpose Image FLIP_LEFT_RIGHT image image transpose Image ROTATE_270 elif orientation 8 image image transpose Image ROTATE_90 return image
@content_type 'text/plain' def text body charset 'utf-8' **kwargs return body read decode charset
@contextmanagerdef for_range builder count start None intp None if intp is None intp count typeif start is None start intp 0 stop countbbcond builder append_basic_block 'for cond' bbbody builder append_basic_block 'for body' bbend builder append_basic_block 'for end' def do_break builder branch bbend bbstart builder basic_blockbuilder branch bbcond with builder goto_block bbcond index builder phi intp name 'loop index' pred builder icmp_signed '<' index stop builder cbranch pred bbbody bbend with builder goto_block bbbody yield Loop index do_break bbbody builder basic_blockincr increment_index builder index terminate builder bbcond index add_incoming start bbstart index add_incoming incr bbbody builder position_at_end bbend
@contextmanagerdef for_range builder count start None intp None if intp is None intp count typeif start is None start intp 0 stop countbbcond builder append_basic_block 'for cond' bbbody builder append_basic_block 'for body' bbend builder append_basic_block 'for end' def do_break builder branch bbend bbstart builder basic_blockbuilder branch bbcond with builder goto_block bbcond index builder phi intp name 'loop index' pred builder icmp_signed '<' index stop builder cbranch pred bbbody bbend with builder goto_block bbbody yield Loop index do_break bbbody builder basic_blockincr increment_index builder index terminate builder bbcond index add_incoming start bbstart index add_incoming incr bbbody builder position_at_end bbend
def extract_translations file_obj xpi get_filepath file_obj messages {}try with zipfile ZipFile xpi 'r' as source file_list source namelist locales {name split '/' [1] for name in file_list if name startswith '_locales/' and name endswith '/messages json' }for locale in locales corrected_locale find_language locale if not corrected_locale continuefname '_locales/{0}/messages json' format locale try data source read fname messages[corrected_locale] decode_json data except KeyError continueexcept IOError passreturn messages
def cftype_to_value cftype if not cftype return NonetypeID cf CFGetTypeID cftype if typeID in known_cftypes convert_function known_cftypes[typeID]return convert_function cftype else return cftype
@jit nopython True cache True def lex_min_ratio_test tableau pivot slack_start argmins nrows tableau shape[0]num_candidates nrowsfor i in range nrows argmins[i] inum_argmins min_ratio_test_no_tie_breaking tableau pivot -1 argmins num_candidates if num_argmins 1 return argmins[0]for j in range slack_start slack_start + nrows if j pivot continuenum_argmins min_ratio_test_no_tie_breaking tableau pivot j argmins num_argmins if num_argmins 1 breakreturn argmins[0]
def get_next_url_for_login_page request redirect_to request GET get 'next' None if redirect_to and not http is_safe_url redirect_to log error u'Unsaferedirectparameterdetected % redirect_to r' {'redirect_to' redirect_to} redirect_to Noneif not redirect_to try redirect_to reverse 'dashboard' except NoReverseMatch redirect_to reverse 'home' if any param in request GET for param in POST_AUTH_PARAMS params [ param request GET[param] for param in POST_AUTH_PARAMS if param in request GET ]params append 'next' redirect_to redirect_to '{}?{}' format reverse 'finish_auth' urllib urlencode params return redirect_to
def start_version module version rpc start_version_async module version rpc get_result
def artifactory registry xml_parent data artifactory XML SubElement xml_parent 'org jfrog hudson ArtifactoryRedeployPublisher' helpers artifactory_optional_props artifactory data 'publishers' XML SubElement artifactory 'matrixParams' text ' ' join data get 'matrix-params' [] details XML SubElement artifactory 'details' helpers artifactory_common_details details data XML SubElement details 'repositoryKey' text data get 'release-repo-key' '' XML SubElement details 'snapshotsRepositoryKey' text data get 'snapshot-repo-key' '' plugin XML SubElement details 'stagingPlugin' XML SubElement plugin 'pluginName' text 'None'helpers artifactory_deployment_patterns artifactory data helpers artifactory_env_vars_patterns artifactory data
def artifactory registry xml_parent data artifactory XML SubElement xml_parent 'org jfrog hudson ArtifactoryRedeployPublisher' helpers artifactory_optional_props artifactory data 'publishers' XML SubElement artifactory 'matrixParams' text ' ' join data get 'matrix-params' [] details XML SubElement artifactory 'details' helpers artifactory_common_details details data XML SubElement details 'repositoryKey' text data get 'release-repo-key' '' XML SubElement details 'snapshotsRepositoryKey' text data get 'snapshot-repo-key' '' plugin XML SubElement details 'stagingPlugin' XML SubElement plugin 'pluginName' text 'None'helpers artifactory_deployment_patterns artifactory data helpers artifactory_env_vars_patterns artifactory data
def artifactory registry xml_parent data artifactory XML SubElement xml_parent 'org jfrog hudson ArtifactoryRedeployPublisher' helpers artifactory_optional_props artifactory data 'publishers' XML SubElement artifactory 'matrixParams' text ' ' join data get 'matrix-params' [] details XML SubElement artifactory 'details' helpers artifactory_common_details details data XML SubElement details 'repositoryKey' text data get 'release-repo-key' '' XML SubElement details 'snapshotsRepositoryKey' text data get 'snapshot-repo-key' '' plugin XML SubElement details 'stagingPlugin' XML SubElement plugin 'pluginName' text 'None'helpers artifactory_deployment_patterns artifactory data helpers artifactory_env_vars_patterns artifactory data
def _is_national_number_suffix_of_other numobj1 numobj2 nn1 str numobj1 national_number nn2 str numobj2 national_number return nn1 endswith nn2 or nn2 endswith nn1
def rotation_angles m x np arctan2 m[ 2 1 ] m[ 2 2 ] c2 np sqrt m[ 0 0 ] ** 2 + m[ 1 0 ] ** 2 y np arctan2 - m[ 2 0 ] c2 s1 np sin x c1 np cos x z np arctan2 s1 * m[ 0 2 ] - c1 * m[ 0 1 ] c1 * m[ 1 1 ] - s1 * m[ 1 2 ] return x y z
def rotation_angles m x np arctan2 m[ 2 1 ] m[ 2 2 ] c2 np sqrt m[ 0 0 ] ** 2 + m[ 1 0 ] ** 2 y np arctan2 - m[ 2 0 ] c2 s1 np sin x c1 np cos x z np arctan2 s1 * m[ 0 2 ] - c1 * m[ 0 1 ] c1 * m[ 1 1 ] - s1 * m[ 1 2 ] return x y z
def mpi_tag_key a if isinstance a op MPISend MPIRecv MPIRecvWait MPISendWait return a op tagelse return 0
def _locate_repo_files repo rewrite False ret_val []files []conf_dirs ['/etc/xbps d/' '/usr/share/xbps d/']name_glob '* conf'regex re compile '\\s*repository\\s* \\s*' + repo + '/?\\s* # * ?$' for cur_dir in conf_dirs files extend glob glob cur_dir + name_glob for filename in files write_buff []with salt utils fopen filename 'r' as cur_file for line in cur_file if regex match line ret_val append filename else write_buff append line if rewrite and filename in ret_val if len write_buff > 0 with salt utils fopen filename 'w' as rewrite_file rewrite_file write '' join write_buff else os remove filename return ret_val
def get_engine_by_slug slug None if not slug or type slug is not str raise TypeError "Invalidslug'%s'" slug selected_engines filter lambda engine hasattr engine 'SLUG' and engine SLUG slug get_engines if len selected_engines 0 raise ValueError "NoTTSenginefoundforslug'%s'" % slug else if len selected_engines > 1 print "WARNING MultipleTTSenginesfoundforslug'%s' " + 'Thisismostcertainlyabug ' % slug engine selected_engines[0]if not engine is_available raise ValueError "TTSengine'%s'isnotavailable dueto" + 'missingdependencies etc ' % slug return engine
def text3d ax xyz s zdir 'z' size None angle 0 usetex False **kwargs x y z xyzif zdir 'y' xy1 z1 x z y elif zdir 'y' xy1 z1 y z x else xy1 z1 x y z text_path TextPath 0 0 s size size usetex usetex trans Affine2D rotate angle translate xy1[0] xy1[1] p1 PathPatch trans transform_path text_path **kwargs ax add_patch p1 art3d pathpatch_2d_to_3d p1 z z1 zdir zdir
def getClosestOppositeIntersectionPaths yIntersectionPaths yIntersectionPaths sort compareDistanceFromCenter beforeFirst yIntersectionPaths[0] yMinusCenter < 0 0 yCloseToCenterPaths [yIntersectionPaths[0]]for yIntersectionPath in yIntersectionPaths[1 ] beforeSecond yIntersectionPath yMinusCenter < 0 0 if beforeFirst beforeSecond yCloseToCenterPaths append yIntersectionPath return yCloseToCenterPathsreturn yCloseToCenterPaths
def jssafe text u'' if text __class__ unicode text _force_unicode text return _Unsafe text translate _js_escapes
def jssafe text u'' if text __class__ unicode text _force_unicode text return _Unsafe text translate _js_escapes
def _rmtree path from config import CONFif CONF['noconfirm'] choice 'y'elif sys stdout isatty choice compat stdin_input 'WARNING Theoutputdirectory"%s"andALLITSCONTENTSwillbeREMOVED Continue? y/n ' % path else raise SystemExit 'Error Theoutputdirectory"%s"isnotempty Pleaseremoveallitscontentsorusethe-yoption removeoutputdirectorywithoutconfirmation ' % path if choice strip lower 'y' logger info 'Removingdir%s' path shutil rmtree path else raise SystemExit 'Useraborted'
def unicoder p force False if isinstance p unicode return pif isinstance p str if gUTF or force try return p decode 'utf-8' except return p decode codepage 'replace' return p decode codepage 'replace' else return unicode str p
def get_code2lang_map lang_code None force False global CODE2LANG_MAPif force or not CODE2LANG_MAP lmap softload_json settings LANG_LOOKUP_FILEPATH logger logging debug CODE2LANG_MAP {}for lc entry in lmap iteritems CODE2LANG_MAP[lcode_to_ietf lc ] entryreturn CODE2LANG_MAP get lcode_to_ietf lang_code if lang_code else CODE2LANG_MAP
def darken color percent return adjust color 2 - percent
def store_emails recipient_ids notification_type event user node timestamp **context if notification_type 'none' returntemplate event + ' html mako' context['user'] usernode_lineage_ids get_node_lineage node if node else [] for user_id in recipient_ids if user_id user _id continuerecipient OSFUser load user_id context['localized_timestamp'] localize_timestamp timestamp recipient message mails render_message template **context digest NotificationDigest timestamp timestamp send_type notification_type event event user recipient message message node_lineage node_lineage_ids digest save
def check_regexs filename matchers extras []for expressions in matchers expression extramatchers expressionsmatch1 expression search filename if match1 for m in extramatchers match2 m findall filename match1 end if match2 for match in match2 if type match type and len match > 1 extras append match[1] else extras append match breakreturn match1 extras return None None
def custom_object_scope *args return CustomObjectScope *args
def custom_object_scope *args return CustomObjectScope *args
def custom_object_scope *args return CustomObjectScope *args
def getRoundedPoint point return Vector3 round point x round point y round point z
def _stop_timers canvas for attr in dir canvas try attr_obj getattr canvas attr except NotImplementedError attr_obj Noneif isinstance attr_obj Timer attr_obj stop
def _stop_timers canvas for attr in dir canvas try attr_obj getattr canvas attr except NotImplementedError attr_obj Noneif isinstance attr_obj Timer attr_obj stop
def create_lti_user lti_user_id lti_consumer edx_password str uuid uuid4 created Falsewhile not created try edx_user_id generate_random_edx_username edx_email '{}@{}' format edx_user_id settings LTI_USER_EMAIL_DOMAIN with transaction atomic edx_user User objects create_user username edx_user_id password edx_password email edx_email edx_user_profile UserProfile user edx_user edx_user_profile save created Trueexcept IntegrityError passlti_user LtiUser lti_consumer lti_consumer lti_user_id lti_user_id edx_user edx_user lti_user save return lti_user
def _estimate_gaussian_parameters X resp reg_covar covariance_type nk resp sum axis 0 + 10 * np finfo resp dtype eps means np dot resp T X / nk[ np newaxis] covariances {'full' _estimate_gaussian_covariances_full 'tied' _estimate_gaussian_covariances_tied 'diag' _estimate_gaussian_covariances_diag 'spherical' _estimate_gaussian_covariances_spherical}[covariance_type] resp X nk means reg_covar return nk means covariances
def provider_uri_rewrites providers return _load_provider_feature 'uri_rewrites' providers
def provider_uri_rewrites providers return _load_provider_feature 'uri_rewrites' providers
def provider_uri_rewrites providers return _load_provider_feature 'uri_rewrites' providers
def testAuthentication host None username None password None apikey None params {u'mode' u'queue' u'output' u'json' u'ma_username' username u'ma_password' password u'apikey' apikey}url urljoin host u'api' data helpers getURL url params params session session returns u'json' verify False if not data return False data result sabText _checkSabResponse data if not result return False sabText return True u'Success'
def _normalize_query_parameter value if isinstance value Model value value key if isinstance value datetime date and not isinstance value datetime datetime value _date_to_datetime value elif isinstance value datetime time value _time_to_datetime value return value
def prefix_indexes config if hasattr config 'slaveinput' prefix 'test_{[slaveid]}' format config slaveinput else prefix 'test'for key index in settings ES_INDEXES items if not index startswith prefix settings ES_INDEXES[key] '{prefix}_amo_{index}' format prefix prefix index index settings CACHE_PREFIX 'amo {0} ' format prefix settings KEY_PREFIX settings CACHE_PREFIX
def replace_nonprintables string new_string ''modified 0for c in string o ord c if o < 31 new_string + '^' + chr ord '@' + o modified + 1elif o 127 new_string + '^?'modified + 1else new_string + cif modified and S3 Config Config urlencoding_mode 'fixbucket' warning '%dnon-printablecharactersreplacedin %s' % modified new_string return new_string
def setup_logrotate app_name watch log_size app_logrotate_script '{0}/appscale-{1}' format LOGROTATE_CONFIG_DIR app_name contents '/var/log/appscale/{watch}* log{{\nsize{size}\nmissingok\nrotate7\ncompress\ndelaycompress\nnotifempty\ncopytruncate\n}}\n' format watch watch size log_size logging debug 'Logrotatefile {}-Contents \n{}' format app_logrotate_script contents with open app_logrotate_script 'w' as app_logrotate_fd app_logrotate_fd write contents return True
def getProfileString p []alt []global settingsListfor set in settingsList if set isProfile if set getName in tempOverride p append set getName + ' ' + tempOverride[set getName ] else p append set getName + ' ' + set getValue encode 'utf-8' elif set isAlteration if set getName in tempOverride alt append set getName + ' ' + tempOverride[set getName ] else alt append set getName + ' ' + set getValue encode 'utf-8' ret '\x08' join p + '\x0c' + '\x08' join alt ret base64 b64encode zlib compress ret 9 return ret
def _deactivate_invalidation certificate try certificate_invalidation CertificateInvalidation objects get generated_certificate certificate active True certificate_invalidation deactivate except CertificateInvalidation DoesNotExist pass
@memoize_default None evaluator_is_first_arg True def follow_param evaluator param def eval_docstring docstr param_str str param name return set [p for string in _search_param_in_docstr docstr param_str for p in _evaluate_for_statement_string evaluator string module ] func param parent_functionmodule param get_parent_until docstr func raw_doctypes eval_docstring docstr if func name value '__init__' cls func get_parent_until Class if cls type 'classdef' types eval_docstring cls raw_doc return types
def attachable name path None cachekey 'lxc attachable{0}{1}' format name path try return __context__[cachekey]except KeyError _ensure_exists name path path log debug 'CheckingifLXCcontainer{0}isattachable' format name cmd 'lxc-attach'if path cmd + '-P{0}' format pipes quote path cmd + '--clear-env-n{0}--/usr/bin/env' format name result __salt__['cmd retcode'] cmd python_shell False output_loglevel 'quiet' ignore_retcode True 0 __context__[cachekey] resultreturn __context__[cachekey]
def valid_post_signature request signature_header SIGNATURE_BODY_HEADER return valid_signature 'Body {}' format request body request headers get signature_header field 'body'
def get_flags record props 'admin_review' 'admin-review' _lazy 'AdminReview' 'is_jetpack' 'jetpack' _lazy 'JetpackAdd-on' 'requires_restart' 'requires_restart' _lazy 'RequiresRestart' 'has_info_request' 'info' _lazy 'MoreInformationRequested' 'has_editor_comment' 'editor' _lazy 'ContainsReviewerComment' 'sources_provided' 'sources-provided' _lazy 'Sourcesprovided' 'is_webextension' 'webextension' _lazy 'WebExtension' return [ cls title for prop cls title in props if getattr record prop ]
def setgroups groups max_groups Nonetry max_groups os sysconf u'SC_NGROUPS_MAX' except Exception passtry return _setgroups_hack groups[ max_groups] except OSError as exc if exc errno errno EPERM raiseif any group not in groups for group in os getgroups raise
def mkdir session ds_path dc_ref LOG debug 'Creatingdirectorywithpath%s' ds_path session _call_method session vim 'MakeDirectory' session vim service_content fileManager name str ds_path datacenter dc_ref createParentDirectories True LOG debug 'Createddirectorywithpath%s' ds_path
def packages pkg_list update False pkg_list [pkg for pkg in pkg_list if not is_installed pkg ]if pkg_list install pkg_list update
def render_string_template template_string context None context_instance None if context is None context {}template Template template_string if 'user' not in context and context_instance if 'request' in context_instance context update {'user' context_instance['request']} return template render context
def mul_sign lh_expr rh_expr is_pos lh_expr is_zero or rh_expr is_zero or lh_expr is_positive and rh_expr is_positive or lh_expr is_negative and rh_expr is_negative is_neg lh_expr is_zero or rh_expr is_zero or lh_expr is_positive and rh_expr is_negative or lh_expr is_negative and rh_expr is_positive return is_pos is_neg
def _uniquify_projs projs check_active True sort True final_projs []for proj in projs if not any _proj_equal p proj check_active for p in final_projs final_projs append proj my_count count len final_projs def sorter x 'Sortinaniceway 'digits [s for s in x['desc'] if s isdigit ]if digits sort_idx int digits[ -1 ] else sort_idx next my_count return sort_idx x['desc'] return sorted final_projs key sorter if sort else final_projs
def post_http_server test host port data expected_response 'ok' def make_post host port data request post 'http //{host} {port}' format host host port port data data timeout SOCKET_TIMEOUT_FOR_POLLING persistent False def failed failure Message new message_type u'acceptance http_query_failed' reason unicode failure write return Falserequest addCallbacks content failed return requestd verify_socket host port d addCallback lambda _ loop_until reactor lambda make_post host port data d addCallback test assertEqual expected_response return d
def post_http_server test host port data expected_response 'ok' def make_post host port data request post 'http //{host} {port}' format host host port port data data timeout SOCKET_TIMEOUT_FOR_POLLING persistent False def failed failure Message new message_type u'acceptance http_query_failed' reason unicode failure write return Falserequest addCallbacks content failed return requestd verify_socket host port d addCallback lambda _ loop_until reactor lambda make_post host port data d addCallback test assertEqual expected_response return d
def post_http_server test host port data expected_response 'ok' def make_post host port data request post 'http //{host} {port}' format host host port port data data timeout SOCKET_TIMEOUT_FOR_POLLING persistent False def failed failure Message new message_type u'acceptance http_query_failed' reason unicode failure write return Falserequest addCallbacks content failed return requestd verify_socket host port d addCallback lambda _ loop_until reactor lambda make_post host port data d addCallback test assertEqual expected_response return d
def _group_lengths grouping from itertools import chain repeatif not grouping return []elif grouping[ -1 ] 0 and len grouping > 2 return chain grouping[ -1 ] repeat grouping[ -2 ] elif grouping[ -1 ] _locale CHAR_MAX return grouping[ -1 ]else raise ValueError 'unrecognisedformatforgrouping'
def _group_lengths grouping from itertools import chain repeatif not grouping return []elif grouping[ -1 ] 0 and len grouping > 2 return chain grouping[ -1 ] repeat grouping[ -2 ] elif grouping[ -1 ] _locale CHAR_MAX return grouping[ -1 ]else raise ValueError 'unrecognisedformatforgrouping'
def add_special_arithmetic_methods cls arith_method None comp_method None bool_method None use_numexpr True force False select None exclude None have_divmod False new_methods _create_methods arith_method comp_method bool_method use_numexpr default_axis None special True have_divmod have_divmod def _wrap_inplace_method method '\nreturnaninplacewrapperforthismethod\n'def f self other result method self other self _update_inplace result reindex_like self copy False _data verify_is_copy False return selfreturn fnew_methods update dict __iadd__ _wrap_inplace_method new_methods['__add__'] __isub__ _wrap_inplace_method new_methods['__sub__'] __imul__ _wrap_inplace_method new_methods['__mul__'] __itruediv__ _wrap_inplace_method new_methods['__truediv__'] __ipow__ _wrap_inplace_method new_methods['__pow__'] if not compat PY3 new_methods['__idiv__'] new_methods['__div__']add_methods cls new_methods new_methods force force select select exclude exclude
def generate_signed_url bucket_name blob_name storage_client storage Client bucket storage_client get_bucket bucket_name blob bucket blob blob_name url blob generate_signed_url expiration datetime timedelta hours 1 method 'GET' print 'Thesignedurlfor{}is{}' format blob name url
def get_errstring url base 'InvalidURL' url_error url errorString if url_error return base + '-{}' format url_error else return base
def has_course_ended end_date return datetime now utc > end_date if end_date is not None else False
def reset_token_store auth reset_default_token_store
def add_kdb_reader sub_signature cls _kdb_readers[sub_signature] cls
def make_symbolizer project binary_images referenced_images None driver Driver to_load referenced_imagesif to_load is None to_load [x['uuid'] for x in binary_images] dsym_paths loaded dsymcache fetch_dsyms project to_load user_images []for img in binary_images if img['uuid'] in loaded user_images append img return ReportSymbolizer driver dsym_paths user_images
def get_all_alarms region None prefix None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile alarms conn describe_alarms results odict OrderedDict for alarm in alarms alarm _metric_alarm_to_dict alarm name alarm['name']if prefix if name startswith prefix continuename prefix + alarm['name'] del alarm['name']alarm_sls []alarm_sls append {'name' name} alarm_sls append {'attributes' alarm} results[ 'managealarm' + name ] {'boto_cloudwatch_alarm present' alarm_sls}return _safe_dump results
def node_completed_status checknode u'TODO placethisinthebase pyfileandrefactor'node_state_does_not_require_overwrite checknode overwrite is False or checknode overwrite is None and not checknode _interface always_run hash_exists Falsetry hash_exists _ _ _ checknode hash_exists except Exception hash_exists Falsereturn hash_exists and node_state_does_not_require_overwrite
def hashed source_filename prepared_options thumbnail_extension **kwargs parts u' ' join [source_filename] + prepared_options short_sha hashlib sha1 parts encode u'utf-8' digest short_hash base64 urlsafe_b64encode short_sha[ 9] decode u'utf-8' return u' ' join [short_hash thumbnail_extension]
def package pkg_name update False if not is_installed pkg_name install pkg_name update
def lowerstrip s all False return strip_punc s lower strip all all
def lowerstrip s all False return strip_punc s lower strip all all
def transmit msg lane_stack transmit msg remote_yard uid
def time_difference date1 date2 later mktime date1 timetuple + date1 microsecond / 1000000 0 earlier mktime date2 timetuple + date2 microsecond / 1000000 0 return later - earlier
def getProfileSetting name if name in tempOverride return tempOverride[name]global settingsDictionaryif name in settingsDictionary and settingsDictionary[name] isProfile return settingsDictionary[name] getValue traceback print_stack sys stderr write 'Error "%s"notfoundinprofilesettings\n' % name return ''
def kdd_apk actual predicted k 10 if len predicted > k predicted predicted[ k]score 0 0num_hits 0 0for i p in enumerate predicted if p in actual and p not in predicted[ i] num_hits + 1 0score + num_hits / i + 1 0 if not actual return 0 0return score / len actual
def kdd_apk actual predicted k 10 if len predicted > k predicted predicted[ k]score 0 0num_hits 0 0for i p in enumerate predicted if p in actual and p not in predicted[ i] num_hits + 1 0score + num_hits / i + 1 0 if not actual return 0 0return score / len actual
def _update_stylesheet obj get_stylesheet cache_clear if not sip isdeleted obj obj setStyleSheet get_stylesheet obj STYLESHEET
def site_enabled config enable_site config reload_service 'apache2'
@conf commands registerdef fletcher16_checkbytes binbuf offset if len binbuf < offset raise Exception 'Packettooshortforcheckbytes%d' % len binbuf binbuf binbuf[ offset] + '\x00\x00' + binbuf[ offset + 2 ] c0 c1 _fletcher16 binbuf x len binbuf - offset - 1 * c0 - c1 % 255 if x < 0 x + 255y 510 - c0 - x if y > 255 y - 255return chr x + chr y
def _specialized_from_args signatures args kwargs raise Exception 'yettobeimplemented'
def build_auth_sub_data http_request timestamp nonce return '%s%s%s%s' % http_request method str http_request uri str timestamp nonce
def build_auth_sub_data http_request timestamp nonce return '%s%s%s%s' % http_request method str http_request uri str timestamp nonce
def aggregate_metadata_delete context aggregate_id key IMPL aggregate_metadata_delete context aggregate_id key
def cbClose result from twisted internet import reactorreactor stop
@contextlib contextmanagerdef multimap cores None if cores is None cores max multiprocessing cpu_count - 1 1 def wrapper func def wrap self timeout None return func self timeout timeout if timeout is not None else 1e+100 return wrapIMapIterator next wrapper IMapIterator next pool multiprocessing Pool cores yield pool imap pool terminate
def register_optimizer name opt if name in predefined_optimizers raise ValueError 'Optimizernamealreadytaken %s' % name predefined_optimizers[name] opt
@receiver post_save sender ApiAccessRequest dispatch_uid 'api_access_request_post_save_email' def send_request_email sender instance created **kwargs if created _send_new_pending_email instance
def rmsle actual predicted return np sqrt msle actual predicted
def join a *p j afor b in p fs drive path _split b if j '' or fs '' or drive '' or path[ 1] in _roots j belif j[ -1 ] ' ' j j + b else j j + ' ' + b return j
def getAbsoluteFolderPath filePath folderName '' absoluteFolderPath os path dirname os path abspath filePath if folderName '' return absoluteFolderPathreturn os path join absoluteFolderPath folderName
def percentileRank frame column None kind 'mean' fun lambda xs score percentileofscore remove_na xs score kind kind results {}framet frame Tif column is not None if isinstance column Series for date xs in compat iteritems frame T results[date] fun xs column get date NaN else for date xs in compat iteritems frame T results[date] fun xs xs[column] results Series results else for column in frame columns for date xs in compat iteritems framet results setdefault date {} [column] fun xs xs[column] results DataFrame results Treturn results
def percentileRank frame column None kind 'mean' fun lambda xs score percentileofscore remove_na xs score kind kind results {}framet frame Tif column is not None if isinstance column Series for date xs in compat iteritems frame T results[date] fun xs column get date NaN else for date xs in compat iteritems frame T results[date] fun xs xs[column] results Series results else for column in frame columns for date xs in compat iteritems framet results setdefault date {} [column] fun xs xs[column] results DataFrame results Treturn results
def _convert_to_float_if_possible s try ret float s except ValueError TypeError ret sreturn ret
def quote str return str replace '\\' '\\\\' replace '"' '\\"'
def plot_really_bad_images images really_bad_image_indices [324 582 659 726 846 956 1124 1393 1773 1868 2018 2109 2654 4199 4201 4620 5457 5642]n len really_bad_image_indices really_bad_images [images[j] for j in really_bad_image_indices]fig plt figure figsize 10 2 for j in xrange 1 n + 1 ax fig add_subplot 2 9 j ax matshow really_bad_images[ j - 1 ] cmap matplotlib cm binary plt xticks np array [] plt yticks np array [] plt show
@app route '/_snapshot' def snapshot img cam getImage tf tempfile NamedTemporaryFile suffix ' png' loc 'static/' + tf name split '/' [ -1 ] tf close img save loc print 'location' locprint 'json' json dumps loc return json dumps loc
@app route '/_snapshot' def snapshot img cam getImage tf tempfile NamedTemporaryFile suffix ' png' loc 'static/' + tf name split '/' [ -1 ] tf close img save loc print 'location' locprint 'json' json dumps loc return json dumps loc
@skip 'win32' def test_new_thread_is_background import threadglobal donedone Nonedef f global donedone Thread CurrentThread IsBackgroundthread start_new_thread f while done None Thread Sleep 100 Assert done
@skip 'win32' def test_new_thread_is_background import threadglobal donedone Nonedef f global donedone Thread CurrentThread IsBackgroundthread start_new_thread f while done None Thread Sleep 100 Assert done
def average_clustering G nodes None mode 'dot' if nodes is None nodes Gccs latapy_clustering G nodes nodes mode mode return float sum ccs[v] for v in nodes / len nodes
def _extend_external_network_default core_plugin net_res net_db if net_db external is not None net_res[IS_DEFAULT] net_db external is_defaultreturn net_res
def _extend_external_network_default core_plugin net_res net_db if net_db external is not None net_res[IS_DEFAULT] net_db external is_defaultreturn net_res
def random pages 1 query_params {u'list' u'random' u'rnnamespace' 0 u'rnlimit' pages}request _wiki_request query_params titles [page[u'title'] for page in request[u'query'][u'random']]if len titles 1 return titles[0]return titles
def output_xml data code headers None resp make_response dumps {'response' data} code resp headers extend headers or {} return resp
def auth username sharedsecret **kwargs return sharedsecret __opts__ get 'sharedsecret'
def get_demography_template stream model tp_dir None if tp_dir is None filename sep join [builtin_tpl_dir model + ' par' ] else filename sep join [tp_dir model + ' par' ] with open filename 'r' as f l f readline while l '' stream write l l f readline
def test_with_settings_with_other_context_managers env testval1 'outer1'prev_lcwd env lcwddef some_task eq_ env testval1 'inner1' ok_ env lcwd endswith 'here' decorated_task decorators with_settings lcd 'here' testval1 'inner1' some_task decorated_task ok_ env testval1 'outer1' eq_ env lcwd prev_lcwd
@pytest fixturedef evil_member return _require_user 'evil_member' 'Evilmember'
def get_data_files import sysfrom os path import join abspath dirname exists splitpath abspath dirname __file__ starting_points [path]if not path startswith sys prefix starting_points append sys prefix for path in starting_points while path '/' share_jupyter join path 'share' 'jupyter' 'hub' if exists join share_jupyter 'static' 'components' return share_jupyter path _ split path return ''
def _objectsToStrings objects arglist strings proto myObjects objects copy for argname argparser in arglist argparser toBox argname strings myObjects proto return strings
def _notebook_run path kernel_name 'python%d' % sys version_info[0] this_file_directory os path dirname __file__ errors []with tempfile NamedTemporaryFile suffix ' ipynb' mode 'wt' as fout with open path as f nb nbformat read f as_version 4 nb metadata get 'kernelspec' {} ['name'] kernel_nameep ExecutePreprocessor kernel_name kernel_name timeout 10 try ep preprocess nb {'metadata' {'path' this_file_directory}} except CellExecutionError as e if 'SKIP' in e traceback print str e traceback split '\n' [ -2 ]else raise eexcept TimeoutError as e print efinally nbformat write nb fout return nb errors
def _notebook_run path kernel_name 'python%d' % sys version_info[0] this_file_directory os path dirname __file__ errors []with tempfile NamedTemporaryFile suffix ' ipynb' mode 'wt' as fout with open path as f nb nbformat read f as_version 4 nb metadata get 'kernelspec' {} ['name'] kernel_nameep ExecutePreprocessor kernel_name kernel_name timeout 10 try ep preprocess nb {'metadata' {'path' this_file_directory}} except CellExecutionError as e if 'SKIP' in e traceback print str e traceback split '\n' [ -2 ]else raise eexcept TimeoutError as e print efinally nbformat write nb fout return nb errors
@instrumented_task name 'sentry tasks process_buffer process_incr' def process_incr **kwargs from sentry import appapp buffer process **kwargs
def get_processor_decline_html params payment_support_email configuration_helpers get_value 'payment_support_email' settings PAYMENT_SUPPORT_EMAIL msg _ 'Sorry Ourpaymentprocessordidnotacceptyourpayment Thedecisiontheyreturnedwas{decision_text} andthereasonwas{reason_text} Youwerenotcharged Pleasetryadifferentformofpayment Contactuswithpayment-relatedquestionsat{email} ' formatted msg format decision_text '<spanclass "decision">{}</span>' format params['decision'] reason_text '<spanclass "reason">{code} {msg}</span>' format code params['reasonCode'] msg REASONCODE_MAP[params['reasonCode']] email payment_support_email return '<pclass "error_msg">{}</p>' format formatted
def is_list_view path method view if hasattr view 'action' return view action 'list' if method lower 'get' return Falsepath_components path strip '/' split '/' if path_components and '{' in path_components[ -1 ] return Falsereturn True
def is_list_view path method view if hasattr view 'action' return view action 'list' if method lower 'get' return Falsepath_components path strip '/' split '/' if path_components and '{' in path_components[ -1 ] return Falsereturn True
def show for manager in Gcf get_all_fig_managers pass
def sanitize_output output if output is None return ''else return output rstrip '\r\n'
def sanitize_output output if output is None return ''else return output rstrip '\r\n'
def is_theme_dir _dir theme_sub_directories {'lms' 'cms'}return bool os path isdir _dir and theme_sub_directories intersection os listdir _dir
def is_theme_dir _dir theme_sub_directories {'lms' 'cms'}return bool os path isdir _dir and theme_sub_directories intersection os listdir _dir
@with_settings foo ['foo'] bar {'bar' 'bar'} baz 'baz' qux set 'qux' def test_require_complex_non_empty_values require 'foo' 'bar' 'baz' 'qux'
def getRoundedToThreePlaces number return str round number 3
def getRoundedToThreePlaces number return str round number 3
def can_represent_dtype dtype return dtype in REPRESENTABLE_DTYPES or dtype kind in STRING_KINDS
def can_represent_dtype dtype return dtype in REPRESENTABLE_DTYPES or dtype kind in STRING_KINDS
def to_label name capitalize True label name replace '_' '' if capitalize label label capitalize return label
def parametrize_ternary_quadratic eq var coeff diop_type classify_diop eq _dict False if diop_type in 'homogeneous_ternary_quadratic' 'homogeneous_ternary_quadratic_normal' x_0 y_0 z_0 _diop_ternary_quadratic var coeff return _parametrize_ternary_quadratic x_0 y_0 z_0 var coeff
def parametrize_ternary_quadratic eq var coeff diop_type classify_diop eq _dict False if diop_type in 'homogeneous_ternary_quadratic' 'homogeneous_ternary_quadratic_normal' x_0 y_0 z_0 _diop_ternary_quadratic var coeff return _parametrize_ternary_quadratic x_0 y_0 z_0 var coeff
def lookupText name timeout None return getResolver lookupText name timeout
def parse_time timestr for method in [_parse_time_epoch _parse_time_timestamp _parse_time_now_and_utc] seconds method timestr if seconds is not None return int seconds raise ValueError "Invalidtimeformat'%s' " % timestr
def parse_time timestr for method in [_parse_time_epoch _parse_time_timestamp _parse_time_now_and_utc] seconds method timestr if seconds is not None return int seconds raise ValueError "Invalidtimeformat'%s' " % timestr
def parse_time timestr for method in [_parse_time_epoch _parse_time_timestamp _parse_time_now_and_utc] seconds method timestr if seconds is not None return int seconds raise ValueError "Invalidtimeformat'%s' " % timestr
def getEvaluatedString defaultValue elementNode key if elementNode None return defaultValueif key in elementNode attributes return str getEvaluatedValueObliviously elementNode key return defaultValue
def remaining_args oldArgs newArgList pattern '\\s+' join re escape a for a in newArgList + '\\s*$' matchObj re search pattern oldArgs return oldArgs[matchObj start ]
def remaining_args oldArgs newArgList pattern '\\s+' join re escape a for a in newArgList + '\\s*$' matchObj re search pattern oldArgs return oldArgs[matchObj start ]
def get_product_search_handler_class if settings OSCAR_PRODUCT_SEARCH_HANDLER is not None return import_string settings OSCAR_PRODUCT_SEARCH_HANDLER if is_solr_supported return get_class 'catalogue search_handlers' 'ProductSearchHandler' elif is_elasticsearch_supported return get_class 'catalogue search_handlers' 'ESProductSearchHandler' else return get_class 'catalogue search_handlers' 'SimpleProductSearchHandler'
def make_script_file directory effects builder ScriptBuilder effects fd filename tempfile mkstemp dir directory text True os write fd builder script os close fd os chmod filename 365 return os path basename filename
def wipe_disks job disk_list for disk in disk_list partition wipe_filesystem job disk['mountpt']
def create_fake_repository test_case files source_repo FilePath test_case mktemp source_repo createDirectoryfor key in files new_file source_repo preauthChild key if not new_file parent exists new_file parent makedirs new_file setContent files[key] return 'file //' + source_repo path
@Profiler profiledef test_bulk_insert_mappings n session Session bind engine session bulk_insert_mappings Customer [dict name 'customername%d' % i description 'customerdescription%d' % i for i in range n ] session commit
def find_executable path None if path is None dirnames os environ['PATH'] split os pathsep suffixes ['th']else dirnames [path]suffixes ['th' os path join 'bin' 'th' os path join 'install' 'bin' 'th' ]for dirname in dirnames dirname dirname strip '"' for suffix in suffixes path os path join dirname suffix if os path isfile path and os access path os X_OK return pathreturn None
def _get_array shape dtype if len shape 2 and shape[0] 2 x np zeros shape dtype dtype x[0 1 ] -1 x[1] 2return xelif len shape 2 and shape[0] shape[1] x np zeros shape dtype dtype j np arange shape[0] x[ j j ] 2x[ j[ -1 ] j[ -1 ] + 1 ] -1 x[ j[ -1 ] + 1 j[ -1 ] ] -1 return xelse np random seed 1234 return np random randn *shape astype dtype
def _get_code data position obj_end opts element_name code position _get_string data position obj_end opts element_name return Code code position
def test_random_sample_prob_range a db from_sequence range 50 npartitions 5 with pytest raises ValueError a random_sample -1 with pytest raises ValueError a random_sample 1 1
def request_user_has_resource_db_permission permission_type valid_method_names ['get_one' 'get' 'post' 'put' 'delete']def decorate func function_name func __name__if function_name not in valid_method_names raise Exception 'Thisdecoratorshouldonlybeusedtowrap%smethods' % ' ' join valid_method_names @wraps func def func_wrapper *args **kwargs controller_instance args[0]resource_id args[1]get_one_db_method controller_instance get_one_db_methodresource_db get_one_db_method resource_id assert resource_db is not None utils assert_request_user_has_resource_db_permission request pecan request resource_db resource_db permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def request_user_has_resource_db_permission permission_type valid_method_names ['get_one' 'get' 'post' 'put' 'delete']def decorate func function_name func __name__if function_name not in valid_method_names raise Exception 'Thisdecoratorshouldonlybeusedtowrap%smethods' % ' ' join valid_method_names @wraps func def func_wrapper *args **kwargs controller_instance args[0]resource_id args[1]get_one_db_method controller_instance get_one_db_methodresource_db get_one_db_method resource_id assert resource_db is not None utils assert_request_user_has_resource_db_permission request pecan request resource_db resource_db permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
def request_user_has_resource_db_permission permission_type valid_method_names ['get_one' 'get' 'post' 'put' 'delete']def decorate func function_name func __name__if function_name not in valid_method_names raise Exception 'Thisdecoratorshouldonlybeusedtowrap%smethods' % ' ' join valid_method_names @wraps func def func_wrapper *args **kwargs controller_instance args[0]resource_id args[1]get_one_db_method controller_instance get_one_db_methodresource_db get_one_db_method resource_id assert resource_db is not None utils assert_request_user_has_resource_db_permission request pecan request resource_db resource_db permission_type permission_type return func *args **kwargs return func_wrapperreturn decorate
@with_setup prepare_stdout def test_output_with_failed_colorless_with_table runner Runner feature_name 'failed_table' verbosity 3 no_color True runner run assert_stdout_lines_with_traceback u'\nFeature TableFail#tests/functional/output_features/failed_table/failed_table feature 1\n\nScenario Seeitfail#tests/functional/output_features/failed_table/failed_table feature 2\nGivenIhaveadumbstepthatpasses\u2665#tests/functional/output_features/failed_table/failed_table_steps py 20\nAndthisonefails#tests/functional/output_features/failed_table/failed_table_steps py 24\nTraceback mostrecentcalllast \nFile"% lettuce_core_file s" line% call_line d in__call__\nret self function self step *args **kw \nFile"% step_file s" line25 intof\nassertFalse\nAssertionError\nThenthisonewillbeskipped#tests/functional/output_features/failed_table/failed_table_steps py 28\nAndthisonewillbeskipped#tests/functional/output_features/failed_table/failed_table_steps py 28\nAndthisonedoesnotevenhasdefinition#tests/functional/output_features/failed_table/failed_table feature 12 undefined \n\n1feature 0passed \n1scenario 0passed \n5steps 1failed 2skipped 1undefined 1passed \n\nYoucanimplementstepdefinitionsforundefinedstepswiththesesnippets \n\n#-*-coding utf-8-*-\nfromlettuceimportstep\n\n@step u\'Andthisonedoesnotevenhasdefinition\' \ndefand_this_one_does_not_even_has_definition step \nassertFalse \'Thisstepmustbeimplemented\'\n\nListoffailedscenarios \nScenario Seeitfail#tests/functional/output_features/failed_table/failed_table feature 2\n\n' % {'lettuce_core_file' lettuce_path 'core py' 'step_file' abspath lettuce_path ' ' 'tests' 'functional' 'output_features' 'failed_table' 'failed_table_steps py' 'call_line' call_line}
def cyclic_find subseq alphabet string ascii_lowercase n None if isinstance subseq int long width 'all' if n is None else n * 8 subseq packing pack subseq width 'little' False if n is None and len subseq 4 log warn_once 'cyclic_find expects4-bytesubsequencesbydefault yougave%r\n' % subseq + 'Unlessyouspecifiedcyclic n %i youprobablyjustwantthefirst4bytes \n' % len subseq + 'Truncatingthedataat4bytes Specifycyclic_find n %i tooverridethis ' % len subseq subseq subseq[ 4]if any c not in alphabet for c in subseq return -1 n n or len subseq return _gen_find subseq de_bruijn alphabet n
def build_match_conditions doctype as_condition True import frappe desk reportviewreturn frappe desk reportview build_match_conditions doctype as_condition
def _nearest_real_complex_idx fro to which assert which in 'real' 'complex' order np argsort np abs fro - to mask np isreal fro[order] if which 'complex' mask ~ mask return order[np where mask [0][0]]
def list_team_repos team_name profile 'github' ignore_cache False cached_team get_team team_name profile profile if not cached_team log error 'Team{0}doesnotexist ' format team_name return Falseif cached_team get 'repos' and not ignore_cache return cached_team get 'repos' try client _get_client profile organization client get_organization _get_config_value profile 'org_name' team organization get_team cached_team['id'] except UnknownObjectException as e log exception 'Resourcenotfound {0}' format cached_team['id'] try repos {}for repo in team get_repos permission 'pull'if repo permissions admin permission 'admin'elif repo permissions push permission 'push'repos[repo name lower ] {'permission' permission}cached_team['repos'] reposreturn reposexcept UnknownObjectException as e log exception 'Resourcenotfound {0}' format cached_team['id'] return []
def slow t t slow Truereturn t
def logarithmic return [ dimensionless_unscaled function_units dex np log10 lambda x 10 0 ** x ]
def logarithmic return [ dimensionless_unscaled function_units dex np log10 lambda x 10 0 ** x ]
def _check_even_rewrite func arg return func arg args[0] - arg
def pages_to_list items objs []while True try page items next for item in page objs append item except GeneratorExit breakreturn objs
def redirectTo URL request if isinstance URL unicode raise TypeError 'UnicodeobjectnotallowedasURL' request setHeader 'Content-Type' 'text/html charset utf-8' request redirect URL content '\n<html>\n<head>\n<metahttp-equiv "refresh"content "0 URL % url s">\n</head>\n<bodybgcolor "#FFFFFF"text "#000000">\n<ahref "% url s">clickhere</a>\n</body>\n</html>\n' % {'url' nativeString URL } if _PY3 content content encode 'utf8' return content
def get_lexer_for_mimetype _mime **options for modname name _ _ mimetypes in LEXERS itervalues if _mime in mimetypes if name not in _lexer_cache _load_lexers modname return _lexer_cache[name] **options for cls in find_plugin_lexers if _mime in cls mimetypes return cls **options raise ClassNotFound 'nolexerformimetype%rfound' % _mime
def pauseUnpause n d defer Deferred def f result return resultd callback 1 d pause for i in xrange n d addCallback f d addErrback f d addBoth f d addCallbacks f d unpause
def pauseUnpause n d defer Deferred def f result return resultd callback 1 d pause for i in xrange n d addCallback f d addErrback f d addBoth f d addCallbacks f d unpause
@celery_app task base ArchiverTask ignore_result False @logged 'make_copy_request' def make_copy_request job_pk url data create_app_context job ArchiveJob load job_pk src dst user job info provider data['source']['provider']logger info 'Sendingcopyrequestforaddon {0}onnode {1}' format provider dst _id res requests post url data json dumps data if res status_code not in http OK http CREATED http ACCEPTED raise HTTPError res status_code
@celery_app task base ArchiverTask ignore_result False @logged 'make_copy_request' def make_copy_request job_pk url data create_app_context job ArchiveJob load job_pk src dst user job info provider data['source']['provider']logger info 'Sendingcopyrequestforaddon {0}onnode {1}' format provider dst _id res requests post url data json dumps data if res status_code not in http OK http CREATED http ACCEPTED raise HTTPError res status_code
@memoizeddef check_badchars data chars None if to_int data is None to_search dataelse data to_hex to_int data [2 ]if len data % 2 0 data '0' + data to_search codecs decode data 'hex' if not chars chars config Option get 'badchars' if chars for c in chars if c in to_search return Truereturn False
@memoizeddef check_badchars data chars None if to_int data is None to_search dataelse data to_hex to_int data [2 ]if len data % 2 0 data '0' + data to_search codecs decode data 'hex' if not chars chars config Option get 'badchars' if chars for c in chars if c in to_search return Truereturn False
def git_version process subprocess Popen [u'git' u'--version'] stdout subprocess PIPE stdout stderr process communicate assert process returncode 0 u'Failedtodeterminegitversion 'matches re search u'\\s \\d+ ? \\ \\d+ * [\\s\\ ]' stdout return Revision lenient matches group 1
def stash_conf_values conf {'bind_host' CONF bind_host 'bind_port' CONF bind_port 'tcp_keepidle' CONF cert_file 'backlog' CONF backlog 'key_file' CONF key_file 'cert_file' CONF cert_file}return conf
def no_skip_on_missing_deps wrapped @functools wraps wrapped def wrapper *args **kwargs try return wrapped *args **kwargs except testtools TestCase skipException unittest2 case SkipTest as e if base bool_from_env 'OS_FAIL_ON_MISSING_DEPS' tools fail '%scannotbeskippedbecauseOS_FAIL_ON_MISSING_DEPSisenabled skipreason %s' % wrapped __name__ e raisereturn wrapper
def no_skip_on_missing_deps wrapped @functools wraps wrapped def wrapper *args **kwargs try return wrapped *args **kwargs except testtools TestCase skipException unittest2 case SkipTest as e if base bool_from_env 'OS_FAIL_ON_MISSING_DEPS' tools fail '%scannotbeskippedbecauseOS_FAIL_ON_MISSING_DEPSisenabled skipreason %s' % wrapped __name__ e raisereturn wrapper
def _get_safe_url url parts urlsplit url if parts username is None return urlelse frags list parts if parts port frags[1] '{0}@{1} {2}' format parts username parts hostname parts port else frags[1] '{0}@{1}' format parts username parts hostname return urlunsplit frags
def configure_environment if 'HTTP_ACCEPT_LANGUAGE' not in os environ os environ['HTTP_ACCEPT_LANGUAGE'] DEFAULT_LOCALESif 'TOOL_SHED_TEST_FILE_DIR' not in os environ os environ['TOOL_SHED_TEST_FILE_DIR'] TOOL_SHED_TEST_DATAos environ['GALAXY_TEST_ENVIRONMENT_CONFIGURED'] '1'
def modified_pelican_run self context self settings copy context['filenames'] {}context['localsiteurl'] self settings['SITEURL']generators [cls context context settings self settings path self path theme self theme output_path self output_path for cls in self get_generator_classes ]for p in generators if hasattr p 'generate_context' p generate_context writer self get_writer for p in generators if hasattr p 'generate_output' p generate_output writer next g for g in generators if isinstance g ArticlesGenerator next g for g in generators if isinstance g PagesGenerator return context
def modified_pelican_run self context self settings copy context['filenames'] {}context['localsiteurl'] self settings['SITEURL']generators [cls context context settings self settings path self path theme self theme output_path self output_path for cls in self get_generator_classes ]for p in generators if hasattr p 'generate_context' p generate_context writer self get_writer for p in generators if hasattr p 'generate_output' p generate_output writer next g for g in generators if isinstance g ArticlesGenerator next g for g in generators if isinstance g PagesGenerator return context
def var_str name shape size np prod shape ind np indices shape + 1 reshape -1 size names [ '[' + ' ' join map str i + ']' for i in zip *ind ]names[0] '%s%s' % name names[0] return names
@FileSystem in_directory current_directory 'django' 'alfaces' def test_limit_by_app_getting_one_app status out commands getstatusoutput 'pythonmanage pyharvest--verbosity 3--no-color--apps foobar' assert_equals status 0 out assert 'TestthedjangoappDONOTHING' not in out assert 'TestthedjangoappFOOBAR' in out
def json2list jsonstr if jsonstr '' value_list []else if jsonstr[0] '[' value_list json2py jsonstr else value_list jsonstr split ' ' if not isinstance value_list list value_list [value_list]return value_list
def escape pattern if isinstance pattern str alphanum _alphanum_strs list pattern for i c in enumerate pattern if c not in alphanum if c '\x00' s[i] '\\000'else s[i] '\\' + c return '' join s else alphanum _alphanum_bytess []esc ord '\\' for c in pattern if c in alphanum s append c elif c 0 s extend '\\000' else s append esc s append c return bytes s
@app route '/scans/<int scan_id>/exceptions/' methods ['GET'] @requires_authdef list_exceptions scan_id scan_info get_scan_info_from_id scan_id if scan_info is None abort 404 'Scannotfound' data []all_exceptions scan_info w3af_core exception_handler get_all_exceptions for exception_id exception_data in enumerate all_exceptions data append exception_to_json exception_data scan_id exception_id return jsonify {'items' data}
@app route '/scans/<int scan_id>/exceptions/' methods ['GET'] @requires_authdef list_exceptions scan_id scan_info get_scan_info_from_id scan_id if scan_info is None abort 404 'Scannotfound' data []all_exceptions scan_info w3af_core exception_handler get_all_exceptions for exception_id exception_data in enumerate all_exceptions data append exception_to_json exception_data scan_id exception_id return jsonify {'items' data}
def recv_until sock suffix message sock recv 4096 if not message raise EOFError 'socketclosed' while not message endswith suffix data sock recv 4096 if not data raise IOError 'received{ r}thensocketclosed' format message message + datareturn message
def DispatchWithEvents clsid user_event_class disp Dispatch clsid if not disp __class__ __dict__ get 'CLSID' try ti disp _oleobj_ GetTypeInfo disp_clsid ti GetTypeAttr [0] tlb index ti GetContainingTypeLib tla tlb GetLibAttr gencache EnsureModule tla[0] tla[1] tla[3] tla[4] bValidateFile 0 disp_class gencache GetClassForProgID str disp_clsid except pythoncom com_error raise TypeError 'ThisCOMobjectcannotautomatethemakepyprocess-pleaserunmakepymanuallyforthisobject' else disp_class disp __class__clsid disp_class CLSIDtry from types import ClassType as new_typeexcept ImportError new_type typeevents_class getevents clsid if events_class is None raise ValueError 'ThisCOMobjectdoesnotsupportevents ' result_class new_type 'COMEventClass' disp_class events_class user_event_class {'__setattr__' _event_setattr_} instance result_class disp _oleobj_ events_class __init__ instance instance if hasattr user_event_class '__init__' user_event_class __init__ instance return EventsProxy instance
def softmax X tmp X - X max axis 1 [ np newaxis] np exp tmp out X X / X sum axis 1 [ np newaxis]return X
def get_provide_specs_and_objects category return _load_provide_objects category copy
def trigger_event event None **kwargs res {'result' False 'message' 'Somethingwentwrong'}data {}for value in 'value1' 'value2' 'value3' 'Value1' 'Value2' 'Value3' if value in kwargs data[value lower ] kwargs[value]data['occurredat'] time strftime '%B%d %Y%I %M%p' time localtime result _query event event method 'POST' data json dumps data if 'status' in result if result['status'] 200 res['result'] Trueres['message'] result['text']elif 'error' in result res['message'] result['error']return res
def MutableNamedTupleRow cursor from recordtype import recordtypeattr_names [x[0] for x in cursor _ColBufferList]class Row recordtype 'Row' attr_names rename True cursor_description cursor descriptiondef __init__ self iterable super Row self __init__ *iterable def __iter__ self for field_name in self __slots__ yield getattr self field_name def __getitem__ self index if isinstance index slice return tuple getattr self x for x in self __slots__[index] return getattr self self __slots__[index] def __setitem__ self index value setattr self self __slots__[index] value return Row
def MutableNamedTupleRow cursor from recordtype import recordtypeattr_names [x[0] for x in cursor _ColBufferList]class Row recordtype 'Row' attr_names rename True cursor_description cursor descriptiondef __init__ self iterable super Row self __init__ *iterable def __iter__ self for field_name in self __slots__ yield getattr self field_name def __getitem__ self index if isinstance index slice return tuple getattr self x for x in self __slots__[index] return getattr self self __slots__[index] def __setitem__ self index value setattr self self __slots__[index] value return Row
def hashable obj if not obj __hash__ return str obj return obj
def message_get context message_id return IMPL message_get context message_id
@contextlib contextmanagerdef profiling profile_start yield profile_stop
@contextlib contextmanagerdef profiling profile_start yield profile_stop
def _ensure_requested_network_ordering accessor unordered preferred if preferred unordered sort key lambda i preferred index accessor i
def logsumexp arr axis 0 arr np rollaxis arr axis vmax arr max axis 0 out np log np sum np exp arr - vmax axis 0 out + vmaxreturn out
def get_service hass config discovery_info None host config get CONF_HOST port config get CONF_PORT return LannouncerNotificationService hass host port
def test_config_alterations_instance class LineConfig Config no_prefix Trueshow_legend Falsefill Truepretty_print Truex_labels ['a' 'b' 'c']config LineConfig line1 Line config line1 add '_' [1 2 3] l1 line1 render config stroke Falseline2 Line config line2 add '_' [1 2 3] l2 line2 render assert l1 l2 l1bis line1 render assert l1 l1bis
def test_config_alterations_instance class LineConfig Config no_prefix Trueshow_legend Falsefill Truepretty_print Truex_labels ['a' 'b' 'c']config LineConfig line1 Line config line1 add '_' [1 2 3] l1 line1 render config stroke Falseline2 Line config line2 add '_' [1 2 3] l2 line2 render assert l1 l2 l1bis line1 render assert l1 l1bis
def read path attribute **kwargs kwargs salt utils clean_kwargs **kwargs hex_ kwargs pop 'hex' False if kwargs salt utils invalid_kwargs kwargs cmd ['xattr' '-p']if hex_ cmd append '-x' cmd extend [attribute path] try ret salt utils mac_utils execute_return_result cmd except CommandExecutionError as exc if 'Nosuchfile' in exc strerror raise CommandExecutionError 'Filenotfound {0}' format path if 'Nosuchxattr' in exc strerror raise CommandExecutionError 'Attributenotfound {0}' format attribute raise CommandExecutionError 'UnknownError {0}' format exc strerror return ret
def get_ *keyname mdata _check_mdata_get ret {}if len keyname 0 keyname list_ for k in keyname if mdata cmd '{0}{1}' format mdata k res __salt__['cmd run_all'] cmd ret[k] res['stdout'] if res['retcode'] 0 else '' else ret[k] ''return ret
def guided_tour_finished if request ajax True utable s3db tour_userperson_id auth s3_logged_in_person query utable person_id person_id & utable tour_config_id request post_vars tour_id db query update resume '' completed True trip_counter utable trip_counter + 1 return json dumps {} else redirect URL f 'config'
def decorate_fn_with_doc new_fn old_fn additional_text '' def wrapper *args **kw return new_fn *args **kw if old_fn __doc__ wrapper __doc__ old_fn __doc__ + additional_text return wrapper
def str_endswith arr pat na np nan f lambda x x endswith pat return _na_map f arr na dtype bool
def str_endswith arr pat na np nan f lambda x x endswith pat return _na_map f arr na dtype bool
def diop_general_pythagorean eq param symbols 'm' integer True var coeff diop_type classify_diop eq _dict False if diop_type 'general_pythagorean' return _diop_general_pythagorean var coeff param
def check_cdf_slope cdf norm_intensity np linspace 0 1 len cdf slope intercept np polyfit norm_intensity cdf 1 assert 0 9 < slope < 1 1
def __virtual__ if __virtualname__ not in __opts__['fileserver_backend'] return Falsetry salt utils gitfs GitFS __opts__ return __virtualname__except FileserverConfigError passreturn False
def __virtual__ if __virtualname__ not in __opts__['fileserver_backend'] return Falsetry salt utils gitfs GitFS __opts__ return __virtualname__except FileserverConfigError passreturn False
@permission_required [ 'AccountLookup' 'View' ] def app_activity request addon_id app get_object_or_404 Webapp with_deleted pk addon_id user_items ActivityLog objects for_apps [app] exclude action__in mkt LOG_HIDE_DEVELOPER admin_items ActivityLog objects for_apps [app] filter action__in mkt LOG_HIDE_DEVELOPER user_items paginate request user_items per_page 20 admin_items paginate request admin_items per_page 20 return render request 'lookup/app_activity html' {'admin_items' admin_items 'app' app 'user_items' user_items}
def extract_patch textid os downsample temp '${PYLEARN2_DATA_PATH}/textures/brodatz/D%i gif' % textid fname string_utils preprocess temp img_i Image open fname img_i img_i resize img_i size[0] / downsample img_i size[1] / downsample Image BILINEAR x numpy random randint 0 img_i size[0] - os y numpy random randint 0 img_i size[1] - os patch img_i crop x y x + os y + os return patch x y
def info contact_points None port None cql_user None cql_pass None query 'selectcluster_name \ndata_center \npartitioner \nhost_id \nrack \nrelease_version \ncql_version \nschema_version \nthrift_version\nfromsystem local\nlimit1 'ret {}try ret cql_query query contact_points port cql_user cql_pass except CommandExecutionError log critical 'CouldnotlistCassandrainfo ' raiseexcept BaseException as e log critical 'UnexpectederrorwhilelistingCassandrainfo {0}' format str e raisereturn ret
def run_with *drivers def decorator test if isinstance test type and issubclass test TestBase for attr in dir test value getattr test attr if callable value and attr startswith 'test_' if six PY3 value _run_with driverselse value __func__ _run_with driverselse test _run_with driversreturn testreturn decorator
def _find_all_simple path results os path join base file for base dirs files in os walk path followlinks True for file in files return filter os path isfile results
def get_debug_info func def debug_info_replacement self **form try if 'debugcount' not in form raise ValueError 'Youmustprovideadebugcountparameter' debugcount form pop 'debugcount' try debugcount int debugcount except ValueError raise ValueError 'Badvaluefordebugcount' if debugcount not in self debug_infos raise ValueError 'Debug%snolongerfound maybeithasexpired? ' % debugcount debug_info self debug_infos[debugcount]return func self debug_info debug_info **form except ValueError as e form['headers']['status'] '500ServerError'return '<html>Therewasanerror %s</html>' % html_quote e return debug_info_replacement
def get_debug_info func def debug_info_replacement self **form try if 'debugcount' not in form raise ValueError 'Youmustprovideadebugcountparameter' debugcount form pop 'debugcount' try debugcount int debugcount except ValueError raise ValueError 'Badvaluefordebugcount' if debugcount not in self debug_infos raise ValueError 'Debug%snolongerfound maybeithasexpired? ' % debugcount debug_info self debug_infos[debugcount]return func self debug_info debug_info **form except ValueError as e form['headers']['status'] '500ServerError'return '<html>Therewasanerror %s</html>' % html_quote e return debug_info_replacement
def _make_nxm_w *args **kw t _fix_types kw pop 'type' _nxm_maskable_numeric_entry ok Falsefor tt in t if _issubclass tt _nxm_maskable ok Truebreakif not ok t insert 0 _nxm_maskable return _make_nxm type t *args **kw
def freemem conn __get_conn mem conn getInfo [1]mem - 256for vm_ in list_domains dom _get_domain vm_ if dom ID > 0 mem - dom info [2] / 1024 return mem
def freemem conn __get_conn mem conn getInfo [1]mem - 256for vm_ in list_domains dom _get_domain vm_ if dom ID > 0 mem - dom info [2] / 1024 return mem
def freemem conn __get_conn mem conn getInfo [1]mem - 256for vm_ in list_domains dom _get_domain vm_ if dom ID > 0 mem - dom info [2] / 1024 return mem
def freemem conn __get_conn mem conn getInfo [1]mem - 256for vm_ in list_domains dom _get_domain vm_ if dom ID > 0 mem - dom info [2] / 1024 return mem
def freemem conn __get_conn mem conn getInfo [1]mem - 256for vm_ in list_domains dom _get_domain vm_ if dom ID > 0 mem - dom info [2] / 1024 return mem
def line line poly toolpath Polygon x1 y1 x2 y2 linepoly addPoint toolpath Point x1 y1 poly addPoint toolpath Point x2 y2 return poly
def line line poly toolpath Polygon x1 y1 x2 y2 linepoly addPoint toolpath Point x1 y1 poly addPoint toolpath Point x2 y2 return poly
def collect names match lambda name True match_dir lambda name True for name in names if os path isdir name for root dirs filenames in os walk name dirs[ ] [dir for dir in dirs if match_dir dir ]for filename in filenames if match filename yield os path join root filename else yield name
def Range s1 s2 None if s2 result CodeRange ord s1 ord s2 + 1 result str 'Range %s %s ' % s1 s2 else ranges []for i in range 0 len s1 2 ranges append CodeRange ord s1[i] ord s1[ i + 1 ] + 1 result Alt *ranges result str 'Range %s ' % repr s1 return result
def create_vlan_interface namespace port_name mac_address ip_address vlan_tag ip_wrap ip_lib IPWrapper namespace dev_name '%s %d' % port_name vlan_tag ip_wrap add_vlan dev_name port_name vlan_tag dev ip_wrap device dev_name dev addr add str ip_address dev link set_address mac_address dev link set_up return dev
def create_vlan_interface namespace port_name mac_address ip_address vlan_tag ip_wrap ip_lib IPWrapper namespace dev_name '%s %d' % port_name vlan_tag ip_wrap add_vlan dev_name port_name vlan_tag dev ip_wrap device dev_name dev addr add str ip_address dev link set_address mac_address dev link set_up return dev
def distrib_codename with settings hide 'running' 'stdout' return run 'lsb_release--codename--short'
def get_fc_hbas_info hbas get_fc_hbas hbas_info []for hba in hbas wwpn hba['port_name'] replace '0x' '' wwnn hba['node_name'] replace '0x' '' device_path hba['ClassDevicepath']device hba['ClassDevice']hbas_info append {'port_name' wwpn 'node_name' wwnn 'host_device' device 'device_path' device_path} return hbas_info
def weight_variable shape initial tf zeros shape return tf Variable initial
def install_build_utils apt_install BUILD_UTILS_PKGS
def dpid_to_str dpid alwaysLong False if type dpid is long or type dpid is int dpid struct pack ' Q' dpid assert len dpid 8 r '-' join [ '%02x' % ord x for x in dpid[2 ]] if alwaysLong or dpid[0 2] '\x00' * 2 r + ' ' + str struct unpack ' H' dpid[0 2] [0] return r
def Canonicalize node output None **kw if output apply _implementation node output write kw else s StringIO StringIO apply _implementation node s write kw return s getvalue
def strict_eq x y __tracebackhide__ Trueassert x y assert issubclass type x type y or issubclass type y type x if isinstance x dict and isinstance y dict x sorted x items y sorted y items elif isinstance x set and isinstance y set x sorted x y sorted y assert repr x repr y
def strict_eq x y __tracebackhide__ Trueassert x y assert issubclass type x type y or issubclass type y type x if isinstance x dict and isinstance y dict x sorted x items y sorted y items elif isinstance x set and isinstance y set x sorted x y sorted y assert repr x repr y
def _getinfos_dns spec infos {}fullinfos {}fields {'domain' 'value' 'domaintarget' 'targetval'}for field in fields try if fields[field] not in spec continueinfos[field] []fullinfos[field] []for domain in utils get_domains spec get 'full' + fields[field] spec[fields[field]] infos[field] append domain[ utils MAXVALLEN] if len domain > utils MAXVALLEN fullinfos[field] append domain if not infos[field] del infos[field]if not fullinfos[field] del fullinfos[field]except Exception passres {}if infos res['infos'] infosif fullinfos res['fullinfos'] fullinfosreturn res
def main for line in MARKDOWN_TEMPLATE splitlines if line startswith '$tag ' print Tag line build_help else print line
def main for line in MARKDOWN_TEMPLATE splitlines if line startswith '$tag ' print Tag line build_help else print line
def getVisibleObjects archivableObjects visibleObjects []for archivableObject in archivableObjects if archivableObject getVisible visibleObjects append archivableObject return visibleObjects
def strip_user_meta_prefix server_type key return key[len get_user_meta_prefix server_type ]
def YouCompleteMeInstance custom_options {} def Decorator test @functools wraps test def Wrapper *args **kwargs ycm YouCompleteMe _MakeUserOptions custom_options _WaitUntilReady try test ycm *args **kwargs finally StopServer ycm return Wrapperreturn Decorator
def _dict_with_extra_specs_if_authorized context inst_type_query inst_type_dict dict inst_type_query if not is_admin_context context del inst_type_dict['extra_specs']else extra_specs {x['key'] x['value'] for x in inst_type_query['extra_specs']}inst_type_dict['extra_specs'] extra_specsreturn inst_type_dict
def camelcase string return u'' join word capitalize for word in re split u'[-_]' string
def camelcase string return u'' join word capitalize for word in re split u'[-_]' string
def enabled name **kwargs ret {'name' name 'changes' {} 'result' True 'comment' ''}ret update _enable name None **kwargs return ret
def send_feedback_message_email recipient_id feedback_messages email_subject "You'vereceived%snewmessage%sonyourexplorations" % len feedback_messages 's' if len feedback_messages > 1 else '' email_body_template 'Hi%s <br><br>You\'vereceived%snewmessage%sonyourOppiaexplorations <br><ul>%s</ul>Youcanviewandreplytoyourmessagesfromyour<ahref "https //www oppia org/dashboard">dashboard</a> <br>Thanks andhappyteaching <br><br>Bestwishes <br>TheOppiaTeam<br><br>%s'if not feconf CAN_SEND_EMAILS log_new_error 'Thisappcannotsendemailstousers ' returnif not feconf CAN_SEND_FEEDBACK_MESSAGE_EMAILS log_new_error 'Thisappcannotsendfeedbackmessageemailstousers ' returnif not feedback_messages returnrecipient_user_settings user_services get_user_settings recipient_id messages_html ''for _ reference in feedback_messages iteritems for message in reference['messages'] messages_html + '<li>%s %s<br></li>' % reference['title'] message email_body email_body_template % recipient_user_settings username len feedback_messages 's' if len feedback_messages > 1 else '' messages_html EMAIL_FOOTER value _send_email recipient_id feconf SYSTEM_COMMITTER_ID feconf EMAIL_INTENT_FEEDBACK_MESSAGE_NOTIFICATION email_subject email_body feconf NOREPLY_EMAIL_ADDRESS
def send_feedback_message_email recipient_id feedback_messages email_subject "You'vereceived%snewmessage%sonyourexplorations" % len feedback_messages 's' if len feedback_messages > 1 else '' email_body_template 'Hi%s <br><br>You\'vereceived%snewmessage%sonyourOppiaexplorations <br><ul>%s</ul>Youcanviewandreplytoyourmessagesfromyour<ahref "https //www oppia org/dashboard">dashboard</a> <br>Thanks andhappyteaching <br><br>Bestwishes <br>TheOppiaTeam<br><br>%s'if not feconf CAN_SEND_EMAILS log_new_error 'Thisappcannotsendemailstousers ' returnif not feconf CAN_SEND_FEEDBACK_MESSAGE_EMAILS log_new_error 'Thisappcannotsendfeedbackmessageemailstousers ' returnif not feedback_messages returnrecipient_user_settings user_services get_user_settings recipient_id messages_html ''for _ reference in feedback_messages iteritems for message in reference['messages'] messages_html + '<li>%s %s<br></li>' % reference['title'] message email_body email_body_template % recipient_user_settings username len feedback_messages 's' if len feedback_messages > 1 else '' messages_html EMAIL_FOOTER value _send_email recipient_id feconf SYSTEM_COMMITTER_ID feconf EMAIL_INTENT_FEEDBACK_MESSAGE_NOTIFICATION email_subject email_body feconf NOREPLY_EMAIL_ADDRESS
def send_feedback_message_email recipient_id feedback_messages email_subject "You'vereceived%snewmessage%sonyourexplorations" % len feedback_messages 's' if len feedback_messages > 1 else '' email_body_template 'Hi%s <br><br>You\'vereceived%snewmessage%sonyourOppiaexplorations <br><ul>%s</ul>Youcanviewandreplytoyourmessagesfromyour<ahref "https //www oppia org/dashboard">dashboard</a> <br>Thanks andhappyteaching <br><br>Bestwishes <br>TheOppiaTeam<br><br>%s'if not feconf CAN_SEND_EMAILS log_new_error 'Thisappcannotsendemailstousers ' returnif not feconf CAN_SEND_FEEDBACK_MESSAGE_EMAILS log_new_error 'Thisappcannotsendfeedbackmessageemailstousers ' returnif not feedback_messages returnrecipient_user_settings user_services get_user_settings recipient_id messages_html ''for _ reference in feedback_messages iteritems for message in reference['messages'] messages_html + '<li>%s %s<br></li>' % reference['title'] message email_body email_body_template % recipient_user_settings username len feedback_messages 's' if len feedback_messages > 1 else '' messages_html EMAIL_FOOTER value _send_email recipient_id feconf SYSTEM_COMMITTER_ID feconf EMAIL_INTENT_FEEDBACK_MESSAGE_NOTIFICATION email_subject email_body feconf NOREPLY_EMAIL_ADDRESS
def DoesTestHaveLabels cls labels labels set labels for name in dir cls if name startswith 'test' item getattr cls name None if labels intersection getattr item 'labels' set ['small'] return Truereturn False
def DoesTestHaveLabels cls labels labels set labels for name in dir cls if name startswith 'test' item getattr cls name None if labels intersection getattr item 'labels' set ['small'] return Truereturn False
def _expand_item item ret {}ret update item __dict__ return ret
def find_skips start TESTDIR results {}debug 'Searchingin%s' start for root _dirs files in os walk start for name in files if name startswith 'test_' and name endswith 'py' path os path join root name debug 'Searchingin%s' path temp_result find_skips_in_file path for method_name bug_no in temp_result if results get bug_no result_dict results get bug_no if result_dict get name result_dict[name] append method_name else result_dict[name] [method_name]results[bug_no] result_dictelse results[bug_no] {name [method_name]}return results
def find_skips start TESTDIR results {}debug 'Searchingin%s' start for root _dirs files in os walk start for name in files if name startswith 'test_' and name endswith 'py' path os path join root name debug 'Searchingin%s' path temp_result find_skips_in_file path for method_name bug_no in temp_result if results get bug_no result_dict results get bug_no if result_dict get name result_dict[name] append method_name else result_dict[name] [method_name]results[bug_no] result_dictelse results[bug_no] {name [method_name]}return results
def get_effective_user requesting_user target_username if target_username requesting_user username return requesting_userelif target_username '' return AnonymousUser elif can_view_courses_for_username requesting_user target_username return User objects get username target_username else raise PermissionDenied
def get_effective_user requesting_user target_username if target_username requesting_user username return requesting_userelif target_username '' return AnonymousUser elif can_view_courses_for_username requesting_user target_username return User objects get username target_username else raise PermissionDenied
def path_to_3d_segment path zs 0 zdir u'z' if not iterable zs zs np ones len path * zs seg []pathsegs path iter_segments simplify False curves False for x y code z in zip pathsegs zs seg append x y z seg3d [juggle_axes x y z zdir for x y z in seg]return seg3d
def wrap_clause_in_parens sql if sql strip sql u' {} ' format sql return sa text sql
def _get_addons request addons addon_id action items []a MenuItem a selected not addon_id a text a url _ 'AllMyAdd-ons' reverse 'devhub feed_all' if action a url + '?action ' + action items append a for addon in addons item MenuItem try item selected addon_id and addon id int addon_id except ValueError passurl reverse 'devhub feed' args [addon slug] if action url + '?action ' + action item text item url addon name url items append item return items
@register simple_tagdef bootstrap_field *args **kwargs return render_field *args **kwargs
@register simple_tagdef bootstrap_field *args **kwargs return render_field *args **kwargs
def raises exc func *args **kwds try func *args **kwds except exc passelse raise AssertionError '%sdidnotraise%s' % func __name__ _excstr exc
def raises exc func *args **kwds try func *args **kwds except exc passelse raise AssertionError '%sdidnotraise%s' % func __name__ _excstr exc
def raises exc func *args **kwds try func *args **kwds except exc passelse raise AssertionError '%sdidnotraise%s' % func __name__ _excstr exc
def create_http_server host None port 0 try http HTTPServer http bind host host port port except OSError as err console exit 'FailedtocreateHTTPserver {0}' err return http
def find_loader fullname for importer in iter_importers fullname loader importer find_module fullname if loader is not None return loaderreturn None
@profiler trace@memoizeddef tenant_quota_usages request tenant_id None if not tenant_id tenant_id request user project_iddisabled_quotas get_disabled_quotas request usages QuotaUsage for quota in get_tenant_quota_data request disabled_quotas disabled_quotas tenant_id tenant_id usages add_quota quota _get_tenant_compute_usages request usages disabled_quotas tenant_id _get_tenant_network_usages request usages disabled_quotas tenant_id _get_tenant_volume_usages request usages disabled_quotas tenant_id return usages
@profiler trace@memoizeddef tenant_quota_usages request tenant_id None if not tenant_id tenant_id request user project_iddisabled_quotas get_disabled_quotas request usages QuotaUsage for quota in get_tenant_quota_data request disabled_quotas disabled_quotas tenant_id tenant_id usages add_quota quota _get_tenant_compute_usages request usages disabled_quotas tenant_id _get_tenant_network_usages request usages disabled_quotas tenant_id _get_tenant_volume_usages request usages disabled_quotas tenant_id return usages
def twiny ax None if ax is None ax gca ax1 ax twiny draw_if_interactive return ax1
def trim_tables ignore_fields default_fields + optional_fields for doctype in frappe db get_all u'DocType' filters {u'issingle' 0} doctype doctype namecolumns frappe db get_table_columns doctype fields frappe get_meta doctype get_fieldnames_with_value columns_to_remove [f for f in list set columns - set fields if f not in ignore_fields and not f startswith u'_' ]if columns_to_remove print doctype u'columnsremoved ' columns_to_removecolumns_to_remove u' ' join [u'drop`{0}`' format c for c in columns_to_remove] query u'altertable`tab{doctype}`{columns}' format doctype doctype columns columns_to_remove frappe db sql_ddl query
def trim_tables ignore_fields default_fields + optional_fields for doctype in frappe db get_all u'DocType' filters {u'issingle' 0} doctype doctype namecolumns frappe db get_table_columns doctype fields frappe get_meta doctype get_fieldnames_with_value columns_to_remove [f for f in list set columns - set fields if f not in ignore_fields and not f startswith u'_' ]if columns_to_remove print doctype u'columnsremoved ' columns_to_removecolumns_to_remove u' ' join [u'drop`{0}`' format c for c in columns_to_remove] query u'altertable`tab{doctype}`{columns}' format doctype doctype columns columns_to_remove frappe db sql_ddl query
def trim_tables ignore_fields default_fields + optional_fields for doctype in frappe db get_all u'DocType' filters {u'issingle' 0} doctype doctype namecolumns frappe db get_table_columns doctype fields frappe get_meta doctype get_fieldnames_with_value columns_to_remove [f for f in list set columns - set fields if f not in ignore_fields and not f startswith u'_' ]if columns_to_remove print doctype u'columnsremoved ' columns_to_removecolumns_to_remove u' ' join [u'drop`{0}`' format c for c in columns_to_remove] query u'altertable`tab{doctype}`{columns}' format doctype doctype columns columns_to_remove frappe db sql_ddl query
def trim_tables ignore_fields default_fields + optional_fields for doctype in frappe db get_all u'DocType' filters {u'issingle' 0} doctype doctype namecolumns frappe db get_table_columns doctype fields frappe get_meta doctype get_fieldnames_with_value columns_to_remove [f for f in list set columns - set fields if f not in ignore_fields and not f startswith u'_' ]if columns_to_remove print doctype u'columnsremoved ' columns_to_removecolumns_to_remove u' ' join [u'drop`{0}`' format c for c in columns_to_remove] query u'altertable`tab{doctype}`{columns}' format doctype doctype columns columns_to_remove frappe db sql_ddl query
def trim_tables ignore_fields default_fields + optional_fields for doctype in frappe db get_all u'DocType' filters {u'issingle' 0} doctype doctype namecolumns frappe db get_table_columns doctype fields frappe get_meta doctype get_fieldnames_with_value columns_to_remove [f for f in list set columns - set fields if f not in ignore_fields and not f startswith u'_' ]if columns_to_remove print doctype u'columnsremoved ' columns_to_removecolumns_to_remove u' ' join [u'drop`{0}`' format c for c in columns_to_remove] query u'altertable`tab{doctype}`{columns}' format doctype doctype columns columns_to_remove frappe db sql_ddl query
def permission_name name def wraps f f _permission_name namereturn freturn wraps
def permission_name name def wraps f f _permission_name namereturn freturn wraps
def test_launch_about_app client logged_in_client client click jquery ' "img hue-swoosh" [0]' client waits forElement classname 'Hue-ABOUT' timeout '2000'
def test_login_logout client rv login client flaskr app config['USERNAME'] flaskr app config['PASSWORD'] assert 'Youwereloggedin' in rv data rv logout client assert 'Youwereloggedout' in rv data rv login client flaskr app config['USERNAME'] + 'x' flaskr app config['PASSWORD'] assert 'Invalidusername' in rv data rv login client flaskr app config['USERNAME'] flaskr app config['PASSWORD'] + 'x' assert 'Invalidpassword' in rv data
def __virtual__ return __virtualname__
def __virtual__ return __virtualname__
def __virtual__ return __virtualname__
def __virtual__ return __virtualname__
@register_specialize@register_canonicalize@register_useless@gof local_optimizer [T Join] def local_join_1 node if not isinstance node op T Join returntensors node inputs[1 ]if len tensors 1 return [tensors[0]]
def _make_upload_dt return datetime datetime utcnow replace tzinfo utc
def update_jail name if is_jail name cmd 'poudrierejail-u-j{0}' format name ret __salt__['cmd run'] cmd return retelse return 'Couldnotfindjail{0}' format name
def skip_unless_cms func return skipUnless settings ROOT_URLCONF 'cms urls' 'TestonlyvalidinCMS' func
def pem b name s1 b2a_base64 b [ -1 ]s2 ''while s1 s2 + s1[ 64] + '\n' s1 s1[64 ]s '-----BEGIN%s-----\n' % name + s2 + '-----END%s-----\n' % name return s
def get_public_key ssh_conf_path os path expanduser '~/ ssh' dsa_public_key_path os path join ssh_conf_path 'id_dsa pub' dsa_private_key_path os path join ssh_conf_path 'id_dsa' rsa_public_key_path os path join ssh_conf_path 'id_rsa pub' rsa_private_key_path os path join ssh_conf_path 'id_rsa' has_dsa_keypair os path isfile dsa_public_key_path and os path isfile dsa_private_key_path has_rsa_keypair os path isfile rsa_public_key_path and os path isfile rsa_private_key_path if has_dsa_keypair logging info 'DSAkeypairfound usingit' public_key_path dsa_public_key_pathelif has_rsa_keypair logging info 'RSAkeypairfound usingit' public_key_path rsa_public_key_pathelse logging info 'NeitherRSAnorDSAkeypairfound creatingDSAsshkeypair' utils system 'ssh-keygen-tdsa-q-N""-f%s' % dsa_private_key_path public_key_path dsa_public_key_pathpublic_key open public_key_path 'r' public_key_str public_key read public_key close return public_key_str
def linear_rainbow res frac 0 5 nobs res nobsendog res model endogexog res model exoglowidx np ceil 0 5 * 1 - frac * nobs astype int uppidx np floor lowidx + frac * nobs astype int mi_sl slice lowidx uppidx res_mi OLS endog[mi_sl] exog[mi_sl] fit nobs_mi res_mi model endog shape[0]ss_mi res_mi ssrss res ssrfstat ss - ss_mi / nobs - nobs_mi / ss_mi * res_mi df_resid from scipy import statspval stats f sf fstat nobs - nobs_mi res_mi df_resid return fstat pval
def _get_authorized_user requesting_user username None allow_staff False if username is None username requesting_user usernametry existing_user User objects get username username except ObjectDoesNotExist raise UserNotFound _check_authorized requesting_user username allow_staff return existing_user
def _get_authorized_user requesting_user username None allow_staff False if username is None username requesting_user usernametry existing_user User objects get username username except ObjectDoesNotExist raise UserNotFound _check_authorized requesting_user username allow_staff return existing_user
def iplot figure_or_data **plot_options if 'auto_open' not in plot_options plot_options['auto_open'] Falseurl plot figure_or_data **plot_options if isinstance figure_or_data dict layout figure_or_data get 'layout' {} else layout {}embed_options dict embed_options['width'] layout get 'width' '100%' embed_options['height'] layout get 'height' 525 try float embed_options['width'] except ValueError TypeError passelse embed_options['width'] str embed_options['width'] + 'px' try float embed_options['height'] except ValueError TypeError passelse embed_options['height'] str embed_options['height'] + 'px' return tools embed url **embed_options
@pytest mark django_dbdef test_multiselect_inactive_users_and_contacts rf regular_user view MultiselectAjaxView as_view assert 'joe' in regular_user username results _get_search_results rf view 'auth User' 'joe' assert len results 1 assert results[0] get 'id' regular_user id assert results[0] get 'name' regular_user username contact PersonContact objects create first_name 'Joe' last_name 'Somebody' results _get_search_results rf view 'shuup PersonContact' 'joe' assert len results 1 assert results[0] get 'id' contact id assert results[0] get 'name' contact name contact is_active Falsecontact save results _get_search_results rf view 'shuup PersonContact' 'joe' assert len results 0
def _sgf_init_gamestate sgf_root props sgf_root propertiess_size props get 'SZ' ['19'] [0]s_player props get 'PL' ['B'] [0]gs go GameState int s_size if 'AB' in props for stone in props['AB'] gs do_move _parse_sgf_move stone go BLACK if 'AW' in props for stone in props['AW'] gs do_move _parse_sgf_move stone go WHITE gs current_player go BLACK if s_player 'B' else go WHITE return gs
@gen coroutinedef wait_for_server ip port timeout 10 loop ioloop IOLoop current tic loop time while loop time - tic < timeout if can_connect ip port returnelse yield gen sleep 0 1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds" format **locals
@gen coroutinedef wait_for_server ip port timeout 10 loop ioloop IOLoop current tic loop time while loop time - tic < timeout if can_connect ip port returnelse yield gen sleep 0 1 raise TimeoutError "Serverat{ip} {port}didn'trespondin{timeout}seconds" format **locals
@contextmanagerdef respect_language language if language prev translation get_language translation activate language try yield finally translation activate prev else yield
@contextmanagerdef respect_language language if language prev translation get_language translation activate language try yield finally translation activate prev else yield
def main args parse_args if args verify verify for fname parts in get_sources items data generate parts fname os path join LIBRARY fname with open fname 'w' as afd afd seek 0 afd write data getvalue
def main args parse_args if args verify verify for fname parts in get_sources items data generate parts fname os path join LIBRARY fname with open fname 'w' as afd afd seek 0 afd write data getvalue
def main args parse_args if args verify verify for fname parts in get_sources items data generate parts fname os path join LIBRARY fname with open fname 'w' as afd afd seek 0 afd write data getvalue
def graph_number_of_cliques G cliques None if cliques is None cliques list find_cliques G return len cliques
def _check_mode handle mode ''if hasattr handle 'mode' mode handle modeif mode 1 returnmode str mode if mode and 'U' in mode upper raise ValueError 'SFFfilesmustNOTbeopenedinuniversalnewlinesmode Binarymodeisrecommended althoughonUnixthedefaultmodeisalsofine ' elif mode and 'B' not in mode upper and sys platform 'win32' raise ValueError 'SFFfilesmustbeopenedinbinarymodeonWindows'
def backup_get_all_by_host context host return IMPL backup_get_all_by_host context host
def update_dme username password dme_id ip_address dme_url 'https //www dnsmadeeasy com/servlet/updateip'dme_url + '?username %s&password %s&id %s&ip %s's urllib request urlopen dme_url % username password dme_id ip_address return s read
def update_dme username password dme_id ip_address dme_url 'https //www dnsmadeeasy com/servlet/updateip'dme_url + '?username %s&password %s&id %s&ip %s's urllib request urlopen dme_url % username password dme_id ip_address return s read
def set_logging log_level myfilename None if myfilename and ipython_version try if ipython_version startswith '0 10' __IPYTHON__ set_custom_exc Exception ipython_exception_handler else ip get_ipython ip set_custom_exc Exception ipython_exception_handler except NameError sys exc_clear level read_logging_level log_level if level and myfilename fileHandler logging FileHandler filename myfilename fileHandler setLevel level fileHandler setFormatter formatter logger addHandler fileHandler logger removeHandler consoleHandler print 'Nowloggingto' myfilename 'withlevel' log_levelelif level print 'Nowloggingwithlevel' log_levellogger setLevel level
def toplevel_wrapper *args **kwargs return ndb toplevel *args **kwargs
def toplevel_wrapper *args **kwargs return ndb toplevel *args **kwargs
def structure_tensor image sigma 1 mode 'constant' cval 0 image _prepare_grayscale_input_2D image imx imy _compute_derivatives image mode mode cval cval Axx ndi gaussian_filter imx * imx sigma mode mode cval cval Axy ndi gaussian_filter imx * imy sigma mode mode cval cval Ayy ndi gaussian_filter imy * imy sigma mode mode cval cval return Axx Axy Ayy
def structure_tensor image sigma 1 mode 'constant' cval 0 image _prepare_grayscale_input_2D image imx imy _compute_derivatives image mode mode cval cval Axx ndi gaussian_filter imx * imx sigma mode mode cval cval Axy ndi gaussian_filter imx * imy sigma mode mode cval cval Ayy ndi gaussian_filter imy * imy sigma mode mode cval cval return Axx Axy Ayy
def structure_tensor image sigma 1 mode 'constant' cval 0 image _prepare_grayscale_input_2D image imx imy _compute_derivatives image mode mode cval cval Axx ndi gaussian_filter imx * imx sigma mode mode cval cval Axy ndi gaussian_filter imx * imy sigma mode mode cval cval Ayy ndi gaussian_filter imy * imy sigma mode mode cval cval return Axx Axy Ayy
def get_model image_size subject_names feature Fisherfaces classifier NearestNeighbor dist_metric EuclideanDistance k 1 return ExtendedPredictableModel feature feature classifier classifier image_size image_size subject_names subject_names
def get_model image_size subject_names feature Fisherfaces classifier NearestNeighbor dist_metric EuclideanDistance k 1 return ExtendedPredictableModel feature feature classifier classifier image_size image_size subject_names subject_names
def get_model image_size subject_names feature Fisherfaces classifier NearestNeighbor dist_metric EuclideanDistance k 1 return ExtendedPredictableModel feature feature classifier classifier image_size image_size subject_names subject_names
def parse_cmdline argv global BASE_DIRECTORY VERBOSE SUMMARYDEFAULT_BASE_DIR os path join os path dirname os path realpath sys argv[0] 'collectors' parser OptionParser description 'Runspylintrecursivelyonadirectory' parser add_option '-b' '--base-dir' dest 'base_directory' metavar 'DIR' default DEFAULT_BASE_DIR help 'Directorytostartlinting' parser add_option '-v' '--verbose' dest 'verbose' action 'store_true' default False help 'Verbosemode logdebugmessages ' parser add_option '-a' '--show-all' dest 'show_all' action 'store_true' default False help 'Bydefault weareonlyshowingerrorlines' parser add_option '-s' '--summary' dest 'summary' action 'store_true' default False help 'Showsummaryreport' options args parser parse_args args argv[1 ] VERBOSE options verboseBASE_DIRECTORY options base_directoryreturn options args
def soap_fault message None actor None code None detail None _string _actor _code _detail Noneif message _string soapenv Fault_faultstring text message if actor _actor soapenv Fault_faultactor text actor if code _code soapenv Fault_faultcode text code if detail _detail soapenv Fault_detail text detail fault soapenv Fault faultcode _code faultstring _string faultactor _actor detail _detail return '%s' % fault
def attach_issue_statuses queryset as_field 'issue_statuses_attr' model queryset modelsql '\nSELECTjson_agg \nrow_to_json projects_issuestatus \nORDERBYprojects_issuestatus order\n \nFROMprojects_issuestatus\nWHEREprojects_issuestatus project_id {tbl} id\n'sql sql format tbl model _meta db_table queryset queryset extra select {as_field sql} return queryset
def _getTerminalCharset try charset locale getpreferredencoding if charset return charsetexcept locale Error AttributeError passtry charset locale nl_langinfo locale CODESET if charset return charsetexcept locale Error AttributeError passif hasattr sys stdout 'encoding' and sys stdout encoding return sys stdout encodingreturn 'ASCII'
def _getTerminalCharset try charset locale getpreferredencoding if charset return charsetexcept locale Error AttributeError passtry charset locale nl_langinfo locale CODESET if charset return charsetexcept locale Error AttributeError passif hasattr sys stdout 'encoding' and sys stdout encoding return sys stdout encodingreturn 'ASCII'
def run_dummy_heroku_worker sandbox _imminent_shutdown_delay sys stderr open os path join sandbox u'stderr log' u'w' class TestHerokuWorker HerokuWorker imminent_shutdown_delay _imminent_shutdown_delaydef perform_job self job queue create_file os path join sandbox u'started' for i in range 20 time sleep 0 1 create_file os path join sandbox u'finished' w TestHerokuWorker Queue u'dummy' w main_work_horse None None
def run_dummy_heroku_worker sandbox _imminent_shutdown_delay sys stderr open os path join sandbox u'stderr log' u'w' class TestHerokuWorker HerokuWorker imminent_shutdown_delay _imminent_shutdown_delaydef perform_job self job queue create_file os path join sandbox u'started' for i in range 20 time sleep 0 1 create_file os path join sandbox u'finished' w TestHerokuWorker Queue u'dummy' w main_work_horse None None
def run_dummy_heroku_worker sandbox _imminent_shutdown_delay sys stderr open os path join sandbox u'stderr log' u'w' class TestHerokuWorker HerokuWorker imminent_shutdown_delay _imminent_shutdown_delaydef perform_job self job queue create_file os path join sandbox u'started' for i in range 20 time sleep 0 1 create_file os path join sandbox u'finished' w TestHerokuWorker Queue u'dummy' w main_work_horse None None
def run_dummy_heroku_worker sandbox _imminent_shutdown_delay sys stderr open os path join sandbox u'stderr log' u'w' class TestHerokuWorker HerokuWorker imminent_shutdown_delay _imminent_shutdown_delaydef perform_job self job queue create_file os path join sandbox u'started' for i in range 20 time sleep 0 1 create_file os path join sandbox u'finished' w TestHerokuWorker Queue u'dummy' w main_work_horse None None
def _convert_record2fits format recformat kind dtype _dtype_to_recformat format shape dtype shapeitemsize dtype base itemsizeif dtype char 'U' itemsize itemsize // 4 option str itemsize ndims len shape repeat 1if ndims > 0 nel np array shape dtype 'i8' prod if nel > 1 repeat nelif kind 'a' ntot int repeat * int option output_format str ntot + 'A' elif recformat in NUMPY2FITS if repeat 1 repeat str repeat else repeat ''output_format repeat + NUMPY2FITS[recformat] else raise ValueError 'Illegalformat{} ' format format return output_format
def _convert_record2fits format recformat kind dtype _dtype_to_recformat format shape dtype shapeitemsize dtype base itemsizeif dtype char 'U' itemsize itemsize // 4 option str itemsize ndims len shape repeat 1if ndims > 0 nel np array shape dtype 'i8' prod if nel > 1 repeat nelif kind 'a' ntot int repeat * int option output_format str ntot + 'A' elif recformat in NUMPY2FITS if repeat 1 repeat str repeat else repeat ''output_format repeat + NUMPY2FITS[recformat] else raise ValueError 'Illegalformat{} ' format format return output_format
def latency_echo url count poll copy ctx zmq Context s ctx socket zmq REP if poll p zmq Poller p register s s bind url block zmq NOBLOCK if poll else 0 for i in range count if poll res p poll msg s recv block copy copy if poll res p poll s send msg block copy copy msg s recv assert msg 'done' s close ctx term
def split_string text chars_per_string return [text[i i + chars_per_string ] for i in range 0 len text chars_per_string ]
def split_string text chars_per_string return [text[i i + chars_per_string ] for i in range 0 len text chars_per_string ]
def atomic_open filename mode 'w' if mode in 'r' 'rb' 'r+' 'rb+' 'a' 'ab' raise TypeError "Readorappendmodesdon'tworkwithatomic_open" ntf tempfile NamedTemporaryFile mode prefix ' ___atomic_write' dir os path dirname filename delete False return _AtomicWFile ntf ntf name filename
def verify_iterator_data assertEqual results count 0for count result in enumerate results 1 params get_all_primitive_params result[0] assertEqual len params len result msg 'Nottherightnumberofcolumns?' for expected actual in zip params result assertEqual actual expected return count
def pack_array builder values ty None n len values if ty is None ty values[0] typeary ir ArrayType ty n ir Undefined for i v in enumerate values ary builder insert_value ary v i return ary
def pack_array builder values ty None n len values if ty is None ty values[0] typeary ir ArrayType ty n ir Undefined for i v in enumerate values ary builder insert_value ary v i return ary
@profiler tracedef network_create request **kwargs LOG debug 'network_create kwargs %s' % kwargs if 'net_profile_id' in kwargs kwargs['n1kv profile'] kwargs pop 'net_profile_id' if 'tenant_id' not in kwargs kwargs['tenant_id'] request user project_idbody {'network' kwargs}network neutronclient request create_network body body get 'network' return Network network
def timetrace message idstring tracemessage 'TEST_MESSAGE' final False if message startswith tracemessage try prefix tlast t0 message split None 2 tlast t0 float tlast float t0 except IndexError ValueError t0 time tlast t0t1 t0else t1 time print '**timetrace %s dT %fs total %fs ' % idstring t1 - tlast t1 - t0 if final message '****%s total%f ****' % tracemessage t1 - t0 else message '%s%f%f' % tracemessage t1 t0 return message
def position_of_ngram ngram sentence for i sublist in enumerate ngrams sentence len ngram if ngram sublist return i
def position_of_ngram ngram sentence for i sublist in enumerate ngrams sentence len ngram if ngram sublist return i
def position_of_ngram ngram sentence for i sublist in enumerate ngrams sentence len ngram if ngram sublist return i
def acos x np import_module 'numpy' if isinstance x int float if abs x > 1 return interval - np inf np inf is_valid False else return interval np arccos x np arccos x elif isinstance x interval if x is_valid is False or x start > 1 or x end < -1 return interval - np inf np inf is_valid False elif x start < -1 or x end > 1 return interval - np inf np inf is_valid None else start np arccos x start end np arccos x end return interval start end is_valid x is_valid
def convert_timedelta delta days total_seconds delta days delta seconds hours days * 24 + total_seconds // 3600 minutes total_seconds % 3600 // 60 seconds str total_seconds % 60 zfill 2 microseconds str delta microseconds [ 2] zfill 2 return hours minutes seconds microseconds
def convert_timedelta delta days total_seconds delta days delta seconds hours days * 24 + total_seconds // 3600 minutes total_seconds % 3600 // 60 seconds str total_seconds % 60 zfill 2 microseconds str delta microseconds [ 2] zfill 2 return hours minutes seconds microseconds
def emit_options options return ' ' join '%s %s' % k v for k v in options items
def context s '' log None ctx contexts[ -1 ] sif s and log log 'Context %s' % get_context
def divide_to_width desired_chunks max_width chunks []for c in desired_chunks nb_divides int np ceil c / max_width for i in range nb_divides n c // nb_divides - i chunks append n c - nassert c 0 return tuple chunks
def special_rss_site url return cfg rss_filenames or match_str url cfg rss_odd_titles
@task task ignore_result True def store_likes user likes converter_class get_class_for 'user_conversion' logger info 'celeryisstoring%slikes' % len likes converter_class _store_likes user likes return likes
@task task ignore_result True def store_likes user likes converter_class get_class_for 'user_conversion' logger info 'celeryisstoring%slikes' % len likes converter_class _store_likes user likes return likes
@task task ignore_result True def store_likes user likes converter_class get_class_for 'user_conversion' logger info 'celeryisstoring%slikes' % len likes converter_class _store_likes user likes return likes
@task task ignore_result True def store_likes user likes converter_class get_class_for 'user_conversion' logger info 'celeryisstoring%slikes' % len likes converter_class _store_likes user likes return likes
def signature params shared_secret encoded_params u'' join [u'{key} {value}' format key key value params[key] for key in sorted params keys if key u'signature' ] hasher hmac new shared_secret encode 'utf-8' encoded_params encode 'utf-8' hashlib sha256 return hasher hexdigest
def signature params shared_secret encoded_params u'' join [u'{key} {value}' format key key value params[key] for key in sorted params keys if key u'signature' ] hasher hmac new shared_secret encode 'utf-8' encoded_params encode 'utf-8' hashlib sha256 return hasher hexdigest
@_docstring 'series' def get_series_by_id id includes [] return _do_mb_query 'series' id includes
@_docstring 'series' def get_series_by_id id includes [] return _do_mb_query 'series' id includes
def _maybe_call_get_oauth_user _scope None if 'OAUTH_ERROR_CODE' not in os environ or os environ get 'OAUTH_LAST_SCOPE' None _scope req user_service_pb GetOAuthUserRequest if _scope req set_scope _scope resp user_service_pb GetOAuthUserResponse try apiproxy_stub_map MakeSyncCall 'user' 'GetOAuthUser' req resp os environ['OAUTH_EMAIL'] resp email os environ['OAUTH_AUTH_DOMAIN'] resp auth_domain os environ['OAUTH_USER_ID'] resp user_id os environ['OAUTH_CLIENT_ID'] resp client_id if resp is_admin os environ['OAUTH_IS_ADMIN'] '1'else os environ['OAUTH_IS_ADMIN'] '0'os environ['OAUTH_ERROR_CODE'] ''except apiproxy_errors ApplicationError as e os environ['OAUTH_ERROR_CODE'] str e application_error os environ['OAUTH_ERROR_DETAIL'] e error_detailif _scope os environ['OAUTH_LAST_SCOPE'] _scopeelse os environ pop 'OAUTH_LAST_SCOPE' None _maybe_raise_exception
def get_cohorted_user_partition course for user_partition in course user_partitions if user_partition scheme CohortPartitionScheme return user_partitionreturn None
def get_cohorted_user_partition course for user_partition in course user_partitions if user_partition scheme CohortPartitionScheme return user_partitionreturn None
def get_cohorted_user_partition course for user_partition in course user_partitions if user_partition scheme CohortPartitionScheme return user_partitionreturn None
def filePathDelta origin destination commonItems 0path1 origin path split os sep path2 destination path split os sep for elem1 elem2 in zip path1 path2 if elem1 elem2 commonItems + 1else breakpath [' '] * len path1 - commonItems return path + path2[commonItems ]
def toNorm raw return np power MAX_NORM raw * NORM_RATIO
def toNorm raw return np power MAX_NORM raw * NORM_RATIO
def allocate_controller_key_and_unit_number client_factory devices adapter_type if devices __class__ __name__ 'ArrayOfVirtualDevice' devices devices VirtualDevicetaken _find_allocated_slots devices ret Noneif adapter_type constants ADAPTER_TYPE_IDE ide_keys [dev key for dev in devices if _is_ide_controller dev ]ret _find_controller_slot ide_keys taken 2 elif adapter_type in constants SCSI_ADAPTER_TYPES scsi_keys [dev key for dev in devices if _is_scsi_controller dev ]ret _find_controller_slot scsi_keys taken 16 if ret return ret[0] ret[1] None controller_key -101 bus_number 0if adapter_type in constants SCSI_ADAPTER_TYPES bus_number _get_bus_number_for_scsi_controller devices controller_spec create_controller_spec client_factory controller_key adapter_type bus_number return controller_key 0 controller_spec
def allocate_controller_key_and_unit_number client_factory devices adapter_type if devices __class__ __name__ 'ArrayOfVirtualDevice' devices devices VirtualDevicetaken _find_allocated_slots devices ret Noneif adapter_type constants ADAPTER_TYPE_IDE ide_keys [dev key for dev in devices if _is_ide_controller dev ]ret _find_controller_slot ide_keys taken 2 elif adapter_type in constants SCSI_ADAPTER_TYPES scsi_keys [dev key for dev in devices if _is_scsi_controller dev ]ret _find_controller_slot scsi_keys taken 16 if ret return ret[0] ret[1] None controller_key -101 bus_number 0if adapter_type in constants SCSI_ADAPTER_TYPES bus_number _get_bus_number_for_scsi_controller devices controller_spec create_controller_spec client_factory controller_key adapter_type bus_number return controller_key 0 controller_spec
def detect_face face_file max_results 4 image_content face_file read batch_request [{'image' {'content' base64 b64encode image_content decode 'utf-8' } 'features' [{'type' 'FACE_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service images annotate body {'requests' batch_request} response request execute return response['responses'][0]['faceAnnotations']
def detect_face face_file max_results 4 image_content face_file read batch_request [{'image' {'content' base64 b64encode image_content decode 'utf-8' } 'features' [{'type' 'FACE_DETECTION' 'maxResults' max_results}]}]service get_vision_service request service images annotate body {'requests' batch_request} response request execute return response['responses'][0]['faceAnnotations']
def create_script fname text os linesep join ['#-*-coding utf-8-*-' '' ''] encoding write to_text_string text fname 'utf-8'
def symlink source destination use_sudo False func use_sudo and run_as_root or run func '/bin/ln-s{0}{1}' format quote source quote destination
def play command_str selection paths open_args log item_type 'track' keep_open False item_type + 's' if len selection > 1 else '' ui print_ u'Playing{0}{1} ' format len selection item_type log debug u'executingcommand {}{ r}' command_str open_args try if keep_open command util shlex_split command_str command command + open_args subprocess call command else util interactive_open open_args command_str except OSError as exc raise ui UserError 'Couldnotplaythequery {0}' format exc
@profiler tracedef remove_domain_user_role request user role domain None manager keystoneclient request admin True rolesreturn manager revoke role user user domain domain
def get_api backend api_args reactor cluster_id if backend needs_cluster_id api_args api_args set 'cluster_id' cluster_id if backend needs_reactor api_args api_args set 'reactor' reactor for config_key in backend required_config if config_key not in api_args raise UsageError u'Configurationerror Requiredkey{}ismissing ' format config_key decode 'utf-8' try return backend api_factory **api_args except StorageInitializationError as e if e code StorageInitializationError CONFIGURATION_ERROR raise UsageError u'Configurationerror' *e args else raise
def get_api backend api_args reactor cluster_id if backend needs_cluster_id api_args api_args set 'cluster_id' cluster_id if backend needs_reactor api_args api_args set 'reactor' reactor for config_key in backend required_config if config_key not in api_args raise UsageError u'Configurationerror Requiredkey{}ismissing ' format config_key decode 'utf-8' try return backend api_factory **api_args except StorageInitializationError as e if e code StorageInitializationError CONFIGURATION_ERROR raise UsageError u'Configurationerror' *e args else raise
def get_api backend api_args reactor cluster_id if backend needs_cluster_id api_args api_args set 'cluster_id' cluster_id if backend needs_reactor api_args api_args set 'reactor' reactor for config_key in backend required_config if config_key not in api_args raise UsageError u'Configurationerror Requiredkey{}ismissing ' format config_key decode 'utf-8' try return backend api_factory **api_args except StorageInitializationError as e if e code StorageInitializationError CONFIGURATION_ERROR raise UsageError u'Configurationerror' *e args else raise
def from_text text m Message reader _TextReader text m reader read return m
def process_projection_requirements figure *args **kwargs ispolar kwargs pop u'polar' False projection kwargs pop u'projection' None if ispolar if projection is not None and projection u'polar' raise ValueError u'polar True yetprojection %r Onlyoneoftheseargumentsshouldbesupplied ' % projection projection u'polar'if projection u'polar' kwargs setdefault u'resolution' 1 if isinstance projection six string_types or projection is None projection_class get_projection_class projection elif hasattr projection u'_as_mpl_axes' projection_class extra_kwargs projection _as_mpl_axes kwargs update **extra_kwargs else raise TypeError u'projectionmustbeastring Noneorimplementa_as_mpl_axesmethod Got%r' % projection key figure _make_key *args **kwargs return projection_class kwargs key
def process_projection_requirements figure *args **kwargs ispolar kwargs pop u'polar' False projection kwargs pop u'projection' None if ispolar if projection is not None and projection u'polar' raise ValueError u'polar True yetprojection %r Onlyoneoftheseargumentsshouldbesupplied ' % projection projection u'polar'if projection u'polar' kwargs setdefault u'resolution' 1 if isinstance projection six string_types or projection is None projection_class get_projection_class projection elif hasattr projection u'_as_mpl_axes' projection_class extra_kwargs projection _as_mpl_axes kwargs update **extra_kwargs else raise TypeError u'projectionmustbeastring Noneorimplementa_as_mpl_axesmethod Got%r' % projection key figure _make_key *args **kwargs return projection_class kwargs key
def kill container signal None client _get_client status base_status copy try dcontainer _get_container_infos container ['Id']if is_running dcontainer client kill dcontainer signal signal if signal _valid status comment "Killsignal'{0}'successfullysenttothecontainer'{1}'" format signal container id_ container elif not is_running dcontainer _valid status comment 'Container{0}waskilled' format container id_ container else _invalid status comment 'Container{0}wasnotkilled' format container else _valid status comment 'Container{0}wasalreadystopped' format container id_ container except Exception _invalid status id_ container out traceback format_exc comment 'Anexceptionoccurredwhilekillingyourcontainer{0}' format container __salt__['mine send'] 'dockerng ps' verbose True all True host True return status
def trim_custom_directories repo older_than_days None if not repo returnif older_than_days is None older_than_days settings get_value 'PACKAGES' 'custom_max_age' type int default 40 cmd 'find -typef-atime+%s-execrm-f{}\\ ' % older_than_days repo_run_command repo cmd ignore_status True
def tb_lineno tb return tb tb_lineno
def tb_lineno tb return tb tb_lineno
@bp route '/<int uid>/delete' methods ['POST'] @require_userdef delete uid password request form get 'password' if not password flash _ 'Passwordisrequiredtodeleteatopic' 'info' return redirect url_for ' view' uid uid if not g user check_password password flash _ 'Passwordiswrong' 'error' return redirect url_for ' view' uid uid topic Topic query get_or_404 uid topic delete return redirect url_for ' topics'
def service_delete service_id None name None profile None **connection_args kstone auth profile **connection_args if name service_id service_get name name profile profile **connection_args [name]['id']kstone services delete service_id return 'KeystoneserviceID"{0}"deleted' format service_id
def values expr env env dict env env['__builtins__'] {}c test_expr expr _values_codes return eval c env
def values expr env env dict env env['__builtins__'] {}c test_expr expr _values_codes return eval c env
def values expr env env dict env env['__builtins__'] {}c test_expr expr _values_codes return eval c env
def values expr env env dict env env['__builtins__'] {}c test_expr expr _values_codes return eval c env
def get_running profile 'default' cmd {'cmd' 'list' 'mime' 'prop'}return _do_http cmd profile
def zmq_version_info major ffi new 'int*' minor ffi new 'int*' patch ffi new 'int*' C zmq_version major minor patch return int major[0] int minor[0] int patch[0]
def test_get_by_name assert Operator get_by_name 'SelectKBest' __class__ TPOTSelectKBest
def _wrap_variable_creation func custom_getter original_get_variable tf get_variabledef custom_get_variable *args **kwargs if hasattr kwargs 'custom_getter' raise AttributeError 'Customgettersarenotsupportedforoptimizeevariables ' return original_get_variable custom_getter custom_getter *args **kwargs with mock patch 'tensorflow get_variable' custom_get_variable return func
def gcodePath newType pathType layerThickness startPoint if layerThickness < 0 0 layerThickness 0 01if profile getProfileSetting 'spiralize' 'True' layerThickness profile getProfileSettingFloat 'layer_height' return {'type' newType 'pathType' pathType 'layerThickness' layerThickness 'points' [startPoint] 'extrusion' [0 0]}
@step 'Ihavenotsentanyemails' def mail_not_sent step return mail_sent_count step 0
@step 'Ihavenotsentanyemails' def mail_not_sent step return mail_sent_count step 0
@step 'Ihavenotsentanyemails' def mail_not_sent step return mail_sent_count step 0
def readQueue thread_id None return _readQueue thread_id
@ensure_csrf_cookie@cache_control no_cache True no_store True must_revalidate True @coach_dashboarddef ccx_student_management request course ccx None if not ccx raise Http404action request POST get 'student-action' None student_id request POST get 'student-id' '' email_students 'email-students' in request POST identifiers [student_id]course_key CCXLocator from_course_locator course id unicode ccx id email_params get_email_params course auto_enroll True course_key course_key display_name ccx display_name errors ccx_students_enrolling_center action identifiers email_students course_key email_params ccx coach for error_message in errors messages error request error_message url reverse 'ccx_coach_dashboard' kwargs {'course_id' course_key} return redirect url
def imtext from ansiext import AnsiExtensionmd Markdown output_format 'imtext' extensions [ExtraExtension AnsiExtension ] md stripTopLevelTags Falsereturn md
def buildSomeConnections modules res []for i in range len modules // 3 - 1 res append FullConnection modules[ i * 2 ] modules[ i * 3 + 1 ] return res
def export_courses_to_output_path output_path content_store contentstore module_store modulestore root_dir output_pathcourses module_store get_courses course_ids [x id for x in courses]failed_export_courses []for course_id in course_ids print u'-' * 80 print u'Exportingcourseid {0}to{1}' format course_id output_path try course_dir course_id to_deprecated_string replace '/' ' ' export_course_to_xml module_store content_store course_id root_dir course_dir except Exception as err failed_export_courses append unicode course_id print u' ' * 30 + u'>Oops failedtoexport{0}' format course_id print u'Error 'print errreturn courses failed_export_courses
def export_courses_to_output_path output_path content_store contentstore module_store modulestore root_dir output_pathcourses module_store get_courses course_ids [x id for x in courses]failed_export_courses []for course_id in course_ids print u'-' * 80 print u'Exportingcourseid {0}to{1}' format course_id output_path try course_dir course_id to_deprecated_string replace '/' ' ' export_course_to_xml module_store content_store course_id root_dir course_dir except Exception as err failed_export_courses append unicode course_id print u' ' * 30 + u'>Oops failedtoexport{0}' format course_id print u'Error 'print errreturn courses failed_export_courses
def export_courses_to_output_path output_path content_store contentstore module_store modulestore root_dir output_pathcourses module_store get_courses course_ids [x id for x in courses]failed_export_courses []for course_id in course_ids print u'-' * 80 print u'Exportingcourseid {0}to{1}' format course_id output_path try course_dir course_id to_deprecated_string replace '/' ' ' export_course_to_xml module_store content_store course_id root_dir course_dir except Exception as err failed_export_courses append unicode course_id print u' ' * 30 + u'>Oops failedtoexport{0}' format course_id print u'Error 'print errreturn courses failed_export_courses
def export_courses_to_output_path output_path content_store contentstore module_store modulestore root_dir output_pathcourses module_store get_courses course_ids [x id for x in courses]failed_export_courses []for course_id in course_ids print u'-' * 80 print u'Exportingcourseid {0}to{1}' format course_id output_path try course_dir course_id to_deprecated_string replace '/' ' ' export_course_to_xml module_store content_store course_id root_dir course_dir except Exception as err failed_export_courses append unicode course_id print u' ' * 30 + u'>Oops failedtoexport{0}' format course_id print u'Error 'print errreturn courses failed_export_courses
def markLocation stream RADIUS 5000stream seek - RADIUS 1 outputDoc open 'PyPDF2_pdfLocation txt' 'w' outputDoc write stream read RADIUS outputDoc write 'HERE' outputDoc write stream read RADIUS outputDoc close stream seek - RADIUS 1
def markLocation stream RADIUS 5000stream seek - RADIUS 1 outputDoc open 'PyPDF2_pdfLocation txt' 'w' outputDoc write stream read RADIUS outputDoc write 'HERE' outputDoc write stream read RADIUS outputDoc close stream seek - RADIUS 1
def _layout_to_matrix layout result [ [0] * len layout for i in range len layout ]stack []for i in range len layout i_level layout[i]if stack j stack[ -1 ]j_level layout[j]while j_level > i_level stack pop j stack[ -1 ]j_level layout[j]result[i][j] result[j][i] 1stack append i return result
def check_version version if isinstance version string_types version tuple map int version split ' ' if version > version_info str_version ' ' join map str version raise ValueError "pgiversion'%s'requested '%s'available" % str_version __version__
def check_version version if isinstance version string_types version tuple map int version split ' ' if version > version_info str_version ' ' join map str version raise ValueError "pgiversion'%s'requested '%s'available" % str_version __version__
def annotate_axes index labels points offset_points size ax **kwargs for i in index label labels[i]point points[i]offset offset_points[i]ax annotate label point xytext offset textcoords 'offsetpoints' size size **kwargs return ax
def get_rnd_shuffle builder fnty ir FunctionType ir VoidType rnd_state_ptr_t fn builder function module get_or_insert_function fnty 'numba_rnd_shuffle' fn args[0] add_attribute 'nocapture' return fn
@contextmanagerdef mock_get_score earned 0 possible 1 with patch 'lms djangoapps grades new subsection_grade get_score' as mock_score mock_score return_value ProblemScore raw_earned earned raw_possible possible weighted_earned earned weighted_possible possible weight 1 graded True attempted True yield mock_score
@contextmanagerdef mock_get_score earned 0 possible 1 with patch 'lms djangoapps grades new subsection_grade get_score' as mock_score mock_score return_value ProblemScore raw_earned earned raw_possible possible weighted_earned earned weighted_possible possible weight 1 graded True attempted True yield mock_score
def get_engine hass config if shutil which 'pico2wave' is None _LOGGER error "'pico2wave'wasnotfound" return Falsereturn PicoProvider config[CONF_LANG]
def object_copy self CopySource ExtraArgs None Callback None SourceClient None Config None return self meta client copy CopySource CopySource Bucket self bucket_name Key self key ExtraArgs ExtraArgs Callback Callback SourceClient SourceClient Config Config
def check_sole_error response status strings if isinstance strings str strings [strings]assert response status_code status document loads response data errors document['errors']assert len errors 1 error errors[0]assert error['status'] status assert all s in error['detail'] for s in strings
def check_sole_error response status strings if isinstance strings str strings [strings]assert response status_code status document loads response data errors document['errors']assert len errors 1 error errors[0]assert error['status'] status assert all s in error['detail'] for s in strings
def logsafe val if isinstance val six text_type return valelif isinstance val bytes return val decode 'utf-8' 'replace' elif isinstance val subprocess CalledProcessError try return six text_type val except UnicodeDecodeError return str val decode 'utf-8' 'replace' else return val
def ensure_treasury_data bm_symbol first_date last_date now loader_module filename source INDEX_MAPPING get bm_symbol INDEX_MAPPING['^GSPC'] first_date max first_date loader_module earliest_possible_date path get_data_filepath filename if os path exists path try data pd DataFrame from_csv path tz_localize 'UTC' if has_data_for_dates data first_date last_date return datalast_download_time last_modified_time path if now - last_download_time < ONE_HOUR logger warn 'Refusingtodownloadnewtreasurydatabecauseadownloadsucceededat%s ' % last_download_time return dataexcept OSError IOError ValueError as e logger info 'Loadingdatafor{path}failedwitherror[{error}] ' format path path error e try data loader_module get_treasury_data first_date last_date data to_csv path except OSError IOError HTTPError logger exception 'failedtocachetreasurydata' if not has_data_for_dates data first_date last_date logger warn "Stilldon'thaveexpecteddataafterredownload " return data
def ensure_treasury_data bm_symbol first_date last_date now loader_module filename source INDEX_MAPPING get bm_symbol INDEX_MAPPING['^GSPC'] first_date max first_date loader_module earliest_possible_date path get_data_filepath filename if os path exists path try data pd DataFrame from_csv path tz_localize 'UTC' if has_data_for_dates data first_date last_date return datalast_download_time last_modified_time path if now - last_download_time < ONE_HOUR logger warn 'Refusingtodownloadnewtreasurydatabecauseadownloadsucceededat%s ' % last_download_time return dataexcept OSError IOError ValueError as e logger info 'Loadingdatafor{path}failedwitherror[{error}] ' format path path error e try data loader_module get_treasury_data first_date last_date data to_csv path except OSError IOError HTTPError logger exception 'failedtocachetreasurydata' if not has_data_for_dates data first_date last_date logger warn "Stilldon'thaveexpecteddataafterredownload " return data
@core_helperdef organizations_available permission 'manage_group' include_dataset_count False context {'user' c user}data_dict {'permission' permission 'include_dataset_count' include_dataset_count}return logic get_action 'organization_list_for_user' context data_dict
def resource name def make_responder retriever def responder ids entities [retriever id for id in ids]entities [entity for entity in entities if entity]if len entities 1 return flask jsonify _rep entities[0] expand is_expand elif entities return app response_class json_generator entities root name mimetype 'application/json' else return flask abort 404 responder __name__ 'get_{0}' format name return responderreturn make_responder
@pytest mark django_dbdef test_no_root_view_permissions po_directory nobody default admin view no_permission_sets no_projects project_foo project_bar ALL_PROJECTS [project_foo code project_bar code]foo_user UserFactory create username 'foo' bar_user UserFactory create username 'bar' _require_permission_set foo_user project_foo directory [view] assert items_equal Project accessible_by_user admin ALL_PROJECTS assert items_equal Project accessible_by_user foo_user [project_foo code] assert items_equal Project accessible_by_user bar_user [] assert items_equal Project accessible_by_user default [] assert items_equal Project accessible_by_user nobody [] _require_permission_set default project_bar directory [view] assert items_equal Project accessible_by_user admin ALL_PROJECTS assert items_equal Project accessible_by_user foo_user ALL_PROJECTS assert items_equal Project accessible_by_user bar_user [project_bar code] assert items_equal Project accessible_by_user default [project_bar code] assert items_equal Project accessible_by_user nobody []
@contextlib contextmanagerdef check_remains_sorted X if not hasattr X 'has_sorted_indices' or not X has_sorted_indices yield return yield indices X indices copy X has_sorted_indices FalseX sort_indices assert_array_equal indices X indices 'Expectedsortedindices foundunsorted'
def ipv6_addresses interface with settings hide 'running' 'stdout' res sudo "/sbin/ifconfig% interface s grep'inet6' true" % locals ret {}if res '' return retlines res split '\n' for line in lines if 'addr' in line addr res split [2]else addr res split [1]lower_line line lower addr_scope 'unknown'for scope in ['host' 'link' 'global'] if scope in lower_line addr_scope scoperet[addr_scope] addrreturn ret
def find_words string trie _boundary_re re compile '[%s]+' % re escape DEFAULT_BOUNDARY_CHARS results []start 0while start < len string keys match_all string[start ] trie for key in keys l len key if start + l len string or _boundary_re match string[ start + l ] results append key start start + l m _boundary_re search string start if m is None breakstart m end return results
def find_words string trie _boundary_re re compile '[%s]+' % re escape DEFAULT_BOUNDARY_CHARS results []start 0while start < len string keys match_all string[start ] trie for key in keys l len key if start + l len string or _boundary_re match string[ start + l ] results append key start start + l m _boundary_re search string start if m is None breakstart m end return results
def creation_sequence_to_weights creation_sequence first creation_sequence[0]if isinstance first str if isinstance creation_sequence list wseq creation_sequence[ ]else wseq list creation_sequence elif isinstance first tuple wseq [v[1] for v in creation_sequence]elif isinstance first int wseq uncompact creation_sequence else raise TypeError 'Notavalidcreationsequencetype' wseq reverse w 0prev 'i'for j s in enumerate wseq if s 'i' wseq[j] wprev selif prev 'i' prev sw + 1wseq reverse for j s in enumerate wseq if s 'd' wseq[j] wprev selif prev 'd' prev sw + 1if prev 'd' w + 1wscale 1 0 / float w return [ ww * wscale for ww in wseq]
def get_arch with settings hide 'running' 'stdout' arch run 'uname-m' return arch
def arbitrary_transformation deployment uuid uuid4 return deployment transform ['nodes' uuid] Node uuid uuid
def load_crypto_meta value def b64_decode_meta crypto_meta return {str name base64 b64decode val if name in 'iv' 'key' else b64_decode_meta val if isinstance val dict else val encode 'utf8' if six PY2 else val for name val in crypto_meta items }try if not isinstance value six string_types raise ValueError 'cryptometanotastring' val json loads urlparse unquote_plus value if not isinstance val collections Mapping raise ValueError 'cryptometanotaMapping' return b64_decode_meta val except KeyError ValueError TypeError as err msg 'Badcryptometa%r %s' % value err raise EncryptionException msg
def register_stanza_plugin stanza plugin iterable False overrides False tag u'{%s}%s' % plugin namespace plugin name plugin_info u'plugin_attrib_map' u'plugin_tag_map' u'plugin_iterables' u'plugin_overrides' for attr in plugin_info info getattr stanza attr setattr stanza attr info copy stanza plugin_attrib_map[plugin plugin_attrib] pluginstanza plugin_tag_map[tag] pluginif iterable stanza plugin_iterables add plugin if plugin plugin_multi_attrib multiplugin multifactory plugin plugin plugin_multi_attrib register_stanza_plugin stanza multiplugin if overrides for interface in plugin overrides stanza plugin_overrides[interface] plugin plugin_attrib
def coord_distance lat1 lon1 lat2 lon2 lon1 lat1 lon2 lat2 map math radians [lon1 lat1 lon2 lat2] dlon lon2 - lon1 dlat lat2 - lat1 a math sin dlat / 2 ** 2 + math cos lat1 * math cos lat2 * math sin dlon / 2 ** 2 c 2 * math asin math sqrt a km 6367 * c return km
def execute_request service property_uri request return service searchanalytics query siteUrl property_uri body request execute
def parse_query_string return dict [param urllib unquote value ] for param value in x split ' ' 1 if ' ' in x else [x None] for x in os getenv 'QUERY_STRING' '' split '&'
def get_info app env account container None swift_source None env setdefault 'swift infocache' {} if container path '/v1/%s/%s' % account container path_env env copy path_env['PATH_INFO'] pathreturn get_container_info path_env app swift_source swift_source else path '/v1/%s' % account path_env env copy path_env['PATH_INFO'] pathreturn get_account_info path_env app swift_source swift_source
@pytest mark parametrize 'repo_type repo_url repo_name' [ 'git' 'https //github com/hello/world git' 'world' 'hg' 'https //bitbucket org/foo/bar' 'bar' ] def test_clone_should_invoke_vcs_command mocker clone_dir repo_type repo_url repo_name mocker patch 'cookiecutter vcs is_vcs_installed' autospec True return_value True mock_subprocess mocker patch 'cookiecutter vcs subprocess check_output' autospec True expected_repo_dir os path normpath os path join clone_dir repo_name branch 'foobar'repo_dir vcs clone repo_url checkout branch clone_to_dir clone_dir no_input True assert repo_dir expected_repo_dir mock_subprocess assert_any_call [repo_type 'clone' repo_url] cwd clone_dir stderr subprocess STDOUT mock_subprocess assert_any_call [repo_type 'checkout' branch] cwd expected_repo_dir stderr subprocess STDOUT
@task def rerun_course source_course_key_string destination_course_key_string user_id fields None from edxval api import copy_course_videostry source_course_key CourseKey from_string source_course_key_string destination_course_key CourseKey from_string destination_course_key_string fields deserialize_fields fields if fields else None store modulestore with store default_store 'split' store clone_course source_course_key destination_course_key user_id fields fields initialize_permissions destination_course_key User objects get id user_id CourseRerunState objects succeeded course_key destination_course_key copy_course_videos source_course_key destination_course_key return 'succeeded'except DuplicateCourseError as exc CourseRerunState objects failed course_key destination_course_key logging exception u'CourseRerunError' return 'duplicatecourse'except Exception as exc CourseRerunState objects failed course_key destination_course_key logging exception u'CourseRerunError' try modulestore delete_course destination_course_key user_id except ItemNotFoundError passreturn 'exception ' + unicode exc
def bartlett M return bartlett_ M
def bartlett M return bartlett_ M
def strings app_file app_dir tools_dir try print '[INFO]ExtractingStringsfromAPK'strings_jar tools_dir + 'strings_from_apk jar' args [ settings JAVA_PATH + 'java' '-jar' strings_jar app_dir + app_file app_dir]subprocess call args dat ''try with io open app_dir + 'strings json' mode 'r' encoding 'utf8' errors 'ignore' as file_pointer dat file_pointer read except passdat dat[1 -1 ] split ' ' return datexcept PrintException '[ERROR]ExtractingStringsfromAPK'
def calculate_wait_for_retry retry_attempt wait_time 2 ** retry_attempt max_jitter wait_time / 4 0 wait_time + random uniform - max_jitter max_jitter return max 1 min wait_time _MAX_RETRY_WAIT
def calculate_wait_for_retry retry_attempt wait_time 2 ** retry_attempt max_jitter wait_time / 4 0 wait_time + random uniform - max_jitter max_jitter return max 1 min wait_time _MAX_RETRY_WAIT
def body_quopri_len str count 0for c in str if bqre match c count + 3else count + 1return count
@register assignment_tagdef assignment_one_default one two 'hi' return 'assignment_one_default-Expectedresult %s %s' % one two
def find_package_data package_data {'IPython core' ['profile/README*'] 'IPython core tests' ['* png' '* jpg' 'daft_extension/* py'] 'IPython lib tests' ['* wav'] 'IPython testing plugin' ['* txt']}return package_data
@decoratordef assert_signal_called signal **expected handler Mock def on_call **kwargs return handler **kwargs signal connect on_call try yield handler finally signal disconnect on_call handler assert_called_with signal signal **expected
def isValidImage field_data all_data from PIL import Imagefrom cStringIO import StringIOtry content field_data['content']except TypeError raise ValidationError gettext 'Nofilewassubmitted Checktheencodingtypeontheform ' try Image open StringIO content except IOError raise ValidationError gettext 'Uploadavalidimage Thefileyouuploadedwaseithernotanimageoracorruptedimage '
def isValidImage field_data all_data from PIL import Imagefrom cStringIO import StringIOtry content field_data['content']except TypeError raise ValidationError gettext 'Nofilewassubmitted Checktheencodingtypeontheform ' try Image open StringIO content except IOError raise ValidationError gettext 'Uploadavalidimage Thefileyouuploadedwaseithernotanimageoracorruptedimage '
def GetClassForCLSID clsid clsid str clsid if CLSIDToClass HasClass clsid return CLSIDToClass GetClass clsid mod GetModuleForCLSID clsid if mod is None return Nonetry return CLSIDToClass GetClass clsid except KeyError return None
@world absorbdef id_click elem_id css_click '#{}' format elem_id
def gruntz e z z0 dir '+' if not z is_Symbol raise NotImplementedError 'SecondargumentmustbeaSymbol' r Noneif z0 oo r limitinf e z elif z0 - oo r limitinf e subs z - z z else if str dir '-' e0 e subs z z0 - 1 / z elif str dir '+' e0 e subs z z0 + 1 / z else raise NotImplementedError "dirmustbe'+'or'-'" r limitinf e0 z return r rewrite 'intractable' deep True
def recv files dest ret {}for path data in six iteritems files if os path basename path os path basename dest and not os path isdir dest final destelif os path isdir dest final os path join dest os path basename path elif os path isdir os path dirname dest final destelse return 'Destinationunavailable'try with salt utils fopen final 'w+' as fp_ fp_ write data ret[final] Trueexcept IOError ret[final] Falsereturn ret
def pr_instance_type pe_id if pe_id etable current s3db pr_pentityrow current db etable pe_id pe_id select etable instance_type limitby 0 1 first if row return row instance_typereturn None
def Array dtype size None ref False def getArrayType self 'AlittlefunctiontoreplacethegetType methodofarrays\n\nItreturnsastringrepresentationofthearrayelementtypeinsteadofthe\nintegervalue NTA_BasicTypeenum returnedbytheorigianlarray\n'return self _dtypeif ref assert size is None index basicTypes index dtype if index -1 raise Exception 'Invaliddatatype ' + dtype if size and size < 0 raise Exception 'Arraysizemustbepositive' suffix 'ArrayRef' if ref else 'Array' arrayFactory getattr engine dtype + suffix arrayFactory getType getArrayTypeif size a arrayFactory size else a arrayFactory a _dtype basicTypes[index]return a
def sab_sanitize_foldername name CH_ILLEGAL '\\/<>?* "'CH_LEGAL '++{} @#`'FL_ILLEGAL CH_ILLEGAL + ' \x92"' FL_LEGAL CH_LEGAL + "-''" uFL_ILLEGAL FL_ILLEGAL decode 'latin-1' uFL_LEGAL FL_LEGAL decode 'latin-1' if not name return nameif isinstance name unicode illegal uFL_ILLEGALlegal uFL_LEGALelse illegal FL_ILLEGALlegal FL_LEGALlst []for ch in name strip if ch in illegal ch legal[illegal find ch ]lst append ch else lst append ch name '' join lst name name strip ' ' if not name name 'unknown'return name
def sab_sanitize_foldername name CH_ILLEGAL '\\/<>?* "'CH_LEGAL '++{} @#`'FL_ILLEGAL CH_ILLEGAL + ' \x92"' FL_LEGAL CH_LEGAL + "-''" uFL_ILLEGAL FL_ILLEGAL decode 'latin-1' uFL_LEGAL FL_LEGAL decode 'latin-1' if not name return nameif isinstance name unicode illegal uFL_ILLEGALlegal uFL_LEGALelse illegal FL_ILLEGALlegal FL_LEGALlst []for ch in name strip if ch in illegal ch legal[illegal find ch ]lst append ch else lst append ch name '' join lst name name strip ' ' if not name name 'unknown'return name
def finger_master hash_type None keyname 'master pub'if hash_type is None hash_type __opts__['hash_type']fingerprint salt utils pem_finger os path join __opts__['pki_dir'] keyname sum_type hash_type return {'local' {keyname fingerprint}}
def task_enable_docker_plugin distribution if is_systemd_distribution distribution return sequence [run_from_args ['systemctl' 'enable' 'flocker-docker-plugin'] run_from_args ['systemctl' START 'flocker-docker-plugin'] run_from_args ['systemctl' START 'docker'] ] elif is_ubuntu distribution return sequence [run_from_args ['service' 'flocker-docker-plugin' 'restart'] run_from_args ['service' 'docker' 'restart'] ] else raise DistributionNotSupported distribution distribution
def safe_to_snap client repository None retry_interval 120 retry_count 3 if not repository raise MissingArgument 'Novaluefor"repository"provided' for count in range 1 retry_count + 1 in_progress snapshot_in_progress client repository repository if in_progress logger info 'Snapshotalreadyinprogress {0}' format in_progress logger info 'Pausing{0}secondsbeforeretrying ' format retry_interval time sleep retry_interval logger info 'Retry{0}of{1}' format count retry_count else return Truereturn False
def make_colorscale colors scale None colorscale []if len colors < 2 raise exceptions PlotlyError 'Youmustinputalistofcolorsthathasatleasttwocolors ' if scale is None scale_incr 1 0 / len colors - 1 return [[ i * scale_incr color] for i color in enumerate colors ]else if len colors len scale raise exceptions PlotlyError 'Thelengthofcolorsandscalemustbethesame ' validate_scale_values scale colorscale [list tup for tup in zip scale colors ]return colorscale
def make_colorscale colors scale None colorscale []if len colors < 2 raise exceptions PlotlyError 'Youmustinputalistofcolorsthathasatleasttwocolors ' if scale is None scale_incr 1 0 / len colors - 1 return [[ i * scale_incr color] for i color in enumerate colors ]else if len colors len scale raise exceptions PlotlyError 'Thelengthofcolorsandscalemustbethesame ' validate_scale_values scale colorscale [list tup for tup in zip scale colors ]return colorscale
def make_colorscale colors scale None colorscale []if len colors < 2 raise exceptions PlotlyError 'Youmustinputalistofcolorsthathasatleasttwocolors ' if scale is None scale_incr 1 0 / len colors - 1 return [[ i * scale_incr color] for i color in enumerate colors ]else if len colors len scale raise exceptions PlotlyError 'Thelengthofcolorsandscalemustbethesame ' validate_scale_values scale colorscale [list tup for tup in zip scale colors ]return colorscale
def make_colorscale colors scale None colorscale []if len colors < 2 raise exceptions PlotlyError 'Youmustinputalistofcolorsthathasatleasttwocolors ' if scale is None scale_incr 1 0 / len colors - 1 return [[ i * scale_incr color] for i color in enumerate colors ]else if len colors len scale raise exceptions PlotlyError 'Thelengthofcolorsandscalemustbethesame ' validate_scale_values scale colorscale [list tup for tup in zip scale colors ]return colorscale
def translate_attributes op server_dict operation_kwargs auto_disk_config_raw server_dict pop API_DISK_CONFIG None if auto_disk_config_raw is not None auto_disk_config disk_config_from_api auto_disk_config_raw operation_kwargs['auto_disk_config'] auto_disk_configif API_ACCESS_V4 in server_dict operation_kwargs['access_ip_v4'] server_dict pop API_ACCESS_V4 if API_ACCESS_V6 in server_dict operation_kwargs['access_ip_v6'] server_dict pop API_ACCESS_V6 if 'preserve_ephemeral' in server_dict and op REBUILD preserve strutils bool_from_string server_dict pop 'preserve_ephemeral' strict True operation_kwargs['preserve_ephemeral'] preserveif 'personality' in server_dict if op REBUILD operation_kwargs['files_to_inject'] get_injected_files server_dict pop 'personality' if op CREATE operation_kwargs['injected_files'] get_injected_files server_dict pop 'personality' []
def primary_key_hash keys if isinstance keys[0] six text_type keys[0] keys[0] encode 'utf-8' return hashlib sha1 keys[0] hexdigest
def _is_url_dns urlstr url qurl_from_user_input urlstr assert url isValid if utils raises ValueError ipaddress ip_address urlstr and not QHostAddress urlstr isNull log url debug 'BogusIPURL->False' return Falsehost url host if not host log url debug 'URLhasnohost->False' return Falselog url debug 'DoingDNSrequestfor{}' format host info QHostInfo fromName host return not info error
def is_initialized cr cr execute "SELECTrelnameFROMpg_classWHERErelkind 'r'ANDrelname 'ir_module_module'" return len cr fetchall > 0
def confirm question default True if default suffix 'Y/n'else suffix 'y/N'while True response prompt '%s[%s]' % question suffix lower if not response return defaultif response in ['y' 'yes'] return Trueif response in ['n' 'no'] return Falseprint "Ididn'tunderstandyou Pleasespecify' y es'or' n o' "
def get_default_yarncluster global MR_NAME_CACHEtry return conf YARN_CLUSTERS[MR_NAME_CACHE]except KeyError return get_yarn
def getMaximumByPathComplex path maximum complex -999999999 0 -999999999 0 for point in path maximum getMaximum maximum point return maximum
def real_name magic_func magic_name magic_func __name__if magic_name startswith 'magic_' magic_name magic_name[len 'magic_' ]return getattr magic_func 'argcmd_name' magic_name
def delete_ikepolicy ikepolicy profile None conn _auth profile return conn delete_ikepolicy ikepolicy
def _get_auth_type entity id includes if 'user-tags' in includes or 'user-ratings' in includes return AUTH_YESelif entity startswith 'collection' if not id return AUTH_YESelse return AUTH_IFSETelse return AUTH_NO
def marker_comparator matches markers def comparator marker1 marker2 '\nTheactualcomparatorfunction \n'matches_count marker_weight matches marker2 - marker_weight matches marker1 if matches_count return matches_countlen_diff len marker2 - len marker1 if len_diff return len_diffreturn markers index marker2 - markers index marker1 return comparator
@LocalContextdef scramble raw_bytes *a **kw return encode raw_bytes force 1 *a **kw
@LocalContextdef scramble raw_bytes *a **kw return encode raw_bytes force 1 *a **kw
def regions return get_regions 'ses' connection_cls SESConnection
def _can_use_numexpr op op_str a b dtype_check if op_str is not None if np prod a shape > _MIN_ELEMENTS dtypes set for o in [a b] if hasattr o 'get_dtype_counts' s o get_dtype_counts if len s > 1 return Falsedtypes set s index elif isinstance o np ndarray dtypes set [o dtype name] if not len dtypes or _ALLOWED_DTYPES[dtype_check] > dtypes return Truereturn False
def get_stores ret dict cmd "Get-ChildItem-Path'Cert \\' Select-ObjectLocationName StoreNames"items _cmd_run cmd cmd as_json True for item in items ret[item['LocationName']] list for store in item['StoreNames'] ret[item['LocationName']] append store return ret
@pytest fixturedef admin_user default_groups user User username 'test_admin' email 'test_admin@example org' password 'test' primary_group default_groups[0] activated True user save return user
@login_requireddef unfollow request username template_name 'relationships/relationship_delete_confirm html' success_template_name 'relationships/relationship_delete_success html' content_type 'text/html' to_user get_object_or_404 User username username from_user request usernext request GET get 'next' None if request method 'POST' relationship get_object_or_404 Relationship to_user to_user from_user from_user relationship delete if request is_ajax response {'success' 'Success' 'to_user' {'username' to_user username 'user_id' to_user pk} 'from_user' {'username' from_user username 'user_id' from_user pk}}return HttpResponse json dumps response content_type 'application/json' if next return HttpResponseRedirect next template_name success_template_namecontext {'to_user' to_user 'next' next}return render_to_response template_name context context_instance RequestContext request content_type content_type
def get_hello return 'foo'
def get_hello return 'foo'
def get_hello return 'foo'
def nickname_commands *command_list def add_attribute function if not hasattr function u'rule' function rule []rule u'\n^\n$nickname[ ]?#Nickname \n\\s+ {command} #Commandasgroup1 \n ? \\s+#Whitespacetoendcommand \n #Restofthelineasgroup2 \n ? \\S+ ?#Parameters1-4asgroups3-6 \n ? \\s+ \\S+ ?\n ? \\s+ \\S+ ?\n ? \\s+ \\S+ ?\n *#Acceptanythingaftertheparameters Leaveitupto\n#themoduletoparsetheline \n ?#Group1mustbeNone iftherearenoparameters \n$#EoL sotherearenopartialmatches \n' format command u' ' join command_list function rule append rule return functionreturn add_attribute
def transform_ipynb_uri uri uri_rewrite_list for reg rewrite in uri_rewrite_list matches re match reg uri if matches return rewrite format *matches groups if '?' in uri uri query uri split '?' 1 uri '%s/%s' % uri quote '?' + query return uri
def transform_ipynb_uri uri uri_rewrite_list for reg rewrite in uri_rewrite_list matches re match reg uri if matches return rewrite format *matches groups if '?' in uri uri query uri split '?' 1 uri '%s/%s' % uri quote '?' + query return uri
def extract environ empty False err False formdata cgi parse environ['wsgi input'] environ empty err for key value in formdata iteritems if len value 1 formdata[key] value[0]return formdata
def getRadiusArealizedMultiplier sides return math sqrt globalTau / sides / math sin globalTau / sides
def periodic_tasks if mpstate status setup_mode returnif mpstate settings compdebug & 2 0 returnif mpstate settings heartbeat 0 heartbeat_period frequency mpstate settings heartbeatif heartbeat_period trigger and mpstate settings heartbeat 0 mpstate status counters['MasterOut'] + 1for master in mpstate mav_master send_heartbeat master if heartbeat_check_period trigger check_link_status set_stream_rates for m pm in mpstate modules if hasattr m 'idle_task' try m idle_task except Exception as msg if mpstate settings moddebug 1 print msgelif mpstate settings moddebug > 1 exc_type exc_value exc_traceback sys exc_info traceback print_exception exc_type exc_value exc_traceback limit 2 file sys stdout if m needs_unloading unload_module m name
def register_writer klass if not compat callable klass raise ValueError 'Canonlyregistercallablesasengines' engine_name klass engine_writers[engine_name] klassfor ext in klass supported_extensions if ext startswith ' ' ext ext[1 ]if ext not in _writer_extensions config register_option 'io excel %s writer' % ext engine_name validator str _writer_extensions append ext
def exists path use_sudo False verbose False func use_sudo and sudo or run cmd 'stat%s' % _expand_path path if verbose with settings warn_only True return not func cmd failed with settings hide 'everything' warn_only True return not func cmd failed
def exists path use_sudo False verbose False func use_sudo and sudo or run cmd 'stat%s' % _expand_path path if verbose with settings warn_only True return not func cmd failed with settings hide 'everything' warn_only True return not func cmd failed
def trg_trigger uid res_type res_id cr return WorkflowService new cr uid res_type res_id trigger
def _overrideFunc v t return 'OVERRIDDEN'
def send_notification request notification backends getattr settings 'NOTIFICATION_BACKENDS' [] for cls_name in backends backend import_string cls_name request backend send notification
def ExpandWindowsEnvironmentVariables data_string knowledge_base win_environ_regex re compile '% [^%]+? %' components []offset 0for match in win_environ_regex finditer data_string components append data_string[offset match start ] kb_value getattr knowledge_base 'environ_%s' % match group 1 lower None if isinstance kb_value basestring and kb_value components append kb_value else components append '%%%s%%' % match group 1 offset match end components append data_string[offset ] return '' join components
def get_violations_reports violations_type violations_files []for subdir _dirs files in os walk os path join Env REPORT_DIR for f in files if f '{violations_type} report' format violations_type violations_type violations_files append os path join subdir f return violations_files
def normalize data nfkc True if nfkc data unicodedata normalize u'NFKC' data return data
def getStartsWithCurlyEqualRoundSquare word return word startswith '{' or word startswith ' ' or word startswith ' ' or word startswith '['
@library global_functiondef static path try return django_static path except ValueError as err log error 'Statichelpererror %s' % err return ''
def _get_possible_outcomes m bits size max m shape nqubits int math log size 2 + 0 1 output_matrices []for i in range 1 << len bits output_matrices append zeros 2 ** nqubits 1 bit_masks []for bit in bits bit_masks append 1 << bit for i in range 2 ** nqubits trueness 0for j in range len bit_masks if i & bit_masks[j] trueness + j + 1 output_matrices[trueness][i] m[i]return output_matrices
def _get_possible_outcomes m bits size max m shape nqubits int math log size 2 + 0 1 output_matrices []for i in range 1 << len bits output_matrices append zeros 2 ** nqubits 1 bit_masks []for bit in bits bit_masks append 1 << bit for i in range 2 ** nqubits trueness 0for j in range len bit_masks if i & bit_masks[j] trueness + j + 1 output_matrices[trueness][i] m[i]return output_matrices
def _get_possible_outcomes m bits size max m shape nqubits int math log size 2 + 0 1 output_matrices []for i in range 1 << len bits output_matrices append zeros 2 ** nqubits 1 bit_masks []for bit in bits bit_masks append 1 << bit for i in range 2 ** nqubits trueness 0for j in range len bit_masks if i & bit_masks[j] trueness + j + 1 output_matrices[trueness][i] m[i]return output_matrices
def _get_string buff start_idx str_data ''next_idx start_idx + 1 got_end Falsefor c in buff[start_idx ] if ord c 0 got_end Truebreakstr_data + cnext_idx + 1if not got_end raise InvalidStringException return str_data next_idx
def group name None **attrs attrs setdefault 'cls' Group return command name **attrs
def _remove_async_tag_url question_id return reverse 'questions remove_tag_async' kwargs {'question_id' question_id}
def _remove_async_tag_url question_id return reverse 'questions remove_tag_async' kwargs {'question_id' question_id}
def check_forhash filename if isinstance filename list filename filename[0] path name os path split filename if re search u' _0x[a-z0-9]{32} ' name hashvalue re findall u' _0x[a-z0-9]{32} ' name return True hashvalue else return False None
@ensure_csrf_cookie@login_requireddef export_git request course_key_string course_key CourseKey from_string course_key_string if not has_course_author_access request user course_key raise PermissionDenied course_module modulestore get_course course_key failed Falselog debug 'export_gitcourse_module %s' course_module msg ''if 'action' in request GET and course_module giturl if request GET['action'] 'push' try git_export_utils export_to_git course_module id course_module giturl request user msg _ 'Coursesuccessfullyexportedtogitrepository' except git_export_utils GitExportError as ex failed Truemsg unicode ex return render_to_response 'export_git html' {'context_course' course_module 'msg' msg 'failed' failed}
def has_value key return True if salt utils traverse_dict_and_list __grains__ key False else False
def has_value key return True if salt utils traverse_dict_and_list __grains__ key False else False
def loadMimeTypes mimetype_locations None init mimetypes init init mimetype_locations mimetypes types_map update {' conf' 'text/plain' ' diff' 'text/plain' ' flac' 'audio/x-flac' ' java' 'text/plain' ' oz' 'text/x-oz' ' swf' 'application/x-shockwave-flash' ' wml' 'text/vnd wap wml' ' xul' 'application/vnd mozilla xul+xml' ' patch' 'text/plain'} return mimetypes types_map
def _get_value context key if isinstance context dict if key in context return context[key]elif type context __module__ _BUILTIN_MODULE try attr getattr context key except AttributeError passelse if callable attr return attr return attrreturn _NOT_FOUND
def getdoc object try doc object __doc__except AttributeError return Noneif not isinstance doc types StringTypes return Nonereturn cleandoc doc
def getHitmask image mask []for x in range image get_width mask append [] for y in range image get_height mask[x] append bool image get_at x y [3] return mask
def get_system_packs_base_path return cfg CONF content system_packs_base_path
def test_column_named_items class ItemsTable tables Table items tables Column table ItemsTable [{u'items' 123} {u'items' 2345}] html table as_html request assert u'123' in html assert u'2345' in html
def test_column_named_items class ItemsTable tables Table items tables Column table ItemsTable [{u'items' 123} {u'items' 2345}] html table as_html request assert u'123' in html assert u'2345' in html
def test_column_named_items class ItemsTable tables Table items tables Column table ItemsTable [{u'items' 123} {u'items' 2345}] html table as_html request assert u'123' in html assert u'2345' in html
def add_flex_arithmetic_methods cls flex_arith_method flex_comp_method None flex_bool_method None use_numexpr True force False select None exclude None new_methods _create_methods flex_arith_method flex_comp_method flex_bool_method use_numexpr default_axis 'columns' special False new_methods update dict multiply new_methods['mul'] subtract new_methods['sub'] divide new_methods['div'] for k in 'ror_' 'rxor' 'rand_' if k in new_methods new_methods pop k add_methods cls new_methods new_methods force force select select exclude exclude
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field source in validated_data and isinstance validated_data[field source] list dict for field in serializer _writable_fields u'The` {method_name} `methoddoesnotsupportwritablenestedfieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`onnestedserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__ assert not any u' ' in field source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer fields items u'The` {method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`ondotted-sourceserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field source in validated_data and isinstance validated_data[field source] list dict for field in serializer _writable_fields u'The` {method_name} `methoddoesnotsupportwritablenestedfieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`onnestedserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__ assert not any u' ' in field source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer fields items u'The` {method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`ondotted-sourceserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field source in validated_data and isinstance validated_data[field source] list dict for field in serializer _writable_fields u'The` {method_name} `methoddoesnotsupportwritablenestedfieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`onnestedserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__ assert not any u' ' in field source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer fields items u'The` {method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`ondotted-sourceserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field source in validated_data and isinstance validated_data[field source] list dict for field in serializer _writable_fields u'The` {method_name} `methoddoesnotsupportwritablenestedfieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`onnestedserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__ assert not any u' ' in field source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer fields items u'The` {method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`ondotted-sourceserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__
def raise_errors_on_nested_writes method_name serializer validated_data assert not any isinstance field BaseSerializer and field source in validated_data and isinstance validated_data[field source] list dict for field in serializer _writable_fields u'The` {method_name} `methoddoesnotsupportwritablenestedfieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`onnestedserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__ assert not any u' ' in field source and key in validated_data and isinstance validated_data[key] list dict for key field in serializer fields items u'The` {method_name} `methoddoesnotsupportwritabledotted-sourcefieldsbydefault \nWriteanexplicit` {method_name} `methodforserializer`{module} {class_name}` orset`read_only True`ondotted-sourceserializerfields ' format method_name method_name module serializer __class__ __module__ class_name serializer __class__ __name__
def ndeepmap n func seq if n 1 return [func item for item in seq]elif n > 1 return [ndeepmap n - 1 func item for item in seq]else return func seq
def getRemovedFloat defaultFloat elementNode key prefix prefixKey prefix + key if prefixKey in elementNode attributes floatValue evaluate getEvaluatedFloat None elementNode prefixKey if floatValue None print 'Warning evaluatedvalueingetRemovedFloatByKeysinmatrixisNoneforkey 'print prefixKeyprint 'forelementNodedictionaryvalue 'print elementNode attributes[prefixKey]print 'forelementNodedictionary 'print elementNode attributeselse defaultFloat floatValuedel elementNode attributes[prefixKey]return defaultFloat
@deprecated u'2 1' def allpairs x return [ s f for i f in enumerate x for s in x[ i + 1 ]]
def clean_global_runtime_state reset_runtracker True reset_subsystem False if reset_runtracker RunTracker global_instance reset reset_options False if reset_subsystem Subsystem reset IntermediateTargetFactoryBase reset Goal clear OptionsInitializer reset
def format_call func args None kwargs None full True if full name utils qualname func else name func __name__return '{} {} ' format name format_args args kwargs
@decorators api_view ['GET'] @decorators permission_classes permissions AllowAny @decorators renderer_classes JSONRenderer def cname request host request GET get 'host' if not host return Response {'error' 'hostGETargrequired'} status status HTTP_400_BAD_REQUEST host clean_url host slug cname_to_slug host return Response {'host' host 'slug' slug}
def args task if istask task return task[1 ]elif isinstance task list return taskelse return
def write_stream stream outfile flush try buf outfile bufferexcept AttributeError buf outfilefor chunk in stream buf write chunk if flush outfile flush
def sum_of_squares n k zeros False for t in power_representation n 2 k zeros yield t
def get_or_create_anonymous_cart_from_token token cart_queryset Cart objects all return cart_queryset open filter token token user None get_or_create defaults {u'user' None} [0]
def debug msg level 1 log msg logging DEBUG + 1 - level
@taskdef rabbitmq ctx ctx run 'rabbitmq-server' pty True
def add_deprecated_argument add_argument argument_name nargs class ShowWarning argparse Action 'Actiontologawarningwhenanargumentisused 'def __call__ self unused1 unused2 unused3 option_string None sys stderr write 'Useof{0}isdeprecated \n' format option_string configargparse ACTION_TYPES_THAT_DONT_NEED_A_VALUE add ShowWarning add_argument argument_name action ShowWarning help argparse SUPPRESS nargs nargs
def rm_rf name if not os path exists name returntry shutil rmtree name except OSError as e if e errno errno ENOTDIR safe_delete name elif e errno errno ENOENT raise
def rm_rf name if not os path exists name returntry shutil rmtree name except OSError as e if e errno errno ENOTDIR safe_delete name elif e errno errno ENOENT raise
def rm_rf name if not os path exists name returntry shutil rmtree name except OSError as e if e errno errno ENOTDIR safe_delete name elif e errno errno ENOENT raise
def rm_rf name if not os path exists name returntry shutil rmtree name except OSError as e if e errno errno ENOTDIR safe_delete name elif e errno errno ENOENT raise
def jenkins_result_from_api result if result is None return JenkinsResults RUNNINGelif result in ['FAILURE' 'ABORTED'] return JenkinsResults FAILEDelif result 'SUCCESS' return JenkinsResults PASSEDelse raise AssertionError "Don'tknowhowtohandleJenkinsresult{}" format result
def require_global_staff func @wraps func def wrapped request *args **kwargs if GlobalStaff has_user request user return func request *args **kwargs else return HttpResponseForbidden u'Mustbe{platform_name}stafftoperformthisaction ' format platform_name settings PLATFORM_NAME return login_required wrapped
def require_global_staff func @wraps func def wrapped request *args **kwargs if GlobalStaff has_user request user return func request *args **kwargs else return HttpResponseForbidden u'Mustbe{platform_name}stafftoperformthisaction ' format platform_name settings PLATFORM_NAME return login_required wrapped
def evaluate_quadratic J g s diag None if s ndim 1 Js J dot s q np dot Js Js if diag is not None q + np dot s * diag s else Js J dot s T q np sum Js ** 2 axis 0 if diag is not None q + np sum diag * s ** 2 axis 1 l np dot s g return 0 5 * q + l
def evaluate_quadratic J g s diag None if s ndim 1 Js J dot s q np dot Js Js if diag is not None q + np dot s * diag s else Js J dot s T q np sum Js ** 2 axis 0 if diag is not None q + np sum diag * s ** 2 axis 1 l np dot s g return 0 5 * q + l
def _effective_debug_level ctx bundle extra_filters None default None if default is None default ctx environment debugif bundle config get 'debug' is not None level bundle config debugelse filters merge_filters bundle filters extra_filters level 'merge' if select_filters filters True else None if level is not None if cmp_debug_levels default level > 0 return levelreturn default
def modpythonHandler request from mod_python import apacheconfig_path request get_options get 'config' 'tilestache cfg' config_path realpath pathjoin dirname request filename config_path path_info request path_infoquery_string request args mimetype content requestHandler config_path path_info query_string request status apache HTTP_OKrequest content_type mimetyperequest set_content_length len content request send_http_header request write content return apache OK
def _check_numpy_unicode_bug labels if np_version[ 3] < 1 7 0 and labels dtype kind 'U' raise RuntimeError 'NumPy<1 7 0doesnotimplementsearchsortedonunicodedatacorrectly PleaseupgradeNumPytouseLabelEncoderwithunicodeinputs '
def create_generic_db jobs_dir dataset_id stage if jobs_dir 'none' jobs_dir digits config config_value 'jobs_dir' dataset_dir os path join jobs_dir dataset_id if not os path isdir dataset_dir raise IOError 'Datasetdir%sdoesnotexist' % dataset_dir dataset Job load dataset_dir extension_id dataset extension_idextension_class extensions data get_extension extension_id extension extension_class **dataset extension_userdata feature_encoding dataset feature_encodinglabel_encoding dataset label_encodingbatch_size dataset batch_sizenum_threads dataset num_threadsforce_same_shape dataset force_same_shapedb_creator DbCreator db_creator create_db extension stage dataset_dir batch_size num_threads feature_encoding label_encoding force_same_shape logger info 'GenericDBcreationDone'
def _sc_decode soundcheck if isinstance soundcheck six text_type soundcheck soundcheck encode 'utf-8' try soundcheck codecs decode soundcheck replace '' '' 'hex' soundcheck struct unpack ' iiiiiiiiii' soundcheck except struct error TypeError binascii Error return 0 0 0 0 maxgain max soundcheck[ 2] if maxgain > 0 gain math log10 maxgain / 1000 0 * -10 else gain 0 0peak max soundcheck[6 8] / 32768 0 return round gain 2 round peak 6
def str_join arr sep return _na_map sep join arr
def disable_root_login sshd_config '/etc/ssh/sshd_config' _update_ssh_setting sshd_config 'PermitRootLogin' 'no'
def disable_root_login sshd_config '/etc/ssh/sshd_config' _update_ssh_setting sshd_config 'PermitRootLogin' 'no'
def do_send_confirmation_email invitee referrer subject_template_path 'confirmation/invite_email_subject txt'body_template_path 'confirmation/invite_email_body txt'context {'referrer' referrer 'support_email' settings ZULIP_ADMINISTRATOR 'verbose_support_offers' settings VERBOSE_SUPPORT_OFFERS}if referrer realm is_zephyr_mirror_realm subject_template_path 'confirmation/mituser_invite_email_subject txt'body_template_path 'confirmation/mituser_invite_email_body txt'Confirmation objects send_confirmation invitee invitee email additional_context context subject_template_path subject_template_path body_template_path body_template_path host referrer realm host
@app template_filter 'as_timezone' def as_timezone dt tzname if tzname and timezone tzname return dt astimezone timezone tzname return dt
def get_current_theme request None if _current_theme_class is not _not_set if _current_theme_class return _current_theme_class return Nonevalue cache get THEME_CACHE_KEY if value return valueif request and hasattr request '_current_xtheme' return request _current_xthemetheme _get_current_theme if request request _current_xtheme themecache set THEME_CACHE_KEY theme return theme
def to_encodable_string obj encoding if isinstance obj DataToken obj obj get_value if isinstance obj unicode obj obj encode encoding errors 'ignore' else obj str obj return obj
def to_encodable_string obj encoding if isinstance obj DataToken obj obj get_value if isinstance obj unicode obj obj encode encoding errors 'ignore' else obj str obj return obj
def to_encodable_string obj encoding if isinstance obj DataToken obj obj get_value if isinstance obj unicode obj obj encode encoding errors 'ignore' else obj str obj return obj
def _mult_cal_one data_view one idx cals mult one np asarray one dtype data_view dtype assert data_view shape[1] one shape[1] if mult is not None data_view[ ] np dot mult one else if isinstance idx slice data_view[ ] one[idx]else np take one idx axis 0 out data_view if cals is not None data_view * cals
def revert_strip_none data if isinstance data str and data strip '~' return Noneif isinstance data list data2 []for x in data data2 append revert_strip_none x return data2if isinstance data dict data2 {}for key in data keys data2[key] revert_strip_none data[key] return data2return data
def _net_read sock count expiration s ''while count > 0 _wait_for_readable sock expiration n sock recv count if n '' raise EOFErrorcount count - len n s s + n return s
def datetime_from_iso8601 datetime_str return aniso8601 parse_datetime datetime_str
def conflicting_single_link scheme link if link sink_channel single existing scheme find_links sink_node link sink_node sink_channel link sink_channel if existing assert len existing 1 return existing[0]return None
def conflicting_single_link scheme link if link sink_channel single existing scheme find_links sink_node link sink_node sink_channel link sink_channel if existing assert len existing 1 return existing[0]return None
@when u'wecreatetable' def step_create_table context context cli sendline u'createtablea xtext '
def videos_index_html course return render_to_response 'videos_index html' {'context_course' course 'video_handler_url' reverse_course_url 'videos_handler' unicode course id 'encodings_download_url' reverse_course_url 'video_encodings_download' unicode course id 'previous_uploads' _get_index_videos course 'concurrent_upload_limit' settings VIDEO_UPLOAD_PIPELINE get 'CONCURRENT_UPLOAD_LIMIT' 0 'video_supported_file_formats' VIDEO_SUPPORTED_FILE_FORMATS keys 'video_upload_max_file_size' VIDEO_UPLOAD_MAX_FILE_SIZE_GB}
def videos_index_html course return render_to_response 'videos_index html' {'context_course' course 'video_handler_url' reverse_course_url 'videos_handler' unicode course id 'encodings_download_url' reverse_course_url 'video_encodings_download' unicode course id 'previous_uploads' _get_index_videos course 'concurrent_upload_limit' settings VIDEO_UPLOAD_PIPELINE get 'CONCURRENT_UPLOAD_LIMIT' 0 'video_supported_file_formats' VIDEO_SUPPORTED_FILE_FORMATS keys 'video_upload_max_file_size' VIDEO_UPLOAD_MAX_FILE_SIZE_GB}
def videos_index_html course return render_to_response 'videos_index html' {'context_course' course 'video_handler_url' reverse_course_url 'videos_handler' unicode course id 'encodings_download_url' reverse_course_url 'video_encodings_download' unicode course id 'previous_uploads' _get_index_videos course 'concurrent_upload_limit' settings VIDEO_UPLOAD_PIPELINE get 'CONCURRENT_UPLOAD_LIMIT' 0 'video_supported_file_formats' VIDEO_SUPPORTED_FILE_FORMATS keys 'video_upload_max_file_size' VIDEO_UPLOAD_MAX_FILE_SIZE_GB}
def get_net_size mask binary_str ''for octet in mask split ' ' binary_str + bin int octet [2 ] zfill 8 return len binary_str rstrip '0'
def get_wanna_help_queue_from_session session ret []for project_id in session get PROJECTS_TO_HELP_OUT_KEY [] try project mysite search models Project objects get id project_id except mysite search models Project DoesNotExist continueret append project ret list set ret return ret
def comparePortionDirection portionDirection otherPortionDirection if portionDirection portion > otherPortionDirection portion return 1if portionDirection portion < otherPortionDirection portion return -1 if portionDirection directionReversed < otherPortionDirection directionReversed return -1 return portionDirection directionReversed > otherPortionDirection directionReversed
@pytest fixturedef clear_cache from django core cache import cachesfrom django_redis import get_redis_connectionget_redis_connection 'default' flushdb caches['exports'] clear
def mksalt method None if method is None method methods[0]s '${}$' format method ident if method ident else '' s + '' join _sr choice _saltchars for char in range method salt_chars return s
def device_extents devmem s drvapi cu_device_ptr n c_size_t devptr device_ctypes_pointer devmem driver cuMemGetAddressRange byref s byref n devptr s n s value n value return s s + n
def _process_mass_form f def wrap request *args **kwargs 'Wrap'user request user profileif 'massform' in request POST for key in request POST if 'mass-report' in key try report Report objects get pk request POST[key] form MassActionForm user request POST instance report if form is_valid and user has_permission report mode 'w' form save except Exception passreturn f request *args **kwargs wrap __doc__ f __doc__wrap __name__ f __name__return wrap
def define_xml_str xml conn __get_conn return conn defineXML xml is not None
def vmstat vm_stat ['vmstatus ']vm_stat + utils system_output 'vmstat' verbose False splitlines vm_stat + ['\n']return vm_stat
def main run_wsgi_app wsgiapp
def threadsafe function lock threading RLock def decorator *args **kwargs with lock v function *args **kwargs return vreturn decorator
def threadsafe function lock threading RLock def decorator *args **kwargs with lock v function *args **kwargs return vreturn decorator
def threadsafe function lock threading RLock def decorator *args **kwargs with lock v function *args **kwargs return vreturn decorator
def coerce_types **kwargs def _coerce types return coerce *types return preprocess **valmap _coerce kwargs
def coerce_types **kwargs def _coerce types return coerce *types return preprocess **valmap _coerce kwargs
def GDataEntryFromString xml_string return atom CreateClassFromXMLString GDataEntry xml_string
def relative_symlink source_path link_path if not os path isabs source_path raise ValueError u'Pathforsource {}mustbeabsolute' format source_path if not os path isabs link_path raise ValueError u'Pathforlink {}mustbeabsolute' format link_path if source_path link_path raise ValueError u'Pathforlinkisidenticaltosource {}' format source_path if os path isdir link_path and not os path islink link_path raise ValueError u'Pathforlinkwouldoverwriteanexistingdirectory {}' format link_path try if os path lexists link_path os unlink link_path rel_path os path relpath source_path os path dirname link_path os symlink rel_path link_path except OSError as e if not e errno errno EEXIST or e errno errno ENOENT raise
@world absorbdef css_has_value css_selector value index 0 if value wait_for lambda _ css_value css_selector index index return css_value css_selector index index value
@world absorbdef css_has_value css_selector value index 0 if value wait_for lambda _ css_value css_selector index index return css_value css_selector index index value
def change_minion_cachedir minion_id cachedir data None base None if not isinstance data dict return Falseif base is None base __opts__['cachedir']fname '{0} p' format minion_id path os path join base cachedir fname with salt utils fopen path 'r' as fh_ cache_data msgpack load fh_ cache_data update data with salt utils fopen path 'w' as fh_ msgpack dump cache_data fh_
def change_minion_cachedir minion_id cachedir data None base None if not isinstance data dict return Falseif base is None base __opts__['cachedir']fname '{0} p' format minion_id path os path join base cachedir fname with salt utils fopen path 'r' as fh_ cache_data msgpack load fh_ cache_data update data with salt utils fopen path 'w' as fh_ msgpack dump cache_data fh_
def command from fabtools require deb import package as require_deb_packagefrom fabtools require rpm import package as require_rpm_packagefrom fabtools require portage import package as require_portage_packageres run 'hg--version' quiet True if res failed family distrib_family if family 'debian' require_deb_package 'mercurial' elif family 'gentoo' require_portage_package 'mercurial' elif family 'redhat' require_rpm_package 'mercurial' else raise UnsupportedFamily supported ['debian' 'redhat' 'gentoo']
def match_dhcp_options vpc_conn tags None options None dhcp_options vpc_conn get_all_dhcp_options for dopts in dhcp_options if not tags or get_resource_tags vpc_conn dopts id tags if not options or dopts options options return True dopts return False None
def update backend None fileserver salt fileserver Fileserver __opts__ fileserver update back backend return True
def kegg_link target_db source_db option None if option and option not in ['turtle' 'n-triple'] raise Exception 'Invalidoptionargforkeggconvrequest ' if isinstance source_db list source_db '+' join source_db if option resp _q 'link' target_db source_db option else resp _q 'link' target_db source_db return resp
def hello6 response flash 'HelloWorldinaflash 'return dict message T 'HelloWorld'
def datetime2epoch dt if dt is not None return calendar timegm dt utctimetuple
def fetch_requirements requirements_file_path links []reqs []for req in parse_requirements requirements_file_path session False if req link links append str req link reqs append str req req return reqs links
def robot registry xml_parent data parent XML SubElement xml_parent 'hudson plugins robot RobotPublisher' parent set 'plugin' 'robot' mappings [ 'output-path' 'outputPath' None 'log-file-link' 'logFileLink' '' 'report-html' 'reportFileName' 'report html' 'log-html' 'logFileName' 'log html' 'output-xml' 'outputFileName' 'output xml' 'pass-threshold' 'passThreshold' '0 0' 'unstable-threshold' 'unstableThreshold' '0 0' 'only-critical' 'onlyCritical' True 'enable-cache' 'enableCache' True ]helpers convert_mapping_to_xml parent data mappings fail_required True other_files XML SubElement parent 'otherFiles' for other_file in data get 'other-files' [] XML SubElement other_files 'string' text str other_file XML SubElement parent 'disableArchiveOutput' text str not data get 'archive-output-xml' True lower
def nopackage pkg_name options None if is_installed pkg_name uninstall pkg_name options
def as_vec4 obj default 0 0 0 1 obj np atleast_2d obj if obj shape[ -1 ] < 4 new np empty obj shape[ -1 ] + 4 dtype obj dtype new[ ] defaultnew[ obj shape[ -1 ]] objobj newelif obj shape[ -1 ] > 4 raise TypeError 'Arrayshape%scannotbeconvertedtovec4' % obj shape return obj
def reset_worker_optimizations global trace_task_rettrace_task_ret _trace_task_rettry delattr BaseTask u'_stackprotected' except AttributeError passtry BaseTask __call__ _patched pop u'BaseTask __call__' except KeyError passfrom celery worker import request as request_modulerequest_module trace_task_ret _trace_task_ret
def is_standard return 'DESKTOP_LAUNCH' in os environ
def is_standard return 'DESKTOP_LAUNCH' in os environ
@register_jitabledef _select arry k low high i _partition arry low high while i k if i < k low i + 1 i _partition arry low high else high i - 1 i _partition arry low high return arry[k]
def helmert n full False H np tril np ones n n -1 - np diag np arange n d np arange n * np arange 1 n + 1 H[0] 1d[0] nH_full H / np sqrt d [ np newaxis] if full return H_fullelse return H_full[1 ]
def _get_slogdet_diag_walker a if isinstance a dtype types Complex @register_jitabledef cmplx_diag_walker n a sgn csgn sgn + 0j acc 0 0for k in range n absel np abs a[ k k ] csgn csgn * a[ k k ] / absel acc acc + np log absel return csgn acc return cmplx_diag_walkerelse @register_jitabledef real_diag_walker n a sgn acc 0 0for k in range n v a[ k k ]if v < 0 0 sgn - sgn v - v acc acc + np log v return sgn + 0 0 acc return real_diag_walker
def choose n k if 0 < k < n ntok ktok 1 1 for t in range 1 min k n - k + 1 ntok * nktok * tn - 1return ntok // ktok else return 0
def get_service hass config discovery_info None import boto3aws_config config copy del aws_config[CONF_PLATFORM]del aws_config[CONF_NAME]profile aws_config get CONF_PROFILE_NAME if profile is not None boto3 setup_default_session profile_name profile del aws_config[CONF_PROFILE_NAME]sns_client boto3 client 'sns' **aws_config return AWSSNS sns_client
def user_absent name channel 14 **kwargs ret {'name' name 'result' False 'comment' '' 'changes' {}}user_id_list __salt__['ipmi get_name_uids'] name channel **kwargs if len user_id_list 0 ret['result'] Trueret['comment'] 'useralreadyabsent'return retif __opts__['test'] ret['comment'] 'woulddeleteuser s 'ret['result'] Noneret['changes'] {'delete' user_id_list}return retfor uid in user_id_list __salt__['ipmi delete_user'] uid channel **kwargs ret['comment'] 'user s removed'ret['changes'] {'old' user_id_list 'new' 'None'}return ret
def user_absent name channel 14 **kwargs ret {'name' name 'result' False 'comment' '' 'changes' {}}user_id_list __salt__['ipmi get_name_uids'] name channel **kwargs if len user_id_list 0 ret['result'] Trueret['comment'] 'useralreadyabsent'return retif __opts__['test'] ret['comment'] 'woulddeleteuser s 'ret['result'] Noneret['changes'] {'delete' user_id_list}return retfor uid in user_id_list __salt__['ipmi delete_user'] uid channel **kwargs ret['comment'] 'user s removed'ret['changes'] {'old' user_id_list 'new' 'None'}return ret
def IS_CHARACTER_JUNK ch ws ' DCTB ' return ch in ws
@dog_stats_api timed 'edxapp heartbeat' def heartbeat request try output modulestore heartbeat except HeartbeatFailure as fail return JsonResponse {fail service unicode fail } status 503 cursor connection cursor try cursor execute 'SELECTCURRENT_DATE' cursor fetchone output['SQL'] Trueexcept DatabaseError as fail return JsonResponse {'SQL' unicode fail } status 503 return JsonResponse output
@dog_stats_api timed 'edxapp heartbeat' def heartbeat request try output modulestore heartbeat except HeartbeatFailure as fail return JsonResponse {fail service unicode fail } status 503 cursor connection cursor try cursor execute 'SELECTCURRENT_DATE' cursor fetchone output['SQL'] Trueexcept DatabaseError as fail return JsonResponse {'SQL' unicode fail } status 503 return JsonResponse output
def create_operation arg1 operator arg2 if operator not in OPERATORS raise OperatorCreationError 'unknownoperator"{0}"' format operator opfunc OPERATORS[operator]if opfunc in is_null is_not_null return opfunc arg1 if arg2 is None message 'TocompareavaluetoNULL usetheunaryis_null/is_not_nulloperators 'raise OperatorCreationError message if arg2 is NO_ARGUMENT msg 'expectedanargumentforthisoperatorbutnonewasgiven'raise OperatorCreationError msg return opfunc arg1 arg2
def reinit global _initialized _loaded_packages_initialized Falsedel _loaded_packages[ ]REGISTERED_TYPES clear _init
def assign_regions resource for i in range 0 randint 0 5 random_index randint 0 Region objects all count - 1 region Region objects all [random_index]resource regions add region
def assign_regions resource for i in range 0 randint 0 5 random_index randint 0 Region objects all count - 1 region Region objects all [random_index]resource regions add region
@profiler tracedef policy_create request **kwargs body {'firewall_policy' kwargs}policy neutronclient request create_firewall_policy body get 'firewall_policy' return Policy policy
@receiver score_reset def submissions_score_reset_handler sender **kwargs course_id kwargs['course_id']usage_id kwargs['item_id']user user_by_anonymous_id kwargs['anonymous_user_id'] if user is None returnPROBLEM_WEIGHTED_SCORE_CHANGED send sender None weighted_earned 0 weighted_possible 0 user_id user id anonymous_user_id kwargs['anonymous_user_id'] course_id course_id usage_id usage_id modified kwargs['created_at'] score_db_table ScoreDatabaseTableEnum submissions
@receiver score_reset def submissions_score_reset_handler sender **kwargs course_id kwargs['course_id']usage_id kwargs['item_id']user user_by_anonymous_id kwargs['anonymous_user_id'] if user is None returnPROBLEM_WEIGHTED_SCORE_CHANGED send sender None weighted_earned 0 weighted_possible 0 user_id user id anonymous_user_id kwargs['anonymous_user_id'] course_id course_id usage_id usage_id modified kwargs['created_at'] score_db_table ScoreDatabaseTableEnum submissions
@contextlib contextmanagerdef indent_log num 2 _log_state indentation + numtry yield finally _log_state indentation - num
@contextlib contextmanagerdef indent_log num 2 _log_state indentation + numtry yield finally _log_state indentation - num
@contextlib contextmanagerdef indent_log num 2 _log_state indentation + numtry yield finally _log_state indentation - num
def list_datasets project None bigquery_client bigquery Client project project for dataset in bigquery_client list_datasets print dataset name
@task base PersistOnFailureTask default_retry_delay 30 routing_key settings RECALCULATE_GRADES_ROUTING_KEY def recalculate_subsection_grade_v2 **kwargs _recalculate_subsection_grade recalculate_subsection_grade_v2 **kwargs
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME api_key config get CONF_API_KEY base config get CONF_BASE quote config get CONF_QUOTE parameters {'base' base 'app_id' api_key}rest OpenexchangeratesData _RESOURCE parameters quote response requests get _RESOURCE params parameters timeout 10 if response status_code 200 _LOGGER error 'CheckyourOpenExchangeRatesAPIkey' return Falserest update add_devices [OpenexchangeratesSensor rest name quote ]
@utils arg 'server' metavar '<server>' help _ 'NameorIDofserver ' @utils arg 'name' metavar '<name>' help _ 'Nameofthebackupimage ' @utils arg 'backup_type' metavar '<backup-type>' help _ 'Thebackuptype like"daily"or"weekly" ' @utils arg 'rotation' metavar '<rotation>' help _ 'Intparameterrepresentinghowmanybackupstokeeparound ' def do_backup cs args _find_server cs args server backup args name args backup_type args rotation
def submit_jobs filenames verbose False if not which 'qsub' raise ApplicationNotFoundError "qsubnotfound Can'tsubmitjobs " for file in filenames command 'qsub%s' % file result Popen command shell True universal_newlines True stdout PIPE stderr STDOUT stdout read if verbose print result
@register tagdef highlight parser token bits token split_contents tag_name bits[0]if not len bits % 2 0 raise template TemplateSyntaxError u"'%s'tagrequiresvalidpairingsarguments " % tag_name text_block bits[1]if len bits < 4 raise template TemplateSyntaxError u"'%s'tagrequiresanobjectandaqueryprovidedby'with' " % tag_name if bits[2] u'with' raise template TemplateSyntaxError u"'%s'tag'ssecondargumentshouldbe'with' " % tag_name query bits[3]arg_bits iter bits[4 ] kwargs {}for bit in arg_bits if bit u'css_class' kwargs[u'css_class'] six next arg_bits if bit u'html_tag' kwargs[u'html_tag'] six next arg_bits if bit u'max_length' kwargs[u'max_length'] six next arg_bits return HighlightNode text_block query **kwargs
def nodejs_installator registry xml_parent data npm_node XML SubElement xml_parent 'jenkins plugins nodejs tools NpmPackagesBuildWrapper' try XML SubElement npm_node 'nodeJSInstallationName' text data['name']except KeyError as e raise MissingAttributeError e args[0]
def nodejs_installator registry xml_parent data npm_node XML SubElement xml_parent 'jenkins plugins nodejs tools NpmPackagesBuildWrapper' try XML SubElement npm_node 'nodeJSInstallationName' text data['name']except KeyError as e raise MissingAttributeError e args[0]
@register tag name 'include_raw' def do_include_raw parser token bits token split_contents if len bits 2 raise template TemplateSyntaxError '%rtagtakesoneargument thenameofthetemplatetobeincluded' % bits[0] template_name bits[1]if template_name[0] in '"' "'" and template_name[ -1 ] template_name[0] template_name template_name[1 -1 ] source __ get_template_source template_name return template base TextNode source
def hipchat registry xml_parent data hipchat XML SubElement xml_parent 'jenkins plugins hipchat HipChatNotifier' XML SubElement hipchat 'token' text str data get 'token' '' if 'rooms' in data XML SubElement hipchat 'room' text str ' ' join data['rooms'] mapping [ 'notify-start' 'startNotification' False 'notify-success' 'notifySuccess' False 'notify-aborted' 'notifyAborted' False 'notify-not-built' 'notifyNotBuilt' False 'notify-unstable' 'notifyUnstable' False 'notify-failure' 'notifyFailure' False 'notify-back-to-normal' 'notifyBackToNormal' False ]helpers convert_mapping_to_xml hipchat data mapping fail_required True if 'start-message' in data XML SubElement hipchat 'startJobMessage' text str data['start-message'] if 'complete-message' in data XML SubElement hipchat 'completeJobMessage' text str data['complete-message']
def hipchat registry xml_parent data hipchat XML SubElement xml_parent 'jenkins plugins hipchat HipChatNotifier' XML SubElement hipchat 'token' text str data get 'token' '' if 'rooms' in data XML SubElement hipchat 'room' text str ' ' join data['rooms'] mapping [ 'notify-start' 'startNotification' False 'notify-success' 'notifySuccess' False 'notify-aborted' 'notifyAborted' False 'notify-not-built' 'notifyNotBuilt' False 'notify-unstable' 'notifyUnstable' False 'notify-failure' 'notifyFailure' False 'notify-back-to-normal' 'notifyBackToNormal' False ]helpers convert_mapping_to_xml hipchat data mapping fail_required True if 'start-message' in data XML SubElement hipchat 'startJobMessage' text str data['start-message'] if 'complete-message' in data XML SubElement hipchat 'completeJobMessage' text str data['complete-message']
def log_mask_zero a a np asarray a with np errstate divide 'ignore' a_log np log a a_log[ a < 0 ] 0 0return a_log
def log_mask_zero a a np asarray a with np errstate divide 'ignore' a_log np log a a_log[ a < 0 ] 0 0return a_log
def log_mask_zero a a np asarray a with np errstate divide 'ignore' a_log np log a a_log[ a < 0 ] 0 0return a_log
def test_table_deletion deleted set class TestTable table Table def __del__ self deleted add id self t TestTable {'a' [1 2 3]} the_id id t assert t['a'] parent_table is t del tgc collect assert the_id in deleted
def test_stackedblocks_without_params sb StackedBlocks [Block Block ] assert sb _params is None
def DumpGC ob ADsGetObject 'GC ' IID_IADsContainer for sub_ob in ob print 'GCob %s %s ' % sub_ob Name sub_ob ADsPath
def restore_version if ORIGINAL_VERSION_LINE is None returnwith open u'xonsh/__init__ py' u'r' as f raw f read lines raw splitlines lines[0] ORIGINAL_VERSION_LINEupd u'\n' join lines + u'\n' with open u'xonsh/__init__ py' u'w' as f f write upd
def jaccard u v u _validate_vector u v _validate_vector v dist np double np bitwise_and u v np bitwise_or u 0 v 0 sum / np double np bitwise_or u 0 v 0 sum return dist
def _betmap G_normalized_weight_sources_tuple return nx betweenness_centrality_source *G_normalized_weight_sources_tuple
def name_to_uid name try uid int name except ValueError try pwdrec pwd getpwnam name except KeyError raise ValueError 'Invalidusername%s' % name uid pwdrec[2]else try pwd getpwuid uid except KeyError raise ValueError 'Invaliduserid%s' % name return uid
def name_to_uid name try uid int name except ValueError try pwdrec pwd getpwnam name except KeyError raise ValueError 'Invalidusername%s' % name uid pwdrec[2]else try pwd getpwuid uid except KeyError raise ValueError 'Invaliduserid%s' % name return uid
def _generate_items_for_subtask item_querysets item_fields total_num_items items_per_task total_num_subtasks course_id num_items_queued 0all_item_fields list item_fields all_item_fields append 'pk' num_subtasks 0items_for_task []with track_memory_usage 'course_email subtask_generation memory' course_id for queryset in item_querysets for item in queryset values *all_item_fields iterator if len items_for_task items_per_task and num_subtasks < total_num_subtasks - 1 yield items_for_task num_items_queued + items_per_taskitems_for_task []num_subtasks + 1items_for_task append item if items_for_task yield items_for_task num_items_queued + len items_for_task if num_items_queued total_num_items TASK_LOG info 'Numberofitemsgeneratedbychunking%snotequaltooriginaltotal%s' num_items_queued total_num_items
def _routestopped_config routestopped if routestopped is None routestopped []lines [ROUTESTOPPED_HEADER]for entry in routestopped entry setdefault 'interface' 'eth0' entry setdefault 'host' '0 0 0 0/0' entry setdefault 'options' '-' entry setdefault 'proto' '-' entry setdefault 'dest_port' '-' entry setdefault 'source_port' '-' if isinstance entry['host'] list entry['host'] ' ' join entry['host'] if isinstance entry['options'] list entry['options'] ' ' join entry['options'] lines append ROUTESTOPPED_FORMAT % entry file '/etc/shorewall/routestopped' contents '' join lines use_sudo True
def _routestopped_config routestopped if routestopped is None routestopped []lines [ROUTESTOPPED_HEADER]for entry in routestopped entry setdefault 'interface' 'eth0' entry setdefault 'host' '0 0 0 0/0' entry setdefault 'options' '-' entry setdefault 'proto' '-' entry setdefault 'dest_port' '-' entry setdefault 'source_port' '-' if isinstance entry['host'] list entry['host'] ' ' join entry['host'] if isinstance entry['options'] list entry['options'] ' ' join entry['options'] lines append ROUTESTOPPED_FORMAT % entry file '/etc/shorewall/routestopped' contents '' join lines use_sudo True
def get_namespace name os environ get _ENV_CURRENT_NAMESPACE None if name is None name _config default_namespace_for_request if name is not None set_namespace name if name is None name ''return name
@receiver SignalHandler course_published def course_published_handler sender course_key **kwargs if not isinstance course_key CCXLocator send_ccx_course_published delay unicode course_key
def check_for_date filename matcher x 0if matcher for expression in matcher regex re compile expression match1 regex search filename x + 1if match1 return match1 x return None 0
@with_setup step_runner_environ def test_steps_that_match_groups_and_named_groups_takes_just_named_as_params @step ' he she getsa ?P<what>\\w+ ' def given_action_named step what assert_equals what 'caipirinha' f Feature from_string FEATURE6 feature_result f run scenario_result feature_result scenario_results[0]assert_equals len scenario_result steps_passed 1 assert_equals scenario_result total_steps 1
@with_setup step_runner_environ def test_steps_that_match_groups_and_named_groups_takes_just_named_as_params @step ' he she getsa ?P<what>\\w+ ' def given_action_named step what assert_equals what 'caipirinha' f Feature from_string FEATURE6 feature_result f run scenario_result feature_result scenario_results[0]assert_equals len scenario_result steps_passed 1 assert_equals scenario_result total_steps 1
def pretty expr **settings pp PrettyPrinter settings use_unicode pp _settings['use_unicode']uflag pretty_use_unicode use_unicode try return pp doprint expr finally pretty_use_unicode uflag
def libvlc_media_player_get_time p_mi f _Cfunctions get 'libvlc_media_player_get_time' None or _Cfunction 'libvlc_media_player_get_time' 1 None ctypes c_longlong MediaPlayer return f p_mi
def frt2 a if a ndim 2 or a shape[0] a shape[1] raise ValueError 'Inputmustbeasquare 2-Darray' ai a copy n ai shape[0]f np empty n + 1 n np uint32 f[0] ai sum axis 0 for m in range 1 n for row in range 1 n ai[row] roll ai[row] - row f[m] ai sum axis 0 f[n] ai sum axis 1 return f
def _psrdp cmd rdp '$RDP Get-WmiObject-ClassWin32_TerminalServiceSetting-Namespaceroot\\CIMV2\\TerminalServices-Computer -Authentication6-ErrorActionStop'return __salt__['cmd run'] '{0} {1}' format rdp cmd shell 'powershell' python_shell True
def _psrdp cmd rdp '$RDP Get-WmiObject-ClassWin32_TerminalServiceSetting-Namespaceroot\\CIMV2\\TerminalServices-Computer -Authentication6-ErrorActionStop'return __salt__['cmd run'] '{0} {1}' format rdp cmd shell 'powershell' python_shell True
def update_job name config if 'name' not in config config['name'] namedata json dumps config try response salt utils http query '{0}/scheduler/iso8601' format _base_url method 'POST' data data header_dict {'Content-Type' 'application/json'} log debug 'updateresponse %s' response return {'success' True}except Exception as ex log error 'unabletoupdatechronosjob %s' get_error_message ex return {'exception' {'message' get_error_message ex }}
def test_flattener_layer_state_separation_for_conv conv1 ConvElemwise 8 [2 2] 'sf1' SigmoidConvNonlinearity 0 1 conv2 ConvElemwise 8 [2 2] 'sf2' SigmoidConvNonlinearity 0 1 mlp MLP layers [FlattenerLayer CompositeLayer 'comp' [conv1 conv2] ] input_space Conv2DSpace shape [5 5] num_channels 2 topo_view np random rand 10 5 5 2 astype theano config floatX y np random rand 10 256 astype theano config floatX dataset DenseDesignMatrix topo_view topo_view y y train Train dataset mlp SGD 0 1 batch_size 5 monitoring_dataset dataset train algorithm termination_criterion EpochCounter 1 train main_loop
def test_flattener_layer_state_separation_for_conv conv1 ConvElemwise 8 [2 2] 'sf1' SigmoidConvNonlinearity 0 1 conv2 ConvElemwise 8 [2 2] 'sf2' SigmoidConvNonlinearity 0 1 mlp MLP layers [FlattenerLayer CompositeLayer 'comp' [conv1 conv2] ] input_space Conv2DSpace shape [5 5] num_channels 2 topo_view np random rand 10 5 5 2 astype theano config floatX y np random rand 10 256 astype theano config floatX dataset DenseDesignMatrix topo_view topo_view y y train Train dataset mlp SGD 0 1 batch_size 5 monitoring_dataset dataset train algorithm termination_criterion EpochCounter 1 train main_loop
def test_flattener_layer_state_separation_for_conv conv1 ConvElemwise 8 [2 2] 'sf1' SigmoidConvNonlinearity 0 1 conv2 ConvElemwise 8 [2 2] 'sf2' SigmoidConvNonlinearity 0 1 mlp MLP layers [FlattenerLayer CompositeLayer 'comp' [conv1 conv2] ] input_space Conv2DSpace shape [5 5] num_channels 2 topo_view np random rand 10 5 5 2 astype theano config floatX y np random rand 10 256 astype theano config floatX dataset DenseDesignMatrix topo_view topo_view y y train Train dataset mlp SGD 0 1 batch_size 5 monitoring_dataset dataset train algorithm termination_criterion EpochCounter 1 train main_loop
def module_load_tests loader found_tests pattern result testresources OptimisingTestSuite found_tests testscenarios load_tests_apply_scenarios loader found_tests pattern result addTest found_tests return result
def inflate_denoiser_output centroid_seqs singleton_seqs denoiser_map raw_seqs id_lookup parse_denoiser_mapping denoiser_map flowgram_to_seq_id_lookup flowgram_id_to_seq_id_map raw_seqs for id_ seq in centroid_seqs id cluster_size_str id_ split ' ' cluster_member_ids id_lookup[id]for c in cluster_member_ids yield flowgram_to_seq_id_lookup[c] seq for id_ seq in singleton_seqs yield flowgram_to_seq_id_lookup[id_] seq return
def inflate_denoiser_output centroid_seqs singleton_seqs denoiser_map raw_seqs id_lookup parse_denoiser_mapping denoiser_map flowgram_to_seq_id_lookup flowgram_id_to_seq_id_map raw_seqs for id_ seq in centroid_seqs id cluster_size_str id_ split ' ' cluster_member_ids id_lookup[id]for c in cluster_member_ids yield flowgram_to_seq_id_lookup[c] seq for id_ seq in singleton_seqs yield flowgram_to_seq_id_lookup[id_] seq return
def test_uniform_P l Symbol 'l' real True finite True w Symbol 'w' positive True finite True X Uniform 'x' l l + w assert P X < l 0 and P X > l + w 0
def test_uniform_P l Symbol 'l' real True finite True w Symbol 'w' positive True finite True X Uniform 'x' l l + w assert P X < l 0 and P X > l + w 0
def remove_temp_dir ignore_errors False shutil rmtree get_temp_dir ignore_errors ignore_errors
def _write_w filename vertices data assert len vertices len data fid open filename 'wb' fid write np zeros 2 dtype np uint8 tostring vertices_n len vertices _write_3 fid vertices_n for i in range vertices_n _write_3 fid vertices[i] fid write np array float data[i] dtype '>f4' tostring fid close
def stop_workers worker_sockets log_fh None for i worker in enumerate worker_sockets try worker send 'Servershuttingdownallclients' except error if log_fh log_fh write 'Worker%sseemstobedeadalready Checkforrunaways \n' % i worker close
def _composed *decorators def final_decorator f for d in decorators if not hasattr d '__code__' setattr d '__code__' Fakecode f d f return freturn final_decorator
def _composed *decorators def final_decorator f for d in decorators if not hasattr d '__code__' setattr d '__code__' Fakecode f d f return freturn final_decorator
def get_pages app None pages {}frappe local flags in_get_all_pages Truefolders frappe local flags web_pages_folders or u'www' u'templates/pages' if app apps [app]else apps frappe local flags web_pages_apps or frappe get_installed_apps for app in apps app_path frappe get_app_path app for start in folders path os path join app_path start pages update get_pages_from_path path app app_path frappe local flags in_get_all_pages Falsereturn pages
@export_as_api@ExecutionContext enforce_phase EXECUTION_PHASE BEFORE_TRADING EXECUTION_PHASE HANDLE_BAR EXECUTION_PHASE SCHEDULED def get_order order_id return get_simu_exchange get_order order_id
@export_as_api@ExecutionContext enforce_phase EXECUTION_PHASE BEFORE_TRADING EXECUTION_PHASE HANDLE_BAR EXECUTION_PHASE SCHEDULED def get_order order_id return get_simu_exchange get_order order_id
def main all_command_handlers []parser argparse ArgumentParser description 'HelpertooltointeractwithSpinnakerdeploymentmetrics ' add_global_args parser subparsers parser add_subparsers title 'commands' dest 'command' server_handlers add_handlers all_command_handlers subparsers spectator_handlers add_handlers all_command_handlers subparsers stackdriver_handlers add_handlers all_command_handlers subparsers datadog_handlers add_handlers all_command_handlers subparsers opts parser parse_args options vars opts init_logging options command_processor process_command options['command'] options all_command_handlers
def make_middleware app global_conf None warning_level None if warning_level warning_level int warning_level return HTTPExceptionHandler app warning_level warning_level
def test_get_mutable_mark_dirty class MutableTester XBlock 'Testclasswithmutablefields 'list_field List default [] mutable_test MutableTester TestRuntime services {'field-data' DictFieldData {} } scope_ids Mock spec ScopeIds assert_equals len mutable_test _dirty_fields 0 _test_get mutable_test list_fieldassert_equals len mutable_test _dirty_fields 1 mutable_test list_field []assert_equals len mutable_test _dirty_fields 1 mutable_test save assert_equals len mutable_test _dirty_fields 1 _test_get mutable_test list_fieldassert_equals len mutable_test _dirty_fields 1
def test_get_mutable_mark_dirty class MutableTester XBlock 'Testclasswithmutablefields 'list_field List default [] mutable_test MutableTester TestRuntime services {'field-data' DictFieldData {} } scope_ids Mock spec ScopeIds assert_equals len mutable_test _dirty_fields 0 _test_get mutable_test list_fieldassert_equals len mutable_test _dirty_fields 1 mutable_test list_field []assert_equals len mutable_test _dirty_fields 1 mutable_test save assert_equals len mutable_test _dirty_fields 1 _test_get mutable_test list_fieldassert_equals len mutable_test _dirty_fields 1
def read_possible_plural_rules plurals {}try import gluon contrib plural_rules as packagefor importer modname ispkg in pkgutil iter_modules package __path__ if len modname 2 module __import__ package __name__ + ' ' + modname fromlist [modname] lang modnamepname modname + ' py' nplurals getattr module 'nplurals' DEFAULT_NPLURALS get_plural_id getattr module 'get_plural_id' DEFAULT_GET_PLURAL_ID construct_plural_form getattr module 'construct_plural_form' DEFAULT_CONSTRUCT_PLURAL_FORM plurals[lang] lang nplurals get_plural_id construct_plural_form except ImportError e sys exc_info [1]logging warn 'Unabletoimportpluralrules %s' % e return plurals
def read_possible_plural_rules plurals {}try import gluon contrib plural_rules as packagefor importer modname ispkg in pkgutil iter_modules package __path__ if len modname 2 module __import__ package __name__ + ' ' + modname fromlist [modname] lang modnamepname modname + ' py' nplurals getattr module 'nplurals' DEFAULT_NPLURALS get_plural_id getattr module 'get_plural_id' DEFAULT_GET_PLURAL_ID construct_plural_form getattr module 'construct_plural_form' DEFAULT_CONSTRUCT_PLURAL_FORM plurals[lang] lang nplurals get_plural_id construct_plural_form except ImportError e sys exc_info [1]logging warn 'Unabletoimportpluralrules %s' % e return plurals
def model_save self commit True if self errors raise ValueError "The%scouldnotbecreatedbecausethedatadidn'tvalidate " % self _model _meta object_name return save_instance self self _model commit
def device_memory_size devmem sz getattr devmem '_cuda_memsize_' None if sz is None s e device_extents devmem sz e - s devmem _cuda_memsize_ szassert sz > 0 'zerolengtharray'return sz
def define_total name description manager counters counter _TotalCounter name description manager register counter return counter
def define_total name description manager counters counter _TotalCounter name description manager register counter return counter
def get_model instance return type instance
def get_model instance return type instance
def get_connection fail_silently False return _get_connection backend get_mail_backend host options get 'mail host' port options get 'mail port' username options get 'mail username' password options get 'mail password' use_tls options get 'mail use-tls' fail_silently fail_silently
def get_connection fail_silently False return _get_connection backend get_mail_backend host options get 'mail host' port options get 'mail port' username options get 'mail username' password options get 'mail password' use_tls options get 'mail use-tls' fail_silently fail_silently
def convert_ipv4_to_ipv6 ipv4 converted_ip ' ffff 'split_ipaddress ipv4 split ' ' try socket inet_aton ipv4 except socket error raise ValueError 'ipv4tobeconvertedisinvalid' if len split_ipaddress 4 raise ValueError 'ipv4addressisnotindottedquadformat' for index string in enumerate split_ipaddress if index 1 test str hex int string split 'x' [1] if len test 1 final '0'final + testtest finalelse test str hex int string split 'x' [1] if len test 1 final '0'final + test + ' ' test finalelse test + ' 'converted_ip + testreturn converted_ip
def stSpectralFlux X Xprev sumX numpy sum X + eps sumPrevX numpy sum Xprev + eps F numpy sum X / sumX - Xprev / sumPrevX ** 2 return F
@depends HAS_HDPARM def hpa disks size None hpa_data {}for disk data in hdparms disks 'N' items visible total status data values [0]if visible total or 'disabled' in status hpa_data[disk] {'total' total}else hpa_data[disk] {'total' total 'visible' visible 'hidden' total - visible }if size is None return hpa_datafor disk data in hpa_data items try size data['total'] - int size except if '%' in size size int size strip '%' size 100 - size * data['total'] size / 100if size < 0 size data['total']_hdparm '--yes-i-know-what-i-am-doing-Np{0}{1}' format size disk
@depends HAS_HDPARM def hpa disks size None hpa_data {}for disk data in hdparms disks 'N' items visible total status data values [0]if visible total or 'disabled' in status hpa_data[disk] {'total' total}else hpa_data[disk] {'total' total 'visible' visible 'hidden' total - visible }if size is None return hpa_datafor disk data in hpa_data items try size data['total'] - int size except if '%' in size size int size strip '%' size 100 - size * data['total'] size / 100if size < 0 size data['total']_hdparm '--yes-i-know-what-i-am-doing-Np{0}{1}' format size disk
def _is_from_logout request return getattr request 'is_from_logout' False
def get_computer_name name win32api GetComputerNameEx win32con ComputerNamePhysicalDnsHostname return name if name else False
def _get_flim flim fscale freq sfreq None if flim is None if freq is None flim [ 0 1 if fscale 'log' else 0 0 sfreq / 2 0 ]else if fscale 'linear' flim [freq[0]]else flim [ freq[0] if freq[0] > 0 else 0 1 * freq[1] ]flim + [freq[ -1 ]]if fscale 'log' if flim[0] < 0 raise ValueError 'flim[0]mustbepositive got%s' % flim[0] elif flim[0] < 0 raise ValueError 'flim[0]mustbenon-negative got%s' % flim[0] return flim
def sortfunc x_obj y_obj return cmp y_obj[1] x_obj[1]
@requires_duration@apply_to_mask@apply_to_audiodef loop self n None duration None result self fl_time lambda t t % self duration if n duration n * self duration if duration result result set_duration duration return result
def gzipped f @functools wraps f def view_func *args **kwargs @after_this_requestdef zipper response accept_encoding request headers get 'Accept-Encoding' '' if 'gzip' not in accept_encoding lower return responseresponse direct_passthrough Falseif response status_code < 200 or response status_code > 300 or 'Content-Encoding' in response headers return responsegzip_buffer IO gzip_file gzip GzipFile mode 'wb' fileobj gzip_buffer gzip_file write response data gzip_file close response data gzip_buffer getvalue response headers['Content-Encoding'] 'gzip'response headers['Vary'] 'Accept-Encoding'response headers['Content-Length'] len response data return responsereturn f *args **kwargs return view_func
def _clear_context context for var in x for x in __context__ if x startswith 'chocolatey ' context pop var
def is_true value None try value int value except ValueError TypeError passtry value float value except ValueError TypeError passif isinstance value int float return value > 0 elif isinstance value six string_types return str value lower 'true' else return bool value
def _plot_connectivity_circle_onpick event fig None axes None indices None n_nodes 0 node_angles None ylim [9 10] if event inaxes axes returnif event button 1 if not ylim[0] < event ydata < ylim[1] returnnode_angles node_angles % np pi * 2 node np argmin np abs event xdata - node_angles patches event inaxes patchesfor ii x y in enumerate zip indices[0] indices[1] patches[ii] set_visible node in [x y] fig canvas draw elif event button 3 patches event inaxes patchesfor ii in range np size indices axis 1 patches[ii] set_visible True fig canvas draw
def show_in_pager self data start screen_lines raise TryNext
def central_server_test f return x_server_test f settings CENTRAL_SERVER 'Centralservertest'
def getMinimumFromVec3List vec3List minimum complex 999999999 0 999999999 0 for point in vec3List minimum getMinimum minimum point dropAxis 2 return minimum
def _get_subproject_base subproject entrypoint _get_installed_entrypoint subproject return entrypoint module_name split ' ' [0]
def human_size sz if not sz return Falseunits 'bytes' 'Kb' 'Mb' 'Gb' if isinstance sz basestring sz len sz s i float sz 0 while s > 1024 and i < len units - 1 s / 1024i + 1return '%0 2f%s' % s units[i]
def what file h None if h is None if isinstance file basestring with lopen file u'rb' as f h f read HSIZE else location file tell h file read HSIZE file seek location if isinstance h bytes h memoryview h for tf in tests res tf h if res return resif h[ 2] '\xff\xd8' return u'jpeg'return None
def getTranslateTetragridByTranslation translation return [[1 0 0 0 0 0 translation x] [0 0 1 0 0 0 translation y] [0 0 0 0 1 0 translation z] [0 0 0 0 0 0 1 0]]
def _normparse text return _normexpr functemplate _parse text
def get_service hass config discovery_info None if not AUTH_TOKENS load_token hass config path SESSION_FILE return MatrixNotificationService config get CONF_HOMESERVER config get CONF_DEFAULT_ROOM config get CONF_VERIFY_SSL config get CONF_USERNAME config get CONF_PASSWORD
def l1 id vdata gtable db gis_locationquery gtable parent id & gtable level 'L1' & gtable end_date None aitable db vulnerability_aggregated_indicatoratable db vulnerability_aggregaterquery aitable name 'Resilience' & atable parameter_id aitable parameter_id & atable agg_type 4 rows db query select gtable id gtable name for row in rows query rquery & atable location_id row id _row db query select atable median orderby ~ atable date first resilience 0if _row and _row median is not None resilience int round _row median 0 vdata[row id] dict r resilience n row name l 1 f id return
def _urljoin base url if url startswith 'http //' or url startswith 'https //' return urljoin base url new_base base if base endswith '/' else base + '/' new_url url[1 ] if url startswith '/' else url return new_base + new_url
def validate_base64 value try base64 b64decode value split [1] except Exception as e raise ValidationError e
def asynchronous function arg_names inspect getargspec function argsMessageData collections namedtuple function __name__ arg_names[1 ] @functools wraps function def call_or_send processor *args **kwargs if len args 1 and not kwargs and isinstance args[0] MessageData try return function processor **args[0] _asdict except Exception as exc LOG exception '[%s]Exceptionin"%s" %s' processor name function __name__ exc raiseelse data inspect getcallargs function processor *args **kwargs data pop arg_names[0] return processor queue send function __name__ MessageData **data call_or_send MessageData MessageDatareturn call_or_send
def asynchronous function arg_names inspect getargspec function argsMessageData collections namedtuple function __name__ arg_names[1 ] @functools wraps function def call_or_send processor *args **kwargs if len args 1 and not kwargs and isinstance args[0] MessageData try return function processor **args[0] _asdict except Exception as exc LOG exception '[%s]Exceptionin"%s" %s' processor name function __name__ exc raiseelse data inspect getcallargs function processor *args **kwargs data pop arg_names[0] return processor queue send function __name__ MessageData **data call_or_send MessageData MessageDatareturn call_or_send
def log_info infomsg try infomsg str infomsg except Exception as e infomsg str e for line in infomsg splitlines log msg '[ ]%s' % line
def main utils change_cwd for elem in lint for f in glob glob elem remove f for root _dirs _files in os walk os getcwd path os path basename root if any [fnmatch fnmatch path e for e in recursive_lint] remove root
def main utils change_cwd for elem in lint for f in glob glob elem remove f for root _dirs _files in os walk os getcwd path os path basename root if any [fnmatch fnmatch path e for e in recursive_lint] remove root
def get_console request console_type instance if console_type 'AUTO' check_consoles CONSOLESelse try check_consoles {console_type CONSOLES[console_type]}except KeyError msg _ 'Consoletype"%s"notsupported ' % console_type raise exceptions NotAvailable msg try httpnotimplemented nova_exception HttpNotImplementedexcept AttributeError httpnotimplemented nova_exception HTTPNotImplementedfor con_type api_call in check_consoles items try console api_call request instance id except httpnotimplemented continueexcept Exception LOG debug 'Consolenotavailable' exc_info True continueif con_type 'SERIAL' console_url console urlelse console_url '%s&%s %s ' % console url urlencode {'title' getattr instance 'name' '' } instance id return con_type console_url raise exceptions NotAvailable _ 'Noavailableconsolefound '
def find_diff file1 file2 DEBUG Trueproc subprocess Popen [DIFF file1 file2] stdout subprocess PIPE stderr subprocess PIPE diff_output std_err proc communicate if DEBUG print '>>>Configdifferences 'print diff_outputreturn diff_output
@not_implemented_for 'directed' @not_implemented_for 'multigraph' def jaccard_coefficient G ebunch None def predict u v union_size len set G[u] set G[v] if union_size 0 return 0return len list nx common_neighbors G u v / union_size return _apply_prediction G predict ebunch
def get_series model extra_field None source None **filters extra if extra_field is None else extra_field qs model search order_by '-date' filter **filters values_dict 'date' 'count' *extra if source qs qs source source for val in qs[ 365] date_ parse val['date'][0] date rv dict count val['count'][0] date date_ end date_ if source rv['data'] extract val[source] elif extra_field rv['data'] extract val[extra_field] yield rv
def get_run_marketing_url course_key user course_run get_course_run course_key user return course_run get 'marketing_url'
def get_run_marketing_url course_key user course_run get_course_run course_key user return course_run get 'marketing_url'
def _sigma_est_dwt detail_coeffs distribution 'Gaussian' detail_coeffs detail_coeffs[np nonzero detail_coeffs ]if distribution lower 'gaussian' denom scipy stats norm ppf 0 75 sigma np median np abs detail_coeffs / denom else raise ValueError 'OnlyGaussiannoiseestimationiscurrentlysupported' return sigma
def _insdc_location_string location rec_length try parts location partsif location strand -1 return 'complement %s %s ' % location operator ' ' join _insdc_location_string_ignoring_strand_and_subfeatures p rec_length for p in parts[ -1 ] else return '%s %s ' % location operator ' ' join _insdc_location_string p rec_length for p in parts except AttributeError loc _insdc_location_string_ignoring_strand_and_subfeatures location rec_length if location strand -1 return 'complement %s ' % loc else return loc
def getLens filename lens []fa_instance screed open filename for record in fa_instance lens append len record['sequence'] return sorted lens
def common_log environ response response_time None logger logging getLogger logger setLevel logging INFO if response_time formatter ApacheFormatter with_response_time True try log_entry formatter response status_code environ len response content rt_us response_time except TypeError log_entry formatter response status_code environ len response content rt_ms response_time else formatter ApacheFormatter with_response_time False log_entry formatter response status_code environ len response content logger info log_entry return log_entry
def genHalfAndHalf pset min_ max_ type_ None method random choice genGrow genFull return method pset min_ max_ type_
def add_block_ids payload if 'data' in payload for ele in payload['data'] if 'module_id' in ele ele['block_id'] UsageKey from_string ele['module_id'] block_id
def load_all stream return yaml load_all stream Loader AstropyLoader
def write_to_version_file filename versions os unlink filename contents json dumps versions sort_keys True indent 1 separators ' ' ' ' with open filename 'w' as f f write SHORT_VERSION_PY % contents print "set%sto'%s'" % filename versions['version']
def require_password_change name return __salt__['user update'] name expired True
def require_password_change name return __salt__['user update'] name expired True
def require_password_change name return __salt__['user update'] name expired True
def require_password_change name return __salt__['user update'] name expired True
def promote operator size return lo LinOp lo PROMOTE size [operator] None
def promote operator size return lo LinOp lo PROMOTE size [operator] None
def get_module module_name try module_path module_class module_name rsplit ' ' 1 base_module __import__ module_path globals locals [module_class] module getattr base_module module_class except ImportError AttributeError ValueError as e raise EAException 'Couldnotimportmodule%s %s' % module_name e return module
def _cached_dfs_serialize input_object if input_object is None return Noneinput_type type input_object if input_type in _BASIC_JSON_TYPES return input_objectis_pyrsistent Falseif input_type in _BASIC_JSON_COLLECTIONS obj input_objectelse if _is_pyrsistent input_object is_pyrsistent Truecached_value _cached_dfs_serialize_cache get input_object _UNCACHED_SENTINEL if cached_value is not _UNCACHED_SENTINEL return cached_valueobj _to_serializables input_object result objobj_type type obj if obj_type dict result dict _cached_dfs_serialize key _cached_dfs_serialize value for key value in obj iteritems elif obj_type list or obj_type tuple result list _cached_dfs_serialize x for x in obj if is_pyrsistent _cached_dfs_serialize_cache[input_object] resultreturn result
@logic auth_audit_exemptdef send_email_notifications context data_dict if not request environ get 'paste command_request' _check_access 'send_email_notifications' context data_dict if not converters asbool config get 'ckan activity_streams_email_notifications' raise ValidationError 'ckan activity_streams_email_notificationsisnotenabledinconfig' email_notifications get_and_send_notifications_for_all_users
def volume_list request search_opts None c_client cinderclient request if c_client is None return []return c_client volumes list search_opts search_opts
def volume_list request search_opts None c_client cinderclient request if c_client is None return []return c_client volumes list search_opts search_opts
def package pkg_name update False if not is_installed pkg_name install pkg_name update
def stats r total sum r avg float total / float len r sdsq sum [ i - avg ** 2 for i in r] s sorted list r return dict list zip [u'med' u'avg' u'stddev' u'min' u'max'] s[ len s // 2 ] avg sdsq / len r ** 0 5 min r max r
def poly_map_domain oldx domain window domain np array domain dtype np float64 window np array window dtype np float64 scl window[1] - window[0] / domain[1] - domain[0] off window[0] * domain[1] - window[1] * domain[0] / domain[1] - domain[0] return off + scl * oldx
def poly_map_domain oldx domain window domain np array domain dtype np float64 window np array window dtype np float64 scl window[1] - window[0] / domain[1] - domain[0] off window[0] * domain[1] - window[1] * domain[0] / domain[1] - domain[0] return off + scl * oldx
def dbref accessing_obj accessed_obj *args **kwargs if not args return Falsetry dbref int args[0] strip strip '#' except ValueError return Falseif hasattr accessing_obj 'dbid' return dbref accessing_obj dbid return False
def dbref accessing_obj accessed_obj *args **kwargs if not args return Falsetry dbref int args[0] strip strip '#' except ValueError return Falseif hasattr accessing_obj 'dbid' return dbref accessing_obj dbid return False
def octocat say None return gh octocat say
def get_yaml_entry yaml_dict name entry yaml_dict get name if entry is None return Noneif isinstance entry basestring return [entry]return entry
def get_yaml_entry yaml_dict name entry yaml_dict get name if entry is None return Noneif isinstance entry basestring return [entry]return entry
def allowed_flags args flags flags set flags for arg in args keys try if Options __options__[arg] is_Flag and not arg in flags raise FlagError "'%s'flagisnotallowedinthiscontext" % arg except KeyError raise OptionError "'%s'isnotavalidoption" % arg
def allowed_flags args flags flags set flags for arg in args keys try if Options __options__[arg] is_Flag and not arg in flags raise FlagError "'%s'flagisnotallowedinthiscontext" % arg except KeyError raise OptionError "'%s'isnotavalidoption" % arg
def allowed_flags args flags flags set flags for arg in args keys try if Options __options__[arg] is_Flag and not arg in flags raise FlagError "'%s'flagisnotallowedinthiscontext" % arg except KeyError raise OptionError "'%s'isnotavalidoption" % arg
def _dhtm mag sig np zeros len mag midpt len mag // 2 sig[1 midpt] 1sig[ midpt + 1 ] -1 recon ifft mag * np exp fft sig * ifft np log mag realreturn recon
def render_message_to_string subject_template message_template param_dict language None language language or settings LANGUAGE_CODE with override_language language return get_subject_and_message subject_template message_template param_dict
def render_message_to_string subject_template message_template param_dict language None language language or settings LANGUAGE_CODE with override_language language return get_subject_and_message subject_template message_template param_dict
def handler req Handler req run gluon main wsgibase return apache OK
def get_dynamodb_type val use_boolean True dynamodb_type Noneif val is None dynamodb_type 'NULL'elif is_num val if isinstance val bool and use_boolean dynamodb_type 'BOOL'else dynamodb_type 'N'elif is_str val dynamodb_type 'S'elif isinstance val set frozenset if False not in map is_num val dynamodb_type 'NS'elif False not in map is_str val dynamodb_type 'SS'elif False not in map is_binary val dynamodb_type 'BS'elif is_binary val dynamodb_type 'B'elif isinstance val Mapping dynamodb_type 'M'elif isinstance val list dynamodb_type 'L'if dynamodb_type is None msg 'Unsupportedtype"%s"forvalue"%s"' % type val val raise TypeError msg return dynamodb_type
def get_dynamodb_type val use_boolean True dynamodb_type Noneif val is None dynamodb_type 'NULL'elif is_num val if isinstance val bool and use_boolean dynamodb_type 'BOOL'else dynamodb_type 'N'elif is_str val dynamodb_type 'S'elif isinstance val set frozenset if False not in map is_num val dynamodb_type 'NS'elif False not in map is_str val dynamodb_type 'SS'elif False not in map is_binary val dynamodb_type 'BS'elif is_binary val dynamodb_type 'B'elif isinstance val Mapping dynamodb_type 'M'elif isinstance val list dynamodb_type 'L'if dynamodb_type is None msg 'Unsupportedtype"%s"forvalue"%s"' % type val val raise TypeError msg return dynamodb_type
def pofile pofile **kwargs return _pofile_or_mofile pofile 'pofile' **kwargs
def isolate_query_ctes full_text text_before_cursor if not full_text return full_text text_before_cursor tuple ctes remainder extract_ctes full_text if not ctes return full_text text_before_cursor current_position len text_before_cursor meta []for cte in ctes if cte start < current_position < cte stop text_before_cursor full_text[cte start current_position]full_text full_text[cte start cte stop]return full_text text_before_cursor meta cols ColumnMetadata name None for name in cte columns meta append TableMetadata cte name cols full_text full_text[ctes[ -1 ] stop ]text_before_cursor text_before_cursor[ctes[ -1 ] stop current_position]return full_text text_before_cursor tuple meta
def test_smote_wrong_kind kind 'rnd'smote SMOTE kind kind random_state RND_SEED assert_raises ValueError smote fit_sample X Y
def ensure_unicode text if isinstance text str return text decode pyreadline_codepage 'replace' return text
def truncated f @functools wraps f def wrapper self hints *args **kwargs if not hasattr hints 'limit' raise exception UnexpectedError _ 'Cannottruncateadrivercallwithouthintslistasfirstparameterafterself' if hints limit is None or hints filters return f self hints *args **kwargs list_limit hints limit['limit']hints set_limit list_limit + 1 ref_list f self hints *args **kwargs if len ref_list > list_limit hints set_limit list_limit truncated True return ref_list[ list_limit]else hints set_limit list_limit return ref_listreturn wrapper
def truncated f @functools wraps f def wrapper self hints *args **kwargs if not hasattr hints 'limit' raise exception UnexpectedError _ 'Cannottruncateadrivercallwithouthintslistasfirstparameterafterself' if hints limit is None or hints filters return f self hints *args **kwargs list_limit hints limit['limit']hints set_limit list_limit + 1 ref_list f self hints *args **kwargs if len ref_list > list_limit hints set_limit list_limit truncated True return ref_list[ list_limit]else hints set_limit list_limit return ref_listreturn wrapper
def channel_shift_multi x intensity channel_index 2 if is_random factor np random uniform - intensity intensity else factor intensityresults []for data in x data np rollaxis data channel_index 0 min_x max_x np min data np max data channel_images [np clip x_channel + factor min_x max_x for x_channel in x]data np stack channel_images axis 0 data np rollaxis x 0 channel_index + 1 results append data return np asarray results
def _convert_host_to_ip host addrinfo socket getaddrinfo host 80 0 0 socket SOL_TCP ips []for family socktype proto canonname sockaddr in addrinfo ip sockaddr[0]ips append family ip if family socket AF_INET ips append socket AF_INET6 ' ffff ' + ip return ips
def force_link src dest return utils system 'ln-sf%s%s' % src dest
@register filterdef localtime value return do_timezone value timezone get_current_timezone
def showWarning text parent None help '' title 'Anki' return showInfo text parent help 'warning' title title
def encode bits nt_to_bits None if nt_to_bits is None nt_to_bits DEFAULT_GOLAY_NT_TO_BITSbits numpy array bits reshape 12 1 res numpy dot DEFAULT_G T bits codeword divmod res ravel 2 [1]return _bits_to_seq codeword nt_to_bits
def get_path temp_dir None cache_length 24 map_vendor_oids True ca_path temp _ca_path temp_dir if temp and _cached_path_needs_update ca_path cache_length empty_set set with path_lock if _cached_path_needs_update ca_path cache_length with open ca_path u'wb' as f for cert trust_oids reject_oids in extract_from_system if trust_oids empty_set and reject_oids empty_set f write armor u'CERTIFICATE' cert else if map_vendor_oids trust_oids _map_oids trust_oids reject_oids _map_oids reject_oids f write armor u'TRUSTEDCERTIFICATE' TrustedCertificate [Certificate load cert CertificateAux {u'trust' trust_oids u'reject' reject_oids} ] dump if not ca_path raise CACertsError u'NoCAcertsfound' return ca_path
def get_path temp_dir None cache_length 24 map_vendor_oids True ca_path temp _ca_path temp_dir if temp and _cached_path_needs_update ca_path cache_length empty_set set with path_lock if _cached_path_needs_update ca_path cache_length with open ca_path u'wb' as f for cert trust_oids reject_oids in extract_from_system if trust_oids empty_set and reject_oids empty_set f write armor u'CERTIFICATE' cert else if map_vendor_oids trust_oids _map_oids trust_oids reject_oids _map_oids reject_oids f write armor u'TRUSTEDCERTIFICATE' TrustedCertificate [Certificate load cert CertificateAux {u'trust' trust_oids u'reject' reject_oids} ] dump if not ca_path raise CACertsError u'NoCAcertsfound' return ca_path
def alternating n for perm in variations list range n n p Permutation perm if p is_even yield p
def data_fun times global nn_samp len times window np zeros n_samp start stop [int ii * float n_samp / 2 * n_dipoles for ii in 2 * n 2 * n + 1 ]window[start stop] 1 0n + 1data 2 5e-08 * np sin 2 0 * np pi * 10 0 * n * times data * windowreturn data
def GetArtifactKnowledgeBase client_obj allow_uninitialized False client_schema client_obj Schemakb client_obj Get client_schema KNOWLEDGE_BASE if not allow_uninitialized if not kb raise artifact_utils KnowledgeBaseUninitializedError 'KnowledgeBaseemptyfor%s ' % client_obj urn if not kb os raise artifact_utils KnowledgeBaseAttributesMissingError 'KnowledgeBasemissingOSfor%s Knowledgebasecontent %s' % client_obj urn kb if not kb kb client_schema KNOWLEDGE_BASE SetCoreGRRKnowledgeBaseValues kb client_obj if kb os 'Windows' if not kb environ_allusersappdata and kb environ_allusersprofile if kb os_major_version > 6 kb environ_allusersappdata u'c \\programdata'kb environ_allusersprofile u'c \\programdata'else kb environ_allusersappdata u'c \\documentsandsettings\\AllUsers\\ApplicationData'kb environ_allusersprofile u'c \\documentsandsettings\\AllUsers'return kb
def GetArtifactKnowledgeBase client_obj allow_uninitialized False client_schema client_obj Schemakb client_obj Get client_schema KNOWLEDGE_BASE if not allow_uninitialized if not kb raise artifact_utils KnowledgeBaseUninitializedError 'KnowledgeBaseemptyfor%s ' % client_obj urn if not kb os raise artifact_utils KnowledgeBaseAttributesMissingError 'KnowledgeBasemissingOSfor%s Knowledgebasecontent %s' % client_obj urn kb if not kb kb client_schema KNOWLEDGE_BASE SetCoreGRRKnowledgeBaseValues kb client_obj if kb os 'Windows' if not kb environ_allusersappdata and kb environ_allusersprofile if kb os_major_version > 6 kb environ_allusersappdata u'c \\programdata'kb environ_allusersprofile u'c \\programdata'else kb environ_allusersappdata u'c \\documentsandsettings\\AllUsers\\ApplicationData'kb environ_allusersprofile u'c \\documentsandsettings\\AllUsers'return kb
@pytest fixture def fake_proc monkeypatch stubs p guiprocess GUIProcess 'testprocess' monkeypatch setattr p '_proc' stubs fake_qprocess return p
def read_model_metadata source if isinstance source compat string_type parts compat urlparse source if parts scheme in '' 'file' and os path isdir parts path source parts pathreturn read_model_metadata_bundle source elif len parts scheme 1 and os path isdir source return read_model_metadata_bundle source else return _json_from_url source else return json load source
def _find_tcl_tk_darwin_frameworks binaries tcl_root tk_root Nonefor nm fnm in binaries if nm 'Tcl' tcl_root os path join os path dirname fnm 'Resources/Scripts' elif nm 'Tk' tk_root os path join os path dirname fnm 'Resources/Scripts' return tcl_root tk_root
def cxSimulatedBinary ind1 ind2 eta for i x1 x2 in enumerate zip ind1 ind2 rand random random if rand < 0 5 beta 2 0 * rand else beta 1 0 / 2 0 * 1 0 - rand beta ** 1 0 / eta + 1 0 ind1[i] 0 5 * 1 + beta * x1 + 1 - beta * x2 ind2[i] 0 5 * 1 - beta * x1 + 1 + beta * x2 return ind1 ind2
def cxSimulatedBinary ind1 ind2 eta for i x1 x2 in enumerate zip ind1 ind2 rand random random if rand < 0 5 beta 2 0 * rand else beta 1 0 / 2 0 * 1 0 - rand beta ** 1 0 / eta + 1 0 ind1[i] 0 5 * 1 + beta * x1 + 1 - beta * x2 ind2[i] 0 5 * 1 - beta * x1 + 1 + beta * x2 return ind1 ind2
def get_group_id name vpc_id None vpc_name None region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile if name startswith 'sg-' log debug 'group{0}isagroupid get_group_idnotcalled ' format name return namegroup _get_group conn conn name name vpc_id vpc_id vpc_name vpc_name region region key key keyid keyid profile profile return getattr group 'id' None
def normalise_alias_format_string alias_format display Nonerepresentation []if isinstance alias_format six string_types display alias_formatrepresentation append alias_format elif isinstance alias_format dict display alias_format get 'display' representation alias_format get 'representation' or [] if isinstance representation six string_types representation [representation]else raise TypeError "alias_format'%s'isneitheradictionaryorstringtype " % repr alias_format return display representation
@library global_functiondef is_watching_discussion_locale user locale return NewPostInLocaleEvent is_notifying user locale locale
def dump_object header obj result header + '\n' for key in obj hash if key 'afe' or key 'hash' continueresult + '%20s %s\n' % key obj hash[key] return result
def create_truefalse_cond prompt 'yesorno[default no]?' path None def truefalse_cond visitor node None 'Promptstheuserforatrue/falsecondition 'tf TrueFalse prompt prompt path path rtn visitor visit tf return rtnreturn truefalse_cond
def test_member_completion superConsole SendKeys 'outputRedirectStart{ }True{ }{ENTER}' testRegex ''superConsole SendKeys 'printc {TAB}{ENTER}' testRegex + ' Cdoc pretest 'superConsole SendKeys 'try {ENTER}' superConsole SendKeys 'printf {TAB}x{ENTER}' superConsole SendKeys '{BACKSPACE}except {ENTER}' superConsole SendKeys 'print"EXC"{ENTER}{ENTER}{ENTER}' testRegex + 'EXC'superConsole SendKeys 'outputRedirectStop{ }{ }{ENTER}' verifyResults getTestOutput [0] testRegex
def error_msg_from_exception e msg u''if hasattr e u'message' if type e message is dict msg e message get u'message' elif e message msg u'{}' format e message return msg or u'{}' format e
def _walk_js_scopes scope lpath None if lpath is None lpath []for subscope in scope if subscope tag 'variable' and not subscope continuesublpath lpath + [subscope get 'name' ] yield subscope sublpath for r in _walk_js_scopes subscope sublpath yield r
def ps cmd if not LINUX cmd cmd replace '--no-headers' '' if SUNOS cmd cmd replace '-ocommand' '-ocomm' cmd cmd replace '-ostart' '-ostime' p subprocess Popen cmd shell 1 stdout subprocess PIPE output p communicate [0] strip if PY3 output str output sys stdout encoding if not LINUX output output split '\n' [1] strip try return int output except ValueError return output
def get_logger path None format_ None name None global loggerif logger return loggerelse return create_logger path format_ name
def CreateBudget client budget_service client GetService 'BudgetService' version 'v201609' budget {'name' 'InterplanetaryCruiseAppBudget#%s' % uuid uuid4 'amount' {'microAmount' '50000000'} 'deliveryMethod' 'STANDARD' 'isExplicitlyShared' False}budget_operations [{'operator' 'ADD' 'operand' budget}]budget_id budget_service mutate budget_operations ['value'][0]['budgetId']return budget_id
def CreateBudget client budget_service client GetService 'BudgetService' version 'v201609' budget {'name' 'InterplanetaryCruiseAppBudget#%s' % uuid uuid4 'amount' {'microAmount' '50000000'} 'deliveryMethod' 'STANDARD' 'isExplicitlyShared' False}budget_operations [{'operator' 'ADD' 'operand' budget}]budget_id budget_service mutate budget_operations ['value'][0]['budgetId']return budget_id
def _get_visible_update course_update_items if isinstance course_update_items dict if course_update_items get 'status' CourseInfoModule STATUS_DELETED return _make_update_dict course_update_items else return {'error' _ 'Courseupdatenotfound ' 'status' 404}return [_make_update_dict update for update in course_update_items if update get 'status' CourseInfoModule STATUS_DELETED ]
@frappe whitelist def add_tag tag dt dn color None DocTags dt add dn tag return tag
def fetch_page base_url page session return session get base_url + '?page {}' format page json
@FileSystem in_directory current_directory 'django' 'alfaces' def test_limit_by_app_getting_all_apps_by_comma status out commands getstatusoutput 'pythonmanage pyharvest--verbosity 3--no-color--apps foobar donothing' assert_equals status 0 out assert 'TestthedjangoappDONOTHING' in out assert 'TestthedjangoappFOOBAR' in out
def forgiving_round value precision 0 try value round float value precision return int value if precision 0 else value except ValueError TypeError return value
def expire name cherrypy serving request config get 'tools sessions name' 'session_id' one_year 60 * 60 * 24 * 365 e time time - one_year cherrypy serving response cookie[name]['expires'] httputil HTTPDate e
def libvlc_media_discoverer_media_list p_mdis f _Cfunctions get 'libvlc_media_discoverer_media_list' None or _Cfunction 'libvlc_media_discoverer_media_list' 1 class_result MediaList ctypes c_void_p MediaDiscoverer return f p_mdis
def newid length 16 l int math ceil float length * 6 0 / 8 0 return base64 b64encode os urandom l [ length] decode 'ascii'
def load mod persist False pre_mods lsmod res __salt__['cmd run_all'] 'modprobe{0}' format mod python_shell False if res['retcode'] 0 post_mods lsmod mods _new_mods pre_mods post_mods persist_mods set if persist persist_mods _set_persistent_module mod return sorted list mods persist_mods else return 'Errorloadingmodule{0} {1}' format mod res['stderr']
def load mod persist False pre_mods lsmod res __salt__['cmd run_all'] 'modprobe{0}' format mod python_shell False if res['retcode'] 0 post_mods lsmod mods _new_mods pre_mods post_mods persist_mods set if persist persist_mods _set_persistent_module mod return sorted list mods persist_mods else return 'Errorloadingmodule{0} {1}' format mod res['stderr']
def load mod persist False pre_mods lsmod res __salt__['cmd run_all'] 'modprobe{0}' format mod python_shell False if res['retcode'] 0 post_mods lsmod mods _new_mods pre_mods post_mods persist_mods set if persist persist_mods _set_persistent_module mod return sorted list mods persist_mods else return 'Errorloadingmodule{0} {1}' format mod res['stderr']
def set_ key value profile None conn salt utils memcached get_conn profile time profile get 'expire' DEFAULT_EXPIRATION return salt utils memcached set_ conn key value time time
def text_of relpath thisdir os path dirname __file__ file_path os path join thisdir os path normpath relpath with open file_path as f text f read return text
def delete_api_key apiKey region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile conn delete_api_key apiKey apiKey return {'deleted' True}except ClientError as e return {'deleted' False 'error' salt utils boto3 get_error e }
def run_discovery entry_point cached False reg_cache {}if cached reg_cache cache registry_cache registry WidgetRegistry discovery WidgetDiscovery registry cached_descriptions reg_cache discovery run if cached cache save_registry_cache reg_cache return registry
def get_current_user try return User except UserNotFoundError return None
def ExpectingFunctionArgs clean_lines linenum line clean_lines elided[linenum]return Match '^\\s*MOCK_ CONST_ ?METHOD\\d+ _T ?\\ ' line or linenum > 2 and Match '^\\s*MOCK_ ? CONST_ ?METHOD\\d+ ? _T ?\\ ? \\S+ ?\\s*$' clean_lines elided[ linenum - 1 ] or Match '^\\s*MOCK_ ? CONST_ ?METHOD\\d+ ? _T ?\\ \\s*$' clean_lines elided[ linenum - 2 ] or Search '\\bstd m?function\\s*\\<\\s*$' clean_lines elided[ linenum - 1 ]
def _run_module_code code init_globals None mod_name None mod_fname None mod_loader None pkg_name None with _TempModule mod_name as temp_module with _ModifiedArgv0 mod_fname mod_globals temp_module module __dict___run_code code mod_globals init_globals mod_name mod_fname mod_loader pkg_name return mod_globals copy
def _run_module_code code init_globals None mod_name None mod_fname None mod_loader None pkg_name None with _TempModule mod_name as temp_module with _ModifiedArgv0 mod_fname mod_globals temp_module module __dict___run_code code mod_globals init_globals mod_name mod_fname mod_loader pkg_name return mod_globals copy
def NO_MERGE writer segments return segments
def NO_MERGE writer segments return segments
def NO_MERGE writer segments return segments
def arrangeByType service_list preferred_types def enumerate elts 'Returnaniterablethatpairstheindexofanelementwith\nthatelement \n\nForPython2 2compatibility'return zip range len elts elts def bestMatchingService service 'Returntheindexofthefirstmatchingtype orsomething\nhigherifnotypematches \n\nThisprovidesanorderinginwhichserviceelementsthat\ncontainatypethatcomesearlierinthepreferredtypeslist\ncomebeforeserviceelementsthatcomelater Ifaservice\nelementhasmorethanonetype themostpreferredonewins \n'for i t in enumerate preferred_types if preferred_types[i] in service type_uris return ireturn len preferred_types prio_services [ bestMatchingService s orig_index s for orig_index s in enumerate service_list ]prio_services sort for i in range len prio_services prio_services[i] prio_services[i][2]return prio_services
def arrangeByType service_list preferred_types def enumerate elts 'Returnaniterablethatpairstheindexofanelementwith\nthatelement \n\nForPython2 2compatibility'return zip range len elts elts def bestMatchingService service 'Returntheindexofthefirstmatchingtype orsomething\nhigherifnotypematches \n\nThisprovidesanorderinginwhichserviceelementsthat\ncontainatypethatcomesearlierinthepreferredtypeslist\ncomebeforeserviceelementsthatcomelater Ifaservice\nelementhasmorethanonetype themostpreferredonewins \n'for i t in enumerate preferred_types if preferred_types[i] in service type_uris return ireturn len preferred_types prio_services [ bestMatchingService s orig_index s for orig_index s in enumerate service_list ]prio_services sort for i in range len prio_services prio_services[i] prio_services[i][2]return prio_services
def arrangeByType service_list preferred_types def enumerate elts 'Returnaniterablethatpairstheindexofanelementwith\nthatelement \n\nForPython2 2compatibility'return zip range len elts elts def bestMatchingService service 'Returntheindexofthefirstmatchingtype orsomething\nhigherifnotypematches \n\nThisprovidesanorderinginwhichserviceelementsthat\ncontainatypethatcomesearlierinthepreferredtypeslist\ncomebeforeserviceelementsthatcomelater Ifaservice\nelementhasmorethanonetype themostpreferredonewins \n'for i t in enumerate preferred_types if preferred_types[i] in service type_uris return ireturn len preferred_types prio_services [ bestMatchingService s orig_index s for orig_index s in enumerate service_list ]prio_services sort for i in range len prio_services prio_services[i] prio_services[i][2]return prio_services
def arrangeByType service_list preferred_types def enumerate elts 'Returnaniterablethatpairstheindexofanelementwith\nthatelement \n\nForPython2 2compatibility'return zip range len elts elts def bestMatchingService service 'Returntheindexofthefirstmatchingtype orsomething\nhigherifnotypematches \n\nThisprovidesanorderinginwhichserviceelementsthat\ncontainatypethatcomesearlierinthepreferredtypeslist\ncomebeforeserviceelementsthatcomelater Ifaservice\nelementhasmorethanonetype themostpreferredonewins \n'for i t in enumerate preferred_types if preferred_types[i] in service type_uris return ireturn len preferred_types prio_services [ bestMatchingService s orig_index s for orig_index s in enumerate service_list ]prio_services sort for i in range len prio_services prio_services[i] prio_services[i][2]return prio_services
def findAround pic pat xy None r None if xy and r h w pat shape[ 2] x y xypic pic[ y - r y + h + r x - r x + w + r ]matches cv2 matchTemplate pat pic cv2 TM_CCOEFF_NORMED yf xf np unravel_index matches argmax matches shape return x - r + xf y - r + yf if xy and r else xf yf
def get_mandlebrot_escape_values width height x_vals np linspace -3 2 width y_vals np linspace -1 5 1 5 height grid np meshgrid x_vals y_vals v_get_num_escape_turns np vectorize get_num_escape_turns return v_get_num_escape_turns *grid astype np float
def read_from_numa_maps pid key numa_maps open '/proc/%s/numa_maps' % pid numa_map_info numa_maps read numa_maps close numa_maps_dict {}numa_pattern ' ^[\\dabcdfe]+ \\s+ *%s[ ] \\d+ ' % key for address number in re findall numa_pattern numa_map_info re M numa_maps_dict[address] numberreturn numa_maps_dict
def check_update github_slug current_version prereleases False releases get_valid_releases github_slug prereleases wf logger info u'{0}releasesfor{1}' format len releases github_slug if not len releases raise ValueError u'Novalidreleasesfor{0}' format github_slug latest_release releases[0]vr Version latest_release[u'version'] vl Version current_version wf logger debug u'Latest {0 r}Installed {1 r}' format vr vl if vr > vl wf cache_data u'__workflow_update_status' {u'version' latest_release[u'version'] u'download_url' latest_release[u'download_url'] u'available' True} return Truewf cache_data u'__workflow_update_status' {u'available' False} return False
def _package_search data_dict context {'model' model 'session' model Session 'user' c user 'auth_user_obj' c userobj}if 'sort' not in data_dict or not data_dict['sort'] data_dict['sort'] 'metadata_modifieddesc'if 'rows' not in data_dict or not data_dict['rows'] data_dict['rows'] ITEMS_LIMITquery logic get_action 'package_search' context data_dict copy return query['count'] query['results']
def default_select identifier all_entry_points if len all_entry_points 0 raise PluginMissingError identifier elif len all_entry_points 1 return all_entry_points[0]elif len all_entry_points > 1 raise AmbiguousPluginError all_entry_points
def default_select identifier all_entry_points if len all_entry_points 0 raise PluginMissingError identifier elif len all_entry_points 1 return all_entry_points[0]elif len all_entry_points > 1 raise AmbiguousPluginError all_entry_points
def inspect mode 'all' priority 19 **kwargs collector _ 'collector' try return collector Inspector cachedir __opts__['cachedir'] piddir os path dirname __opts__['pidfile'] request_snapshot mode priority priority **kwargs except InspectorSnapshotException as ex raise CommandExecutionError ex except Exception as ex log error _get_error_message ex raise Exception ex
def ffmpeg_movie_from_frames filename folder fps digits 6 s '%' + '%02d' % digits + 'd png' cmd [get_setting 'FFMPEG_BINARY' '-y' '-f' 'image2' '-r' '%d' % fps '-i' os path join folder folder + '/' + s '-b' '%dk' % bitrate '-r' '%d' % self fps filename]subprocess_call cmd
def hmean a axis 0 dtype None if not isinstance a np ndarray a np array a dtype dtype if np all a > 0 if isinstance a np ma MaskedArray size a count axis elif axis is None a a ravel size a shape[0]else size a shape[axis]return size / np sum 1 0 / a axis axis dtype dtype else raise ValueError 'Harmonicmeanonlydefinedifallelementsgreaterthanzero'
def intermediate_points start end graph_data newdata []newdata append start graph_data[0][0] + graph_data[1][0] - graph_data[0][0] / 2 0 graph_data[0][1] for index in range 1 len graph_data - 1 lastxval lastyval graph_data[ index - 1 ] xval yval graph_data[index] nextxval nextyval graph_data[ index + 1 ]newdata append lastxval + xval - lastxval / 2 0 xval + nextxval - xval / 2 0 yval newdata append xval + nextxval - xval / 2 0 end graph_data[ -1 ][1] return newdata
def intermediate_points start end graph_data newdata []newdata append start graph_data[0][0] + graph_data[1][0] - graph_data[0][0] / 2 0 graph_data[0][1] for index in range 1 len graph_data - 1 lastxval lastyval graph_data[ index - 1 ] xval yval graph_data[index] nextxval nextyval graph_data[ index + 1 ]newdata append lastxval + xval - lastxval / 2 0 xval + nextxval - xval / 2 0 yval newdata append xval + nextxval - xval / 2 0 end graph_data[ -1 ][1] return newdata
def stop_service pidfile pidfh open pidfile pid int pidfh readline os kill pid signal SIGTERM
def stop_service pidfile pidfh open pidfile pid int pidfh readline os kill pid signal SIGTERM
def get_city_data data pd read_csv pm get_data_file 'pymc3 examples' 'data/srrs2 dat' cty_data pd read_csv pm get_data_file 'pymc3 examples' 'data/cty dat' data data[ data state 'MN' ]data['fips'] data stfips * 1000 + data cntyfips cty_data['fips'] cty_data stfips * 1000 + cty_data ctfips data['lradon'] np log np where data activity 0 0 1 data activity data data merge cty_data 'inner' on 'fips' unique data[['fips']] drop_duplicates unique['group'] np arange len unique unique set_index 'fips' return data merge unique 'inner' on 'fips'
@pytest mark skipif 'notHAS_BEAUTIFUL_SOUP' def test_identify_table_fail table_in ['<tableid "foo"><tr><th>A</th></tr>' '<tr><td>B</td></tr></table>']with pytest raises core InconsistentTableError as err Table read table_in format 'ascii html' htmldict {'table_id' 'bad_id'} guess False assert str err endswith "ERROR HTMLtableid'bad_id'notfound" with pytest raises core InconsistentTableError as err Table read table_in format 'ascii html' htmldict {'table_id' 3} guess False assert str err endswith 'ERROR HTMLtablenumber3notfound'
def attachment_specs_delete context attachment_id key return IMPL attachment_specs_delete context attachment_id key
def de_dupe_version_table apps schema_editor db_alias schema_editor connection aliasVersion apps get_model u'reversion' u'Version' keep_version_ids Version objects using db_alias order_by values_list u'revision_id' u'content_type_id' u'object_id' annotate max_pk models Max u'pk' values_list u'max_pk' flat True if keep_version_ids count Version objects using db_alias all count returndelete_version_ids list Version objects using db_alias exclude pk__in keep_version_ids values_list u'pk' flat True Version objects using db_alias filter pk__in delete_version_ids delete
def de_dupe_version_table apps schema_editor db_alias schema_editor connection aliasVersion apps get_model u'reversion' u'Version' keep_version_ids Version objects using db_alias order_by values_list u'revision_id' u'content_type_id' u'object_id' annotate max_pk models Max u'pk' values_list u'max_pk' flat True if keep_version_ids count Version objects using db_alias all count returndelete_version_ids list Version objects using db_alias exclude pk__in keep_version_ids values_list u'pk' flat True Version objects using db_alias filter pk__in delete_version_ids delete
def convert_behave_to_cucumber_json behave_filename cucumber_filename encoding 'UTF-8' pretty True dump_kwargs {'encoding' encoding}if pretty dump_kwargs update indent 2 sort_keys True with open behave_filename 'r' as behave_json with open cucumber_filename 'w+' as output_file cucumber_json b2c convert json load behave_json encoding json dump cucumber_json output_file **dump_kwargs return 0
def convert_behave_to_cucumber_json behave_filename cucumber_filename encoding 'UTF-8' pretty True dump_kwargs {'encoding' encoding}if pretty dump_kwargs update indent 2 sort_keys True with open behave_filename 'r' as behave_json with open cucumber_filename 'w+' as output_file cucumber_json b2c convert json load behave_json encoding json dump cucumber_json output_file **dump_kwargs return 0
def apply_view_middleware request urlconf getattr request 'urlconf' settings ROOT_URLCONF urlresolvers set_urlconf urlconf resolver urlresolvers RegexURLResolver '^/' urlconf resolver_match resolver resolve request path_info callback callback_args callback_kwargs resolver_matchrequest resolver_match resolver_matchfor middleware_path in settings MIDDLEWARE_CLASSES mw_class import_string middleware_path try mw_instance mw_class except MiddlewareNotUsed continueif hasattr mw_instance 'process_view' mw_instance process_view request callback callback_args callback_kwargs return request
def import_curve p a b g r name 'dummyName' oid 1 3 132 0 255 if isinstance p str p pkcs_os2ip p if isinstance a str a pkcs_os2ip a if isinstance b str b pkcs_os2ip b if isinstance r str r pkcs_os2ip r curve CurveFp p a b x y extract_coordinates g curve generator Point curve x y r return Curve name curve generator oid
def decode value *args **kwargs if isinstance value str value value decode 'utf-8' assert isinstance value unicode return json loads value *args **kwargs
def enable_mpl_offline resize False strip_style False verbose False show_link True link_text 'Exporttoplot ly' validate True init_notebook_mode ip ipython core getipython get_ipython formatter ip display_formatter formatters['text/html']formatter for_type matplotlib figure Figure lambda fig iplot_mpl fig resize strip_style verbose show_link link_text validate
@_ensure_existsdef copy_to name source dest overwrite False makedirs False path sourcetry if source startswith 'salt //' cached_source __salt__['cp cache_file'] source if not cached_source raise CommandExecutionError 'Unabletocache{0}' format source path cached_sourceexcept AttributeError raise SaltInvocationError 'Invalidsourcefile{0}' format source if _sd_version > 219 passreturn __salt__['container_resource copy_to'] name path dest container_type __virtualname__ exec_driver EXEC_DRIVER overwrite overwrite makedirs makedirs
def test_feature_max_length_on_step_with_table_keys feature Feature from_string FEATURE7 assert_equals feature max_length 74
def _rescale_layout pos scale 1 pos - pos min axis 0 pos * scale / pos max return pos
def get_scanner hass config scanner ThomsonDeviceScanner config[DOMAIN] return scanner if scanner success_init else None
def volume_admin_metadata_get context volume_id return IMPL volume_admin_metadata_get context volume_id
def _calculate_overquota project_quotas user_quotas deltas project_usages user_usages overs []for res delta in deltas items if delta > 0 if 0 < project_quotas[res] < delta + project_usages[res]['total'] LOG debug 'Requestisoverprojectquotaforresource"% res s" Projectlimit % limit s delta % delta s currenttotalprojectusage % total s' {'res' res 'limit' project_quotas[res] 'delta' delta 'total' project_usages[res]['total']} overs append res elif 0 < user_quotas[res] < delta + user_usages[res]['total'] LOG debug 'Requestisoveruserquotaforresource"% res s" Userlimit % limit s delta % delta s currenttotaluserusage % total s' {'res' res 'limit' user_quotas[res] 'delta' delta 'total' user_usages[res]['total']} overs append res return overs
def get_fczm_drivers _ensure_loaded 'cinder/zonemanager/drivers' return [DriverInfo x for x in interface _fczm_register]
def trace a offset 0 axis1 0 axis2 1 dtype None out None return a trace offset axis1 axis2 dtype out
def dump_config profile 'default' cmd {'cmd' 'dump' 'mime' 'prop'}return _do_http cmd profile
def get_cluster_ref_from_name session cluster_name cls session _call_method vim_util 'get_objects' 'ClusterComputeResource' ['name'] for cluster in cls if cluster propSet[0] val cluster_name return cluster objreturn None
def insert_fake_data db tablename **kw column_names []column_value_placeholders []column_values []for k v in kw items column_names append k column_value_placeholders append '%s' column_values append v column_names ' ' join column_names column_value_placeholders ' ' join column_value_placeholders db run 'INSERTINTO{} {} VALUES {} ' format tablename column_names column_value_placeholders column_values return kw
def create_function_query session model functions processed []for function in functions if 'name' not in function raise KeyError 'Missing`name`keyinfunctionobject' if 'field' not in function raise KeyError 'Missing`field`keyinfunctionobject' funcname fieldname function['name'] function['field'] funcobj getattr func funcname try field getattr model fieldname except AttributeError as exception exception field fieldnameraise exceptionprocessed append funcobj field return session query *processed
def create_function_query session model functions processed []for function in functions if 'name' not in function raise KeyError 'Missing`name`keyinfunctionobject' if 'field' not in function raise KeyError 'Missing`field`keyinfunctionobject' funcname fieldname function['name'] function['field'] funcobj getattr func funcname try field getattr model fieldname except AttributeError as exception exception field fieldnameraise exceptionprocessed append funcobj field return session query *processed
def create_function_query session model functions processed []for function in functions if 'name' not in function raise KeyError 'Missing`name`keyinfunctionobject' if 'field' not in function raise KeyError 'Missing`field`keyinfunctionobject' funcname fieldname function['name'] function['field'] funcobj getattr func funcname try field getattr model fieldname except AttributeError as exception exception field fieldnameraise exceptionprocessed append funcobj field return session query *processed
def pix2cm pixels monitor if not isinstance monitor monitors Monitor msg 'cm2pixrequiresamonitors Monitorobjectasthesecondargumentbutreceived%s'raise ValueError msg % str type monitor scrWidthCm monitor getWidth scrSizePix monitor getSizePix if scrSizePix is None msg 'Monitor%shasnoknownsizeinpixels SEEMONITORCENTER 'raise ValueError msg % monitor name if scrWidthCm is None msg 'Monitor%shasnoknownwidthincm SEEMONITORCENTER 'raise ValueError msg % monitor name return pixels * float scrWidthCm / scrSizePix[0]
def pix2cm pixels monitor if not isinstance monitor monitors Monitor msg 'cm2pixrequiresamonitors Monitorobjectasthesecondargumentbutreceived%s'raise ValueError msg % str type monitor scrWidthCm monitor getWidth scrSizePix monitor getSizePix if scrSizePix is None msg 'Monitor%shasnoknownsizeinpixels SEEMONITORCENTER 'raise ValueError msg % monitor name if scrWidthCm is None msg 'Monitor%shasnoknownwidthincm SEEMONITORCENTER 'raise ValueError msg % monitor name return pixels * float scrWidthCm / scrSizePix[0]
def create context entity_id traversal_id is_update stack_id values {'entity_id' entity_id 'traversal_id' traversal_id 'is_update' is_update 'atomic_key' 0 'stack_id' stack_id 'input_data' {}}return sync_point_object SyncPoint create context values
def n_to_data n if n < 0 raise NetworkXError 'Numbersingraph6formatmustbenon-negative ' if n < 62 return [n]if n < 258047 return [63 n >> 12 & 63 n >> 6 & 63 n & 63 ]if n < 68719476735 return [63 63 n >> 30 & 63 n >> 24 & 63 n >> 18 & 63 n >> 12 & 63 n >> 6 & 63 n & 63 ]raise NetworkXError 'Numbersabove68719476735arenotsupportedbygraph6'
def build_pool test_case return StoragePool reactor create_zfs_pool test_case FilePath test_case mktemp
def _get_mac_address ip_address from subprocess import Popen PIPEpid Popen ['arp' '-n' ip_address] stdout PIPE pid_component pid communicate [0]match re search ' [a-f\\d]{1 2}\\ {5}[a-f\\d]{1 2} ' encode 'UTF-8' pid_component if match is not None return match groups [0]else return None
def _revoke_challenge global challengechallenge None
def rename_register llvmir def repl mat return '%_dot_ {0}' format mat group 1 return re_regname sub repl llvmir
def rename_register llvmir def repl mat return '%_dot_ {0}' format mat group 1 return re_regname sub repl llvmir
def rename_register llvmir def repl mat return '%_dot_ {0}' format mat group 1 return re_regname sub repl llvmir
def GetAllHeaders message name for header_line in message getallmatchingheaders name yield header_line split ' ' 1 [1] strip
def main_for_service reactor service service startService stop Deferred reactor addSystemEventTrigger 'before' 'shutdown' _chain_stop_result service stop return stop
def make_template resource_definitions version 'heat_template_version' '2015-04-30' child_env None tmpl template Template dict [version] env child_env for name defn in resource_definitions tmpl add_resource defn name return tmpl
def make_template resource_definitions version 'heat_template_version' '2015-04-30' child_env None tmpl template Template dict [version] env child_env for name defn in resource_definitions tmpl add_resource defn name return tmpl
def remove_record module gcdns record overwrite module boolean module params['overwrite'] ttl module params['ttl']record_data module params['record_data']if record is None return Falseif not overwrite if not _records_match record data['ttl'] record data['rrdatas'] ttl record_data module fail_json msg 'cannotdeleteduetonon-matchingttlorrecord_data ' + 'ttl %d record_data %s' % ttl record_data + 'originalttl %d originalrecord_data %s' % record data['ttl'] record data['rrdatas'] changed False if not module check_mode gcdns delete_record record return True
def libvlc_media_player_set_position p_mi f_pos f _Cfunctions get 'libvlc_media_player_set_position' None or _Cfunction 'libvlc_media_player_set_position' 1 1 None None MediaPlayer ctypes c_float return f p_mi f_pos
def set_cuda_disabled global cuda_available cuda_warning_is_displayedcuda_available False
def path_to_resource project path type None project_path path_relative_to_project_root project path if project_path is None project_path rope base project _realpath path project rope base project get_no_project if type is None return project get_resource project_path if type 'file' return project get_file project_path if type 'folder' return project get_folder project_path return None
def sanitize_choices choices choices_all seen set others [x for x in choices_all if x not in choices ]res []for s in choices if s in list choices_all + ['*'] if not s in seen or seen add s res extend list others if s '*' else [s] return res
def circvar samples high 2 * pi low 0 axis None samples ang _circfuncs_common samples high low S sin ang mean axis axis C cos ang mean axis axis R hypot S C return high - low / 2 0 / pi ** 2 * 2 * log 1 / R
def client_range_to_segment_range client_start client_end segment_size segment_start int client_start // segment_size * segment_size if client_start is not None else None segment_end None if client_end is None else int client_end // segment_size + 1 * segment_size - 1 if client_start is not None else int math ceil float client_end / segment_size + 1 * segment_size return segment_start segment_end
def chemical_equations_equal eq1 eq2 exact False left1 arrow1 right1 split_on_arrow eq1 left2 arrow2 right2 split_on_arrow eq2 if arrow1 '' or arrow2 '' return Falseif arrow1 arrow2 return Falsetry factor_left divide_chemical_expression left1 left2 if not factor_left return Falsefactor_right divide_chemical_expression right1 right2 if not factor_right return Falseif factor_left factor_right return Falseif exact and factor_left 1 return Falsereturn Trueexcept ParseException return False
def scipy_exponweib_sucks value alpha beta pdf np log sp exponweib pdf value 1 alpha scale beta if np isinf pdf return sp exponweib logpdf value 1 alpha scale beta return pdf
def create_agent_config_map config try bridge_mappings q_utils parse_mappings config OVS bridge_mappings except ValueError as e raise ValueError _ 'Parsingbridge_mappingsfailed %s ' % e kwargs dict integ_br config OVS integration_bridge tun_br config OVS tunnel_bridge local_ip config OVS local_ip bridge_mappings bridge_mappings root_helper config AGENT root_helper polling_interval config AGENT polling_interval enable_tunneling config OVS enable_tunneling if kwargs['enable_tunneling'] and not kwargs['local_ip'] msg _ 'Tunnellingcannotbeenabledwithoutavalidlocal_ip ' raise ValueError msg return kwargs
def render_markdown markdown_text return markdown markdown markdown_text
@contextlib contextmanagerdef redirect_fd fd save os dup fd r w os pipe try os dup2 w fd yield io open r 'r' finally os close w os dup2 save fd os close save
def timestamp date return date - datetime 1970 1 1 total_seconds
def aggregate_keywords keywords sep prefix raw False processed []encode encode_to_py3bytes_or_py2strfor k v in keywords items if len k 1 if v is not False processed append encode '-' + k if v is not True processed append encode v else if not raw k k replace '_' '-' if v is True processed append encode '--' + k elif v is False passelif sep is None or sep '' processed append encode prefix + k processed append encode v else arg encode '%s%s%s%s' % prefix k sep v processed append arg return processed
def package_list out err DETAILS['server'] sendline 'pkg_list\n' return parse out
def package_list out err DETAILS['server'] sendline 'pkg_list\n' return parse out
def _has_option option family 'ipv4' cmd '{0}--help' format _iptables_cmd family if option in __salt__['cmd run'] cmd output_loglevel 'quiet' return Truereturn False
def _manager_worker_process output_queue futures is_shutdown log info 'startingupmanagerworker %s' threading current_thread while not is_shutdown is_set try workitem output_queue get future futures get workitem work_id None log debug 'dequeuemanagerresponse %s' workitem if not future continueif workitem is_exception future set_exception workitem response else future set_result workitem response log debug 'updatedfutureresult %s' future del futures[workitem work_id]except Exception as ex log exception 'errorinmanager' log info 'managerworkershuttingdown %s' threading current_thread
def _manager_worker_process output_queue futures is_shutdown log info 'startingupmanagerworker %s' threading current_thread while not is_shutdown is_set try workitem output_queue get future futures get workitem work_id None log debug 'dequeuemanagerresponse %s' workitem if not future continueif workitem is_exception future set_exception workitem response else future set_result workitem response log debug 'updatedfutureresult %s' future del futures[workitem work_id]except Exception as ex log exception 'errorinmanager' log info 'managerworkershuttingdown %s' threading current_thread
def build_flask_context request return HTTPContext url request url method request method user_agent request user_agent string referrer request referrer remote_ip request remote_addr
def build_flask_context request return HTTPContext url request url method request method user_agent request user_agent string referrer request referrer remote_ip request remote_addr
def display_structure structure parentparts [] if parentparts name ' ' join parentparts else print 'HEADER'name 'TEXT'is_multipart isinstance structure[0] list if is_multipart parttype 'multipart/%s' % structure[1] lower else parttype '%s/%s' % structure[ 2] lower print '%-9s' % name parttype if is_multipart printsubparts structure[0]for i in range len subparts display_structure subparts[i] parentparts + [str i + 1 ] else if structure[6] print 'size %s' % structure[6] if structure[8] disposition namevalues structure[8]print disposition for i in range 0 len namevalues 2 print '%s %r' % namevalues[i i + 2 ] print
def file_size filename fd os open filename os O_RDONLY try return os lseek fd 0 os SEEK_END except KeyboardInterrupt as e raise eexcept Exception as e raise Exception "file_sizefailedtoobtainthesizeof'%s' %s" % filename str e finally os close fd
def to_epoch_milliseconds dt return int math floor 1000 0 * epoch_timestamp dt
def on_cleanup_list filename skip_nzb False lst cfg cleanup_list if lst name ext os path splitext filename ext ext strip lower name name strip for k in lst item k strip strip ' ' lower item ' ' + item if item ext or ext '' and item name and not skip_nzb and item ' nzb' return Truereturn False
@taskdef prepare_index index_pk from kuma wiki search import WikiDocumentTypefrom kuma search models import Indexcls WikiDocumentTypees cls get_connection 'indexing' index Index objects get pk index_pk Index objects recreate_index es es index index temporary_settings {'index' {'refresh_interval' '-1' 'number_of_replicas' '0'}}es indices put_settings temporary_settings index index prefixed_name
def create_transfer_manager client config osutil None executor_cls Noneif not config use_threads executor_cls NonThreadedExecutorreturn TransferManager client config osutil executor_cls
def test_periodic_command_fixed_delay fd schedule PeriodicCommandFixedDelay at_time at datetime datetime now delay datetime timedelta seconds 2 function lambda None assert fd due is True assert fd next due is False
def test_periodic_command_fixed_delay fd schedule PeriodicCommandFixedDelay at_time at datetime datetime now delay datetime timedelta seconds 2 function lambda None assert fd due is True assert fd next due is False
@click command 'serve_default_site' @click argument 'state' type click Choice ['on' 'off'] def config_serve_default_site state state True if state 'on' else False update_config {'serve_default_site' state}
@click command 'serve_default_site' @click argument 'state' type click Choice ['on' 'off'] def config_serve_default_site state state True if state 'on' else False update_config {'serve_default_site' state}
def get_generated_by_for_biom_tables return 'QIIME' + get_qiime_library_version
def setup_modifiers node field None context None in_tree_view False modifiers {}if field is not None transfer_field_to_modifiers field modifiers transfer_node_to_modifiers node modifiers context context in_tree_view in_tree_view transfer_modifiers_to_node modifiers node
def service_get_by_compute_host context host return IMPL service_get_by_compute_host context host
@set_databasedef get item **kwargs if item selector Nonefor attr value in item iteritems if not selector selector getattr Item attr value else selector & getattr Item attr value return Item get selector
def get_container_data_volumes container volumes_option volumes []volumes_option volumes_option or [] container_mounts dict mount[u'Destination'] mount for mount in container get u'Mounts' or {} image_volumes [VolumeSpec parse volume for volume in container image_config[u'ContainerConfig'] get u'Volumes' or {} ]for volume in set volumes_option + image_volumes if volume external continuemount container_mounts get volume internal if not mount continueif not mount get u'Name' continuevolume volume _replace external mount[u'Name'] volumes append volume return volumes
def to_unicode s encoding None if six PY3 return to_str s encoding else if isinstance s str return s decode encoding or __salt_system_encoding__ return unicode s
def _to_stublist degree_sequence return list chaini [n] * d for n d in enumerate degree_sequence
def get_tag return sys implementation cache_tag
def _removeOldBackRefs senderkey signal receiver receivers try index receivers index receiver except ValueError return Falseelse oldReceiver receivers[index]del receivers[index]found 0signals connections get signal if signals is not None for sig recs in connections get signal {} iteritems if sig signal for rec in recs if rec is oldReceiver found 1breakif not found _killBackref oldReceiver senderkey return Truereturn False
def _removeOldBackRefs senderkey signal receiver receivers try index receivers index receiver except ValueError return Falseelse oldReceiver receivers[index]del receivers[index]found 0signals connections get signal if signals is not None for sig recs in connections get signal {} iteritems if sig signal for rec in recs if rec is oldReceiver found 1breakif not found _killBackref oldReceiver senderkey return Truereturn False
def setup_platform hass config add_devices discovery_info None if discovery_info is None returnhomematic get_component 'homematic' return homematic setup_hmdevice_discovery_helper hass HMLight discovery_info add_devices
def precompute_idfs wglobal dfs total_docs return dict termid wglobal df total_docs for termid df in iteritems dfs
def mark_as_cover container name if name not in container mime_map raise ValueError u'Cannotmark%sascoverasitdoesnotexist' % name mt container mime_map[name]if not is_raster_image mt raise ValueError u'Cannotmark%sasthecoverimageasitisnotarasterimage' % name if container book_type u'azw3' mark_as_cover_azw3 container name else mark_as_cover_epub container name
def mark_as_cover container name if name not in container mime_map raise ValueError u'Cannotmark%sascoverasitdoesnotexist' % name mt container mime_map[name]if not is_raster_image mt raise ValueError u'Cannotmark%sasthecoverimageasitisnotarasterimage' % name if container book_type u'azw3' mark_as_cover_azw3 container name else mark_as_cover_epub container name
def get_indices client try indices list client indices get_settings index '_all' params {'expand_wildcards' 'open closed'} version_number get_version client logger debug 'DetectedElasticsearchversion{0}' format ' ' join map str version_number if version_number > 2 4 2 and version_number < 5 0 0 logger debug 'UsingElasticsearch> 2 4 2<5 0 0' if client indices exists index ' security' logger debug 'Foundthe" security"index Addingtolistofallindices' if not ' security' in indices indices append ' security' logger debug 'Allindices {0}' format indices return indicesexcept Exception as e raise FailedExecution 'Failedtogetindices Error {0}' format e
def new key *args **kwargs return XORCipher key *args **kwargs
def _initialize_headers headers return {} if headers is None else dict headers
def init_addons settings routes True from website addons base import init_addonsettings ADDONS_AVAILABLE getattr settings 'ADDONS_AVAILABLE' [] settings ADDONS_AVAILABLE_DICT getattr settings 'ADDONS_AVAILABLE_DICT' OrderedDict for addon_name in settings ADDONS_REQUESTED if settings USE_POSTGRES try addon apps get_app_config 'addons_{}' format addon_name except LookupError addon Noneelse addon init_addon app addon_name routes routes if addon if addon not in settings ADDONS_AVAILABLE settings ADDONS_AVAILABLE append addon settings ADDONS_AVAILABLE_DICT[addon short_name] addonsettings ADDON_CAPABILITIES render_addon_capabilities settings ADDONS_AVAILABLE
def has_meta_cmd query try first_token query split [0]if first_token lower in u'alter' u'create' u'drop' return Trueexcept Exception return Falsereturn False
def has_meta_cmd query try first_token query split [0]if first_token lower in u'alter' u'create' u'drop' return Trueexcept Exception return Falsereturn False
def base64_decodestring instr if six PY3 b salt utils to_bytes instr data base64 decodebytes b try return salt utils to_str data except UnicodeDecodeError return datareturn base64 decodestring instr
def VarintEncode value result ''if value < 0 raise ValueError 'Varintcannotencodeanegativenumber ' bits value & 127 value >> 7while value result + HIGH_CHR_MAP[bits]bits value & 127 value >> 7result + CHR_MAP[bits]return result
def resolve_email_domain domain try answer dns resolver query domain 'MX' raise_on_no_answer False except dns resolver NXDOMAIN print 'Error Nosuchdomain' domain returnif answer rrset is not None records sorted answer key lambda record record preference print 'Thisdomainhas' len records 'MXrecords' for record in records name record exchange to_text omit_final_dot True print 'Priority' record preference resolve_hostname name else print 'ThisdomainhasnoexplicitMXrecords'print 'AttemptingtoresolveitasanA AAAA orCNAME'resolve_hostname domain
def resolve_email_domain domain try answer dns resolver query domain 'MX' raise_on_no_answer False except dns resolver NXDOMAIN print 'Error Nosuchdomain' domain returnif answer rrset is not None records sorted answer key lambda record record preference print 'Thisdomainhas' len records 'MXrecords' for record in records name record exchange to_text omit_final_dot True print 'Priority' record preference resolve_hostname name else print 'ThisdomainhasnoexplicitMXrecords'print 'AttemptingtoresolveitasanA AAAA orCNAME'resolve_hostname domain
def shutdown_program logging info 'Performingsabnzbdshutdown' sabnzbd halt cherrypy engine exit sabnzbd SABSTOP True
def test_class_injection_does_not_break_collection testdir testdir makeconftest '\nfromtest_injectimportTestClass\ndefpytest_generate_tests metafunc \nTestClass changed_var {}\n' testdir makepyfile test_inject '\nclassTestClass object \ndeftest_injection self \n"""Testbeingparametrized """\npass\n' result testdir runpytest assert 'RuntimeError dictionarychangedsizeduringiteration' not in result stdout str result stdout fnmatch_lines ['*1passed*']
def test_class_injection_does_not_break_collection testdir testdir makeconftest '\nfromtest_injectimportTestClass\ndefpytest_generate_tests metafunc \nTestClass changed_var {}\n' testdir makepyfile test_inject '\nclassTestClass object \ndeftest_injection self \n"""Testbeingparametrized """\npass\n' result testdir runpytest assert 'RuntimeError dictionarychangedsizeduringiteration' not in result stdout str result stdout fnmatch_lines ['*1passed*']
def _sync_db_and_registry qs app_id existing dict m module m for m in qs to_add [m for m in module_registry if m not in existing ]to_delete [m for m in existing if m not in module_registry ]for m in to_add DiscoveryModule objects get_or_create module m app app_id DiscoveryModule objects filter module__in to_delete app app_id delete if to_add or to_delete qs _result_cache None
def remove_users caller role *users if not len users 1 and caller users[0] _check_caller_authority caller role role remove_users *users
def render template **kwargs try return _env get_template template render **kwargs except jinja2 exceptions UndefinedError log misc exception 'UndefinedErrorwhilerendering' + template err_path os path join 'html' 'undef_error html' err_template utils read_file err_path tb traceback format_exc return err_template format pagename template traceback tb
def main ip_addr1 raw_input 'pynet-rtr1IPaddress ' ip_addr2 raw_input 'pynet-rtr2IPaddress ' community_string getpass getpass prompt 'Communitystring ' pynet_rtr1 ip_addr1 community_string 161 pynet_rtr2 ip_addr2 community_string 161 for a_device in pynet_rtr1 pynet_rtr2 print '\n*********************'for the_oid in SYS_NAME SYS_DESCR snmp_data snmp_helper snmp_get_oid a_device oid the_oid output snmp_helper snmp_extract snmp_data print outputprint '*********************'print
def ffill_query_in_range expr lower upper checkpoints None odo_kwargs None ts_field TS_FIELD_NAME odo_kwargs odo_kwargs or {} computed_lower materialized_checkpoints get_materialized_checkpoints checkpoints expr fields lower odo_kwargs pred expr[ts_field] < upper if computed_lower is not None pred & expr[ts_field] > computed_lower raw pd concat materialized_checkpoints odo expr[pred] pd DataFrame **odo_kwargs ignore_index True raw loc[ ts_field] raw loc[ ts_field] astype 'datetime64[ns]' return raw
def ffill_query_in_range expr lower upper checkpoints None odo_kwargs None ts_field TS_FIELD_NAME odo_kwargs odo_kwargs or {} computed_lower materialized_checkpoints get_materialized_checkpoints checkpoints expr fields lower odo_kwargs pred expr[ts_field] < upper if computed_lower is not None pred & expr[ts_field] > computed_lower raw pd concat materialized_checkpoints odo expr[pred] pd DataFrame **odo_kwargs ignore_index True raw loc[ ts_field] raw loc[ ts_field] astype 'datetime64[ns]' return raw
def build_response request data code encoding response Response response encoding encodingresponse raw dataresponse url request urlresponse request requestresponse status_code get_status_code_from_code_response code response raw seek 0 response dispatch_hook u'response' request hooks response return response
def set_urlconf urlconf_name if urlconf_name _urlconfs value urlconf_nameelif hasattr _urlconfs 'value' del _urlconfs value
def _superlative interface comparison_result class ComparisonProxy proxyForInterface interface '_original' def __cmp__ self other return comparison_resultreturn ComparisonProxy
def _superlative interface comparison_result class ComparisonProxy proxyForInterface interface '_original' def __cmp__ self other return comparison_resultreturn ComparisonProxy
def absent name vhost '/' runas None ret {'name' name 'result' True 'comment' '' 'changes' {}}policy_exists __salt__['rabbitmq policy_exists'] vhost name runas runas if not policy_exists ret['comment'] "Policy'{0}{1}'isnotpresent " format vhost name return retif not __opts__['test'] result __salt__['rabbitmq delete_policy'] vhost name runas runas if 'Error' in result ret['result'] Falseret['comment'] result['Error']return retelif 'Deleted' in result ret['comment'] 'Deleted'ret['changes'] {'new' '' 'old' name}if __opts__['test'] ret['result'] Noneret['comment'] "Policy'{0}{1}'willberemoved " format vhost name return ret
def absent name vhost '/' runas None ret {'name' name 'result' True 'comment' '' 'changes' {}}policy_exists __salt__['rabbitmq policy_exists'] vhost name runas runas if not policy_exists ret['comment'] "Policy'{0}{1}'isnotpresent " format vhost name return retif not __opts__['test'] result __salt__['rabbitmq delete_policy'] vhost name runas runas if 'Error' in result ret['result'] Falseret['comment'] result['Error']return retelif 'Deleted' in result ret['comment'] 'Deleted'ret['changes'] {'new' '' 'old' name}if __opts__['test'] ret['result'] Noneret['comment'] "Policy'{0}{1}'willberemoved " format vhost name return ret
def create_gzip_file filepath overwrite compressed_path filepath + ' gz' with open filepath 'rb' as uncompressed gzip_compress_obj zlib compressobj COMPRESSION_LEVEL zlib DEFLATED WBITS uncompressed_data uncompressed read gzipped_data gzip_compress_obj compress uncompressed_data gzipped_data + gzip_compress_obj flush if len gzipped_data > len uncompressed_data logger debug 'Noimprovement %s' % filepath returnwith open compressed_path 'wb' as compressed logger debug 'Compressing %s' % filepath try compressed write gzipped_data except Exception as ex logger critical 'Gzipcompressionfailed %s' % ex if overwrite logger debug 'Overwriting %swith%s' % filepath compressed_path os remove filepath os rename compressed_path filepath
def create_gzip_file filepath overwrite compressed_path filepath + ' gz' with open filepath 'rb' as uncompressed gzip_compress_obj zlib compressobj COMPRESSION_LEVEL zlib DEFLATED WBITS uncompressed_data uncompressed read gzipped_data gzip_compress_obj compress uncompressed_data gzipped_data + gzip_compress_obj flush if len gzipped_data > len uncompressed_data logger debug 'Noimprovement %s' % filepath returnwith open compressed_path 'wb' as compressed logger debug 'Compressing %s' % filepath try compressed write gzipped_data except Exception as ex logger critical 'Gzipcompressionfailed %s' % ex if overwrite logger debug 'Overwriting %swith%s' % filepath compressed_path os remove filepath os rename compressed_path filepath
def create_gzip_file filepath overwrite compressed_path filepath + ' gz' with open filepath 'rb' as uncompressed gzip_compress_obj zlib compressobj COMPRESSION_LEVEL zlib DEFLATED WBITS uncompressed_data uncompressed read gzipped_data gzip_compress_obj compress uncompressed_data gzipped_data + gzip_compress_obj flush if len gzipped_data > len uncompressed_data logger debug 'Noimprovement %s' % filepath returnwith open compressed_path 'wb' as compressed logger debug 'Compressing %s' % filepath try compressed write gzipped_data except Exception as ex logger critical 'Gzipcompressionfailed %s' % ex if overwrite logger debug 'Overwriting %swith%s' % filepath compressed_path os remove filepath os rename compressed_path filepath
def site server_name template_contents None template_source None enabled True check_config True **kwargs if not is_installed 'nginx-common' server config_filename '/etc/nginx/sites-available/%s conf' % server_name context {'port' 80}context update kwargs context['server_name'] server_nametemplate_file config_filename template_contents template_source context use_sudo True link_filename '/etc/nginx/sites-enabled/%s conf' % server_name if enabled if not is_link link_filename run_as_root 'ln-s% config_filename s% link_filename s' % locals if check_config with settings hide 'running' 'warnings' warn_only True if run_as_root 'nginx-t' failed run_as_root 'rm% link_filename s' % locals message red 'Errorin% server_name snginxsiteconfig disablingforsafety ' % locals abort message elif is_link link_filename run_as_root 'rm% link_filename s' % locals reload_service 'nginx'
def ylim *args **kwargs ax gca ret ax set_ylim *args **kwargs draw_if_interactive return ret
def _nova_to_osvif_network network netobj objects network Network id network['id'] bridge_interface network get_meta 'bridge_interface' subnets _nova_to_osvif_subnets network['subnets'] if network['bridge'] is not None netobj bridge network['bridge']if network['label'] is not None netobj label network['label']if network get_meta 'mtu' is not None netobj mtu network get_meta 'mtu' if network get_meta 'multi_host' is not None netobj multi_host network get_meta 'multi_host' if network get_meta 'should_create_bridge' is not None netobj should_provide_bridge network get_meta 'should_create_bridge' if network get_meta 'should_create_vlan' is not None netobj should_provide_vlan network get_meta 'should_create_vlan' if network get_meta 'vlan' is None raise exception NovaException _ 'Missingvlannumberin%s' % network netobj vlan network get_meta 'vlan' return netobj
def js_del_alert ident return 'try{del_message "%s" }catch err {}\n' % ident
def js_del_alert ident return 'try{del_message "%s" }catch err {}\n' % ident
def js_del_alert ident return 'try{del_message "%s" }catch err {}\n' % ident
def _needs_eeg_average_ref_proj info eeg_sel pick_types info meg False eeg True ref_meg False exclude 'bads' return len eeg_sel > 0 and not info['custom_ref_applied'] and not _has_eeg_average_ref_proj info['projs']
def _needs_eeg_average_ref_proj info eeg_sel pick_types info meg False eeg True ref_meg False exclude 'bads' return len eeg_sel > 0 and not info['custom_ref_applied'] and not _has_eeg_average_ref_proj info['projs']
def call_func spec *args return resolve_func spec *args
def map_tag source target source_tag if target u'universal' if source u'wsj' source u'en-ptb'if source u'brown' source u'en-brown'return tagset_mapping source target [source_tag]
def map_tag source target source_tag if target u'universal' if source u'wsj' source u'en-ptb'if source u'brown' source u'en-brown'return tagset_mapping source target [source_tag]
def test_language_has_first_of lang Language assert_equals lang first_of_examples 'Examples'
def ListClientLogs client obj_store auth_credentials request callback def _OnListClientLogs log_urls logging info 'LISTCLIENTLOGS admin %s clientuser_id %d start %s end %s filter %s num_logs %d' % auth_credentials request['user_id'] ClientLog _IsoDate request['start_timestamp'] ClientLog _IsoDate request['end_timestamp'] request get 'filter' None len log_urls response {'log_urls' log_urls}callback response ClientLog ListClientLogs request['user_id'] request['start_timestamp'] request['end_timestamp'] request get 'filter' None _OnListClientLogs
def ListClientLogs client obj_store auth_credentials request callback def _OnListClientLogs log_urls logging info 'LISTCLIENTLOGS admin %s clientuser_id %d start %s end %s filter %s num_logs %d' % auth_credentials request['user_id'] ClientLog _IsoDate request['start_timestamp'] ClientLog _IsoDate request['end_timestamp'] request get 'filter' None len log_urls response {'log_urls' log_urls}callback response ClientLog ListClientLogs request['user_id'] request['start_timestamp'] request['end_timestamp'] request get 'filter' None _OnListClientLogs
def _load_settings validate True settings {'units' DEFAULT_UNITS 'icons' DEFAULT_ICONS 'days' 3 'version' 2}if os path exists settings_file with open settings_file 'rt' as sf s json load sf if 'version' not in s _migrate_settings s settings update s if validate if 'service' not in settings raise SetupError 'Youneedtosetyourweatherservice' 'Usethe"wsetservice"command ' if 'location' not in settings raise SetupError 'Missingdefaultlocation' 'Youmustspecifyadefaultlocationwiththe"wsetlocation"command' return settings
def get_exps_unresolved_answers_for_default_rule exp_ids def _get_explorations_states_tuples_by_ids exp_ids "Returnsalistofall exp_id state_name tuplesforthegiven\nexp_ids \nE g -[\n 'eid1' 'Introduction' \n 'eid1' 'End' \n 'eid2' 'Introduction' \n 'eid3' 'Introduction' \n]\nwhenexp_ids ['eid1' 'eid2' 'eid3'] \n"explorations exp_services get_multiple_explorations_by_id exp_ids strict False return [ exploration id state_name for exploration in explorations values for state_name in exploration states]explorations_states_tuples _get_explorations_states_tuples_by_ids exp_ids exploration_states_answers_list get_top_state_rule_answers_multi explorations_states_tuples [exp_domain DEFAULT_RULESPEC_STR] exps_answers_mapping {}for ind statewise_answers in enumerate exploration_states_answers_list exp_id explorations_states_tuples[ind][0]if exp_id not in exps_answers_mapping exps_answers_mapping[exp_id] {'count' 0 'unresolved_answers' []}for answer in statewise_answers exps_answers_mapping[exp_id]['count'] + answer['count']answer['state'] explorations_states_tuples[ind][1]exps_answers_mapping[exp_id]['unresolved_answers'] extend statewise_answers for exp_id in exps_answers_mapping exps_answers_mapping[exp_id]['unresolved_answers'] sorted exps_answers_mapping[exp_id]['unresolved_answers'] key lambda a a['count'] reverse True return exps_answers_mapping
def get_exps_unresolved_answers_for_default_rule exp_ids def _get_explorations_states_tuples_by_ids exp_ids "Returnsalistofall exp_id state_name tuplesforthegiven\nexp_ids \nE g -[\n 'eid1' 'Introduction' \n 'eid1' 'End' \n 'eid2' 'Introduction' \n 'eid3' 'Introduction' \n]\nwhenexp_ids ['eid1' 'eid2' 'eid3'] \n"explorations exp_services get_multiple_explorations_by_id exp_ids strict False return [ exploration id state_name for exploration in explorations values for state_name in exploration states]explorations_states_tuples _get_explorations_states_tuples_by_ids exp_ids exploration_states_answers_list get_top_state_rule_answers_multi explorations_states_tuples [exp_domain DEFAULT_RULESPEC_STR] exps_answers_mapping {}for ind statewise_answers in enumerate exploration_states_answers_list exp_id explorations_states_tuples[ind][0]if exp_id not in exps_answers_mapping exps_answers_mapping[exp_id] {'count' 0 'unresolved_answers' []}for answer in statewise_answers exps_answers_mapping[exp_id]['count'] + answer['count']answer['state'] explorations_states_tuples[ind][1]exps_answers_mapping[exp_id]['unresolved_answers'] extend statewise_answers for exp_id in exps_answers_mapping exps_answers_mapping[exp_id]['unresolved_answers'] sorted exps_answers_mapping[exp_id]['unresolved_answers'] key lambda a a['count'] reverse True return exps_answers_mapping
def flip_tree node if hasattr node 'root' node node get_root if node left flip_tree node left if node right flip_tree node right node left node right node right node left
def flip_tree node if hasattr node 'root' node node get_root if node left flip_tree node left if node right flip_tree node right node left node right node right node left
def flip_tree node if hasattr node 'root' node node get_root if node left flip_tree node left if node right flip_tree node right node left node right node right node left
def colorStr c return '%02x' * 4 % colorTuple c
def colorStr c return '%02x' * 4 % colorTuple c
def get_default_actions section try default_actions dict section['default_actions'] except IndexError return {} {} action_dict {action get_metadata name action for action in ACTIONS}invalid_action_set default_actions values - action_dict keys invalid_actions {}if len invalid_action_set 0 invalid_actions {bear action for bear action in default_actions items if action in invalid_action_set }for invalid in invalid_actions keys del default_actions[invalid]actions {bearname action_dict[action_name] for bearname action_name in default_actions items }return actions invalid_actions
def set_nonblocking fd fl fcntl fcntl fd fcntl F_GETFL os O_NONBLOCK fcntl fcntl fd fcntl F_SETFL fl
def set_nonblocking fd fl fcntl fcntl fd fcntl F_GETFL os O_NONBLOCK fcntl fcntl fd fcntl F_SETFL fl
def send_export_mail event_id result job DataGetter get_export_jobs event_id if not job returnevent EventModel query get event_id if not event event_name ' Undefined 'else event_name event namesend_email_after_export job user_email event_name result user DataGetter get_user_by_email job user_email send_notif_after_export user event_name result
def send_export_mail event_id result job DataGetter get_export_jobs event_id if not job returnevent EventModel query get event_id if not event event_name ' Undefined 'else event_name event namesend_email_after_export job user_email event_name result user DataGetter get_user_by_email job user_email send_notif_after_export user event_name result
def check_migration_histories histories delete_ghosts False ignore_ghosts False exists SortedSet ghosts []for h in histories try m h get_migration m migration except exceptions UnknownMigration ghosts append h except ImproperlyConfigured passelse exists add m if ghosts if delete_ghosts for h in ghosts h delete elif not ignore_ghosts raise exceptions GhostMigrations ghosts return exists
def repo_refresh m retvals {'rc' 0 'stdout' '' 'stderr' ''}cmd get_cmd m 'refresh' retvals['cmd'] cmd result retvals['rc'] retvals['stdout'] retvals['stderr'] parse_zypper_xml m cmd return retvals
def _convert_args args for i elem in enumerate args if six PY2 if isinstance elem six text_type args[i] elem encode util arg_encoding elif isinstance elem bytes args[i] elem decode util arg_encoding return args
@RegisterWithArgChecks name 'prefix add_local' req_args [ROUTE_DISTINGUISHER PREFIX NEXT_HOP] opt_args [VRF_RF] def add_local route_dist prefix next_hop route_family VRF_RF_IPV4 try tm CORE_MANAGER get_core_service table_managerlabel tm update_vrf_table route_dist prefix next_hop route_family if label label label[0]return [{ROUTE_DISTINGUISHER route_dist PREFIX prefix VRF_RF route_family VPN_LABEL label}]except BgpCoreError as e raise PrefixError desc e
def GetParentDeviceByType device parent_type parent_type parent_type encode 'mac_roman' while IORegistryEntryGetName device parent_type parent ctypes c_void_p response iokit IORegistryEntryGetParentEntry device 'IOService' encode 'mac_roman' ctypes byref parent if response 0 return Nonedevice parentreturn device
def GetParentDeviceByType device parent_type parent_type parent_type encode 'mac_roman' while IORegistryEntryGetName device parent_type parent ctypes c_void_p response iokit IORegistryEntryGetParentEntry device 'IOService' encode 'mac_roman' ctypes byref parent if response 0 return Nonedevice parentreturn device
@frappe whitelist def get_incoming_rate args from erpnext stock stock_ledger import get_previous_sleif isinstance args basestring args json loads args in_rate 0if args get u'serial_no' or u'' strip in_rate get_avg_purchase_rate args get u'serial_no' else valuation_method get_valuation_method args get u'item_code' previous_sle get_previous_sle args if valuation_method u'FIFO' if not previous_sle return 0 0previous_stock_queue json loads previous_sle get u'stock_queue' u'[]' or u'[]' in_rate get_fifo_rate previous_stock_queue args get u'qty' or 0 if previous_stock_queue else 0 elif valuation_method u'MovingAverage' in_rate previous_sle get u'valuation_rate' or 0 return in_rate
@frappe whitelist def get_incoming_rate args from erpnext stock stock_ledger import get_previous_sleif isinstance args basestring args json loads args in_rate 0if args get u'serial_no' or u'' strip in_rate get_avg_purchase_rate args get u'serial_no' else valuation_method get_valuation_method args get u'item_code' previous_sle get_previous_sle args if valuation_method u'FIFO' if not previous_sle return 0 0previous_stock_queue json loads previous_sle get u'stock_queue' u'[]' or u'[]' in_rate get_fifo_rate previous_stock_queue args get u'qty' or 0 if previous_stock_queue else 0 elif valuation_method u'MovingAverage' in_rate previous_sle get u'valuation_rate' or 0 return in_rate
def preflow_push G s t capacity 'capacity' residual None global_relabel_freq 1 value_only False R preflow_push_impl G s t capacity residual global_relabel_freq value_only R graph['algorithm'] 'preflow_push'return R
def preflow_push G s t capacity 'capacity' residual None global_relabel_freq 1 value_only False R preflow_push_impl G s t capacity residual global_relabel_freq value_only R graph['algorithm'] 'preflow_push'return R
@FileSystem in_directory current_directory 'django' 'alfaces' def test_django_background_server_running_in_background_with_custom_port import tornado ioloopimport tornado webclass MainHandler tornado web RequestHandler def get self self write 'Hello world' raise SystemExit def runserver application tornado web Application [ '/' MainHandler ] application listen 9889 tornado ioloop IOLoop instance start server multiprocessing Process target runserver server start time sleep 1 e 'LettucecouldnotrunthebuiltinDjangoserverat0 0 0 0 9889"\nmaybeyouforgota"runserver"instancerunning?\n\nwellifyoureallydonotwantlettucetoruntheserverforyou thenjustrun \n\npythonmanage py--no-server'try status out commands getstatusoutput 'pythonmanage pyharvest--verbosity 3--no-color--port 9889' assert_equals out e assert_not_equals status 0 finally os kill server pid 9
@FileSystem in_directory current_directory 'django' 'alfaces' def test_django_background_server_running_in_background_with_custom_port import tornado ioloopimport tornado webclass MainHandler tornado web RequestHandler def get self self write 'Hello world' raise SystemExit def runserver application tornado web Application [ '/' MainHandler ] application listen 9889 tornado ioloop IOLoop instance start server multiprocessing Process target runserver server start time sleep 1 e 'LettucecouldnotrunthebuiltinDjangoserverat0 0 0 0 9889"\nmaybeyouforgota"runserver"instancerunning?\n\nwellifyoureallydonotwantlettucetoruntheserverforyou thenjustrun \n\npythonmanage py--no-server'try status out commands getstatusoutput 'pythonmanage pyharvest--verbosity 3--no-color--port 9889' assert_equals out e assert_not_equals status 0 finally os kill server pid 9
def averageOnTime vectors numSamples None if vectors ndim 1 vectors shape -1 1 numTimeSteps len vectors numElements len vectors[0] if numSamples is None numSamples numElementscountOn range numElements else countOn numpy random randint 0 numElements numSamples sumOfLengths 0 0onTimeFreqCounts Nonen 0for i in countOn onTime segments durations _listOfOnTimesInVec vectors[ i] if onTime 0 0 sumOfLengths + onTimen + segmentsonTimeFreqCounts _accumulateFrequencyCounts durations onTimeFreqCounts if n > 0 return sumOfLengths / n onTimeFreqCounts else return 0 0 onTimeFreqCounts
def hue_light registry xml_parent data hue_light XML SubElement xml_parent 'org jenkinsci plugins hue__light LightNotifier' hue_light set 'plugin' 'hue-light' lightId XML SubElement hue_light 'lightId' id_mapping [ 'light-id' 'string' None ]helpers convert_mapping_to_xml lightId data id_mapping fail_required True build_mapping [ 'pre-build' 'preBuild' 'blue' 'good-build' 'goodBuild' 'green' 'unstable-build' 'unstableBuild' 'yellow' 'bad-build' 'badBuild' 'red' ]helpers convert_mapping_to_xml hue_light data build_mapping fail_required True
def hue_light registry xml_parent data hue_light XML SubElement xml_parent 'org jenkinsci plugins hue__light LightNotifier' hue_light set 'plugin' 'hue-light' lightId XML SubElement hue_light 'lightId' id_mapping [ 'light-id' 'string' None ]helpers convert_mapping_to_xml lightId data id_mapping fail_required True build_mapping [ 'pre-build' 'preBuild' 'blue' 'good-build' 'goodBuild' 'green' 'unstable-build' 'unstableBuild' 'yellow' 'bad-build' 'badBuild' 'red' ]helpers convert_mapping_to_xml hue_light data build_mapping fail_required True
def hue_light registry xml_parent data hue_light XML SubElement xml_parent 'org jenkinsci plugins hue__light LightNotifier' hue_light set 'plugin' 'hue-light' lightId XML SubElement hue_light 'lightId' id_mapping [ 'light-id' 'string' None ]helpers convert_mapping_to_xml lightId data id_mapping fail_required True build_mapping [ 'pre-build' 'preBuild' 'blue' 'good-build' 'goodBuild' 'green' 'unstable-build' 'unstableBuild' 'yellow' 'bad-build' 'badBuild' 'red' ]helpers convert_mapping_to_xml hue_light data build_mapping fail_required True
def __virtual__ if not salt utils is_windows and 'ip get_interface' in __salt__ return Truereturn False
def service_get_all_by_topic context topic return IMPL service_get_all_by_topic context topic
def _concat_categorical to_concat axis 0 def _concat_asobject to_concat to_concat [ x get_values if is_categorical_dtype x dtype else x ravel for x in to_concat]res _concat_compat to_concat if axis 1 return res reshape 1 len res else return rescategoricals [x for x in to_concat if is_categorical_dtype x dtype ]if len categoricals len to_concat passelse first to_concat[0]if all first is_dtype_equal other for other in to_concat[1 ] return union_categoricals categoricals return _concat_asobject to_concat
def dbValidator fileused getFileUsed host Configuration get 'nupic cluster database host' port int Configuration get 'nupic cluster database port' user Configuration get 'nupic cluster database user' passwd '*' * len Configuration get 'nupic cluster database passwd' print 'ThisscriptwillvalidatethatyourMySQLissetupcorrectlyfor'print 'NuPIC MySQLisrequiredforNuPICswarming Thesettingsare'print 'definedinaconfigurationfilefoundin'print '$NUPIC/src/nupic/support/nupic-default xmlOutoftheboxthose'print "settingscontainMySQL'sdefaultaccesscredentials "printprint 'Thenupic-default xmlcanbeduplicatedtodefineuserspecific'print 'changescallingthecopiedfile'print '$NUPIC/src/nupic/support/nupic-site xmlRefertothe'print 'nupic-default xmlforadditionalinstructions 'printprint 'Defaults localhost 3306 root nopassword'printprint 'RetrievedthefollowingNuPICconfigurationusing ' fileusedprint 'host ' hostprint 'port ' portprint 'user ' userprint 'passwd ' passwdif testDbConnection host port user passwd print 'Connectionsuccessful 'else print "Couldn'tconnecttothedatabaseoryoudon'thavethepermissionsrequiredtocreatedatabasesandtables PleaseensureyouhaveMySQL\ninstalled running accessibleusingtheNuPICconfigurationsettings andtheuserspecifiedhaspermissiontocreatebothdatabasesandtables "
def dbValidator fileused getFileUsed host Configuration get 'nupic cluster database host' port int Configuration get 'nupic cluster database port' user Configuration get 'nupic cluster database user' passwd '*' * len Configuration get 'nupic cluster database passwd' print 'ThisscriptwillvalidatethatyourMySQLissetupcorrectlyfor'print 'NuPIC MySQLisrequiredforNuPICswarming Thesettingsare'print 'definedinaconfigurationfilefoundin'print '$NUPIC/src/nupic/support/nupic-default xmlOutoftheboxthose'print "settingscontainMySQL'sdefaultaccesscredentials "printprint 'Thenupic-default xmlcanbeduplicatedtodefineuserspecific'print 'changescallingthecopiedfile'print '$NUPIC/src/nupic/support/nupic-site xmlRefertothe'print 'nupic-default xmlforadditionalinstructions 'printprint 'Defaults localhost 3306 root nopassword'printprint 'RetrievedthefollowingNuPICconfigurationusing ' fileusedprint 'host ' hostprint 'port ' portprint 'user ' userprint 'passwd ' passwdif testDbConnection host port user passwd print 'Connectionsuccessful 'else print "Couldn'tconnecttothedatabaseoryoudon'thavethepermissionsrequiredtocreatedatabasesandtables PleaseensureyouhaveMySQL\ninstalled running accessibleusingtheNuPICconfigurationsettings andtheuserspecifiedhaspermissiontocreatebothdatabasesandtables "
def render_to_html eq def err s 'Renderasanerrorspan'return '<spanclass "inline-errorinline">{0}</span>' format s def render_arrow arrow 'Turntextarrowsintoprettyones'if arrow '->' return u'\u2192'if arrow '<->' return u'\u2194'return arrowdef render_expression ex '\nRenderachemicalexpression--noarrows \n'try return _render_to_html _get_final_tree ex except ParseException return err ex def spanify s return u'<spanclass "math">{0}</span>' format s left arrow right split_on_arrow eq if arrow '' return spanify render_expression left return spanify render_expression left + render_arrow arrow + render_expression right
@csrf_exemptdef openid_login_complete request redirect_field_name REDIRECT_FIELD_NAME render_failure None render_failure render_failure or default_render_failure openid_response openid_views parse_openid_response request if not openid_response return render_failure request 'ThisisanOpenIDrelyingpartyendpoint ' if openid_response status SUCCESS external_id openid_response identity_urloid_backend openid_auth OpenIDBackend details oid_backend _extract_user_details openid_response log debug 'openidsuccess details %s' details url getattr settings 'OPENID_SSO_SERVER_URL' None external_domain '{0}{1}' format OPENID_DOMAIN_PREFIX url fullname '%s%s' % details get 'first_name' '' details get 'last_name' '' return _external_login_or_signup request external_id external_domain details details get 'email' '' fullname retfun functools partial redirect get_next_url_for_login_page request return render_failure request 'Openidfailure'
def libvlc_audio_equalizer_set_amp_at_index p_equalizer f_amp u_band f _Cfunctions get 'libvlc_audio_equalizer_set_amp_at_index' None or _Cfunction 'libvlc_audio_equalizer_set_amp_at_index' 1 1 1 None ctypes c_int ctypes c_void_p ctypes c_float ctypes c_uint return f p_equalizer f_amp u_band
def has_forum_access uname course_id rolename try role Role objects get name rolename course_id course_id except Role DoesNotExist return Falsereturn role users filter username uname exists
def has_forum_access uname course_id rolename try role Role objects get name rolename course_id course_id except Role DoesNotExist return Falsereturn role users filter username uname exists
def getVector3Paths complexPaths z 0 0 vector3Paths []for complexPath in complexPaths vector3Paths append getVector3Path complexPath z return vector3Paths
def _existing_file_path_option option_name option_value file_path FilePath option_value if not file_path exists raise UsageError u"Problemwith--{} Filedoesnotexist '{}' " format option_name file_path path return file_path
def reset_gametime global GAME_TIME_OFFSETGAME_TIME_OFFSET runtime ServerConfig objects conf 'gametime_offset' GAME_TIME_OFFSET
def reset_gametime global GAME_TIME_OFFSETGAME_TIME_OFFSET runtime ServerConfig objects conf 'gametime_offset' GAME_TIME_OFFSET
@taskdef run command show True *args **kwargs if show print_command command with hide u'running' return _run command *args **kwargs
def remove_targets Rule Ids region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile if isinstance Ids string_types Ids json loads Ids failures conn remove_targets Rule Rule Ids Ids if failures and failures get 'FailedEntryCount' 0 > 0 return {'failures' failures get 'FailedEntries' 1 }else return {'failures' None}except ClientError as e err __utils__['boto3 get_error'] e if e response get 'Error' {} get 'Code' 'RuleNotFoundException' return {'error' 'Rule{0}notfound' format Rule }return {'error' __utils__['boto3 get_error'] e }
def remove_targets Rule Ids region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile if isinstance Ids string_types Ids json loads Ids failures conn remove_targets Rule Rule Ids Ids if failures and failures get 'FailedEntryCount' 0 > 0 return {'failures' failures get 'FailedEntries' 1 }else return {'failures' None}except ClientError as e err __utils__['boto3 get_error'] e if e response get 'Error' {} get 'Code' 'RuleNotFoundException' return {'error' 'Rule{0}notfound' format Rule }return {'error' __utils__['boto3 get_error'] e }
def remove_targets Rule Ids region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile if isinstance Ids string_types Ids json loads Ids failures conn remove_targets Rule Rule Ids Ids if failures and failures get 'FailedEntryCount' 0 > 0 return {'failures' failures get 'FailedEntries' 1 }else return {'failures' None}except ClientError as e err __utils__['boto3 get_error'] e if e response get 'Error' {} get 'Code' 'RuleNotFoundException' return {'error' 'Rule{0}notfound' format Rule }return {'error' __utils__['boto3 get_error'] e }
def branch2 tree if isinstance tree tuple name subtree treeprint name data2[name] print 'subtree' subtree if testxb branchsum data2[name]else branchsum namefor b in subtree branchsum branchsum + branch2 b else leavessum sum data2[bi] for bi in tree print 'finalbranchwith' tree '' join tree leavessum if testxb return leavessumelse return '' join tree print 'workingonbranch' tree branchsum return branchsum
def split a c 134217729 0 * a abig c - a ah c - abig al a - ah return ah al
def SplitBuffer buff index 0 length None buffer_len length or len buff while index < buffer_len encoded_tag data_index ReadTag buff index tag_type ORD_MAP[encoded_tag[0]] & TAG_TYPE_MASK if tag_type WIRETYPE_VARINT _ new_index VarintReader buff data_index yield encoded_tag '' buff[data_index new_index] index new_indexelif tag_type WIRETYPE_FIXED64 yield encoded_tag '' buff[data_index data_index + 8 ] index 8 + data_index elif tag_type WIRETYPE_FIXED32 yield encoded_tag '' buff[data_index data_index + 4 ] index 4 + data_index elif tag_type WIRETYPE_LENGTH_DELIMITED length start VarintReader buff data_index yield encoded_tag buff[data_index start] buff[start start + length ] index start + length else raise rdfvalue DecodeError 'UnexpectedTag '
def cross_domain origin_check is_trusted_origin **options def cross_domain_wrap fn cors_perms {'origin_check' origin_check 'allow_credentials' bool options get 'allow_credentials' }@wraps fn def cross_domain_handler self *args **kwargs if request params get 'hoist' 'cookie' if cors_perms['origin_check'] g origin name request environ['pylons routes_dict']['action_name']resp fn self *args **kwargs c cookies add 'hoist_%s' % name '' join tup resp response content_type 'text/html'return ''else abort 403 else self check_cors return fn self *args **kwargs cross_domain_handler cors_perms cors_permsreturn cross_domain_handlerreturn cross_domain_wrap
def ln label label_len len label + 2 chunk 70 - label_len // 2 out '%s%s%s' % '-' * chunk label '-' * chunk pad 70 - len out if pad > 0 out out + '-' * pad return out
def _prog shell_cmd if not util exe_exists shell_cmd plug_util path_surgery shell_cmd if not util exe_exists shell_cmd return Nonereturn os path basename shell_cmd
def test_replicate_value_error t1 Time '2007 001' scale 'tai' with pytest raises ValueError as err t1 replicate format 'definitely_not_a_valid_format' assert 'formatmustbeoneof' in str err
def test_replicate_value_error t1 Time '2007 001' scale 'tai' with pytest raises ValueError as err t1 replicate format 'definitely_not_a_valid_format' assert 'formatmustbeoneof' in str err
def _synthesize_stim_channel events n_samples onset events[ 0]stim_channel np zeros n_samples int for onset duration trigger in events stim_channel[onset onset + duration ] triggerreturn stim_channel
def tar_backup_files file_paths target backup_file_location targetif not rename backup_file_location '{0}{1}' format backup_file_location BACKUP_ROLLBACK_SUFFIX logging warning "'{0}'notfound Skippingfilerename " format backup_file_location tar tarfile open backup_file_location 'w' for name in file_paths tar add name tar close return backup_file_location
def install_windowsfeatures name return install name source 'windowsfeatures'
def install_windowsfeatures name return install name source 'windowsfeatures'
def _aggr_weighted_mean inList params assert len inList len params weightsSum sum params if weightsSum 0 return NoneweightedMean 0for i elem in enumerate inList weightedMean + elem * params[i] return weightedMean / weightsSum
def importTrialTypes fileName returnFieldNames False logging warning 'importTrialTypesisDEPRECATED asofv1 70 00 Pleaseuse`importConditions`foridenticalfunctionality ' return importConditions fileName returnFieldNames
def importTrialTypes fileName returnFieldNames False logging warning 'importTrialTypesisDEPRECATED asofv1 70 00 Pleaseuse`importConditions`foridenticalfunctionality ' return importConditions fileName returnFieldNames
def get_sd_auth val sd_auth_pillar_name 'serverdensity' sd_pillar __pillar__ get sd_auth_pillar_name log debug 'ServerDensityPillar {0}' format sd_pillar if not sd_pillar log error 'Couldnotload{0}pillar' format sd_auth_pillar_name raise CommandExecutionError '{0}pillarisrequiredforauthentication' format sd_auth_pillar_name try return sd_pillar[val]except KeyError log error 'Couldnotfindvalue{0}inpillar' format val raise CommandExecutionError '{0}valuewasnotfoundinpillar' format val
def sinh x np import_module 'numpy' if isinstance x int float return interval np sinh x np sinh x elif isinstance x interval return interval np sinh x start np sinh x end is_valid x is_valid else raise NotImplementedError
def render sls_data saltenv 'base' sls '' **kws with warnings catch_warnings record True as warn_list data deserialize sls_data or {} for item in warn_list log warning '{warn}foundin{sls}saltenv {env}' format warn item message sls salt utils url create sls env saltenv log debug 'ResultsofSLSrendering \n{0}' format data return data
def payloads tracking_id client_id requestable extra_info None extra_headers None extra_payload {'v' '1' 'tid' tracking_id 'cid' client_id 'aip' '1'}if extra_info for payload in extra_info extra_payload update payload for request_payload in requestable final_payload dict request_payload final_payload update extra_payload yield final_payload extra_headers
def run_func_until_ret_arg fun kwargs fun_call None argument_being_watched None required_argument_response None status Nonewhile status required_argument_response f_result fun kwargs call fun_call r_set {}for d in f_result if isinstance d list d0 d[0]if isinstance d0 dict for k v in six iteritems d0 r_set[k] vstatus _unwrap_dict r_set argument_being_watched log debug 'Function {0} Watchedarg {1} Response {2}' format str fun split '' [1] argument_being_watched status time sleep 5 return True
def create_local_pifs for host_ref in _db_content['host'] keys _create_local_pif host_ref
def all_simple_paths G source target cutoff None if source not in G raise nx NodeNotFound 'sourcenode%snotingraph' % source if target not in G raise nx NodeNotFound 'targetnode%snotingraph' % target if cutoff is None cutoff len G - 1 if G is_multigraph return _all_simple_paths_multigraph G source target cutoff cutoff else return _all_simple_paths_graph G source target cutoff cutoff
def split_in_lines text return line for line in map str strip text split '\n' if line
def _is_msie8or9 if request user_agent is None or request user_agent browser 'msie' or request user_agent version is None return Falseversion tuple map int request user_agent version split ' ' return 8 0 < version < 10 0
def _is_msie8or9 if request user_agent is None or request user_agent browser 'msie' or request user_agent version is None return Falseversion tuple map int request user_agent version split ' ' return 8 0 < version < 10 0
def _is_msie8or9 if request user_agent is None or request user_agent browser 'msie' or request user_agent version is None return Falseversion tuple map int request user_agent version split ' ' return 8 0 < version < 10 0
def _extract_key_val kv delimiter ' ' pieces kv split delimiter key pieces[0]val delimiter join pieces[1 ] return key val
def _extract_key_val kv delimiter ' ' pieces kv split delimiter key pieces[0]val delimiter join pieces[1 ] return key val
def _client_worker_process factory input_queue output_queue is_shutdown log info 'startingupworker %s' threading current_thread client factory while not is_shutdown is_set try workitem input_queue get timeout 1 log debug 'dequeueworkerrequest %s' workitem if not workitem continuetry log debug 'executingrequestonthread %s' workitem result client execute workitem request output_queue put WorkResponse False workitem work_id result except Exception as exception log exception 'errorinworkerthread %s' threading current_thread output_queue put WorkResponse True workitem work_id exception except Exception as ex passlog info 'requestworkershuttingdown %s' threading current_thread
def get_service hass config discovery_info None if config get CONF_APP_ICON is None icon_file os path join os path dirname __file__ ' ' 'frontend' 'www_static' 'icons' 'favicon-192x192 png' app_icon open icon_file 'rb' read else app_icon config get CONF_APP_ICON return GNTPNotificationService config get CONF_APP_NAME app_icon config get CONF_HOSTNAME config get CONF_PASSWORD config get CONF_PORT
def test_can_parse_two_ordinary_steps steps Step many_from_lines I_DIE_HAPPY splitlines + I_LIKE_VEGETABLES splitlines assert_equals len steps 2 assert isinstance steps[0] Step assert isinstance steps[1] Step assert_equals steps[0] sentence I_DIE_HAPPY assert_equals steps[1] sentence I_LIKE_VEGETABLES
def create_task name location '\\' user_name 'System' password None force False **kwargs if name in list_tasks location and not force return '{0}alreadyexists' format name pythoncom CoInitialize task_service win32com client Dispatch 'Schedule Service' task_service Connect task_definition task_service NewTask 0 edit_task task_definition task_definition user_name user_name password password **kwargs add_action task_definition task_definition **kwargs add_trigger task_definition task_definition **kwargs task_folder task_service GetFolder location _save_task_definition name name task_folder task_folder task_definition task_definition user_name task_definition Principal UserID password password logon_type task_definition Principal LogonType if name in list_tasks location return Trueelse return False
def _collect_dirs start_dir blacklist set ['conftest py' 'nox py'] suffix '_test py' for parent subdirs files in os walk start_dir if any f for f in files if f endswith suffix and f not in blacklist del subdirs[ ] yield parent else subdirs[ ] [s for s in subdirs if s[0] isalpha and os path join parent s not in blacklist ]
def logAttrib obj log attrib value None if log or log is None and obj autoLog if value is None value getattr obj attrib message '%s %s %s' % obj name attrib value __repr__ try obj win logOnFlip message level logging EXP obj obj except AttributeError logging log message level logging EXP obj obj
def logAttrib obj log attrib value None if log or log is None and obj autoLog if value is None value getattr obj attrib message '%s %s %s' % obj name attrib value __repr__ try obj win logOnFlip message level logging EXP obj obj except AttributeError logging log message level logging EXP obj obj
def gcd a b while b > 0 a b b a % b return a
def gcd a b while b > 0 a b b a % b return a
def main connection try mprisctl Mpris2Controller except ImportError returntry mprisctl acquire except dbus exceptions DBusException print "mprisinterfacecouldn'tbeinitialized Isdbusproperlyconfigured?"returnmprisctl run connection mprisctl release
def _get_TV codon_lst1 codon_lst2 codon_table default_codon_table purine 'A' 'G' pyrimidine 'C' 'T' TV [0 0]sites 0for codon1 codon2 in zip codon_lst1 codon_lst2 if '---' not in codon1 codon2 for i j in zip codon1 codon2 if i j passelif i in purine and j in purine TV[0] + 1elif i in pyrimidine and j in pyrimidine TV[0] + 1else TV[1] + 1sites + 1return TV[0] / sites TV[1] / sites
def isTestFile filename basename os path basename filename return basename startswith 'test_' and os path splitext basename [1] ' py'
def ping server port s socket socket socket AF_INET socket SOCK_STREAM try s connect server port return Trueexcept socket error return Falsefinally s close
@dispatch Join DataFrame DataFrame def compute_up t lhs rhs **kwargs result pd merge lhs rhs left_on t on_left right_on t on_right how t how suffixes t suffixes return result reset_index [t fields]
@dispatch Join DataFrame DataFrame def compute_up t lhs rhs **kwargs result pd merge lhs rhs left_on t on_left right_on t on_right how t how suffixes t suffixes return result reset_index [t fields]
@dispatch Join DataFrame DataFrame def compute_up t lhs rhs **kwargs result pd merge lhs rhs left_on t on_left right_on t on_right how t how suffixes t suffixes return result reset_index [t fields]
def walk node from collections import dequetodo deque [node] while todo node todo popleft todo extend iter_child_nodes node yield node
def eval_kfold features labels k 10 scan [ 2 ** t for t in range 0 9 1 ] seed 1234 npts len features kf KFold npts n_folds k random_state seed scores []for s in scan scanscores []for train test in kf X_train features[train]y_train labels[train]X_test features[test]y_test labels[test]clf LogisticRegression C s clf fit X_train y_train score clf score X_test y_test scanscores append score print s score scores append np mean scanscores print scoress_ind np argmax scores s scan[s_ind]print s_ind s return s
def delete_message queue region receipthandle opts None user None queues list_queues region opts user url_map _parse_queue_list queues if queue not in url_map log info '"{0}"queuedoesnotexist ' format queue return Falseout _run_aws 'delete-message' region opts user receipthandle receipthandle queue url_map[queue] return True
def delete_message queue region receipthandle opts None user None queues list_queues region opts user url_map _parse_queue_list queues if queue not in url_map log info '"{0}"queuedoesnotexist ' format queue return Falseout _run_aws 'delete-message' region opts user receipthandle receipthandle queue url_map[queue] return True
def delete_message queue region receipthandle opts None user None queues list_queues region opts user url_map _parse_queue_list queues if queue not in url_map log info '"{0}"queuedoesnotexist ' format queue return Falseout _run_aws 'delete-message' region opts user receipthandle receipthandle queue url_map[queue] return True
def delete_message queue region receipthandle opts None user None queues list_queues region opts user url_map _parse_queue_list queues if queue not in url_map log info '"{0}"queuedoesnotexist ' format queue return Falseout _run_aws 'delete-message' region opts user receipthandle receipthandle queue url_map[queue] return True
def compare_dataset_states discovered_datasets desired_datasets for dataset_id in set discovered_datasets set desired_datasets desired_dataset desired_datasets get dataset_id discovered_dataset discovered_datasets get dataset_id if not compare_dataset_state discovered_dataset discovered_dataset desired_dataset desired_dataset return Falsereturn True
def set_computer_name name if name and six PY2 name name decode 'utf-8' if windll kernel32 SetComputerNameExW win32con ComputerNamePhysicalDnsHostname name ret {'ComputerName' {'Current' get_computer_name }}pending get_pending_computer_name if pending not in None False ret['ComputerName']['Pending'] pendingreturn retreturn False
def check_user_tags dt try frappe db sql u'select`_user_tags`from`tab%s`limit1' % dt except Exception as e if e args[0] 1054 DocTags dt setup
def check_user_tags dt try frappe db sql u'select`_user_tags`from`tab%s`limit1' % dt except Exception as e if e args[0] 1054 DocTags dt setup
def check_user_tags dt try frappe db sql u'select`_user_tags`from`tab%s`limit1' % dt except Exception as e if e args[0] 1054 DocTags dt setup
def read_hdf5 fname title 'h5io' slash 'ignore' h5py _check_h5py if not op isfile fname raise IOError 'file"%s"notfound' % fname if not isinstance title string_types raise ValueError 'titlemustbeastring' with h5py File fname mode 'r' as fid if title not in fid raise ValueError 'no"%s"datafound' % title if isinstance fid[title] h5py Group if 'TITLE' not in fid[title] attrs raise ValueError 'no"%s"datafound' % title data _triage_read fid[title] slash slash return data
def xml_findall xpath def xpath_findall value validate ET iselement value return value findall xpath return transform xpath_findall
def _run_server local_addr local_addr_family local_socket_type local_linger_args remote_addr remote_addr_family remote_socket_type queue class _ThreadedTCPServer SocketServer ThreadingMixIn SocketServer TCPServer object 'Threadedstreamingserverforforwarding'address_family local_addr_familysocket_type local_socket_typeallow_reuse_address Truedef __init__ self handler_class_factory partial _TCPHandler local_linger_args local_linger_args remote_addr remote_addr remote_addr_family remote_addr_family remote_socket_type remote_socket_type super _ThreadedTCPServer self __init__ local_addr handler_class_factory bind_and_activate True server _ThreadedTCPServer queue put [server socket family server server_address] queue close server serve_forever
def _teardown_log global logif log exception_logging_enabled log disable_exception_logging if log warnings_logging_enabled log disable_warnings_logging del logtry logging _acquireLock try loggerDict logging Logger manager loggerDictfor key in loggerDict keys if key 'astropy' or key startswith 'astropy ' del loggerDict[key]finally logging _releaseLock except Exception pass
def _teardown_log global logif log exception_logging_enabled log disable_exception_logging if log warnings_logging_enabled log disable_warnings_logging del logtry logging _acquireLock try loggerDict logging Logger manager loggerDictfor key in loggerDict keys if key 'astropy' or key startswith 'astropy ' del loggerDict[key]finally logging _releaseLock except Exception pass
def patharg path return path replace '\\' '\\\\\\'
def patharg path return path replace '\\' '\\\\\\'
def get_cpu_info try with open CPU_INFO_PATH as fp content fp read except IOError return {}lines content split '\n' result []item Nonelines_count len lines for index line in enumerate lines line line strip if not line if item and index lines_count result append item continuesplit line split ' ' if len split 2 continuename split[0] replace ' DCTB ' '' strip replace '' '_' value split[1] replace ' DCTB ' '' strip if name 'processor' item {}item[name] valuereturn result
def solve_rational_inequalities eqs result S EmptySetfor _eqs in eqs if not _eqs continueglobal_intervals [Interval S NegativeInfinity S Infinity ]for numer denom rel in _eqs numer_intervals solve_poly_inequality numer * denom rel denom_intervals solve_poly_inequality denom ' ' intervals []for numer_interval in numer_intervals for global_interval in global_intervals interval numer_interval intersect global_interval if interval is not S EmptySet intervals append interval global_intervals intervalsintervals []for global_interval in global_intervals for denom_interval in denom_intervals global_interval - denom_intervalif global_interval is not S EmptySet intervals append global_interval global_intervals intervalsif not global_intervals breakfor interval in global_intervals result result union interval return result
def get_trail_by_arn cloudtrail_client trail_arn trails cloudtrail_client describe_trails ['trailList']for trail in trails if trail get 'TrailARN' None trail_arn return trailraise ValueError 'Atrailcouldnotbefoundfor%s' % trail_arn
def getNode template context Context name 'subject' for node in template if isinstance node BlockNode and node name name return node render context elif isinstance node ExtendsNode return getNode node nodelist context name raise Exception "Node'%s'couldnotbefoundintemplate " % name
def _unhandled_mock_read filename raise CommandExecutionError 'Unhandledmockreadfor{0}' format filename
def _unhandled_mock_read filename raise CommandExecutionError 'Unhandledmockreadfor{0}' format filename
def _unhandled_mock_read filename raise CommandExecutionError 'Unhandledmockreadfor{0}' format filename
def _unhandled_mock_read filename raise CommandExecutionError 'Unhandledmockreadfor{0}' format filename
def sort_fields elem field_orders order_dicts dict for field order in field_orders items order_dicts[field] order_key dict for i subfield in enumerate order order_key[subfield] i_sort_fields elem order_dicts
def _listToPhrase things finalDelimiter delimiter ' ' if not isinstance things list tuple raise TypeError 'Thingsmustbealistoratuple' if not things return ''if len things 1 return str things[0] if len things 2 return '%s%s%s' % str things[0] finalDelimiter str things[1] else strThings []for thing in things strThings append str thing return '%s%s%s%s' % delimiter join strThings[ -1 ] delimiter finalDelimiter strThings[ -1 ]
def _listToPhrase things finalDelimiter delimiter ' ' if not isinstance things list tuple raise TypeError 'Thingsmustbealistoratuple' if not things return ''if len things 1 return str things[0] if len things 2 return '%s%s%s' % str things[0] finalDelimiter str things[1] else strThings []for thing in things strThings append str thing return '%s%s%s%s' % delimiter join strThings[ -1 ] delimiter finalDelimiter strThings[ -1 ]
def decode_args args stdin_encoding return [ arg decode stdin_encoding if type arg bytes else arg for arg in args]
def decode_args args stdin_encoding return [ arg decode stdin_encoding if type arg bytes else arg for arg in args]
def list_targets Rule region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile targets conn list_targets_by_rule Rule Rule ret []if targets and 'Targets' in targets keys 'Id' 'Arn' 'Input' 'InputPath' for target in targets get 'Targets' ret append dict [ k target get k for k in keys if k in target ] return {'targets' ret}else return {'targets' None}except ClientError as e err __utils__['boto3 get_error'] e if e response get 'Error' {} get 'Code' 'RuleNotFoundException' return {'error' 'Rule{0}notfound' format Rule }return {'error' __utils__['boto3 get_error'] e }
def E_nl_dirac n l spin_up True Z 1 c Float '137 035999037' if not l > 0 raise ValueError "'l'mustbepositiveorzero" if not n > l raise ValueError "'n'mustbegreaterthan'l'" if l 0 and spin_up is False raise ValueError 'Spinmustbeupforl 0 ' if spin_up skappa - l - 1 else skappa - l c S c beta sqrt skappa ** 2 - Z ** 2 / c ** 2 return c ** 2 / sqrt 1 + Z ** 2 / n + skappa + beta ** 2 / c ** 2 - c ** 2
def direct_get_container node part account container marker None limit None prefix None delimiter None conn_timeout 5 response_timeout 15 end_marker None reverse None path '/%s/%s' % account container return _get_direct_account_container path 'Container' node part marker marker limit limit prefix prefix delimiter delimiter end_marker end_marker reverse reverse conn_timeout conn_timeout response_timeout response_timeout
def WakeStuckFlow session_id session_id rdfvalue SessionID session_id woken 0checked_pending Falsewith queue_manager QueueManager as manager for request responses in manager FetchRequestsAndResponses session_id if not checked_pending task manager Query request client_id task_id 'task %s' % request request task_id if task returnchecked_pending Trueif not responses or responses[ -1 ] type rdf_flows GrrMessage Type STATUS manager QueueClientMessage request request woken + 1if responses and responses[ -1 ] type rdf_flows GrrMessage Type STATUS manager QueueNotification session_id return woken
def get path objectType user None ret {'Path' path 'ACLs' []}sidRet _getUserSid user if path and objectType dc daclConstants objectTypeBit dc getObjectTypeBit objectType path dc processPath path objectTypeBit tdacl _get_dacl path objectTypeBit if tdacl for counter in range 0 tdacl GetAceCount tAce tdacl GetAce counter if not sidRet['sid'] or tAce[2] sidRet['sid'] ret['ACLs'] append _ace_to_text tAce objectTypeBit return ret
def association_proxy target_collection attr **kw return AssociationProxy target_collection attr **kw
def association_proxy target_collection attr **kw return AssociationProxy target_collection attr **kw
def association_proxy target_collection attr **kw return AssociationProxy target_collection attr **kw
def iplot figure_or_data show_link True link_text 'Exporttoplot ly' validate True image None filename 'plot_image' image_width 800 image_height 600 if not __PLOTLY_OFFLINE_INITIALIZED raise PlotlyError '\n' join ['PlotlyOfflinemodehasnotbeeninitializedinthisnotebook Run ' '' 'importplotly' 'plotly offline init_notebook_mode #runatthestartofeveryipythonnotebook'] if not ipython raise ImportError '`iplot`canonlyruninsideanIPythonNotebook ' config {}config['showLink'] show_linkconfig['linkText'] link_text plot_html plotdivid width height _plot_html figure_or_data config validate '100%' 525 True ipython_display display ipython_display HTML plot_html if image if image not in __IMAGE_FORMATS raise ValueError 'Theimageparametermustbeoneofthefollowing {}' format __IMAGE_FORMATS script get_image_download_script 'iplot' format format image width image_width height image_height filename filename plot_id plotdivid time sleep 1 ipython_display display ipython_display HTML script
def base64image src return base64 b64encode _get_file src
def fit_mps dist data x0 None xsorted np sort data if x0 is None x0 getstartparams dist xsorted args xsorted dist print x0 return optimize fmin logmps x0 args args
@documented_contextmanagerdef _setenv variables if callable variables variables variables clean_revert variables pop 'clean_revert' False previous {}new []for key value in variables iteritems if key in state env previous[key] state env[key]else new append key state env[key] valuetry yield finally if clean_revert for key value in variables iteritems if key in state env and value state env[key] if key in previous state env[key] previous[key]else del state env[key]else state env update previous for key in new del state env[key]
def exp_server_version return odoo release version
@monkeypatch_method pdb Pdb 'Pdb' def user_return self frame return_value if self _wait_for_mainpyfile if self mainpyfile self canonic frame f_code co_filename or frame f_lineno < 0 returnself _wait_for_mainpyfile 0self _old_Pdb_user_return frame return_value
@monkeypatch_method pdb Pdb 'Pdb' def user_return self frame return_value if self _wait_for_mainpyfile if self mainpyfile self canonic frame f_code co_filename or frame f_lineno < 0 returnself _wait_for_mainpyfile 0self _old_Pdb_user_return frame return_value
def main parser init_parser args parser parse_args level logging INFOif args debug level logging DEBUGlogging basicConfig format '% asctime s% levelname s% filename s % lineno s% message s' level level logging info 'Loggingstarted' message 'Backingup'if args source_code message + 'sourceand'message + 'datafor {0}' format args app_id logging info message zk_connection_locations appscale_info get_zk_locations_string zookeeper zk ZKTransaction host zk_connection_locations db_info appscale_info get_db_info table db_info[' table']skip_list args skipif not skip_list skip_list []logging info 'Willskipthefollowingkinds {0}' format sorted skip_list ds_backup DatastoreBackup args app_id zookeeper table source_code args source_code skip_list sorted skip_list try ds_backup run finally zookeeper close
def main parser init_parser args parser parse_args level logging INFOif args debug level logging DEBUGlogging basicConfig format '% asctime s% levelname s% filename s % lineno s% message s' level level logging info 'Loggingstarted' message 'Backingup'if args source_code message + 'sourceand'message + 'datafor {0}' format args app_id logging info message zk_connection_locations appscale_info get_zk_locations_string zookeeper zk ZKTransaction host zk_connection_locations db_info appscale_info get_db_info table db_info[' table']skip_list args skipif not skip_list skip_list []logging info 'Willskipthefollowingkinds {0}' format sorted skip_list ds_backup DatastoreBackup args app_id zookeeper table source_code args source_code skip_list sorted skip_list try ds_backup run finally zookeeper close
@register tagdef full_tree_for_model parser token bits token contents split if len bits 4 raise template TemplateSyntaxError _ u'%stagrequiresthreearguments' % bits[0] if bits[2] u'as' raise template TemplateSyntaxError _ u"secondargumentto%stagmustbe'as'" % bits[0] return FullTreeForModelNode bits[1] bits[3]
@register tagdef full_tree_for_model parser token bits token contents split if len bits 4 raise template TemplateSyntaxError _ u'%stagrequiresthreearguments' % bits[0] if bits[2] u'as' raise template TemplateSyntaxError _ u"secondargumentto%stagmustbe'as'" % bits[0] return FullTreeForModelNode bits[1] bits[3]
def acls_from_account_info info acl parse_acl version 2 data info get 'sysmeta' {} get 'core-access-control' if acl is None return Noneadmin_members acl get 'admin' [] readwrite_members acl get 'read-write' [] readonly_members acl get 'read-only' [] if not any admin_members readwrite_members readonly_members return Nonereturn {'admin' admin_members 'read-write' readwrite_members 'read-only' readonly_members}
def max_partition table schema 'default' field None filter None metastore_conn_id 'metastore_default' from airflow hooks hive_hooks import HiveMetastoreHookif ' ' in table schema table table split ' ' hh HiveMetastoreHook metastore_conn_id metastore_conn_id return hh max_partition schema schema table_name table field field filter filter
def tmin a lowerlimit None axis 0 inclusive True nan_policy 'propagate' a axis _chk_asarray a axis am _mask_to_limits a lowerlimit None inclusive False contains_nan nan_policy _contains_nan am nan_policy if contains_nan and nan_policy 'omit' am ma masked_invalid am res ma minimum reduce am axis dataif res ndim 0 return res[ ]return res
def tmin a lowerlimit None axis 0 inclusive True nan_policy 'propagate' a axis _chk_asarray a axis am _mask_to_limits a lowerlimit None inclusive False contains_nan nan_policy _contains_nan am nan_policy if contains_nan and nan_policy 'omit' am ma masked_invalid am res ma minimum reduce am axis dataif res ndim 0 return res[ ]return res
def _createDumpDir if not conf dumpTable and not conf dumpAll and not conf search returnconf dumpPath paths SQLMAP_DUMP_PATH % conf hostname if not os path isdir conf dumpPath try os makedirs conf dumpPath 493 except OSError as ex tempDir tempfile mkdtemp prefix 'sqlmapdump' warnMsg 'unabletocreatedumpdirectory'warnMsg + "'%s' %s " % conf dumpPath getUnicode ex warnMsg + "Usingtemporarydirectory'%s'instead" % tempDir logger warn warnMsg conf dumpPath tempDir
def _build_m3u_filename basename basename re sub '[\\s /\\\\\'\\"]' '_' basename date datetime datetime now strftime '%Y%m%d_%Hh%M' path normpath os path join config['importfeeds']['dir'] as_filename date + '_' + basename + ' m3u' return path
def _require_permission code name content_type from django contrib auth models import Permissioncriteria {'codename' code 'name' name 'content_type' content_type}permission Permission objects get_or_create **criteria [0]return permission
def split w_dyad if 1 in w_dyad return bit Fraction 1 1 child1 [Fraction 0 ] * len w_dyad child2 list 2 * f for f in w_dyad while True for ind val in enumerate child2 if val > bit child2[ind] - bitchild1[ind] + bitif sum child1 1 return tuple child1 tuple child2 bit / 2raise ValueError 'Somethingwrongwithinput{}' format w_dyad
def personas_reviewer_required f @login_required@functools wraps f def wrapper request *args **kw if _view_on_get request or acl check_personas_reviewer request return f request *args **kw raise PermissionDeniedreturn wrapper
@context quietfunc@with_devicedef makedirs path if path '/' makedirs os path dirname path mkdir path
@memoizedef version version __salt__['pkg version'] 'kapacitor' if not version version str __salt__['config option'] 'kapacitor version' 'latest' return version
def get_type type_ if isinstance type_ list type_ tuple type_ for k v in TYPE_MAP iteritems if k type_ return vraise KeyError 'Unknowntype%r' % type_
def get_email recipients sender u'' msg u'' subject u'[NoSubject]' text_content None footer None print_html None formatted None attachments None content None reply_to None cc [] email_account None expose_recipients None content content or msg emailobj EMail sender recipients subject reply_to reply_to cc cc email_account email_account expose_recipients expose_recipients if not content strip startswith u'<' content markdown content emailobj set_html content text_content footer footer print_html print_html formatted formatted if isinstance attachments dict attachments [attachments]for attach in attachments or [] emailobj add_attachment **attach return emailobj
@register filterdef sort_version_aware versions return sorted versions key lambda version comparable_version version verbose_name reverse True
@register filterdef sort_version_aware versions return sorted versions key lambda version comparable_version version verbose_name reverse True
@register filterdef sort_version_aware versions return sorted versions key lambda version comparable_version version verbose_name reverse True
def require_map_reduce conn try import spidermonkeyexcept BaseException try from ming import mimif hasattr conn 'conn' and isinstance conn conn mim Connection import testtoolsraise testtools testcase TestSkipped 'requiresspidermonkey' except ImportError import testtoolsraise testtools testcase TestSkipped 'requiresmim'
def make_gax_publisher_api credentials None host None if credentials is None channel insecure_channel host else channel make_secure_channel credentials DEFAULT_USER_AGENT PublisherClient SERVICE_ADDRESS return PublisherClient channel channel
def get_unsupported_lower_protocol if Version CASSANDRA_VERSION > Version '3 0' return 2else return None
def load_full_proto timestamp java_application False full_key make_key timestamp + config FULL_SUFFIX if java_application full_key '"' + full_key + '"' full_binary memcache get full_key namespace config KEY_NAMESPACE if full_binary is None logging debug 'Nofullrecordat%s' full_key return Nonetry full StatsProto full_binary except Exception as err logging warn 'Badfullrecordat%s %s' full_key err return Noneif full start_timestamp_milliseconds int timestamp * 1000 logging debug 'Hashcollision recordat%dhastimestamp%d' int timestamp * 1000 full start_timestamp_milliseconds return Nonereturn full
def _get_vsan_eligible_disks service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_system host_ref configManager vsanSystemif vsan_system is None msg "VSANSystemConfigManagerisunsetforhost'{0}' VSANconfigurationcannotbechangedwithoutaconfiguredVSANSystem " format host_name log debug msg ret update {host_name {'Error' msg}} continuesuitable_disks []query vsan_system QueryDisksForVsan for item in query if item state 'eligible' suitable_disks append item if not suitable_disks msg "Thehost'{0}'doesnothaveanyVSANeligibledisks " format host_name log warning msg ret update {host_name {'Eligible' msg}} continuedisks _get_host_ssds host_ref + _get_host_non_ssds host_ref matching []for disk in disks for suitable_disk in suitable_disks if disk canonicalName suitable_disk disk canonicalName matching append disk ret update {host_name {'Eligible' matching}} return ret
def _get_vsan_eligible_disks service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_system host_ref configManager vsanSystemif vsan_system is None msg "VSANSystemConfigManagerisunsetforhost'{0}' VSANconfigurationcannotbechangedwithoutaconfiguredVSANSystem " format host_name log debug msg ret update {host_name {'Error' msg}} continuesuitable_disks []query vsan_system QueryDisksForVsan for item in query if item state 'eligible' suitable_disks append item if not suitable_disks msg "Thehost'{0}'doesnothaveanyVSANeligibledisks " format host_name log warning msg ret update {host_name {'Eligible' msg}} continuedisks _get_host_ssds host_ref + _get_host_non_ssds host_ref matching []for disk in disks for suitable_disk in suitable_disks if disk canonicalName suitable_disk disk canonicalName matching append disk ret update {host_name {'Eligible' matching}} return ret
def _get_vsan_eligible_disks service_instance host host_names ret {}for host_name in host_names host_ref _get_host_ref service_instance host host_name host_name vsan_system host_ref configManager vsanSystemif vsan_system is None msg "VSANSystemConfigManagerisunsetforhost'{0}' VSANconfigurationcannotbechangedwithoutaconfiguredVSANSystem " format host_name log debug msg ret update {host_name {'Error' msg}} continuesuitable_disks []query vsan_system QueryDisksForVsan for item in query if item state 'eligible' suitable_disks append item if not suitable_disks msg "Thehost'{0}'doesnothaveanyVSANeligibledisks " format host_name log warning msg ret update {host_name {'Eligible' msg}} continuedisks _get_host_ssds host_ref + _get_host_non_ssds host_ref matching []for disk in disks for suitable_disk in suitable_disks if disk canonicalName suitable_disk disk canonicalName matching append disk ret update {host_name {'Eligible' matching}} return ret
def _process_key evt key evt GetKeyCode if key in KEYMAP return KEYMAP[key] '' if 97 < key < 122 key - 32if key > 32 and key < 127 return keys Key chr key chr key else return None None
def IsBucket name return ObjectStore HasInstance name
def filter_capabilities_by_languages bears languages languages set language lower for language in languages language_bears_capabilities {language set set for language in languages}for section_bears in bears values for bear in section_bears bear_language {language lower for language in bear LANGUAGES} {'all'} & languages language bear_language pop if bear_language else '' capabilities language_bears_capabilities[language] if language else tuple language_bears_capabilities update {language capabilities[0] bear can_detect capabilities[1] bear CAN_FIX } if language else {} return language_bears_capabilities
def bench_optimizer optimizer param_grid return sum apply_optimizer optimizer func a b for func a b in param_grid
def retrieve_contributions_calendar username base_url base_url base_url + 'users/' + username try url base_url + '/contributions' page urlopen url except HTTPError URLError as e print 'Therewasaproblemfetchingdatafrom{0}' format url print eraise SystemExitreturn page read decode 'utf-8'
def fix_case name for s r in LOCALE_NORMALIZATION items name name replace s r return name
def fix_case name for s r in LOCALE_NORMALIZATION items name name replace s r return name
@contextmanagerdef _start_worker_process app concurrency 1 pool u'solo' loglevel WORKER_LOGLEVEL logfile None **kwargs from celery apps multi import Cluster Nodeapp set_current cluster Cluster [Node u'testworker1@%h' ] cluster start yield cluster stopwait
def verify_structure memlen itemsize ndim shape strides offset if offset % itemsize return Falseif offset < 0 or offset + itemsize > memlen return Falseif any v % itemsize for v in strides return Falseif ndim < 0 return ndim 0 and not shape and not strides if 0 in shape return Trueimin sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] < 0 imax sum strides[j] * shape[j] - 1 for j in range ndim if strides[j] > 0 return 0 < offset + imin and offset + imax + itemsize < memlen
@register filterdef follows from_user to_user try relationship Relationship objects get_relationship from_user to_user if relationship and not relationship is_blocked return Trueelse return Falseexcept AttributeError return False
@register filterdef follows from_user to_user try relationship Relationship objects get_relationship from_user to_user if relationship and not relationship is_blocked return Trueelse return Falseexcept AttributeError return False
def _skip_nonwhitespace data pos while pos < len data if data[pos] isspace breakpos + 1return pos
def _skip_nonwhitespace data pos while pos < len data if data[pos] isspace breakpos + 1return pos
def make_fastq_rec header seq qual offset 33 result []if header startswith '>' header header[1 ]result append '@' + header result append seq result append '+' + header result append '' join map chr [ 33 + i for i in qual] return '\n' join result
def get_provider vm_ None if vm_ is None provider __active_provider_name__ or 'ec2' else provider vm_ get 'provider' 'ec2' if ' ' in provider prov_comps provider split ' ' provider prov_comps[0]return provider
def _SetMustSplitOnFirstLeaf node def FindFirstLeaf node if isinstance node pytree Leaf return nodereturn FindFirstLeaf node children[0] pytree_utils SetNodeAnnotation FindFirstLeaf node pytree_utils Annotation MUST_SPLIT True
def b36 number if not number or number < 0 return B36_ALPHABET[0]base36 []while number number i divmod number 36 base36 append B36_ALPHABET[i] return '' join reversed base36
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
def read_pyc filename data read_file filename 'rb' if not is_gae and data[ 4] imp get_magic raise SystemError 'compiledcodeisincompatible' return marshal loads data[marshal_header_size ]
def get_cms_block_link block page return u'//{}/{}/{}' format settings CMS_BASE page block location
def setup_test_view cursor connection cursor cursor execute 'DROPVIEWIFEXISTStko_test_view_2' cursor execute get_create_test_view_sql
def setup_test_view cursor connection cursor cursor execute 'DROPVIEWIFEXISTStko_test_view_2' cursor execute get_create_test_view_sql
def setup_test_view cursor connection cursor cursor execute 'DROPVIEWIFEXISTStko_test_view_2' cursor execute get_create_test_view_sql
def skel_setup environment inventory for key value in environment iteritems if key 'version' continuefor _key _value in value iteritems if _key not in inventory logger debug 'Key%saddedtoinventory' _key inventory[_key] {}if _key endswith 'container' if 'hosts' not in inventory[_key] inventory[_key]['hosts'] []else if 'children' not in inventory[_key] inventory[_key]['children'] []if 'hosts' not in inventory[_key] inventory[_key]['hosts'] []if 'belongs_to' in _value for assignment in _value['belongs_to'] if assignment not in inventory logger debug 'Createdgroup%s' assignment inventory[assignment] {}if 'children' not in inventory[assignment] inventory[assignment]['children'] []if 'hosts' not in inventory[assignment] inventory[assignment]['hosts'] []
def get_weight name backend socket '/var/run/haproxy sock' ha_conn _get_conn socket ha_cmd haproxy cmds getWeight server name backend backend return ha_conn sendCmd ha_cmd
def get_weight name backend socket '/var/run/haproxy sock' ha_conn _get_conn socket ha_cmd haproxy cmds getWeight server name backend backend return ha_conn sendCmd ha_cmd
@print_durationdef mthread_run urls reqs multithread_request urls resps [req resp for req in reqs]
def fastfn outs mode None model None model modelcontext model return model fastfn outs mode
def graycode_subsets gray_code_set for bitstring in list GrayCode len gray_code_set generate_gray yield get_subset_from_bitstring gray_code_set bitstring
def correlation_sum indicators embedding_dim if not indicators ndim 2 raise ValueError 'Indicatorsmustbeamatrix' if not indicators shape[0] indicators shape[1] raise ValueError 'Indicatormatrixmustbesymmetric square ' if embedding_dim 1 indicators_joint indicatorselse corrsum indicators correlation_sum indicators embedding_dim - 1 indicators_joint indicators[1 1 ] * indicators[ -1 -1 ] nobs len indicators_joint corrsum np mean indicators_joint[np triu_indices nobs 1 ] return corrsum indicators_joint
@commands u'endmeeting' @example u' endmeeting' def endmeeting bot trigger if not ismeetingrunning trigger sender bot say u"Can'tdothat startmeetingfirst" returnif not ischair trigger nick trigger sender bot say u'Onlymeetingheadorchairscandothat' returnmeeting_length time time - meetings_dict[trigger sender][u'start'] bot say u'\x02Meetingended \x0ftotalmeetinglength%dseconds' % meeting_length logHTML_end trigger sender htmllog_url meeting_log_baseurl + quote trigger sender + u'/' + figure_logfile_name trigger sender + u' html' logplain u'Meetingendedby%s totalmeetinglength%dseconds' % trigger nick meeting_length trigger sender bot say u'Meetingminutes ' + htmllog_url meetings_dict[trigger sender] Ddict dict del meeting_actions[trigger sender]
def create_test_cache_folder if not os path isdir sickbeard CACHE_DIR os mkdir sickbeard CACHE_DIR
def get blob_key return BlobInfo get blob_key
def transpose_axes data axes asaxes 'CTZYX' for ax in axes if ax not in asaxes raise ValueError 'unknownaxis%s' % ax shape data shapefor ax in reversed asaxes if ax not in axes axes ax + axes shape 1 + shape data data reshape shape data data transpose [axes index ax for ax in asaxes] return data
def transpose_axes data axes asaxes 'CTZYX' for ax in axes if ax not in asaxes raise ValueError 'unknownaxis%s' % ax shape data shapefor ax in reversed asaxes if ax not in axes axes ax + axes shape 1 + shape data data reshape shape data data transpose [axes index ax for ax in asaxes] return data
def transpose_axes data axes asaxes 'CTZYX' for ax in axes if ax not in asaxes raise ValueError 'unknownaxis%s' % ax shape data shapefor ax in reversed asaxes if ax not in axes axes ax + axes shape 1 + shape data data reshape shape data data transpose [axes index ax for ax in asaxes] return data
@require_authorized_admin@dynamic_settingsdef edit_facility_user request ds facility_user_id user_being_edited get_object_or_404 FacilityUser id facility_user_id or None title _ 'Edituser% username s' % {'username' user_being_edited username} return _facility_user request user_being_edited user_being_edited is_teacher user_being_edited is_teacher title title
def filelines source_file source_file seek 0 2 while True line source_file readline if not line sleep 0 1 continue yield line
def get_config_drive_type if CONF config_drive_format 'iso9660' config_drive_type 'cdrom'elif CONF config_drive_format 'vfat' config_drive_type 'disk'else raise exception ConfigDriveUnknownFormat format CONF config_drive_format return config_drive_type
def get_scanner hass config scanner FritzBoxScanner config[DOMAIN] return scanner if scanner success_init else None
def get_scanner hass config scanner FritzBoxScanner config[DOMAIN] return scanner if scanner success_init else None
def get_displayable_collection_summary_dicts_matching_ids collection_ids collection_summaries collection_services get_collection_summaries_matching_ids collection_ids return _get_displayable_collection_summary_dicts collection_summaries
def get_displayable_collection_summary_dicts_matching_ids collection_ids collection_summaries collection_services get_collection_summaries_matching_ids collection_ids return _get_displayable_collection_summary_dicts collection_summaries
def frender path **keywords return Template open path read filename path **keywords
def kill_process proc p1_group psutil Process proc pid child_pids p1_group get_children recursive True for child_pid in child_pids os kill child_pid pid signal SIGKILL
def poisson2d N dtype 'd' format None if N 1 diags asarray [[4]] dtype dtype return dia_matrix diags [0] shape 1 1 asformat format offsets array [0 - N N -1 1] diags empty 5 N ** 2 dtype dtype diags[0] 4diags[1 ] -1 diags[3 N - 1 N] 0diags[4 N N] 0return dia_matrix diags offsets shape N ** 2 N ** 2 asformat format
def assure_image fnc @wraps fnc def _wrapped self img *args **kwargs if not isinstance img Image img self _manager get img return fnc self img *args **kwargs return _wrapped
def assure_image fnc @wraps fnc def _wrapped self img *args **kwargs if not isinstance img Image img self _manager get img return fnc self img *args **kwargs return _wrapped
def _romberg_diff b c k tmp 4 0 ** k return tmp * c - b / tmp - 1 0
def connect_to_cloud_monitoring region None return _create_client ep_name 'monitor' region region
def remove_check module check_id consul_api get_consul_api module if check_id in consul_api agent checks consul_api agent check deregister check_id module exit_json changed True id check_id module exit_json changed False id check_id
def _pmap_model klass record {u'category' u'map' u'fields' {u'key' sorted fqpn cls for cls in klass _checked_key_types u'value' sorted fqpn cls for cls in klass _checked_value_types }}further_classes set for cls in klass _checked_key_types + klass _checked_value_types further_classes add cls return record further_classes
@dodef upload_packages scratch_directory target_bucket version build_server top_level distribution_names available_distributions flocker_source_path top_level for distribution_name in distribution_names distribution DISTRIBUTION_NAME_MAP[distribution_name]architecture distribution native_package_architecture yield update_repo package_directory scratch_directory child '{}-{}-{}' format distribution name distribution version architecture target_bucket target_bucket target_key os path join distribution name + get_package_key_suffix version distribution version architecture source_repo os path join build_server 'results/omnibus' version '{}-{}' format distribution name distribution version packages FLOCKER_PACKAGES flocker_version version distribution distribution
@dodef upload_packages scratch_directory target_bucket version build_server top_level distribution_names available_distributions flocker_source_path top_level for distribution_name in distribution_names distribution DISTRIBUTION_NAME_MAP[distribution_name]architecture distribution native_package_architecture yield update_repo package_directory scratch_directory child '{}-{}-{}' format distribution name distribution version architecture target_bucket target_bucket target_key os path join distribution name + get_package_key_suffix version distribution version architecture source_repo os path join build_server 'results/omnibus' version '{}-{}' format distribution name distribution version packages FLOCKER_PACKAGES flocker_version version distribution distribution
def choose_package file_type file_name if not file_type return Nonefile_type file_type lower file_name file_name lower if 'apk' in file_name return 'apk'elif 'zip' in file_type return 'apk'else return 'apk'
def xml_add_items data try xml '' join [xml_item item for item in data[config ITEMS]] except xml xml_dict data return xml
def get_default_mrcluster global MR_CACHEglobal MR_NAME_CACHEtry all_mrclusters return MR_CACHE get MR_NAME_CACHE except KeyError candidates all_mrclusters if candidates return candidates values [0]return None
def getipbyhost hostname return socket gethostbyname hostname
def bzr_wc_target_exists_no_update test 'bzr_wc_target_exists_no_update'wt '%s-test-%s' % DIR test puts magenta 'Executingtest %s' % test from fabric api import runfrom fabtools files import is_dirfrom fabtools import requireassert not is_dir wt require bazaar working_copy REMOTE_URL wt version '2' require bazaar working_copy REMOTE_URL wt update False assert_wc_exists wt assert run 'bzrrevno%s' % wt '2'
def enqueue_flag_exploration_email_task exploration_id report_text reporter_id payload {'exploration_id' exploration_id 'report_text' report_text 'reporter_id' reporter_id}taskqueue_services enqueue_task feconf TASK_URL_FLAG_EXPLORATION_EMAILS payload 0
def ae_load token_key import gdata alt app_enginekey_name '' join 'gd_auth_token' token_key token_string gdata alt app_engine get_token key_name if token_string is not None return token_from_blob token_string else return None
def get_remote_branch pass
def _download_dataset dataset_dir for filename in [_TRAIN_DATA_FILENAME _TRAIN_LABELS_FILENAME _TEST_DATA_FILENAME _TEST_LABELS_FILENAME] filepath os path join dataset_dir filename if not os path exists filepath print 'Downloadingfile%s ' % filename def _progress count block_size total_size sys stdout write '\r>>Downloading% 1f%%' % float count * block_size / float total_size * 100 0 sys stdout flush filepath _ urllib request urlretrieve _DATA_URL + filename filepath _progress print with tf gfile GFile filepath as f size f Size print 'Successfullydownloaded' filename size 'bytes '
def _require_permission_set user directory positive_permissions None negative_permissions None from pootle_app models permissions import PermissionSetcriteria {'user' user 'directory' directory}permission_set PermissionSet objects get_or_create **criteria [0]if positive_permissions is not None permission_set positive_permissions set positive_permissions if negative_permissions is not None permission_set negative_permissions set negative_permissions permission_set save return permission_set
def wordlist_to_graph_file wordlist dbfile strip True from whoosh filedb structfile import StructFileg GraphCorrector from_word_list wordlist strip strip if isinstance dbfile string_type dbfile open dbfile 'wb' if not isinstance dbfile StructFile dbfile StructFile dbfile g to_file dbfile
def removeDuplicates variable oldList variable split os pathsep newList []for i in oldList if i not in newList newList append i newVariable os pathsep join newList return newVariable
def is_reducible circuit nqubits begin end current_circuit for ndx in reversed range begin end next_gate circuit[ndx]current_circuit next_gate + current_circuit if is_scalar_matrix current_circuit nqubits False return Truereturn False
def avg_and_total iterable items 0total 0 0for item in iterable total + itemitems + 1return total / items total
def axis0_safe_slice X mask len_mask if len_mask 0 return X[safe_mask X mask ]return np zeros shape 0 X shape[1]
def axis0_safe_slice X mask len_mask if len_mask 0 return X[safe_mask X mask ]return np zeros shape 0 X shape[1]
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME remote_config {'name' 'HomeAssistant' 'description' config get CONF_NAME 'id' 'ha component soundtouch' 'port' config get CONF_PORT 'host' config get CONF_HOST }soundtouch_device SoundTouchDevice name remote_config DEVICES append soundtouch_device add_devices [soundtouch_device] descriptions load_yaml_config_file path join path dirname __file__ 'services yaml' hass services register DOMAIN SERVICE_PLAY_EVERYWHERE play_everywhere_service descriptions get SERVICE_PLAY_EVERYWHERE schema SOUNDTOUCH_PLAY_EVERYWHERE hass services register DOMAIN SERVICE_CREATE_ZONE create_zone_service descriptions get SERVICE_CREATE_ZONE schema SOUNDTOUCH_CREATE_ZONE_SCHEMA hass services register DOMAIN SERVICE_REMOVE_ZONE_SLAVE remove_zone_slave descriptions get SERVICE_REMOVE_ZONE_SLAVE schema SOUNDTOUCH_REMOVE_ZONE_SCHEMA hass services register DOMAIN SERVICE_ADD_ZONE_SLAVE add_zone_slave descriptions get SERVICE_ADD_ZONE_SLAVE schema SOUNDTOUCH_ADD_ZONE_SCHEMA
def test_breadcrumb c LocalizingClient response c get reverse 'search' doc pq response content href doc ' breadcrumbsa' [0]eq_ '/' href attrib['href'][0]
def get_flag_url comment if get_comment_app_name DEFAULT_COMMENTS_APP and hasattr get_comment_app 'get_flag_url' return get_comment_app get_flag_url comment else return urlresolvers reverse 'django contrib comments views moderation flag' args comment id
@taskdef python code show True setup u"importos os environ['DJANGO_SETTINGS_MODULE'] '%s settings' importdjango django setup " % env proj_app full_code u'python-c"%s%s"' % setup code replace u'`' u'\\\\`' with project if show print_command code result run full_code show False return result
def test_install_from_local_directory_with_symlinks_to_directories script data to_install data packages join 'symlinks' result script pip 'install' to_install expect_error False pkg_folder script site_packages / 'symlinks' egg_info_folder script site_packages / 'symlinks-0 1 dev0-py%s egg-info' % pyversion assert pkg_folder in result files_created str result stdout assert egg_info_folder in result files_created str result
def test_install_from_local_directory_with_symlinks_to_directories script data to_install data packages join 'symlinks' result script pip 'install' to_install expect_error False pkg_folder script site_packages / 'symlinks' egg_info_folder script site_packages / 'symlinks-0 1 dev0-py%s egg-info' % pyversion assert pkg_folder in result files_created str result stdout assert egg_info_folder in result files_created str result
def parent_dir_action parent fn action cmd_action parent cmds OpenParentDir fn hotkeys SECONDARY_ACTION action setIcon icons folder return action
def mountroot_for_test test_case mountroot FilePath test_case mktemp mountroot makedirs test_case addCleanup umount_all mountroot return mountroot
def mountroot_for_test test_case mountroot FilePath test_case mktemp mountroot makedirs test_case addCleanup umount_all mountroot return mountroot
def mountroot_for_test test_case mountroot FilePath test_case mktemp mountroot makedirs test_case addCleanup umount_all mountroot return mountroot
def limit_validation_results validation messages validation['messages']lim settings VALIDATOR_MESSAGE_LIMITif lim and len messages > lim TYPES {'error' 0 'warning' 2 'notice' 3}def message_key message if message get 'signing_severity' return 1else return TYPES get message get 'type' messages sort key message_key leftover_count len messages - lim del messages[lim ]if validation['errors'] msg_type 'error'elif validation['warnings'] msg_type 'warning'else msg_type 'notice'compat_type msg_type if any msg get 'compatibility_type' for msg in messages else None messages insert 0 {'tier' 1 'type' msg_type 'id' ['validation' 'messages' 'truncated'] 'message' _ "Validationgeneratedtoomanyerrors/warningsso%smessagesweretruncated Afteraddressingthevisiblemessages you'llbeabletoseetheothers " % leftover_count 'description' [] 'compatibility_type' compat_type}
def getKex kexAlgorithm if kexAlgorithm not in _kexAlgorithms raise error ConchError 'Unsupportedkeyexchangealgorithm %s' % kexAlgorithm return _kexAlgorithms[kexAlgorithm]
def poly_collection_2d_to_3d col zs 0 zdir u'z' segments_3d codes paths_to_3d_segments_with_codes col get_paths zs zdir col __class__ Poly3DCollectioncol set_verts_and_codes segments_3d codes col set_3d_properties
def get_imports project pydefined pymodule pydefined get_module module module_imports ModuleImports project pymodule if pymodule pydefined return [stmt import_info for stmt in module imports]return module get_used_imports pydefined
def get_imports project pydefined pymodule pydefined get_module module module_imports ModuleImports project pymodule if pymodule pydefined return [stmt import_info for stmt in module imports]return module get_used_imports pydefined
def ndependents dependencies dependents result dict num_needed dict k len v for k v in dependents items current set k for k v in num_needed items if v 0 while current key current pop result[key] 1 + sum result[parent] for parent in dependents[key] for child in dependencies[key] num_needed[child] - 1if num_needed[child] 0 current add child return result
def ndependents dependencies dependents result dict num_needed dict k len v for k v in dependents items current set k for k v in num_needed items if v 0 while current key current pop result[key] 1 + sum result[parent] for parent in dependents[key] for child in dependencies[key] num_needed[child] - 1if num_needed[child] 0 current add child return result
def ndependents dependencies dependents result dict num_needed dict k len v for k v in dependents items current set k for k v in num_needed items if v 0 while current key current pop result[key] 1 + sum result[parent] for parent in dependents[key] for child in dependencies[key] num_needed[child] - 1if num_needed[child] 0 current add child return result
def _parse_query_string_settings query_kwargs settings None def list_from_query_string s return s split ' ' parsers {'int' int 'float' float 'bool' bool 'list str' lambda s list_from_query_string s 'list escaped' lambda s [urllib2 unquote e for e in list_from_query_string s ] 'list int' lambda s [int i for i in list_from_query_string s ] }settings settings or {} for key in settings if key in query_kwargs query_value query_kwargs[key]needed_type settings[key]if needed_type 'str' try query_kwargs[key] parsers[needed_type] query_value except KeyError ValueError del query_kwargs[key]return query_kwargs
def _parse_query_string_settings query_kwargs settings None def list_from_query_string s return s split ' ' parsers {'int' int 'float' float 'bool' bool 'list str' lambda s list_from_query_string s 'list escaped' lambda s [urllib2 unquote e for e in list_from_query_string s ] 'list int' lambda s [int i for i in list_from_query_string s ] }settings settings or {} for key in settings if key in query_kwargs query_value query_kwargs[key]needed_type settings[key]if needed_type 'str' try query_kwargs[key] parsers[needed_type] query_value except KeyError ValueError del query_kwargs[key]return query_kwargs
def main arguments None if arguments is None arguments sys argv[1 ]server_parameters get_server_parameters arguments config get_config server_parameters config_path configure_log config server_parameters log_level upper importer get_importer config validate_config config server_parameters with get_context server_parameters config importer as context application get_application context run_server application context try logging debug 'thumborrunningat%s %d' % context server ip context server port tornado ioloop IOLoop instance start except KeyboardInterrupt sys stdout write '\n' sys stdout write '--thumborclosedbyuserinterruption--\n'
def get_user email profile 'splunk' **kwargs user_map list_users profile user_found email lower in user_map keys if not kwargs get 'user_details' False and user_found return Trueelif kwargs get 'user_details' False and user_found user user_map[email lower ]response {}for field in ['defaultApp' 'realname' 'name' 'email'] response[field] user[field]response['roles'] []for role in user role_entities response['roles'] append role name return responsereturn False
def get_dims x if isinstance x float or isinstance x int return []elif isinstance x tf Tensor or isinstance x tf Variable return x get_shape as_list elif isinstance x np ndarray return list x shape elif isinstance x RandomVariable return x get_batch_shape as_list else raise NotImplementedError
def subtest_nocleanup function def wrapped self *args **kwds self _cleanup Falseself decored result function self *args **kwds return resultwrapped func_name function func_namereturn wrapped
def test_atomic_download_failure pd seg pd create seg e Exception 'Anything' with pytest raises Exception as err with pd download seg raise eassert err value is e assert not pd is_running seg assert not pd contains seg
def test_atomic_download_failure pd seg pd create seg e Exception 'Anything' with pytest raises Exception as err with pd download seg raise eassert err value is e assert not pd is_running seg assert not pd contains seg
def det a shape 1 a shape[0] a shape[1] batched_a reshape Reshape shape a batched_det BatchDet batched_a return reshape Reshape batched_det
def tree_decode buf ofs 0while ofs < len buf z buf find '\x00' ofs assert z > ofs spl buf[ofs z] split '' 1 assert len spl 2 mode name splsha buf[ z + 1 z + 1 + 20 ]ofs z + 1 + 20 yield int mode 8 name sha
def add_parser_help p p add_argument u'-h' u'--help' action argparse _HelpAction help u'Showthishelpmessageandexit '
def add_parser_help p p add_argument u'-h' u'--help' action argparse _HelpAction help u'Showthishelpmessageandexit '
def define_rss global CFGtry for r in CFG['rss'] ConfigRSS r CFG['rss'][r] except KeyError pass
def define_rss global CFGtry for r in CFG['rss'] ConfigRSS r CFG['rss'][r] except KeyError pass
def define_rss global CFGtry for r in CFG['rss'] ConfigRSS r CFG['rss'][r] except KeyError pass
def define_rss global CFGtry for r in CFG['rss'] ConfigRSS r CFG['rss'][r] except KeyError pass
def _convert_write_result operation command result affected result get 'n' 0 res {'ok' 1 'n' affected}errmsg result get 'errmsg' result get 'err' '' if errmsg if result get 'wtimeout' res['writeConcernError'] {'errmsg' errmsg 'code' 64 'errInfo' {'wtimeout' True}}else error {'index' 0 'code' result get 'code' 8 'errmsg' errmsg}if 'errInfo' in result error['errInfo'] result['errInfo']res['writeErrors'] [error]return resif operation 'insert' res['n'] len command['documents'] elif operation 'update' if 'upserted' in result res['upserted'] [{'index' 0 '_id' result['upserted']}]elif result get 'updatedExisting' is False and affected 1 update command['updates'][0]_id update['u'] get '_id' update['q'] get '_id' res['upserted'] [{'index' 0 '_id' _id}]return res
def get_fullname user None if not user user frappe session userif not hasattr frappe local u'fullnames' frappe local fullnames {}if not frappe local fullnames get user p frappe db get_value u'User' user [u'first_name' u'last_name'] as_dict True if p frappe local fullnames[user] u'' join filter None [p get u'first_name' p get u'last_name' ] or user else frappe local fullnames[user] userreturn frappe local fullnames get user
def ytdl_is_updateable from zipimport import zipimporterreturn isinstance globals get u'__loader__' zipimporter or hasattr sys u'frozen'
def _screenshot viewport None alpha True return read_pixels viewport alpha
def xldate_from_time_tuple time_tuple hour minute second time_tupleif 0 < hour < 24 and 0 < minute < 60 and 0 < second < 60 return second / 60 0 + minute / 60 0 + hour / 24 0 raise XLDateBadTuple 'Invalid hour minute second %r' % hour minute second
def attach_epic_custom_attributes queryset as_field 'epic_custom_attributes_attr' model queryset modelsql '\nSELECTjson_agg \nrow_to_json custom_attributes_epiccustomattribute \nORDERBYcustom_attributes_epiccustomattribute order\n \nFROMcustom_attributes_epiccustomattribute\nWHEREcustom_attributes_epiccustomattribute project_id {tbl} id\n'sql sql format tbl model _meta db_table queryset queryset extra select {as_field sql} return queryset
def last_arg_byref args return args[ -1 ] _obj value
@keras_testdef test_sequence_to_sequence X_train y_train X_test y_test get_test_data nb_train 500 nb_test 200 input_shape 3 5 output_shape 3 5 classification False model Sequential model add TimeDistributedDense y_train shape[ -1 ] input_shape X_train shape[1] X_train shape[2] model compile loss 'hinge' optimizer 'rmsprop' history model fit X_train y_train nb_epoch 20 batch_size 16 validation_data X_test y_test verbose 0 assert history history['val_loss'][ -1 ] < 0 8
@keras_testdef test_sequence_to_sequence X_train y_train X_test y_test get_test_data nb_train 500 nb_test 200 input_shape 3 5 output_shape 3 5 classification False model Sequential model add TimeDistributedDense y_train shape[ -1 ] input_shape X_train shape[1] X_train shape[2] model compile loss 'hinge' optimizer 'rmsprop' history model fit X_train y_train nb_epoch 20 batch_size 16 validation_data X_test y_test verbose 0 assert history history['val_loss'][ -1 ] < 0 8
def escape_parameter text return escape_identifier text replace '-' '_'
def at_server_reload_stop pass
def at_server_reload_stop pass
def iternext_impl func def wrapper context builder sig args pair_type sig return_typepairobj context make_helper builder pair_type func context builder sig args _IternextResult context builder pairobj return impl_ret_borrowed context builder pair_type pairobj _getvalue return wrapper
def iternext_impl func def wrapper context builder sig args pair_type sig return_typepairobj context make_helper builder pair_type func context builder sig args _IternextResult context builder pairobj return impl_ret_borrowed context builder pair_type pairobj _getvalue return wrapper
def iternext_impl func def wrapper context builder sig args pair_type sig return_typepairobj context make_helper builder pair_type func context builder sig args _IternextResult context builder pairobj return impl_ret_borrowed context builder pair_type pairobj _getvalue return wrapper
def iternext_impl func def wrapper context builder sig args pair_type sig return_typepairobj context make_helper builder pair_type func context builder sig args _IternextResult context builder pairobj return impl_ret_borrowed context builder pair_type pairobj _getvalue return wrapper
def delete_asset course_key asset_key try content contentstore find asset_key except NotFoundError raise AssetNotFoundExceptioncontentstore 'trashcan' save content if content thumbnail_location is not None thumbnail_location course_key make_asset_key 'thumbnail' asset_key name try thumbnail_content contentstore find thumbnail_location contentstore 'trashcan' save thumbnail_content contentstore delete thumbnail_content get_id del_cached_content thumbnail_location except Exception logging warning 'Couldnotdeletethumbnail %s' thumbnail_location contentstore delete content get_id del_cached_content content location
def get_data module doctype_info get_doctype_info module data build_config_from_file module if not data data build_standard_config module doctype_info else add_custom_doctypes data doctype_info add_section data _ u'CustomReports' u'fafa-list-alt' get_report_list module data combine_common_sections data data apply_permissions data return data
def test_against_pytpm_doc_example fk5_in SkyCoord u'12h22m54 899s' u'15d49m20 57s' frame FK5 equinox u'J2000' pytpm_out BarycentricTrueEcliptic lon 178 78256462 * u deg lat 16 7597002513 * u deg equinox u'J2000' astropy_out fk5_in transform_to pytpm_out assert pytpm_out separation astropy_out < 1 * u arcmin
def test_against_pytpm_doc_example fk5_in SkyCoord u'12h22m54 899s' u'15d49m20 57s' frame FK5 equinox u'J2000' pytpm_out BarycentricTrueEcliptic lon 178 78256462 * u deg lat 16 7597002513 * u deg equinox u'J2000' astropy_out fk5_in transform_to pytpm_out assert pytpm_out separation astropy_out < 1 * u arcmin
def test_against_pytpm_doc_example fk5_in SkyCoord u'12h22m54 899s' u'15d49m20 57s' frame FK5 equinox u'J2000' pytpm_out BarycentricTrueEcliptic lon 178 78256462 * u deg lat 16 7597002513 * u deg equinox u'J2000' astropy_out fk5_in transform_to pytpm_out assert pytpm_out separation astropy_out < 1 * u arcmin
def test_against_pytpm_doc_example fk5_in SkyCoord u'12h22m54 899s' u'15d49m20 57s' frame FK5 equinox u'J2000' pytpm_out BarycentricTrueEcliptic lon 178 78256462 * u deg lat 16 7597002513 * u deg equinox u'J2000' astropy_out fk5_in transform_to pytpm_out assert pytpm_out separation astropy_out < 1 * u arcmin
def _get_col_o2o parent subname subcls fk_col_name deferrable None initially None ondelete None onupdate None assert subcls Attributes table_name is not None '%rhasnotablename ' % subcls col_args col_kwargs sanitize_args subcls Attributes sqla_column_args _sp_attrs_to_sqla_constraints parent subcls col_kwargs pk_column get_pk_columns subcls pk_key pk_spyne_type pk_columnpk_sqla_type _get_sqlalchemy_type pk_spyne_type if fk_col_name is None fk_col_name subname + '_' + pk_key assert fk_col_name subname 'Thecolumnnamefortheforeignkeymustbedifferentfromthecolumnnamefortheobjectitself 'fk ForeignKey '%s %s' % subcls Attributes table_name pk_key use_alter True name '%s_%s_fkey' % subcls Attributes table_name fk_col_name deferrable deferrable initially initially ondelete ondelete onupdate onupdate return Column fk_col_name pk_sqla_type fk *col_args **col_kwargs
def _get_col_o2o parent subname subcls fk_col_name deferrable None initially None ondelete None onupdate None assert subcls Attributes table_name is not None '%rhasnotablename ' % subcls col_args col_kwargs sanitize_args subcls Attributes sqla_column_args _sp_attrs_to_sqla_constraints parent subcls col_kwargs pk_column get_pk_columns subcls pk_key pk_spyne_type pk_columnpk_sqla_type _get_sqlalchemy_type pk_spyne_type if fk_col_name is None fk_col_name subname + '_' + pk_key assert fk_col_name subname 'Thecolumnnamefortheforeignkeymustbedifferentfromthecolumnnamefortheobjectitself 'fk ForeignKey '%s %s' % subcls Attributes table_name pk_key use_alter True name '%s_%s_fkey' % subcls Attributes table_name fk_col_name deferrable deferrable initially initially ondelete ondelete onupdate onupdate return Column fk_col_name pk_sqla_type fk *col_args **col_kwargs
def fix_iteration_tables cursor connection cursor cursor execute 'DROPTABLEtko_iteration_attributes' cursor execute _CREATE_ITERATION_ATTRIBUTES cursor execute 'DROPTABLEtko_iteration_result' cursor execute _CREATE_ITERATION_RESULTS
def fix_iteration_tables cursor connection cursor cursor execute 'DROPTABLEtko_iteration_attributes' cursor execute _CREATE_ITERATION_ATTRIBUTES cursor execute 'DROPTABLEtko_iteration_result' cursor execute _CREATE_ITERATION_RESULTS
def fix_iteration_tables cursor connection cursor cursor execute 'DROPTABLEtko_iteration_attributes' cursor execute _CREATE_ITERATION_ATTRIBUTES cursor execute 'DROPTABLEtko_iteration_result' cursor execute _CREATE_ITERATION_RESULTS
def serial_listen_ports migrate_data ports []if migrate_data obj_attr_is_set 'serial_listen_ports' ports migrate_data serial_listen_portsreturn ports
def traverse_tree course queue [course]while len queue > 0 node queue pop queue extend node get_children return True
def isReadable poller for fdmask in poller poll 0 mask fdmask[1]if mask & POLLIN return True
def isReadable poller for fdmask in poller poll 0 mask fdmask[1]if mask & POLLIN return True
def isReadable poller for fdmask in poller poll 0 mask fdmask[1]if mask & POLLIN return True
def must_not_be_rejected func @functools wraps func def wrapped *args **kwargs node get_or_http_error Node kwargs get 'nid' kwargs get 'pid' allow_deleted True if node sanction and node sanction is_rejected raise HTTPError http GONE data dict message_long 'Thisregistrationhasbeenrejected' return func *args **kwargs return wrapped
def must_not_be_rejected func @functools wraps func def wrapped *args **kwargs node get_or_http_error Node kwargs get 'nid' kwargs get 'pid' allow_deleted True if node sanction and node sanction is_rejected raise HTTPError http GONE data dict message_long 'Thisregistrationhasbeenrejected' return func *args **kwargs return wrapped
def must_not_be_rejected func @functools wraps func def wrapped *args **kwargs node get_or_http_error Node kwargs get 'nid' kwargs get 'pid' allow_deleted True if node sanction and node sanction is_rejected raise HTTPError http GONE data dict message_long 'Thisregistrationhasbeenrejected' return func *args **kwargs return wrapped
def must_not_be_rejected func @functools wraps func def wrapped *args **kwargs node get_or_http_error Node kwargs get 'nid' kwargs get 'pid' allow_deleted True if node sanction and node sanction is_rejected raise HTTPError http GONE data dict message_long 'Thisregistrationhasbeenrejected' return func *args **kwargs return wrapped
def get_configuration dev bmRequestType util build_request_type util CTRL_IN util CTRL_TYPE_STANDARD util CTRL_RECIPIENT_DEVICE return dev ctrl_transfer bmRequestType bRequest 8 data_or_wLength 1 [0]
def yield_address space start length None reverse False if not length length linux_process_info address_sizecont Truewhile space is_valid_address start and cont try value read_address space start length yield value except struct error cont False yield None if reverse start - lengthelse start + length
def libvlc_video_get_spu_delay p_mi f _Cfunctions get 'libvlc_video_get_spu_delay' None or _Cfunction 'libvlc_video_get_spu_delay' 1 None ctypes c_int64 MediaPlayer return f p_mi
def register_plugin impl name None if name is None name impl namewith REGISTRY_LOCK PLUGIN_REGISTRY[name] implif name not in PLUGIN_DEPENDENTS PLUGIN_DEPENDENTS[name] set for dep in impl dependencies if dep not in PLUGIN_DEPENDENTS PLUGIN_DEPENDENTS[dep] set PLUGIN_DEPENDENTS[dep] add name
def objtag accessing_obj accessed_obj *args **kwargs return accessed_obj tags get *args
def test_non_broadcasting_parameters a 3b np array [[1 2 3] [4 5 6]] c np array [[1 2 3 4] [1 2 3 4]] class TestModel Model p1 Parameter p2 Parameter p3 Parameter def evaluate self *args returnfor args in itertools permutations a b c with pytest raises InputParameterError TestModel *args
def test_non_broadcasting_parameters a 3b np array [[1 2 3] [4 5 6]] c np array [[1 2 3 4] [1 2 3 4]] class TestModel Model p1 Parameter p2 Parameter p3 Parameter def evaluate self *args returnfor args in itertools permutations a b c with pytest raises InputParameterError TestModel *args
def get_cert_file try current_path os path realpath __file__ ca_cert_path os path join current_path ' ' ' ' ' ' 'conf' 'cacert pem' return os path abspath ca_cert_path except Exception return None
def enforce_shopping_cart_enabled func def func_wrapper *args **kwargs '\nWrapperfunctionthatdoestheenforcementthat\ntheshoppingcartfeatureisenabled\n'if not is_shopping_cart_enabled raise Http404return func *args **kwargs return func_wrapper
def enforce_shopping_cart_enabled func def func_wrapper *args **kwargs '\nWrapperfunctionthatdoestheenforcementthat\ntheshoppingcartfeatureisenabled\n'if not is_shopping_cart_enabled raise Http404return func *args **kwargs return func_wrapper
def enforce_shopping_cart_enabled func def func_wrapper *args **kwargs '\nWrapperfunctionthatdoestheenforcementthat\ntheshoppingcartfeatureisenabled\n'if not is_shopping_cart_enabled raise Http404return func *args **kwargs return func_wrapper
def enforce_shopping_cart_enabled func def func_wrapper *args **kwargs '\nWrapperfunctionthatdoestheenforcementthat\ntheshoppingcartfeatureisenabled\n'if not is_shopping_cart_enabled raise Http404return func *args **kwargs return func_wrapper
def filldoc docdict unindent_params True if unindent_params docdict unindent_dict docdict def decorate f f __doc__ docformat f __doc__ docdict return freturn decorate
def remove_docker_files for filename in ['dev yml' 'docker-compose yml' ' dockerignore'] os remove os path join PROJECT_DIRECTORY filename shutil rmtree os path join PROJECT_DIRECTORY 'compose'
def approx_hessian point vars None model None from numdifftools import Jacobianmodel modelcontext model if vars is None vars model cont_varsvars inputvars vars point Point point model model bij DictToArrayBijection ArrayOrdering vars point dlogp bij mapf model fastdlogp vars def grad_logp point return np nan_to_num dlogp point '\nFindthejacobianofthegradientfunctionatthecurrentposition\nthisshouldbetheHessian invertittofindtheapproximate\ncovariancematrix \n'return - Jacobian grad_logp bij map point
def approx_hessian point vars None model None from numdifftools import Jacobianmodel modelcontext model if vars is None vars model cont_varsvars inputvars vars point Point point model model bij DictToArrayBijection ArrayOrdering vars point dlogp bij mapf model fastdlogp vars def grad_logp point return np nan_to_num dlogp point '\nFindthejacobianofthegradientfunctionatthecurrentposition\nthisshouldbetheHessian invertittofindtheapproximate\ncovariancematrix \n'return - Jacobian grad_logp bij map point
def no_prefix name return name startswith 'E' and not name startswith 'EVENT'
def no_prefix name return name startswith 'E' and not name startswith 'EVENT'
def has_isoread return has_userland_tool 'iso-read'
def has_isoread return has_userland_tool 'iso-read'
def has_isoread return has_userland_tool 'iso-read'
def has_isoread return has_userland_tool 'iso-read'
def getAreaLoopAbsolute loop return abs getAreaLoop loop
def cut_after node levels removed if levels 0 removed extend node children node children []else removed_local []for child in node children if child visible cut_after child levels - 1 removed else removed_local append child for removed_child in removed_local node children remove removed_child removed extend removed_local
def key_subtitles subtitle video languages services order key ''for sort_item in order if sort_item LANGUAGE_INDEX key + '{0 03d}' format len languages - languages index subtitle language - 1 key + '{0 01d}' format subtitle language languages[languages index subtitle language ] elif sort_item SERVICE_INDEX key + '{0 02d}' format len services - services index subtitle service - 1 elif sort_item SERVICE_CONFIDENCE key + '{0 04d}' format int subtitle confidence * 1000 elif sort_item MATCHING_CONFIDENCE confidence 0if subtitle release confidence matching_confidence video subtitle key + '{0 04d}' format int confidence * 1000 return int key
def is_ip_addr text try v dns ipv4 inet_aton text return Trueexcept socket error return False
def mul_shapes lh_shape rh_shape if lh_shape 1 1 return rh_shapeelif rh_shape 1 1 return lh_shapeelse if lh_shape[1] rh_shape[0] raise ValueError 'Incompatibledimensions%s%s' % lh_shape rh_shape return lh_shape[0] rh_shape[1]
def _vis_minibatch im_blob rois_blob labels_blob overlaps import matplotlib pyplot as pltfor i in xrange rois_blob shape[0] rois rois_blob[i ]im_ind rois[0]roi rois[1 ]im im_blob[im_ind ] transpose 1 2 0 copy im + cfg PIXEL_MEANSim im[ 2 1 0 ]im im astype np uint8 cls labels_blob[i]plt imshow im print 'class ' cls 'overlap ' overlaps[i]plt gca add_patch plt Rectangle roi[0] roi[1] roi[2] - roi[0] roi[3] - roi[1] fill False edgecolor 'r' linewidth 3 plt show
def expose_api_raw_anonymous func return expose_api func to_json False user_required False
def expose_api_raw_anonymous func return expose_api func to_json False user_required False
def expose_api_raw_anonymous func return expose_api func to_json False user_required False
@doctest_depends_on modules 'numpy' def symarray prefix shape **kwargs from numpy import empty ndindexarr empty shape dtype object for index in ndindex shape arr[index] Symbol '%s_%s' % prefix '_' join map str index **kwargs return arr
def best_search_result conda_target conda_context None channels_override None conda_context _ensure_conda_context conda_context if not channels_override conda_context ensure_channels_configured search_cmd [conda_context conda_exec 'search' '--full-name' '--json']if channels_override search_cmd append '--override-channels' for channel in channels_override search_cmd extend ['--channel' channel] search_cmd append conda_target package res commands execute search_cmd hits json loads res get conda_target package [] hits sorted hits key lambda hit LooseVersion hit['version'] reverse True if len hits 0 return None None best_result hits[0] False for hit in hits if is_search_hit_exact conda_target hit best_result hit True breakreturn best_result
@currydef lossless_float_to_int funcname func argname arg if not isinstance arg float return argarg_as_int int arg if arg arg_as_int warnings warn '{f}expectedanintforargument{name r} butgotfloat{arg} Coercingtoint ' format f funcname name argname arg arg return arg_as_intraise TypeError arg
def load_app target global NORUN NORUN nr_old True NORUN try tmp default_app push rv load target return rv if callable rv else tmp finally default_app remove tmp NORUN nr_old
def load_app target global NORUN NORUN nr_old True NORUN try tmp default_app push rv load target return rv if callable rv else tmp finally default_app remove tmp NORUN nr_old
def load_app target global NORUN NORUN nr_old True NORUN try tmp default_app push rv load target return rv if callable rv else tmp finally default_app remove tmp NORUN nr_old
@nox parametrize 'sample' SAMPLES_WITH_GENERATED_READMES def session_readmegen session sample session install 'jinja2' 'pyyaml' if os path exists os path join sample 'requirements txt' session install '-r' os path join sample 'requirements txt' in_file os path join sample 'README rst in' session run 'python' 'scripts/readme-gen/readme_gen py' in_file
def fix_location_header request response if 'Location' in response and request get_host response['Location'] request build_absolute_uri response['Location'] return response
def fix_location_header request response if 'Location' in response and request get_host response['Location'] request build_absolute_uri response['Location'] return response
def recall_score y_real y_pred _ r _ precision_recall_fscore y_real y_pred return np average r
def alias thumbnailer thumbnail_options source_filename thumbnail_extension **kwargs return u' ' join [source_filename thumbnail_options get u'ALIAS' u'' thumbnail_extension]
def str_to_bytes size units ['' 'b' 'kb' 'mb' 'gb' 'tb' 'pb' 'eb' 'zb' 'yb']curr_size sizetry if size lower 'infinity' try curr_item size strip split '' curr_size '' join curr_item curr_size int curr_size except ValueError curr_item size strip split '' curr_unit curr_item[ -1 ] strip lower curr_item curr_item[0 -1 ]curr_size '' join curr_item try curr_size float curr_size except ValueError error 'Unabletoconvertsize' + str size raise MalformedYMLException error try pos units index curr_unit for x in range pos 1 -1 curr_size * 1024except ValueError error 'Unabletoconvertsize' + str size raise MalformedYMLException error except UnboundLocalError NameError passelse curr_size -1 except AttributeError passreturn curr_size
def str_to_bytes size units ['' 'b' 'kb' 'mb' 'gb' 'tb' 'pb' 'eb' 'zb' 'yb']curr_size sizetry if size lower 'infinity' try curr_item size strip split '' curr_size '' join curr_item curr_size int curr_size except ValueError curr_item size strip split '' curr_unit curr_item[ -1 ] strip lower curr_item curr_item[0 -1 ]curr_size '' join curr_item try curr_size float curr_size except ValueError error 'Unabletoconvertsize' + str size raise MalformedYMLException error try pos units index curr_unit for x in range pos 1 -1 curr_size * 1024except ValueError error 'Unabletoconvertsize' + str size raise MalformedYMLException error except UnboundLocalError NameError passelse curr_size -1 except AttributeError passreturn curr_size
def aes_decrypt_text data password key_size_bytes NONCE_LENGTH_BYTES 8data bytes_to_intlist base64 b64decode data encode u'utf-8' password bytes_to_intlist password encode u'utf-8' key password[ key_size_bytes] + [0] * key_size_bytes - len password key aes_encrypt key[ BLOCK_SIZE_BYTES] key_expansion key * key_size_bytes // BLOCK_SIZE_BYTES nonce data[ NONCE_LENGTH_BYTES]cipher data[NONCE_LENGTH_BYTES ]class Counter object __value nonce + [0] * BLOCK_SIZE_BYTES - NONCE_LENGTH_BYTES def next_value self temp self __valueself __value inc self __value return tempdecrypted_data aes_ctr_decrypt cipher key Counter plaintext intlist_to_bytes decrypted_data return plaintext
@synchronized IO_LOCK def get_new_id prefix folder check_list None for n in xrange 10000 try if not os path exists folder os makedirs folder fd path tempfile mkstemp '' 'SABnzbd_%s_' % prefix folder os close fd head tail os path split path if not check_list or tail not in check_list return tailexcept logging error T 'Failureintempfile mkstemp' logging info 'Traceback ' exc_info True raise IOError
@synchronized IO_LOCK def get_new_id prefix folder check_list None for n in xrange 10000 try if not os path exists folder os makedirs folder fd path tempfile mkstemp '' 'SABnzbd_%s_' % prefix folder os close fd head tail os path split path if not check_list or tail not in check_list return tailexcept logging error T 'Failureintempfile mkstemp' logging info 'Traceback ' exc_info True raise IOError
def missing_action request action return Response generate_template 'missing_action html' action action status 404
def missing_action request action return Response generate_template 'missing_action html' action action status 404
def make_quartiles q1 q3 return graph_objs Scatter x [0 0] y [q1 q3] text [ 'lower-quartile ' + '{ 0 2f}' format q1 'upper-quartile ' + '{ 0 2f}' format q3 ] mode 'lines' line graph_objs Line width 4 color 'rgb 0 0 0 ' hoverinfo 'text'
@app errorhandler 500 def error_500_handler error new_issue 'https //github com/andresriancho/w3af/issues/new'try exc_type exc_value exc_traceback sys exc_info filepath traceback extract_tb exc_traceback [ -1 ][0]filename basename filepath lineno function_name get_last_call_info exc_traceback response jsonify {'code' 500 'message' str error 'filename' filename 'line_number' lineno 'function_name' function_name 'exception_type' error __class__ __name__ 'please' new_issue} except Exception as e response jsonify {'code' 500 'exception' str error 'handler_exception' str e 'please' new_issue 'message' 'RESTAPIerror'} response status_code 500return response
@app errorhandler 500 def error_500_handler error new_issue 'https //github com/andresriancho/w3af/issues/new'try exc_type exc_value exc_traceback sys exc_info filepath traceback extract_tb exc_traceback [ -1 ][0]filename basename filepath lineno function_name get_last_call_info exc_traceback response jsonify {'code' 500 'message' str error 'filename' filename 'line_number' lineno 'function_name' function_name 'exception_type' error __class__ __name__ 'please' new_issue} except Exception as e response jsonify {'code' 500 'exception' str error 'handler_exception' str e 'please' new_issue 'message' 'RESTAPIerror'} response status_code 500return response
def describe_template_sets import inspectimport systemplatesets inspect getmembers sys modules[__name__] inspect isfunction for name obj in templatesets if name 'describe_template_sets' continueprint name obj __doc__ '\n'
def describe_template_sets import inspectimport systemplatesets inspect getmembers sys modules[__name__] inspect isfunction for name obj in templatesets if name 'describe_template_sets' continueprint name obj __doc__ '\n'
@ensure_csrf_cookie@ensure_valid_course_keydef jump_to_id request course_id module_id course_key SlashSeparatedCourseKey from_deprecated_string course_id items modulestore get_items course_key qualifiers {'name' module_id} if len items 0 raise Http404 u'Couldnotfindid {0}incourse_id {1} Referer {2}' format module_id course_id request META get 'HTTP_REFERER' '' if len items > 1 log warning u'Multipleitemsfoundwithid %sincourse_id %s Referer %s Usingfirst %s' module_id course_id request META get 'HTTP_REFERER' '' items[0] location to_deprecated_string return jump_to request course_id items[0] location to_deprecated_string
@ensure_csrf_cookie@ensure_valid_course_keydef jump_to_id request course_id module_id course_key SlashSeparatedCourseKey from_deprecated_string course_id items modulestore get_items course_key qualifiers {'name' module_id} if len items 0 raise Http404 u'Couldnotfindid {0}incourse_id {1} Referer {2}' format module_id course_id request META get 'HTTP_REFERER' '' if len items > 1 log warning u'Multipleitemsfoundwithid %sincourse_id %s Referer %s Usingfirst %s' module_id course_id request META get 'HTTP_REFERER' '' items[0] location to_deprecated_string return jump_to request course_id items[0] location to_deprecated_string
def db_remove name user None password None host None port None authdb None conn _connect user password host port authdb authdb if not conn return 'Failedtoconnecttomongodatabase'try log info 'Removingdatabase{0}' format name conn drop_database name except pymongo errors PyMongoError as err log error 'Removingdatabase{0}failedwitherror {1}' format name str err return str err return True
def get_service hass config discovery_info None index config get CONF_INDEX return EcobeeNotificationService index
def GetUserInfo client user kb client Get client Schema KNOWLEDGE_BASE if '\\' in user domain user user split '\\' 1 users [u for u in kb users if u username user and u userdomain domain ]else users [u for u in kb users if u username user ]if not users returnelse return users[0]
def BuildCGIRequest base_env_dict request dev_appserver if request headers is None request headers {}request headers['Content-Type'] 'application/json'url SPI_ROOT_FORMAT % request port request path base_env_dict['REQUEST_METHOD'] 'POST'header_outfile cStringIO StringIO body_outfile cStringIO StringIO WriteHeaders request headers header_outfile len request body body_outfile write request body header_outfile seek 0 body_outfile seek 0 return dev_appserver AppServerRequest url None mimetools Message header_outfile body_outfile
def _iscommand cmd if _isexecutable cmd return Truepath os environ get 'PATH' if not path return Falsefor d in path split os pathsep exe os path join d cmd if _isexecutable exe return Truereturn False
def reload_core host None core_name None ret _get_return_dict if not _check_for_cores err ['solr reload_corecanonlybecalledby"multi-core"minions']return ret update {'success' False 'errors' err} if _get_none_or_value core_name is None and _check_for_cores success Truefor name in __opts__['solr cores'] resp reload_core host name if not resp['success'] success Falsedata {name {'data' resp['data']}}ret _update_return_dict ret success data resp['errors'] resp['warnings'] return retextra ['action RELOAD' 'core {0}' format core_name ]url _format_url 'admin/cores' host host core_name None extra extra return _http_request url
def getlimit stream pipe Pipeline pipe append Limit result pipe stream try return int result except ValueError return result
def runX11 node cmd _display tunnel tunnelX11 node if _display is None return []popen node popen cmd return [tunnel popen]
def set_replication_enabled status host None core_name None if not _is_master and _get_none_or_value host is None return _get_return_dict False errors ['Onlyminionsconfiguredasmastercanrunthis'] cmd 'enablereplication' if status else 'disablereplication' if _get_none_or_value core_name is None and _check_for_cores ret _get_return_dict success Truefor name in __opts__['solr cores'] resp set_replication_enabled status host name if not resp['success'] success Falsedata {name {'data' resp['data']}}ret _update_return_dict ret success data resp['errors'] resp['warnings'] return retelif status return _replication_request cmd host host core_name core_name else return _replication_request cmd host host core_name core_name
def set_replication_enabled status host None core_name None if not _is_master and _get_none_or_value host is None return _get_return_dict False errors ['Onlyminionsconfiguredasmastercanrunthis'] cmd 'enablereplication' if status else 'disablereplication' if _get_none_or_value core_name is None and _check_for_cores ret _get_return_dict success Truefor name in __opts__['solr cores'] resp set_replication_enabled status host name if not resp['success'] success Falsedata {name {'data' resp['data']}}ret _update_return_dict ret success data resp['errors'] resp['warnings'] return retelif status return _replication_request cmd host host core_name core_name else return _replication_request cmd host host core_name core_name
def did_composer_install dir lockFile '{0}/vendor' format dir if os path exists lockFile return Truereturn False
def did_composer_install dir lockFile '{0}/vendor' format dir if os path exists lockFile return Truereturn False
def downsample data n axis 0 if hasattr axis '__len__' if not hasattr n '__len__' n [n] * len axis for i in range len axis data downsample data n[i] axis[i] return dataif n < 1 return datanPts int data shape[axis] / n s list data shape s[axis] nPtss insert axis + 1 n sl [slice None ] * data ndim sl[axis] slice 0 nPts * n d1 data[tuple sl ]d1 shape tuple s d2 d1 mean axis + 1 return d2
def skip msg None return skipif True msg
def check_regexp option opt value if hasattr value 'pattern' return valuetry return re compile value except ValueError raise OptionValueError 'option%s invalidregexpvalue %r' % opt value
def check_regexp option opt value if hasattr value 'pattern' return valuetry return re compile value except ValueError raise OptionValueError 'option%s invalidregexpvalue %r' % opt value
def _clean_rerp_input X data reject flat decim info tstep has_val np unique X nonzero [0] if reject is not None _ inds _reject_data_segments data reject flat decim None info info tstep tstep for t0 t1 in inds has_val np setdiff1d has_val range t0 t1 return X tocsr [has_val] data[ has_val]
def _query path method 'GET' data None params None header_dict None decode True api_key config get_cloud_config_value 'api_key' get_configured_provider __opts__ search_global False management_host config get_cloud_config_value 'management_host' get_configured_provider __opts__ search_global False default 'api vultr com' url 'https //{management_host}/v1/{path}?api_key {api_key}' format management_host management_host path path api_key api_key if header_dict is None header_dict {}result __utils__['http query'] url method method params params data data header_dict header_dict port 443 text True decode decode decode_type 'json' hide_fields ['api_key'] opts __opts__ if 'dict' in result return result['dict']return result
def _add_edge_filter values graph values values astype int center values[ len values // 2 ]for value in values if value center and not graph has_edge center value graph add_edge center value return 0 0
def _add_edge_filter values graph values values astype int center values[ len values // 2 ]for value in values if value center and not graph has_edge center value graph add_edge center value return 0 0
def get_user_permission_level user site if not user is_authenticated raise NoPermissionsExceptionif user is_superuser or not get_cms_setting 'PERMISSION' return ROOT_USER_LEVELhas_global_perms GlobalPagePermission objects get_with_change_permissions user site pk exists if has_global_perms return ROOT_USER_LEVELtry permission PagePermission objects get_with_change_permissions user site order_by 'page__path' [0]except IndexError raise NoPermissionsExceptionreturn permission page depth
def MakeGoogleUniqueID cloud_instance if not cloud_instance zone and cloud_instance project_id and cloud_instance instance_id raise ValueError "Badzone/project_id/id '%s/%s/%s'" % cloud_instance zone cloud_instance project_id cloud_instance instance_id return '/' join [cloud_instance zone split '/' [ -1 ] cloud_instance project_id cloud_instance instance_id]
def modify_dot_attribute module ec2 instance device_name delete_on_termination module params get 'delete_on_termination' changed Falsetry instance update dot instance block_device_mapping[device_name] delete_on_terminationexcept boto exception BotoServerError as e module fail_json msg '%s %s' % e error_code e error_message if delete_on_termination dot try bdt BlockDeviceType delete_on_termination delete_on_termination bdm BlockDeviceMapping bdm[device_name] bdtec2 modify_instance_attribute instance_id instance id attribute 'blockDeviceMapping' value bdm while instance block_device_mapping[device_name] delete_on_termination delete_on_termination time sleep 3 instance update changed Trueexcept boto exception BotoServerError as e module fail_json msg '%s %s' % e error_code e error_message return changed
def arg_encoding try return locale getdefaultlocale [1] or 'utf-8' except ValueError return 'utf-8'
def verify_numerically f g z None tol 1e-06 a 2 b -1 c 3 d 1 f g z Tuple f g z z [z] if isinstance z Symbol else f free_symbols g free_symbols reps list zip z [random_complex_number a b c d for zi in z] z1 f subs reps n z2 g subs reps n return comp z1 z2 tol
@contextmanagerdef captured disallow_stderr True import sysstdout sys stdoutstderr sys stderrsys stdout outfile StringIO sys stderr errfile StringIO c CapturedText try yield c finally c stdout outfile getvalue c stderr strip_expected errfile getvalue sys stdout stdoutsys stderr stderrif disallow_stderr and c stderr raise Exception 'Gotstderroutput %s' % c stderr
def endpoint_create service publicurl None internalurl None adminurl None region None profile None url None interface None **connection_args kstone auth profile **connection_args keystone_service service_get name service profile profile **connection_args if not keystone_service or 'Error' in keystone_service return {'Error' 'Couldnotfindthespecifiedservice'}if _OS_IDENTITY_API_VERSION > 2 kstone endpoints create service keystone_service[service]['id'] region_id region url url interface interface else kstone endpoints create region region service_id keystone_service[service]['id'] publicurl publicurl adminurl adminurl internalurl internalurl return endpoint_get service profile **connection_args
def get_filename path try return os path split path [1]except return ''
def __parse_request_range range_header_text left Noneright Noneif not range_header_text return left right range_header_text range_header_text strip if not range_header_text startswith 'bytes' return left right components range_header_text split ' ' if len components 2 return left right components components[1] split '-' try right int components[1] except passtry left int components[0] except passreturn left right
def __parse_request_range range_header_text left Noneright Noneif not range_header_text return left right range_header_text range_header_text strip if not range_header_text startswith 'bytes' return left right components range_header_text split ' ' if len components 2 return left right components components[1] split '-' try right int components[1] except passtry left int components[0] except passreturn left right
def __parse_request_range range_header_text left Noneright Noneif not range_header_text return left right range_header_text range_header_text strip if not range_header_text startswith 'bytes' return left right components range_header_text split ' ' if len components 2 return left right components components[1] split '-' try right int components[1] except passtry left int components[0] except passreturn left right
def __parse_request_range range_header_text left Noneright Noneif not range_header_text return left right range_header_text range_header_text strip if not range_header_text startswith 'bytes' return left right components range_header_text split ' ' if len components 2 return left right components components[1] split '-' try right int components[1] except passtry left int components[0] except passreturn left right
def config_edit_using_option_strings config_filepath desired_option_strings section edit False desired_options [parse_option_string section desired_option_string raise_on_error True for desired_option_string in desired_option_strings]config_edit config_filepath desired_options edit edit
def _estimate_gaussian_covariances_spherical resp X nk means reg_covar return _estimate_gaussian_covariances_diag resp X nk means reg_covar mean 1
def _VerifySourcesExist sources root_dir missing_sources []for source in sources if isinstance source MSVSProject Filter missing_sources extend _VerifySourcesExist source contents root_dir elif '$' not in source full_path os path join root_dir source if not os path exists full_path missing_sources append full_path return missing_sources
def u string if is_python3 return stringreturn unicode string encoding 'utf-8' errors 'strict'
def trigger_server_restart **kwargs mark_urlconf_as_changed
def order_at a p t if a is_zero return ooif p Poly t t return a as_poly t ET [0][0]power_list []p1 pr a rem p1 tracks_power 1while r is_zero power_list append p1 tracks_power p1 p1 * p1 tracks_power * 2r a rem p1 n 0product Poly 1 t while len power_list 0 final power_list pop productf product * final[0] r a rem productf if r is_zero n + final[1]product productfreturn n
def pad_lines_after_first prefix s return '\n' + prefix join s splitlines
def se_cov cov return np sqrt np diag cov
def utcoffset time _time localtime _time localtime if localtime tm_isdst return time altzone // 3600 return time timezone // 3600
def _int_inversion g x t b a _get_coeff_exp g argument x C g _inflate_fox_h meijerg g an g aother g bm g bother b / t ** a - a return C / t * g
def test_min_zero mlp MLP input_space VectorSpace 1 layers [Maxout layer_name 'test_layer' num_units 1 num_pieces 2 irange 0 05 min_zero True ] X T matrix output mlp fprop X f function [X] output mode 'DEBUG_MODE' f np zeros 1 1 astype X dtype
def test_min_zero mlp MLP input_space VectorSpace 1 layers [Maxout layer_name 'test_layer' num_units 1 num_pieces 2 irange 0 05 min_zero True ] X T matrix output mlp fprop X f function [X] output mode 'DEBUG_MODE' f np zeros 1 1 astype X dtype
def test_min_zero mlp MLP input_space VectorSpace 1 layers [Maxout layer_name 'test_layer' num_units 1 num_pieces 2 irange 0 05 min_zero True ] X T matrix output mlp fprop X f function [X] output mode 'DEBUG_MODE' f np zeros 1 1 astype X dtype
def test_min_zero mlp MLP input_space VectorSpace 1 layers [Maxout layer_name 'test_layer' num_units 1 num_pieces 2 irange 0 05 min_zero True ] X T matrix output mlp fprop X f function [X] output mode 'DEBUG_MODE' f np zeros 1 1 astype X dtype
def file_contains_pattern file pattern if not os path isfile file raise NameError 'file%sdoesnotexist' % file cmd_result utils run 'egrep-q"' + pattern + '"' + file ignore_status True verbose False return not cmd_result exit_status
def run_job tasks log debug u'executingtasks %s' tasks finished_events manager execute options {u'tasks' tasks u'cron' True u'allow_manual' False} priority 5 for _ task_name event_ in finished_events log debug u'taskfinishedexecuting %s' task_name event_ wait log debug u'alltasksinschedulefinishedexecuting'
@taskdef bdist_wininst_sse2 options bdist_wininst_arch options python_version 'sse2'
@pytest mark django_dbdef test_admin_regular_user client default client login username default username password '' response client get ADMIN_URL assert response status_code 403
@pytest mark django_dbdef test_admin_regular_user client default client login username default username password '' response client get ADMIN_URL assert response status_code 403
@pytest mark django_dbdef test_admin_regular_user client default client login username default username password '' response client get ADMIN_URL assert response status_code 403
def _callable_repr method try return fullyQualifiedName method except AttributeError return safe_repr method
def test_byteorder mjd np array [53000 0 54000 0] big_endian mjd astype '>f8' little_endian mjd astype '<f8' time_mjd Time mjd format 'mjd' time_big Time big_endian format 'mjd' time_little Time little_endian format 'mjd' assert np all time_big time_mjd assert np all time_little time_mjd
def _onenorm_matrix_power_nnm A p if int p p or p < 0 raise ValueError 'expectednon-negativeintegerp' p int p if len A shape 2 or A shape[0] A shape[1] raise ValueError 'expectedAtobelikeasquarematrix' v np ones A shape[0] 1 dtype float M A Tfor i in range p v M dot v return max v
def test_compound_model_with_nonstandard_broadcasting offx Shift 1 offy Shift 2 rot AffineTransformation2D [[0 -1 ] [1 0]] m offx & offy rot x y m 0 0 assert x -2 assert y 1 assert isinstance x float assert isinstance y float x y m [0 1 2] [0 1 2] assert np all x [ -2 -3 -4 ] assert np all y [1 2 3]
def test_compound_model_with_nonstandard_broadcasting offx Shift 1 offy Shift 2 rot AffineTransformation2D [[0 -1 ] [1 0]] m offx & offy rot x y m 0 0 assert x -2 assert y 1 assert isinstance x float assert isinstance y float x y m [0 1 2] [0 1 2] assert np all x [ -2 -3 -4 ] assert np all y [1 2 3]
def save_exploration_summary exp_summary exp_summary_model exp_models ExpSummaryModel id exp_summary id title exp_summary title category exp_summary category objective exp_summary objective language_code exp_summary language_code tags exp_summary tags ratings exp_summary ratings scaled_average_rating exp_summary scaled_average_rating status exp_summary status community_owned exp_summary community_owned owner_ids exp_summary owner_ids editor_ids exp_summary editor_ids viewer_ids exp_summary viewer_ids contributor_ids exp_summary contributor_ids contributors_summary exp_summary contributors_summary version exp_summary version exploration_model_last_updated exp_summary exploration_model_last_updated exploration_model_created_on exp_summary exploration_model_created_on first_published_msec exp_summary first_published_msec exp_summary_model put
def trigger_500 request raise Exception "Congratulations you'vetriggeredanexception Gotellallyourfriendswhatanexceptionalpersonyouare "
@register simple_tag name 'favicon_path' def favicon_path default getattr settings 'FAVICON_PATH' 'images/favicon ico' return staticfiles_storage url configuration_helpers get_value 'favicon_path' default
def load_check agentConfig hostname checkname from jmxfetch import JMX_CHECKSagentConfig['checksd_hostname'] hostnameosname get_os checks_places get_checks_places osname agentConfig for config_path in _file_configs_paths osname agentConfig check_name _conf_path_to_check_name config_path if check_name checkname and check_name not in JMX_CHECKS conf_is_valid check_config invalid_check _load_file_config config_path check_name agentConfig if invalid_check and not conf_is_valid return invalid_check load_success load_failure load_check_from_places check_config check_name checks_places agentConfig return load_success values [0] or load_failure for check_name service_disco_check_config in _service_disco_configs agentConfig iteritems if check_name checkname sd_init_config sd_instances service_disco_check_config[1]check_config {'init_config' sd_init_config 'instances' sd_instances} load_success load_failure load_check_from_places check_config check_name checks_places agentConfig return load_success values [0] or load_failure return None
def get_lr_scalers_from_layers owner rval OrderedDict params owner get_params for layer in owner layers contrib layer get_lr_scalers assert isinstance contrib OrderedDict assert not any [ key in rval for key in contrib] assert all [ key in params for key in contrib] rval update contrib assert all [isinstance val float for val in rval values ] return rval
@core_helperdef resource_view_icon resource_view view_plugin datapreview get_view_plugin resource_view['view_type'] return view_plugin info get 'icon' 'picture'
def base_msg_type type_ if type_ is None return Noneif '[' in type_ return type_[ type_ find '[' ]return type_
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if column type length and column type length < len str v if config CONF signing token_format 'PKI' and self __tablename__ 'token' and k 'id' continueraise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if column type length and column type length < len str v if config CONF signing token_format 'PKI' and self __tablename__ 'token' and k 'id' continueraise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if column type length and column type length < len str v if config CONF signing token_format 'PKI' and self __tablename__ 'token' and k 'id' continueraise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
def initialize_decorator init def initialize self *args **kwargs cls type self for k v in kwargs items if hasattr cls k attr getattr cls k if isinstance attr InstrumentedAttribute column attr property columns[0]if isinstance column type String if column type length and column type length < len str v if config CONF signing token_format 'PKI' and self __tablename__ 'token' and k 'id' continueraise exception StringLengthExceeded string v type k length column type length init self *args **kwargs return initialize
@allow_publicdef contribute_view request return serve request 'contribute json' document_root settings ROOT
def debug_msg text prefix 'Debug' msg colorize '%s %s' % prefix str text 'cyan'
def create_alias alias_name target_key_id region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile r {}try conn create_alias alias_name target_key_id r['result'] Trueexcept boto exception BotoServerError as e r['result'] Falser['error'] __utils__['boto get_error'] e return r
def test_np_rng rngs [make_np_rng rng_or_seed 42 which_method 'uniform' make_np_rng rng_or_seed numpy random RandomState 42 which_method 'uniform' make_np_rng default_seed 42 make_np_rng ]random_numbers rngs[0] uniform size 100 equals numpy ones 100 for rng in rngs[1 ] equal random_numbers rng uniform size 100 equals * equalassert equals all
def hello_world_window window gtk Window gtk WINDOW_TOPLEVEL window set_border_width 50 button gtk Button u'HelloWorld' window add button def clicked data print u'Buttonclicked 'button connect u'clicked' clicked button show window show
def random_all pass
def groovy_script registry xml_parent data gst XML SubElement xml_parent 'org jenkinsci plugins scripttrigger groovy GroovyScriptTrigger' gst set 'plugin' 'scripttrigger' mappings [ 'system-script' 'groovySystemScript' False 'script' 'groovyExpression' '' 'script-file-path' 'groovyFilePath' '' 'property-file-path' 'propertiesFilePath' '' 'enable-concurrent' 'enableConcurrentBuild' False 'cron' 'spec' '' ]convert_mapping_to_xml gst data mappings fail_required True label data get 'label' XML SubElement gst 'labelRestriction' text str bool label lower if label XML SubElement gst 'triggerLabel' text label
def groovy_script registry xml_parent data gst XML SubElement xml_parent 'org jenkinsci plugins scripttrigger groovy GroovyScriptTrigger' gst set 'plugin' 'scripttrigger' mappings [ 'system-script' 'groovySystemScript' False 'script' 'groovyExpression' '' 'script-file-path' 'groovyFilePath' '' 'property-file-path' 'propertiesFilePath' '' 'enable-concurrent' 'enableConcurrentBuild' False 'cron' 'spec' '' ]convert_mapping_to_xml gst data mappings fail_required True label data get 'label' XML SubElement gst 'labelRestriction' text str bool label lower if label XML SubElement gst 'triggerLabel' text label
def startsWith str prefix return str[ len prefix ] prefix
def create_buffer length return array array 'B' _dummy_s * length
def _check_for_validation_errors app None try from cStringIO import StringIOexcept ImportError from StringIO import StringIOs StringIO num_errors get_validation_errors s app if num_errors if app sys stderr write style ERROR "Error %scouldn'tbeinstalled becausetherewereerrorsinyourmodel \n" % app else sys stderr write style ERROR "Error Couldn'tinstallapps becausetherewereerrorsinoneormoremodels \n" s seek 0 sys stderr write s read sys exit 1
def _check_for_validation_errors app None try from cStringIO import StringIOexcept ImportError from StringIO import StringIOs StringIO num_errors get_validation_errors s app if num_errors if app sys stderr write style ERROR "Error %scouldn'tbeinstalled becausetherewereerrorsinyourmodel \n" % app else sys stderr write style ERROR "Error Couldn'tinstallapps becausetherewereerrorsinoneormoremodels \n" s seek 0 sys stderr write s read sys exit 1
def np_datetime64_compat s *args **kwargs if not _np_version_under1p11 s tz_replacer s return np datetime64 s *args **kwargs
def read_bearer_token_file filename f open filename bearer_token f readline strip f close return bearer_token
def _inflate_fox_h g a if a < 0 return _inflate_fox_h _flip_g g - a p S a p q S a q D g _inflate_g g q z g argumentD / 2 * pi ** 1 - p / 2 * p ** - S 1 / 2 z / p ** p bs [ n + 1 / p for n in range p ]return D meijerg g an g aother g bm list g bother + bs z
def _inflate_fox_h g a if a < 0 return _inflate_fox_h _flip_g g - a p S a p q S a q D g _inflate_g g q z g argumentD / 2 * pi ** 1 - p / 2 * p ** - S 1 / 2 z / p ** p bs [ n + 1 / p for n in range p ]return D meijerg g an g aother g bm list g bother + bs z
def topological_sort_as_sets dependency_graph todo dependency_graph copy while todo current {node for node deps in todo items if len deps 0 }if not current raise ValueError 'Cyclicdependencyingraph {}' format ' ' join repr x for x in todo items yield current todo {node dependencies - current for node dependencies in todo items if node not in current }
def set_windows_appusermodelid try return windll shell32 SetCurrentProcessExplicitAppUserModelID 'spyder Spyder' except AttributeError return 'SetCurrentProcessExplicitAppUserModelIDnotfound'
def set_windows_appusermodelid try return windll shell32 SetCurrentProcessExplicitAppUserModelID 'spyder Spyder' except AttributeError return 'SetCurrentProcessExplicitAppUserModelIDnotfound'
def _assert_complete_surface surf from source_space import _get_solidstot_angle 0 0cm surf['rr'] mean axis 0 logger info '%sCMis%6 2f%6 2f%6 2fmm' % _surf_name[surf['id']] 1000 * cm[0] 1000 * cm[1] 1000 * cm[2] tot_angle _get_solids surf['rr'][surf['tris']] cm[np newaxis ] [0]if np abs tot_angle / 2 * np pi - 1 0 > 1e-05 raise RuntimeError 'Surface%sisnotcomplete sumofsolidangles %g*4*PIinstead ' % _surf_name[surf['id']] tot_angle
def request_latency results limit scenario_results [r['scenario'] for r in results if r['scenario'] get 'metrics' and r['scenario']['metrics'] get 'call_durations' ]if len scenario_results > 0 unique_metrics []for result in scenario_results if result['metrics'] not in unique_metrics unique_metrics append result['metrics'] total_requests 0requests_under_limit 0for metric in unique_metrics for duration num_requests in metric['call_durations'] iteritems if float duration < limit requests_under_limit + num_requeststotal_requests + metric['ok_count'] + metric['err_count'] return float requests_under_limit / total_requests return None
def request_latency results limit scenario_results [r['scenario'] for r in results if r['scenario'] get 'metrics' and r['scenario']['metrics'] get 'call_durations' ]if len scenario_results > 0 unique_metrics []for result in scenario_results if result['metrics'] not in unique_metrics unique_metrics append result['metrics'] total_requests 0requests_under_limit 0for metric in unique_metrics for duration num_requests in metric['call_durations'] iteritems if float duration < limit requests_under_limit + num_requeststotal_requests + metric['ok_count'] + metric['err_count'] return float requests_under_limit / total_requests return None
def request_latency results limit scenario_results [r['scenario'] for r in results if r['scenario'] get 'metrics' and r['scenario']['metrics'] get 'call_durations' ]if len scenario_results > 0 unique_metrics []for result in scenario_results if result['metrics'] not in unique_metrics unique_metrics append result['metrics'] total_requests 0requests_under_limit 0for metric in unique_metrics for duration num_requests in metric['call_durations'] iteritems if float duration < limit requests_under_limit + num_requeststotal_requests + metric['ok_count'] + metric['err_count'] return float requests_under_limit / total_requests return None
def request_latency results limit scenario_results [r['scenario'] for r in results if r['scenario'] get 'metrics' and r['scenario']['metrics'] get 'call_durations' ]if len scenario_results > 0 unique_metrics []for result in scenario_results if result['metrics'] not in unique_metrics unique_metrics append result['metrics'] total_requests 0requests_under_limit 0for metric in unique_metrics for duration num_requests in metric['call_durations'] iteritems if float duration < limit requests_under_limit + num_requeststotal_requests + metric['ok_count'] + metric['err_count'] return float requests_under_limit / total_requests return None
def test_syntax_error_for_scenarios_with_no_name expect Feature from_string when called_with FEATURE20 to throw LettuceSyntaxError 'Inthefeature"Myscenarioshavenoname" scenariosmusthaveaname makesuretodeclareascenariolikethis `Scenario nameofyourscenario`'
def test_syntax_error_for_scenarios_with_no_name expect Feature from_string when called_with FEATURE20 to throw LettuceSyntaxError 'Inthefeature"Myscenarioshavenoname" scenariosmusthaveaname makesuretodeclareascenariolikethis `Scenario nameofyourscenario`'
def test_syntax_error_for_scenarios_with_no_name expect Feature from_string when called_with FEATURE20 to throw LettuceSyntaxError 'Inthefeature"Myscenarioshavenoname" scenariosmusthaveaname makesuretodeclareascenariolikethis `Scenario nameofyourscenario`'
@mock_streams 'stdout' def test_global_parallel_honors_runs_once @decorators runs_oncedef mytask print 'yolo'with settings hide 'everything' parallel True execute mytask hosts ['localhost' '127 0 0 1'] result sys stdout getvalue eq_ result 'yolo\n' assert result 'yolo\nyolo\n'
@mock_streams 'stdout' def test_global_parallel_honors_runs_once @decorators runs_oncedef mytask print 'yolo'with settings hide 'everything' parallel True execute mytask hosts ['localhost' '127 0 0 1'] result sys stdout getvalue eq_ result 'yolo\n' assert result 'yolo\nyolo\n'
def _calc_beta rk rk_norm rk1 rk1_norm rkk1 rk1[0] - rk[0] size np sqrt np dot rkk1 rkk1 rkk1 / sizenum rk_norm + np dot rk rkk1 den rk1_norm + np dot rk1 rkk1 res np log num / den / size return res
def _calc_beta rk rk_norm rk1 rk1_norm rkk1 rk1[0] - rk[0] size np sqrt np dot rkk1 rkk1 rkk1 / sizenum rk_norm + np dot rk rkk1 den rk1_norm + np dot rk1 rkk1 res np log num / den / size return res
def prep_jid nocache False passed_jid None jid passed_jidfor returner_ in __opts__[CONFIG_KEY] if jid is None jid _mminion returners['{0} prep_jid' format returner_ ] nocache nocache else r_jid _mminion returners['{0} prep_jid' format returner_ ] nocache nocache if r_jid jid log debug 'Uhh crudthejidsdonotmatch' return jid
def prep_jid nocache False passed_jid None jid passed_jidfor returner_ in __opts__[CONFIG_KEY] if jid is None jid _mminion returners['{0} prep_jid' format returner_ ] nocache nocache else r_jid _mminion returners['{0} prep_jid' format returner_ ] nocache nocache if r_jid jid log debug 'Uhh crudthejidsdonotmatch' return jid
def not_in_ a b msg None assert a not in b msg or '%risin%r' % a b
def _get_view_to_display_matrix scene from mayavi core ui mayavi_scene import MayaviScenefrom tvtk pyface tvtk_scene import TVTKSceneif not isinstance scene MayaviScene TVTKScene raise TypeError 'scenemustbeaninstanceofTVTKScene/MayaviScene foundtype%s' % type scene x y tuple scene get_size view_to_disp_mat np array [[ x / 2 0 0 0 0 0 x / 2 0 ] [0 0 - y / 2 0 0 0 y / 2 0 ] [0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0]] return view_to_disp_mat
def _get_view_to_display_matrix scene from mayavi core ui mayavi_scene import MayaviScenefrom tvtk pyface tvtk_scene import TVTKSceneif not isinstance scene MayaviScene TVTKScene raise TypeError 'scenemustbeaninstanceofTVTKScene/MayaviScene foundtype%s' % type scene x y tuple scene get_size view_to_disp_mat np array [[ x / 2 0 0 0 0 0 x / 2 0 ] [0 0 - y / 2 0 0 0 y / 2 0 ] [0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0]] return view_to_disp_mat
def _get_view_to_display_matrix scene from mayavi core ui mayavi_scene import MayaviScenefrom tvtk pyface tvtk_scene import TVTKSceneif not isinstance scene MayaviScene TVTKScene raise TypeError 'scenemustbeaninstanceofTVTKScene/MayaviScene foundtype%s' % type scene x y tuple scene get_size view_to_disp_mat np array [[ x / 2 0 0 0 0 0 x / 2 0 ] [0 0 - y / 2 0 0 0 y / 2 0 ] [0 0 0 0 1 0 0 0] [0 0 0 0 0 0 1 0]] return view_to_disp_mat
def completions_sorting_key word word word lower prio1 prio2 0 0 if word startswith '__' prio1 2elif word startswith '_' prio1 1if word endswith ' ' prio1 -1 if word startswith '%%' if not '%' in word[2 ] word word[2 ]prio2 2elif word startswith '%' if not '%' in word[1 ] word word[1 ]prio2 1return prio1 word prio2
def field_definition resource chained_fields definition config DOMAIN[resource]subfields chained_fields split ' ' for field in subfields if field not in definition get 'schema' {} if 'data_relation' in definition sub_resource definition['data_relation']['resource']definition config DOMAIN[sub_resource]if field not in definition['schema'] returndefinition definition['schema'][field]field_type definition get 'type' if field_type 'list' definition definition['schema']elif field_type 'objectid' passreturn definition
def remove_article text u'' return re sub u' ?i ^ ? ? A ? \\s+to n? The \\s \\w ' u'\\1' text
def uid pid start_time parameter time time 'uid' status_path '/proc/%s/status' % pid uid_line _get_line status_path 'Uid ' parameter try result int uid_line split [1] _log_runtime parameter '%s[Uid]' % status_path start_time return resultexcept exc IOError 'unabletoparsethe%sUidentry %s' % status_path uid_line _log_failure parameter exc raise exc
def preBuild site optimize site config get 'optimize' [] if 'js' in optimize site external_manager register_optimizer ClosureJSOptimizer if 'css' in optimize site external_manager register_optimizer YUICSSOptimizer
def _get_ch_type inst ch_type if ch_type is None for type_ in ['mag' 'grad' 'planar1' 'planar2' 'eeg'] if type_ in inst ch_type type_breakelse raise RuntimeError 'Noplottablechanneltypesfound' return ch_type
def do_terminate_threads whitelist list for t in threading enumerate if not isinstance t TerminatableThread continueif whitelist and t not in whitelist continuet schedule_termination t stop_and_join
def archive cwd output rev 'tip' fmt None prefix None user None cmd ['hg' 'archive' '{0}' format output '--rev' '{0}' format rev ]if fmt cmd append '--type' cmd append '{0}' format fmt if prefix cmd append '--prefix' cmd append '"{0}"' format prefix return __salt__['cmd run'] cmd cwd cwd runas user python_shell False
def archive cwd output rev 'tip' fmt None prefix None user None cmd ['hg' 'archive' '{0}' format output '--rev' '{0}' format rev ]if fmt cmd append '--type' cmd append '{0}' format fmt if prefix cmd append '--prefix' cmd append '"{0}"' format prefix return __salt__['cmd run'] cmd cwd cwd runas user python_shell False
def regions regions get_regions 'route53' region_cls Route53RegionInfo connection_cls Route53Connection regions append Route53RegionInfo name 'universal' endpoint 'route53 amazonaws com' connection_cls Route53Connection return regions
def _get_row row key if row is not None value row[0]if isinstance value sqlite3 Binary bytes and key 'resumed_from' value cPickle loads bytes value return valueraise KeyError key
def dependency_check registry xml_parent data dependency_check XML SubElement xml_parent 'org jenkinsci plugins DependencyCheck DependencyCheckPublisher' helpers build_trends_publisher '[DEPENDENCYCHECK]' dependency_check data
def dependency_check registry xml_parent data dependency_check XML SubElement xml_parent 'org jenkinsci plugins DependencyCheck DependencyCheckPublisher' helpers build_trends_publisher '[DEPENDENCYCHECK]' dependency_check data
def customize_config_vars _config_vars if not _supports_universal_builds _remove_universal_flags _config_vars _override_all_archs _config_vars _check_for_unavailable_sdk _config_vars return _config_vars
def _count1Bits num ret 0while num > 0 num num >> 1 ret + 1return ret
@control_command args [ u'task_name' text_t u'soft' float u'hard' float ] signature u'<task_name><soft_secs>[hard_secs]' def time_limit state task_name None hard None soft None **kwargs try task state app tasks[task_name]except KeyError logger error u'Changetimelimitattemptforunknowntask%s' task_name exc_info True return nok u'unknowntask' task soft_time_limit softtask time_limit hardlogger info u'Newtimelimitsfortasksoftype%s soft %shard %s' task_name soft hard return ok u'timelimitssetsuccessfully'
@control_command args [ u'task_name' text_t u'soft' float u'hard' float ] signature u'<task_name><soft_secs>[hard_secs]' def time_limit state task_name None hard None soft None **kwargs try task state app tasks[task_name]except KeyError logger error u'Changetimelimitattemptforunknowntask%s' task_name exc_info True return nok u'unknowntask' task soft_time_limit softtask time_limit hardlogger info u'Newtimelimitsfortasksoftype%s soft %shard %s' task_name soft hard return ok u'timelimitssetsuccessfully'
@must_have_permission ADMIN @must_be_valid_projectdef new_draft_registration auth node *args **kwargs if node is_registration raise HTTPError http FORBIDDEN data {'message_short' "Can'tcreatedraft" 'message_long' 'Creatingdraftregistrationsonregisteredprojectsisnotallowed '} data request valuesschema_name data get 'schema_name' if not schema_name raise HTTPError http BAD_REQUEST data {'message_short' 'Mustspecifyaschema_name' 'message_long' 'Pleasespecifyaschema_name'} schema_version data get 'schema_version' 2 meta_schema get_schema_or_fail Q 'name' 'eq' schema_name & Q 'schema_version' 'eq' int schema_version draft DraftRegistration create_from_node node user auth user schema meta_schema data {} return redirect node web_url_for 'edit_draft_registration_page' draft_id draft _id
def bool_to_bitarray value value value flatbit_no 7byte 0bytes []for v in value if v byte 1 << bit_no if bit_no 0 bytes append byte bit_no 7byte 0else bit_no - 1if bit_no 7 bytes append byte return struct_pack u'{}B' format len bytes *bytes
def bool_to_bitarray value value value flatbit_no 7byte 0bytes []for v in value if v byte 1 << bit_no if bit_no 0 bytes append byte bit_no 7byte 0else bit_no - 1if bit_no 7 bytes append byte return struct_pack u'{}B' format len bytes *bytes
def StartFlowAndWait client_id token None timeout DEFAULT_TIMEOUT **flow_args flow_urn flow GRRFlow StartFlow client_id client_id token token sync True **flow_args WaitForFlow flow_urn token token timeout timeout return flow_urn
def _FindApiJars lib_dir result {}for jar_file in _FilesMatching lib_dir lambda f f endswith ' jar' manifest jarfile ReadManifest jar_file if manifest section manifest sections get 'com/google/appengine/api/' if section and 'Specification-Version' in section result[jar_file] section['Specification-Version']return result
def listen ipAddr '127 0 0 1' port 9001 global oscThreadsthread_id '%s %d' % ipAddr port if thread_id in oscThreads returnLogger debug 'OSC Startthread<%s>' % thread_id oscThreads[thread_id] OSCServer ipAddr ipAddr port port oscThreads[thread_id] start return thread_id
def is_python_interpreter_valid_name filename pattern ' *python \\d\\ ?\\d* ? w ? exe ?$'if re match pattern filename flags re I is None return Falseelse return True
def is_python_interpreter_valid_name filename pattern ' *python \\d\\ ?\\d* ? w ? exe ?$'if re match pattern filename flags re I is None return Falseelse return True
def getPluginFileNames craftSequence getReadCraftSequence craftSequence sort return craftSequence
def get_course_display_string descriptor return '' join [descriptor display_org_with_default descriptor display_number_with_default]
def get_course_display_string descriptor return '' join [descriptor display_org_with_default descriptor display_number_with_default]
def pack_session item _init_globals session _SESSION_HANDLER get item sessid if session and session conn_time item conn_time return item conn_time and item sessid and '__packed_session__' _GA item 'sessid' _GA item 'conn_time' return None
def pack_session item _init_globals session _SESSION_HANDLER get item sessid if session and session conn_time item conn_time return item conn_time and item sessid and '__packed_session__' _GA item 'sessid' _GA item 'conn_time' return None
def pack_session item _init_globals session _SESSION_HANDLER get item sessid if session and session conn_time item conn_time return item conn_time and item sessid and '__packed_session__' _GA item 'sessid' _GA item 'conn_time' return None
def seterr divide False if _errdict['divide'] divide clear_cache _errdict['divide'] divide
def seterr divide False if _errdict['divide'] divide clear_cache _errdict['divide'] divide
def Timestamp year month day hour minute second return datetime datetime year month day hour minute second
def get_site_dict app_name 'filebrowser' if app_name not in _sites_cache return {}deployed get_resolver get_urlconf app_dict[app_name]return dict k v for k v in _sites_cache[app_name] items if k in deployed
def get_site_dict app_name 'filebrowser' if app_name not in _sites_cache return {}deployed get_resolver get_urlconf app_dict[app_name]return dict k v for k v in _sites_cache[app_name] items if k in deployed
def describe_api_key apiKey region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile response conn get_api_key apiKey apiKey return {'apiKey' _convert_datetime_str response }except ClientError as e return {'error' salt utils boto3 get_error e }
def Element *args **kw v html_parser makeelement *args **kw return v
def diop_general_sum_of_even_powers eq limit 1 var coeff diop_type classify_diop eq _dict False if diop_type 'general_sum_of_even_powers' for k in coeff keys if k is_Pow and coeff[k] p k expreturn _diop_general_sum_of_even_powers var p - coeff[1] limit
@pytest fixturedef monkeypatch mpatch MonkeyPatch yield mpatch mpatch undo
@pytest fixturedef monkeypatch mpatch MonkeyPatch yield mpatch mpatch undo
@pytest fixturedef monkeypatch mpatch MonkeyPatch yield mpatch mpatch undo
def get_service hass config discovery_info None mail_service MailNotificationService config get CONF_SERVER config get CONF_PORT config get CONF_SENDER config get CONF_STARTTLS config get CONF_USERNAME config get CONF_PASSWORD config get CONF_RECIPIENT config get CONF_DEBUG if mail_service connection_is_valid return mail_serviceelse return None
def _adjustLoggingFormatter if hasattr FORMATTER '_format' returndef format record message FORMATTER _format record message boldifyMessage message if kb get 'prependFlag' message '\n%s' % message kb prependFlag Falsereturn messageFORMATTER _format FORMATTER formatFORMATTER format format
def _adjustLoggingFormatter if hasattr FORMATTER '_format' returndef format record message FORMATTER _format record message boldifyMessage message if kb get 'prependFlag' message '\n%s' % message kb prependFlag Falsereturn messageFORMATTER _format FORMATTER formatFORMATTER format format
def _choose_random_tests tests ratio seed rnd random Random rnd seed seed if isinstance tests unittest TestSuite tests _flatten_suite tests tests rnd sample tests int len tests * ratio tests sorted tests key lambda case case id return unittest TestSuite tests
def getBoundedLatitude latitude return round min 179 9 max 0 1 latitude 1
def colors name if color_enabled return _colors[name]return ''
def token_freqs doc freq defaultdict int for tok in tokens doc freq[tok] + 1return freq
def addif br None iface None return _os_dispatch 'addif' br iface
def setup hass config import thingspeakconf config[DOMAIN]api_key conf get CONF_API_KEY channel_id conf get CONF_ID entity conf get CONF_WHITELIST try channel thingspeak Channel channel_id api_key api_key timeout TIMEOUT channel get except RequestException _LOGGER error 'ErrorwhileaccessingtheThingSpeakchannel PleasecheckthatthechannelexistsandyourAPIkeyiscorrect ' return Falsedef thingspeak_listener entity_id old_state new_state 'Listenforneweventsandsendthemtothingspeak 'if new_state is None or new_state state in STATE_UNKNOWN '' STATE_UNAVAILABLE returntry if new_state entity_id entity return_state state_helper state_as_number new_state except ValueError returntry channel update {'field1' _state} except RequestException _LOGGER error "Errorwhilesendingvalue'%s'toThingspeak" _state event track_state_change hass entity thingspeak_listener return True
def softmax X copy True if copy X np copy X max_prob np max X axis 1 reshape -1 1 X - max_probnp exp X X sum_prob np sum X axis 1 reshape -1 1 X / sum_probreturn X
def find_intersection x tr_bounds lb ub lb_centered lb - x ub_centered ub - x lb_total np maximum lb_centered - tr_bounds ub_total np minimum ub_centered tr_bounds orig_l np equal lb_total lb_centered orig_u np equal ub_total ub_centered tr_l np equal lb_total - tr_bounds tr_u np equal ub_total tr_bounds return lb_total ub_total orig_l orig_u tr_l tr_u
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME stop config get CONF_STOP_ID route config get CONF_ROUTE data PublicTransportData stop route add_devices [DublinPublicTransportSensor data stop route name ]
def head url **kwargs kwargs setdefault 'headers' dict useragent_header config kwargs pop 'config' None if config kwargs setdefault 'verify' _get_tls_cacert url config with warnings catch_warnings if not kwargs get 'verify' warnings filterwarnings 'ignore' category InsecureRequestWarning return requests get url **kwargs
def can_view_courses_for_username requesting_user target_username if requesting_user username target_username return Trueelif not target_username raise TypeError 'target_usernamemustbespecified' else staff GlobalStaff return staff has_user requesting_user
def can_view_courses_for_username requesting_user target_username if requesting_user username target_username return Trueelif not target_username raise TypeError 'target_usernamemustbespecified' else staff GlobalStaff return staff has_user requesting_user
def between marker what None keepempty False marker_re re compile marker def process app what_ name obj options lines if what and what_ not in what returndeleted 0delete Trueorig_lines lines[ ]for i line in enumerate orig_lines if delete lines pop i - deleted deleted + 1if marker_re match line delete not delete if delete lines pop i - deleted deleted + 1if not lines and not keepempty lines[ ] orig_linesif lines and lines[ -1 ] lines append '' return process
def init history interface WebHistoryInterface history parent history QWebHistoryInterface setDefaultInterface interface
def can_do_meijer a1 a2 b1 b2 numeric True from sympy import unpolarify expandr hyperexpand meijerg a1 a2 b1 b2 z if r has meijerg return Falser unpolarify expand r force True power_base True power_exp False mul False log False multinomial False basic False if not numeric return Truerepl {}for n a in enumerate meijerg a1 a2 b1 b2 z free_symbols - {z} repl[a] randcplx n return tn meijerg a1 a2 b1 b2 z subs repl r subs repl z
def can_do_meijer a1 a2 b1 b2 numeric True from sympy import unpolarify expandr hyperexpand meijerg a1 a2 b1 b2 z if r has meijerg return Falser unpolarify expand r force True power_base True power_exp False mul False log False multinomial False basic False if not numeric return Truerepl {}for n a in enumerate meijerg a1 a2 b1 b2 z free_symbols - {z} repl[a] randcplx n return tn meijerg a1 a2 b1 b2 z subs repl r subs repl z
def _run_as_pg command with cd '~postgres' return sudo command user 'postgres'
def vech A length A shape[1]vechvec []for i in range length b iwhile b < length vechvec append A[ b i ] b b + 1 vechvec np asarray vechvec return vechvec
def survey_buildQuestionnaireFromTemplate template_id questions survey_getAllQuestionsForTemplate template_id return buildQuestionsForm questions readOnly True
def survey_buildQuestionnaireFromTemplate template_id questions survey_getAllQuestionsForTemplate template_id return buildQuestionsForm questions readOnly True
@commands u'info' @example u' infoallboardmemberspresent' def meetinginfo bot trigger if not ismeetingrunning trigger sender bot say u"Can'tdothat startmeetingfirst" returnif not trigger group 2 bot say u'try infosomeinformativething' returnif not ischair trigger nick trigger sender bot say u'Onlymeetingheadorchairscandothat' returnlogplain u'INFO ' + trigger group 2 trigger sender logHTML_listitem trigger group 2 trigger sender bot say u'\x02INFO\x0f ' + trigger group 2
def check_whitelist request_host whitelist if ' ' not in request_host request_host request_host + ' 80' if request_host in whitelist return Truereturn any match_host request_host host for host in whitelist
def queue_models models context MAX_CYCLES 5model_queue []number_remaining_models len models allowed_cycles MAX_CYCLESwhile number_remaining_models > 0 previous_number_remaining_models number_remaining_modelsmodel models pop 0 if check_dependencies model model_queue model_class ModelCode model model context context model_queue append model_class else models append model number_remaining_models len models if number_remaining_models previous_number_remaining_models allowed_cycles - 1if allowed_cycles < 0 missing_models [ModelCode model m context context for m in models]model_queue + missing_modelsmodels[ ] missing_modelsbreakelse allowed_cycles MAX_CYCLESreturn model_queue
@_ConfigurableFilter executable 'HTML_TIDY_EXECUTABLE' def html_tidy_withconfig infile executable 'tidy5' return _html_tidy_runner infile '-quiet--show-infono--show-warningsno-utf8-indent-configtidy5 conf-modify%1' executable executable
def service_get_all_by_binary context binary include_disabled False return IMPL service_get_all_by_binary context binary include_disabled include_disabled
def write_index group return u'%s_%s' % settings ES_INDEX_PREFIX settings ES_WRITE_INDEXES[group]
def _normalize_index df index if not isinstance df DataFrame return indexelif isinstance index list return [_normalize_index df col for col in index]elif isinstance index Series and index name in df columns and index _name df[index name] _name return index nameelif isinstance index DataFrame and set index columns issubset df columns and index _name df[index columns] _name return list index columns else return index
def _normalize_index df index if not isinstance df DataFrame return indexelif isinstance index list return [_normalize_index df col for col in index]elif isinstance index Series and index name in df columns and index _name df[index name] _name return index nameelif isinstance index DataFrame and set index columns issubset df columns and index _name df[index columns] _name return list index columns else return index
def regions from boto cognito identity layer1 import CognitoIdentityConnectionreturn get_regions 'cognito-identity' connection_cls CognitoIdentityConnection
def commit container repository None tag None message None author None conf None status base_status copy client _get_client try container _get_container_infos container ['Id']commit_info client commit container repository repository tag tag message message author author conf conf found Falsefor k in 'Id' 'id' 'ID' if k in commit_info found Trueimage_id commit_info[k]if not found raise Exception 'Invalidcommitreturn' image _get_image_infos image_id ['Id']comment 'Image{0}createdfrom{1}' format image container _valid status id_ image out commit_info comment comment except Exception _invalid status id_ container out traceback format_exc return status
def Char c if len c 1 result CodeRange ord c ord c + 1 else result SpecialSymbol c result str 'Char %s ' % repr c return result
def scale image factor resample Image NEAREST if factor 1 return image copy elif factor < 0 raise ValueError 'thefactormustbegreaterthan0' else size int round factor * image width int round factor * image height return image resize size resample
def scale image factor resample Image NEAREST if factor 1 return image copy elif factor < 0 raise ValueError 'thefactormustbegreaterthan0' else size int round factor * image width int round factor * image height return image resize size resample
def scale image factor resample Image NEAREST if factor 1 return image copy elif factor < 0 raise ValueError 'thefactormustbegreaterthan0' else size int round factor * image width int round factor * image height return image resize size resample
def find_release_date_source xblock if xblock category 'chapter' return xblockparent_location modulestore get_parent_location xblock location revision ModuleStoreEnum RevisionOption draft_preferred if not parent_location return xblockparent modulestore get_item parent_location if parent start xblock start return xblockelse return find_release_date_source parent
def find_release_date_source xblock if xblock category 'chapter' return xblockparent_location modulestore get_parent_location xblock location revision ModuleStoreEnum RevisionOption draft_preferred if not parent_location return xblockparent modulestore get_item parent_location if parent start xblock start return xblockelse return find_release_date_source parent
def find_release_date_source xblock if xblock category 'chapter' return xblockparent_location modulestore get_parent_location xblock location revision ModuleStoreEnum RevisionOption draft_preferred if not parent_location return xblockparent modulestore get_item parent_location if parent start xblock start return xblockelse return find_release_date_source parent
def test_type_constructor_overloads global calledimport clrclr AddReference 'IronPythonTest' import IronPythonTest interop net type clrtype as IPTcalled Falseclass MyType type def __clrtype__ self global calledcalled Truereturn IPT SanityConstructorOverloadsclass X object __metaclass__ MyTypedef __init__ self *args **kwargs passAreEqual called True temp X Assert str temp startswith '<first' str temp
def set_connection_info url user True section keypath reg_info user try hive _winreg ConnectRegistry None section try key _winreg CreateKey hive keypath except passkey _winreg OpenKey hive keypath mykey _winreg CreateKey key 'api' _winreg SetValueEx mykey 'url' None _winreg REG_SZ url _winreg CloseKey mykey _winreg CloseKey key except WindowsError if user set_connection_info url user False passfinally _winreg CloseKey hive
def test_replace_column_qtable a [1 2 3] * u m b [4 5 6]t table QTable [a b] names ['a' 'b'] ta t['a']tb t['b']ta info meta {'aa' [0 1 2 3 4]}ta info format '%f't replace_column 'a' a to 'cm' assert np all t['a'] ta assert t['a'] is not ta assert t['b'] is tb assert t colnames ['a' 'b'] assert t['a'] info meta is None assert t['a'] info format is None
def play_nice_with_threads sleep True weak False deadline None if weak or threading activeCount < 4 time sleep 0 return 0deadline time time + 5 if deadline is None else deadline while True activity_threshold 180 - time time + LAST_USER_ACTIVITY / 120 delay max 0 001 min 0 1 0 1 * activity_threshold if not sleep breakif LIVE_USER_ACTIVITIES < 1 time sleep delay else time sleep max delay 0 25 if QUITTING or LIVE_USER_ACTIVITIES < 1 breakif time time > deadline breakreturn delay
def play_nice_with_threads sleep True weak False deadline None if weak or threading activeCount < 4 time sleep 0 return 0deadline time time + 5 if deadline is None else deadline while True activity_threshold 180 - time time + LAST_USER_ACTIVITY / 120 delay max 0 001 min 0 1 0 1 * activity_threshold if not sleep breakif LIVE_USER_ACTIVITIES < 1 time sleep delay else time sleep max delay 0 25 if QUITTING or LIVE_USER_ACTIVITIES < 1 breakif time time > deadline breakreturn delay
def play_nice_with_threads sleep True weak False deadline None if weak or threading activeCount < 4 time sleep 0 return 0deadline time time + 5 if deadline is None else deadline while True activity_threshold 180 - time time + LAST_USER_ACTIVITY / 120 delay max 0 001 min 0 1 0 1 * activity_threshold if not sleep breakif LIVE_USER_ACTIVITIES < 1 time sleep delay else time sleep max delay 0 25 if QUITTING or LIVE_USER_ACTIVITIES < 1 breakif time time > deadline breakreturn delay
def load_check_from_places check_config check_name checks_places agentConfig load_success load_failure {} {} for check_path_builder in checks_places check_path check_path_builder check_name if not os path exists check_path continue check_is_valid check_class load_failure get_valid_check_class check_name check_path if not check_is_valid continue load_success load_failure _initialize_check check_config check_name check_class agentConfig _update_python_path check_config log debug 'Loaded%s' % check_path breakreturn load_success load_failure
def load_check_from_places check_config check_name checks_places agentConfig load_success load_failure {} {} for check_path_builder in checks_places check_path check_path_builder check_name if not os path exists check_path continue check_is_valid check_class load_failure get_valid_check_class check_name check_path if not check_is_valid continue load_success load_failure _initialize_check check_config check_name check_class agentConfig _update_python_path check_config log debug 'Loaded%s' % check_path breakreturn load_success load_failure
def load_check_from_places check_config check_name checks_places agentConfig load_success load_failure {} {} for check_path_builder in checks_places check_path check_path_builder check_name if not os path exists check_path continue check_is_valid check_class load_failure get_valid_check_class check_name check_path if not check_is_valid continue load_success load_failure _initialize_check check_config check_name check_class agentConfig _update_python_path check_config log debug 'Loaded%s' % check_path breakreturn load_success load_failure
def handle_405 environ start_response _methods util wsgi_path_item environ '_methods' headers {}if _methods headers['allow'] str _methods raise webob exc HTTPMethodNotAllowed _ 'Themethodspecifiedisnotallowedforthisresource ' headers headers json_formatter util json_error_formatter
def select_directory paths if not paths return core getcwd for path in paths if core isdir path return pathreturn os path dirname paths[0]
def prefix_unit unit prefixes from sympy physics unitsystems units import Unitprefixed_units []for prefix in prefixes prefixed_units append Unit unit abbrev unit abbrev prefix prefixes[prefix] return prefixed_units
def _get_nics vm_ nics []if 'public_lan' in vm_ firewall_rules []lan_id set_public_lan int vm_['public_lan'] if 'public_firewall_rules' in vm_ firewall_rules _get_firewall_rules vm_['public_firewall_rules'] nics append NIC lan lan_id name 'public' firewall_rules firewall_rules if 'private_lan' in vm_ firewall_rules []if 'private_firewall_rules' in vm_ firewall_rules _get_firewall_rules vm_['private_firewall_rules'] nic NIC lan int vm_['private_lan'] name 'private' firewall_rules firewall_rules if 'nat' in vm_ nic nat vm_['nat']nics append nic return nics
@tx atomicdef remove_vote obj user obj_type apps get_model 'contenttypes' 'ContentType' objects get_for_model obj with advisory_lock 'vote-{}-{}' format obj_type id obj id qs Vote objects filter content_type obj_type object_id obj id user user if not qs exists returnqs delete votes _ Votes objects get_or_create content_type obj_type object_id obj id votes count F 'count' - 1 votes save
def roles_required *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perms [Permission RoleNeed role for role in roles]for perm in perms if not perm can if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return fn *args **kwargs return decorated_viewreturn wrapper
def roles_required *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perms [Permission RoleNeed role for role in roles]for perm in perms if not perm can if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return fn *args **kwargs return decorated_viewreturn wrapper
def roles_required *roles def wrapper fn @wraps fn def decorated_view *args **kwargs perms [Permission RoleNeed role for role in roles]for perm in perms if not perm can if _security _unauthorized_callback return _security _unauthorized_callback else return _get_unauthorized_view return fn *args **kwargs return decorated_viewreturn wrapper
def _read_footer file_obj footer_size _get_footer_size file_obj if logger isEnabledFor logging DEBUG logger debug u'Footersizeinbytes %s' footer_size file_obj seek - 8 + footer_size 2 tin TFileTransport file_obj pin TCompactProtocolFactory get_protocol tin fmd parquet_thrift FileMetaData fmd read pin return fmd
def require_context fn @functools wraps fn def _require_cuda_context *args **kws get_context return fn *args **kws return _require_cuda_context
def require_context fn @functools wraps fn def _require_cuda_context *args **kws get_context return fn *args **kws return _require_cuda_context
def parse_and_instantiate parent_to text indent all_tokens seen_ts tokenize_snippet_text parent_to text indent __ALLOWED_TOKENS __ALLOWED_TOKENS_IN_TABSTOPS _TOKEN_TO_TEXTOBJECT resolve_ambiguity all_tokens seen_ts finalize all_tokens seen_ts parent_to
def parse_and_instantiate parent_to text indent all_tokens seen_ts tokenize_snippet_text parent_to text indent __ALLOWED_TOKENS __ALLOWED_TOKENS_IN_TABSTOPS _TOKEN_TO_TEXTOBJECT resolve_ambiguity all_tokens seen_ts finalize all_tokens seen_ts parent_to
def zmap scores compare axis 0 ddof 0 scores compare map np asanyarray [scores compare] mns compare mean axis axis sstd compare std axis axis ddof ddof if axis and mns ndim < compare ndim return scores - np expand_dims mns axis axis / np expand_dims sstd axis axis else return scores - mns / sstd
def thin_lv_create vg_name thinpool_name 'lvthinpool' thinpool_size '1 5G' thinlv_name 'lvthin' thinlv_size '1G' tp_cmd 'lvcreate--thinpool%s--size%s%s' % thinpool_name thinpool_size vg_name try utils run tp_cmd except error CmdError as detail logging debug detail raise error TestError 'Createthinvolumepoolfailed ' logging debug 'Createdthinvolumepool %s' thinpool_name lv_cmd 'lvcreate--name%s--virtualsize%s--thin%s/%s' % thinlv_name thinlv_size vg_name thinpool_name try utils run lv_cmd except error CmdError as detail logging debug detail raise error TestError 'Createthinvolumefailed ' logging debug 'Createdthinvolume %s' thinlv_name return thinpool_name thinlv_name
def getFabmetheusToolsPath subName '' return getJoinedPath getFabmetheusUtilitiesPath 'fabmetheus_tools' subName
def col_create fid body url build_url RESOURCE id fid route 'col' return request 'post' url json body
def col_create fid body url build_url RESOURCE id fid route 'col' return request 'post' url json body
@synchronized IO_LOCK def remove_data _id path path os path join path _id try if os path exists path os remove path logging info '%sremoved' path except logging debug 'Failedtoremove%s' path
def remove_repeating substr s index s find substr if index > 0 return u'' join [s[ index + len substr ] s[ index + len substr ] replace substr u'' ] return s
def stripascii string ord_ ord if sys version_info[0] < 3 else lambda x x i len string while i i - 1if 8 < ord_ string[i] < 127 breakelse i -1 return string[ i + 1 ]
def surrogate_escape error chars error object[error start error end]assert len chars 1 val ord chars val + 56320return __builtin__ unichr val error end
def oneTransportTest testMethod @wraps testMethod def actualTestMethod builder other ConnectableProtocol class ServerProtocol ConnectableProtocol def connectionMade self try testMethod builder self reactor self transport finally if self transport is not None self transport loseConnection if other transport is not None other transport loseConnection serverProtocol ServerProtocol runProtocolsWithReactor builder serverProtocol other TCPCreator return actualTestMethod
def oneTransportTest testMethod @wraps testMethod def actualTestMethod builder other ConnectableProtocol class ServerProtocol ConnectableProtocol def connectionMade self try testMethod builder self reactor self transport finally if self transport is not None self transport loseConnection if other transport is not None other transport loseConnection serverProtocol ServerProtocol runProtocolsWithReactor builder serverProtocol other TCPCreator return actualTestMethod
def oneTransportTest testMethod @wraps testMethod def actualTestMethod builder other ConnectableProtocol class ServerProtocol ConnectableProtocol def connectionMade self try testMethod builder self reactor self transport finally if self transport is not None self transport loseConnection if other transport is not None other transport loseConnection serverProtocol ServerProtocol runProtocolsWithReactor builder serverProtocol other TCPCreator return actualTestMethod
def test_strf_index ea ea rules[0]['index'] 'logstash-%Y %m %d'ea rules[0]['use_strftime_index'] Truestart ts_to_dt '2015-01-02T12 34 45Z' end ts_to_dt '2015-01-02T16 15 14Z' assert ea get_index ea rules[0] start end 'logstash-2015 01 02' end ts_to_dt '2015-01-03T01 02 03Z' assert ea get_index ea rules[0] start end 'logstash-2015 01 02 logstash-2015 01 03' assert ea get_index ea rules[0] 'logstash-*' ea rules[0]['index'] 'logstash-%Y %m'assert ea get_index ea rules[0] 'logstash-*' ea rules[0]['index'] 'logstash-%Y %m-stuff'assert ea get_index ea rules[0] 'logstash-*-stuff'
def test_strf_index ea ea rules[0]['index'] 'logstash-%Y %m %d'ea rules[0]['use_strftime_index'] Truestart ts_to_dt '2015-01-02T12 34 45Z' end ts_to_dt '2015-01-02T16 15 14Z' assert ea get_index ea rules[0] start end 'logstash-2015 01 02' end ts_to_dt '2015-01-03T01 02 03Z' assert ea get_index ea rules[0] start end 'logstash-2015 01 02 logstash-2015 01 03' assert ea get_index ea rules[0] 'logstash-*' ea rules[0]['index'] 'logstash-%Y %m'assert ea get_index ea rules[0] 'logstash-*' ea rules[0]['index'] 'logstash-%Y %m-stuff'assert ea get_index ea rules[0] 'logstash-*-stuff'
def truncate toTruncate charsToKeep 50 if len toTruncate > charsToKeep truncated toTruncate[ charsToKeep] + ' ' return truncatedelse return toTruncate
@_api_version 1 21 @_client_version '1 5 0' def networks names None ids None response _client_wrapper 'networks' names names ids ids _clear_context return response
def assert_list obj expected_type string_types can_be_none True default key_arg None allowable list Fileset OrderedSet set tuple raise_type ValueError def get_key_msg key None if key is None return u''else return u"Inkey'{}' " format key allowable tuple allowable key_msg get_key_msg key_arg val objif val is None if can_be_none val list default else raise raise_type u'{}Expectedanobjectofacceptabletype{} receivedNoneandcan_be_noneisFalse' format key_msg allowable if isinstance val allowable lst list val for e in lst if not isinstance e expected_type raise raise_type u'{}Expectedalistcontainingvaluesoftype{} insteadgotavalue{}of{}' format key_msg expected_type e e __class__ return lstelse raise raise_type u'{}Expectedanobjectofacceptabletype{} received{}instead' format key_msg allowable val
def write_metadata_pil file metadata from PIL import Image PngImagePluginim Image open file meta PngImagePlugin PngInfo for k v in metadata items meta add_text k v 0 im save file 'PNG' pnginfo meta return True
def clean_gallery_out build_dir build_image_dir os path join build_dir '_images' if os path exists build_image_dir filelist os listdir build_image_dir for filename in filelist if filename startswith 'sphx_glr' and filename endswith 'png' os remove os path join build_image_dir filename
def lookupMailRename name timeout None return getResolver lookupMailRename name timeout
def get_initializable_thread_fields context ret get_editable_fields Thread user_id context['cc_requester']['id'] type 'thread' context ret NON_UPDATABLE_THREAD_FIELDSreturn ret
def uniqueDLLNames createAssembly '' 'ZERO' 1 default_filename '0' createAssembly '' 'ONE' 1 default_filename '1' createAssembly '' 'a' 1 default_filename 'a' createAssembly '' 'UNDERSCORE' 1 default_filename '_' createAssembly '' 'WHITESPACE' 1 default_filename 'aA' temp ''for i in xrange 0 15 temp temp + 'aaaaaaaaaa' createAssembly '' 'BIGFILENAME' 1 default_filename temp
def _has_rational_power expr symbol a p q Wild 'a' Wild 'p' Wild 'q' pattern_match expr match a * p ** q or {} if pattern_match get a S Zero is S Zero return False S One elif p not in pattern_match keys return False S One elif isinstance pattern_match[q] Rational and pattern_match[p] has symbol if not pattern_match[q] q S One return True pattern_match[q] q if not isinstance pattern_match[a] Pow or isinstance pattern_match[a] Mul return False S One else return _has_rational_power pattern_match[a] symbol
def _has_rational_power expr symbol a p q Wild 'a' Wild 'p' Wild 'q' pattern_match expr match a * p ** q or {} if pattern_match get a S Zero is S Zero return False S One elif p not in pattern_match keys return False S One elif isinstance pattern_match[q] Rational and pattern_match[p] has symbol if not pattern_match[q] q S One return True pattern_match[q] q if not isinstance pattern_match[a] Pow or isinstance pattern_match[a] Mul return False S One else return _has_rational_power pattern_match[a] symbol
def str_to_bool value if isinstance value basestring value value strip lower if value in ['true' 't' 'yes' 'y'] return Trueelif value in ['false' 'f' 'no' 'n' ''] return Falseelse raise NotImplementedError 'Unknownbool%s' % value return value
def str_to_bool value if isinstance value basestring value value strip lower if value in ['true' 't' 'yes' 'y'] return Trueelif value in ['false' 'f' 'no' 'n' ''] return Falseelse raise NotImplementedError 'Unknownbool%s' % value return value
def extend_config config config_items for key val in list config_items items if hasattr config key setattr config key val return config
def extend_config config config_items for key val in list config_items items if hasattr config key setattr config key val return config
def test_default_task_loading docs tasks load_fabfile fabfile 'default_tasks' ok_ isinstance crawl 'mymodule' tasks Task
def invalidate_cms_page_cache version _get_cache_version _set_cache_version version + 1
def mobile_view request url '/' if not url url '/' view args kwargs resolve url if view mobile_view raise Http404 'OMG Iseemyself ' kwargs['request'] requestkwargs['response_format'] 'html'response view *args **kwargs if response status_code 302 and not response['Location'][ 2] '/m' response['Location'] '/m' + response['Location'] return response
def get_vnc_port session min_port CONF vmware vnc_portport_total CONF vmware vnc_port_totalallocated_ports _get_allocated_vnc_ports session max_port min_port + port_total for port in range min_port max_port if port not in allocated_ports return portraise exception ConsolePortRangeExhausted min_port min_port max_port max_port
def build_absolute_uri host_url path None path path or '' if path startswith 'http //' or path startswith 'https //' return pathif host_url endswith '/' and path startswith '/' path path[1 ]return host_url + path
def build_absolute_uri host_url path None path path or '' if path startswith 'http //' or path startswith 'https //' return pathif host_url endswith '/' and path startswith '/' path path[1 ]return host_url + path
def set_ key value service None profile None service _get_service service profile keyring set_password service key value
def token_to_cms signed_text copy_of_text signed_text replace '-' '/' lines ['-----BEGINCMS-----']lines + [copy_of_text[n n + 64 ] for n in range 0 len copy_of_text 64 ]lines append '-----ENDCMS-----\n' return '\n' join lines
def skip_without_tool tool_id def method_wrapper method def get_tool_ids api_test_case index api_test_case galaxy_interactor get 'tools' data dict in_panel False tools index json tool_ids [itemgetter 'id' _ for _ in tools]return tool_idsdef wrapped_method api_test_case *args **kwargs if tool_id not in get_tool_ids api_test_case from nose plugins skip import SkipTestraise SkipTest return method api_test_case *args **kwargs wrapped_method __name__ method __name__return wrapped_methodreturn method_wrapper
def _flag current_flag _flag flag_flag flag << 1return current_flag
def aggregate_get_by_host context host key None return IMPL aggregate_get_by_host context host key
def _get_pb_likelihood likelihood likelihood_pb image_annotator_pb2 Likelihood Name likelihood return Likelihood[likelihood_pb]
def _get_pb_likelihood likelihood likelihood_pb image_annotator_pb2 Likelihood Name likelihood return Likelihood[likelihood_pb]
def unregister ident if ident in _handlers del _handlers[ident]
def unregister ident if ident in _handlers del _handlers[ident]
def __del api_key url data url make_url api_key url req Request url headers {'Content-Type' 'application/json'} data json dumps data req get_method lambda 'DELETE' return json loads urlopen req read
def _cleanName n if not n return u''n n replace 'Filmographybytypefor' '' return n
def get_and_group_by_field cr uid obj ids field context None res {}for record in obj read cr uid ids [field] context context key record[field]res setdefault key[0] if isinstance key tuple else key [] append record['id'] return res
def _is_running_from_main_thread return tornado ioloop IOLoop current instance False
def document_tabs r tab_opts [{'tablename' 'assess_rat' 'resource' 'rat' 'one_title' '1Assessment' 'num_title' 'Assessments'} {'tablename' 'irs_ireport' 'resource' 'ireport' 'one_title' '1IncidentReport' 'num_title' 'IncidentReports'} {'tablename' 'cr_shelter' 'resource' 'shelter' 'one_title' '1Shelter' 'num_title' 'Shelters'} {'tablename' 'req_req' 'resource' 'req' 'one_title' '1Request' 'num_title' 'Requests'}]tabs [ T 'Details' None ]crud_string s3base S3CRUD crud_stringfor tab_opt in tab_opts tablename tab_opt['tablename']if tablename in db and document_id in db[tablename] table db[tablename]query table deleted False & table document_id r id tab_count db query count if tab_count 0 label crud_string tablename 'label_create' elif tab_count 1 label tab_opt['one_title']else label T str tab_count + tab_opt['num_title'] tabs append label tab_opt['resource'] return tabs
def document_tabs r tab_opts [{'tablename' 'assess_rat' 'resource' 'rat' 'one_title' '1Assessment' 'num_title' 'Assessments'} {'tablename' 'irs_ireport' 'resource' 'ireport' 'one_title' '1IncidentReport' 'num_title' 'IncidentReports'} {'tablename' 'cr_shelter' 'resource' 'shelter' 'one_title' '1Shelter' 'num_title' 'Shelters'} {'tablename' 'req_req' 'resource' 'req' 'one_title' '1Request' 'num_title' 'Requests'}]tabs [ T 'Details' None ]crud_string s3base S3CRUD crud_stringfor tab_opt in tab_opts tablename tab_opt['tablename']if tablename in db and document_id in db[tablename] table db[tablename]query table deleted False & table document_id r id tab_count db query count if tab_count 0 label crud_string tablename 'label_create' elif tab_count 1 label tab_opt['one_title']else label T str tab_count + tab_opt['num_title'] tabs append label tab_opt['resource'] return tabs
@pytest mark cmddef test_import_user_nofile with pytest raises CommandError as e call_command 'import' assert 'toofewarguments' in str e
def caller_name skip 2 stack inspect stack start 0 + skip if len stack < start + 1 return ''parentframe stack[start][0]name []module inspect getmodule parentframe if module name append module __name__ if 'self' in parentframe f_locals name append parentframe f_locals['self'] __class__ __name__ codename parentframe f_code co_nameif codename '<module>' name append codename del parentframereturn ' ' join name
def _dismiss_notification request course_action_state_id try action_state CourseRerunState objects find_first id course_action_state_id except CourseActionStateItemNotFoundError return HttpResponseBadRequest if action_state state CourseRerunUIStateManager State FAILED remove_all_instructors action_state course_key action_state delete return JsonResponse {'success' True}
def rename_variables fstruct vars None used_vars new_vars None fs_class u'default' if fs_class u'default' fs_class _default_fs_class fstruct if new_vars is None new_vars {}if vars is None vars find_variables fstruct fs_class else vars set vars used_vars find_variables fstruct fs_class union used_vars return _rename_variables copy deepcopy fstruct vars used_vars new_vars fs_class set
def collatz start start int start begin time time steps []while start 1 steps append start if start > 1 if start % 2 0 start start / 2 else start start * 3 + 1 return steps time time - begin
@pytest mark django_dbdef test_file_extension_bad FileExtension objects create name 'foo' with pytest raises IntegrityError FileExtension objects create name 'foo'
@pytest mark django_dbdef test_file_extension_bad FileExtension objects create name 'foo' with pytest raises IntegrityError FileExtension objects create name 'foo'
def get_repository name cmd u'Get-PSRepository"{0}"' format name no_ret _pshell cmd return name not in list_modules
def resolve_uri s namespaces cdao_namespaces cdao_to_obo True xml_style False if cdao_to_obo and s startswith 'cdao ' return resolve_uri 'obo %s' % cdao_elements[s[5 ]] namespaces cdao_to_obo for prefix in namespaces if xml_style s s replace prefix + ' ' '{%s}' % namespaces[prefix] else s s replace prefix + ' ' namespaces[prefix] return s
def get_table_names_from_sql context sql def _get_table_names_from_plan plan table_names []if plan get 'RelationName' table_names append plan['RelationName'] if 'Plans' in plan for child_plan in plan['Plans'] table_name _get_table_names_from_plan child_plan if table_name table_names extend table_name return table_namesresult context['connection'] execute 'EXPLAIN FORMATJSON {0}' format sql encode 'utf-8' fetchone table_names []try query_plan json loads result['QUERYPLAN'] plan query_plan[0]['Plan']table_names extend _get_table_names_from_plan plan except ValueError log error 'Couldnotparsequeryplan' return table_names
def get_table_names_from_sql context sql def _get_table_names_from_plan plan table_names []if plan get 'RelationName' table_names append plan['RelationName'] if 'Plans' in plan for child_plan in plan['Plans'] table_name _get_table_names_from_plan child_plan if table_name table_names extend table_name return table_namesresult context['connection'] execute 'EXPLAIN FORMATJSON {0}' format sql encode 'utf-8' fetchone table_names []try query_plan json loads result['QUERYPLAN'] plan query_plan[0]['Plan']table_names extend _get_table_names_from_plan plan except ValueError log error 'Couldnotparsequeryplan' return table_names
def get_table_names_from_sql context sql def _get_table_names_from_plan plan table_names []if plan get 'RelationName' table_names append plan['RelationName'] if 'Plans' in plan for child_plan in plan['Plans'] table_name _get_table_names_from_plan child_plan if table_name table_names extend table_name return table_namesresult context['connection'] execute 'EXPLAIN FORMATJSON {0}' format sql encode 'utf-8' fetchone table_names []try query_plan json loads result['QUERYPLAN'] plan query_plan[0]['Plan']table_names extend _get_table_names_from_plan plan except ValueError log error 'Couldnotparsequeryplan' return table_names
@retry 2 delay 0 5 backoff 1 1 def safe_deepcopy instance return copy deepcopy instance
def convert_otu_table_relative otu_table sample_ids otu_ids otu_counts consensus otu_tableotu_counts asarray otu_counts float otu_counts otu_counts / otu_counts sum otu_counts where isnan otu_counts 0 0 otu_counts return sample_ids otu_ids otu_counts consensus
def gpu_safe_new x tag '' if hasattr x 'name' and x name is not None nw_name x name + tag else nw_name Noneif isinstance x theano Constant return x clone nw_x x type nw_x name nw_namereturn nw_x
def gpu_safe_new x tag '' if hasattr x 'name' and x name is not None nw_name x name + tag else nw_name Noneif isinstance x theano Constant return x clone nw_x x type nw_x name nw_namereturn nw_x
def check_paired_arrays X Y X Y check_pairwise_arrays X Y if X shape Y shape raise ValueError 'XandYshouldbeofsameshape Theywererespectively%rand%rlong ' % X shape Y shape return X Y
def debug_option if g['debug'] g['traceback'] append traceback format_exc
def debug_option if g['debug'] g['traceback'] append traceback format_exc
def _run_command cmd options params [cmd]params extend options return __salt__['cmd run_all'] params python_shell False
def delete_neutron_ports ports for port in ports device ip_lib IPDevice port if device exists device link delete LOG info _LI 'Deletingport %s' port
def update_contact doc method contact_name frappe db get_value u'Contact' {u'email_id' doc name} if contact_name contact frappe get_doc u'Contact' contact_name for key in u'first_name' u'last_name' u'phone' if doc get key contact set key doc get key contact flags ignore_mandatory Truecontact save ignore_permissions True
def find_sink_node digr node digr nodes [0]while digr neighbors node node digr neighbors node [0]return node
def find_sink_node digr node digr nodes [0]while digr neighbors node node digr neighbors node [0]return node
def find_uncommitted_filefields sender instance **kwargs uncommitted instance _uncommitted_filefields []fields sender _meta fieldsif kwargs get 'update_fields' None update_fields set kwargs['update_fields'] fields update_fields intersection fields for field in fields if isinstance field FileField if not getattr instance field name _committed uncommitted append field name
def find_uncommitted_filefields sender instance **kwargs uncommitted instance _uncommitted_filefields []fields sender _meta fieldsif kwargs get 'update_fields' None update_fields set kwargs['update_fields'] fields update_fields intersection fields for field in fields if isinstance field FileField if not getattr instance field name _committed uncommitted append field name
def find_uncommitted_filefields sender instance **kwargs uncommitted instance _uncommitted_filefields []fields sender _meta fieldsif kwargs get 'update_fields' None update_fields set kwargs['update_fields'] fields update_fields intersection fields for field in fields if isinstance field FileField if not getattr instance field name _committed uncommitted append field name
def create_xml_str xml conn __get_conn return conn createXML xml 0 is not None
def ridder f a b args xtol _xtol rtol _rtol maxiter _iter full_output False disp True if not isinstance args tuple args args if xtol < 0 raise ValueError 'xtoltoosmall %g< 0 ' % xtol if rtol < _rtol raise ValueError 'rtoltoosmall %g<%g ' % rtol _rtol r _zeros _ridder f a b xtol rtol maxiter args full_output disp return results_c full_output r
def ridder f a b args xtol _xtol rtol _rtol maxiter _iter full_output False disp True if not isinstance args tuple args args if xtol < 0 raise ValueError 'xtoltoosmall %g< 0 ' % xtol if rtol < _rtol raise ValueError 'rtoltoosmall %g<%g ' % rtol _rtol r _zeros _ridder f a b xtol rtol maxiter args full_output disp return results_c full_output r
def capped_binomial_deviance actual predicted return np mean capped_log10_likelihood actual predicted
def imsave file data **kwargs tifargs {}for key in 'byteorder' 'bigtiff' 'software' 'imagej' if key in kwargs tifargs[key] kwargs[key]del kwargs[key]if 'bigtiff' not in tifargs and 'imagej' not in tifargs and data size * data dtype itemsize > 2000 * 2 ** 20 tifargs['bigtiff'] Truewith TiffWriter file **tifargs as tif tif save data **kwargs
@needs_hostdef open_shell command None _execute channel default_channel command command pty True combine_stderr True invoke_shell True
def _fiff_get_fid fname if isinstance fname string_types if op splitext fname [1] lower ' gz' logger debug 'Usinggzip' fid GzipFile fname 'rb' else logger debug 'UsingnormalI/O' fid open fname 'rb' else fid fnamefid seek 0 return fid
def _fiff_get_fid fname if isinstance fname string_types if op splitext fname [1] lower ' gz' logger debug 'Usinggzip' fid GzipFile fname 'rb' else logger debug 'UsingnormalI/O' fid open fname 'rb' else fid fnamefid seek 0 return fid
def enumeration *values **kwargs if not values and all isinstance value string_types and value for value in values raise ValueError 'expectedanon-emptysequenceofstrings got%s' % values if len values len set values raise ValueError 'enumerationitemsmustbeunique got%s' % values attrs dict [ value value for value in values] attrs update {'_values' list values '_default' values[0] '_case_sensitive' kwargs get 'case_sensitive' True } return type 'Enumeration' Enumeration attrs
def wminkowski u v p w u _validate_vector u v _validate_vector v w _validate_vector w if p < 1 raise ValueError 'pmustbeatleast1' dist norm w * u - v ord p return dist
def build_all html latex
def eq_ a b msg None assert a b msg or '%r %r' % a b
def _linear_banded_jac t y a ml mu _band_count a bjac []for k in range mu 0 -1 bjac append np r_[ [0] * k np diag a k ] bjac append np diag a for k in range -1 - ml - 1 -1 bjac append np r_[ np diag a k [0] * - k ] return bjac
def get_dist Y W domain return np bincount Y weights W minlength len domain class_var values
def get_file_list results return {code file for result in results for code in result affected_code}
def get_file_list results return {code file for result in results for code in result affected_code}
def trimtail data proportiontocut 0 2 tail 'left' inclusive True True axis None tail str tail lower [0]if tail 'l' limits proportiontocut None elif tail 'r' limits None proportiontocut else raise TypeError "Thetailargumentshouldbein 'left' 'right' " return trimr data limits limits axis axis inclusive inclusive
def _aybabtu c l [c Versioned]for b in inspect getmro c if b not in l and issubclass b Versioned l append b return l[2 ]
def _setAuthCred if kb passwordMgr and all _ is not None for _ in conf scheme conf hostname conf port conf authUsername conf authPassword kb passwordMgr add_password None '%s //%s %d' % conf scheme conf hostname conf port conf authUsername conf authPassword
@decorator decoratordef requires_duration f clip *a **k if clip duration is None raise ValueError "Attribute'duration'notset" else return f clip *a **k
def delete_exploration_summary exploration_id exp_models ExpSummaryModel get exploration_id delete
def create_bem_flow name 'bem' out_format 'stl' '\nInitializetheworkflow\n'bemflow pe Workflow name name '\nDefinetheinputstotheworkflow \n'inputnode pe Node niu IdentityInterface fields ['subject_id' 'subjects_dir'] name 'inputspec' '\nDefineallthenodesoftheworkflow \n\nfssource usedtoretrieveaseg mgz\nmri_convert convertsaseg mgztoaseg nii\ntessellate tessellatesregionsinaseg mgz\nsurfconvert convertsregionstostereolithographic stl format\n\n'watershed_bem pe Node interface mne WatershedBEM name 'WatershedBEM' surfconvert pe MapNode fs MRIsConvert out_datatype out_format iterfield ['in_file'] name 'surfconvert' '\nConnectthenodes\n'bemflow connect [ inputnode watershed_bem [ 'subject_id' 'subject_id' 'subjects_dir' 'subjects_dir' ] watershed_bem surfconvert [ 'mesh_files' 'in_file' ] ] '\nSetupanoutputnodethatdefinesrelevantinputsoftheworkflow \n'outputnode pe Node niu IdentityInterface fields ['meshes'] name 'outputspec' bemflow connect [ surfconvert outputnode [ 'converted' 'meshes' ] ] return bemflow
def create_bem_flow name 'bem' out_format 'stl' '\nInitializetheworkflow\n'bemflow pe Workflow name name '\nDefinetheinputstotheworkflow \n'inputnode pe Node niu IdentityInterface fields ['subject_id' 'subjects_dir'] name 'inputspec' '\nDefineallthenodesoftheworkflow \n\nfssource usedtoretrieveaseg mgz\nmri_convert convertsaseg mgztoaseg nii\ntessellate tessellatesregionsinaseg mgz\nsurfconvert convertsregionstostereolithographic stl format\n\n'watershed_bem pe Node interface mne WatershedBEM name 'WatershedBEM' surfconvert pe MapNode fs MRIsConvert out_datatype out_format iterfield ['in_file'] name 'surfconvert' '\nConnectthenodes\n'bemflow connect [ inputnode watershed_bem [ 'subject_id' 'subject_id' 'subjects_dir' 'subjects_dir' ] watershed_bem surfconvert [ 'mesh_files' 'in_file' ] ] '\nSetupanoutputnodethatdefinesrelevantinputsoftheworkflow \n'outputnode pe Node niu IdentityInterface fields ['meshes'] name 'outputspec' bemflow connect [ surfconvert outputnode [ 'converted' 'meshes' ] ] return bemflow
def _clean_names names remove_whitespace False before_dash True cleaned []for name in names if '' in name and remove_whitespace name name replace '' '' if '-' in name and before_dash name name split '-' [0]if name endswith '_virtual' name name[ -8 ]cleaned append name return cleaned
def setStateLocation stateLocation if stateLocation is None returnif not stateLocation endswith '/' stateLocation + '/'stateLocation + const TRANSPORT_NAME lower + '/' if not os path exists stateLocation log info "Creatingdirectorypath`%s' " % stateLocation os makedirs stateLocation log debug "Settingthestatelocationto`%s' " % stateLocation const STATE_LOCATION stateLocation
def regions from boto awslambda layer1 import AWSLambdaConnectionreturn get_regions 'awslambda' connection_cls AWSLambdaConnection
def zeroize name ret {'name' name 'changes' {} 'result' True 'comment' ''}ret['changes'] __salt__['junos zeroize'] return ret
def migrate cr version migrate_from_audittrail cr
@outer_atomicdef delete_problem_module_state xmodule_instance_args _module_descriptor student_module _task_input student_module delete track_function _get_track_function_for_task student_module student xmodule_instance_args track_function 'problem_delete_state' {} return UPDATE_STATUS_SUCCEEDED
def dispatch_aliases app current_appaliases_map app config get 'ALIASES_MAP' if aliases_map and request path in aliases_map alias aliases_map[request path]status alias get 'status' 200 if alias['alias_type'] 'endpoint' endpoint alias['to']if alias get 'action' 'redirect' return redirect url_for endpoint **request args else return app process_response app make_response app view_functions[endpoint] elif alias['alias_type'] 'long_slug' long_slug alias['to']if alias get 'action' 'redirect' return redirect long_slug else endpoint route_from long_slug [0]return app process_response app make_response app view_functions[endpoint] elif alias['alias_type'] 'url' return redirect alias['to'] elif alias['alias_type'] 'string' return render_template_string alias['to'] status elif alias['alias_type'] 'template' return render_template alias['to'] status
def tanhm A A _asarray_square A return _maybe_real A solve coshm A sinhm A
def policy task_instance pass
def policy task_instance pass
def policy task_instance pass
def _GetHWInfos client_list batch_size 10000 token None hw_infos {}logging info '%dclientstoprocess ' len client_list c 0for batch in utils Grouper client_list batch_size logging info 'Processingbatch %d-%d' c c + batch_size c + len batch client_objs aff4 FACTORY MultiOpen batch age aff4 ALL_TIMES token token for client in client_objs hwi client GetValuesForAttribute client Schema HARDWARE_INFO hw_infos[client urn] set [ '%s' % x serial_number for x in hwi] return hw_infos
def _GetHWInfos client_list batch_size 10000 token None hw_infos {}logging info '%dclientstoprocess ' len client_list c 0for batch in utils Grouper client_list batch_size logging info 'Processingbatch %d-%d' c c + batch_size c + len batch client_objs aff4 FACTORY MultiOpen batch age aff4 ALL_TIMES token token for client in client_objs hwi client GetValuesForAttribute client Schema HARDWARE_INFO hw_infos[client urn] set [ '%s' % x serial_number for x in hwi] return hw_infos
def absent name stop False path None ret {'name' name 'changes' {} 'result' True 'comment' "Container'{0}'doesnotexist" format name }if not __salt__['lxc exists'] name path path return retif __opts__['test'] ret['result'] Noneret['comment'] "Container'{0}'wouldbedestroyed" format name return rettry result __salt__['lxc destroy'] name stop stop path path except SaltInvocationError CommandExecutionError as exc ret['result'] Falseret['comment'] 'Failedtodestroycontainer {0}' format exc else ret['changes']['state'] result['state']ret['comment'] "Container'{0}'wasdestroyed" format name return ret
def easy_install package try easy main ['-U' package] return Trueexcept print 'Unabletoinstall%susingeasy_install Pleasereadtheinstructionsformanualinstallation Exiting' % package print 'Error %s %s' % exc_info [0] exc_info [1] return False
@dispatch Expr MongoQuery def post_compute e q scope None scope {'$project' toolz merge {'_id' 0} dict col 1 for col in e fields }q q append scope if not e dshape shape result get_result q coll aggregate list q query [0]if isscalar e dshape measure return result[e _name]else return get e fields result dicts get_result q coll aggregate list q query if isscalar e dshape measure return list pluck e fields[0] dicts default None else return list pluck e fields dicts default None
def _get_disk_of_partition devpath st None diskpath re sub ' ? ?< \\d p ?\\d+$' '' devpath if diskpath devpath try st_disk os stat diskpath if stat S_ISBLK st_disk st_mode return diskpath st_disk except OSError passif st is None st os stat devpath return devpath st
def expand_key k dims def inds i ind rv []if ind - 0 9 > 0 rv append ind - 0 9 rv append ind if ind + 0 9 < dims[i] - 1 rv append ind + 0 9 return rvshape []for i ind in enumerate k[1 ] num 1if ind > 0 num + 1if ind < dims[i] - 1 num + 1shape append num seq list product [k[0]] *[inds i ind for i ind in enumerate k[1 ] ] return reshapelist shape seq
def expand_key k dims def inds i ind rv []if ind - 0 9 > 0 rv append ind - 0 9 rv append ind if ind + 0 9 < dims[i] - 1 rv append ind + 0 9 return rvshape []for i ind in enumerate k[1 ] num 1if ind > 0 num + 1if ind < dims[i] - 1 num + 1shape append num seq list product [k[0]] *[inds i ind for i ind in enumerate k[1 ] ] return reshapelist shape seq
def get_auth_params_from_request request return request user username request user token id request user tenant_id base url_for request 'compute' base url_for request 'identity'
def allowed_formats if gprefs[u'auto_add_everything'] allowed AllAllowed else allowed AUTO_ADDED - frozenset gprefs[u'blocked_auto_formats'] return allowed
def migrate_drafts_metadata_key schema drafts DraftRegistration find Q 'registration_schema' 'eq' schema total_drafts drafts count logger info 'Examining{}draftsforimproperkey' format total_drafts draft_count 0for draft in drafts draft_count + 1if draft registration_metadata get 'recommended-methods' {} get 'value' {} get 'undefined' {} draft registration_metadata['recommended-methods']['value']['procedure'] draft registration_metadata['recommended-methods']['value'] pop 'undefined' draft save logger info '{}/{}Migratedkeyfor{}' format draft_count total_drafts draft _id else logger info '{}/{}Keyalreadycorrectfor{} Nochange ' format draft_count drafts count draft _id
def initialized return DETAILS get 'initialized' False
def initialized return DETAILS get 'initialized' False
def is_field_error errors if isinstance errors list tuple for e in errors if isinstance e string_types return Truereturn False
def is_field_error errors if isinstance errors list tuple for e in errors if isinstance e string_types return Truereturn False
def zca_whitening x principal_components print principal_components shape x shape print flatx shapewhitex np dot flatx principal_components x np reshape whitex x shape[0] x shape[1] x shape[2] return x
def recvfd socketfd data flags ancillary recv1msg socketfd [ cmsg_level cmsg_type packedFD ] ancillary[unpackedFD] unpack 'i' packedFD return unpackedFD data
def _handle_subset_cert_request config domains cert existing ' ' join cert names question 'Youhaveanexistingcertificatethatcontainsaportionofthedomainsyourequested ref {0} {br}{br}Itcontainsthesenames {1}{br}{br}Yourequestedthesenamesforthenewcertificate {2} {br}{br}Doyouwanttoexpandandreplacethisexistingcertificatewiththenewcertificate?' format cert configfile filename existing ' ' join domains br os linesep if config expand or config renew_by_default or zope component getUtility interfaces IDisplay yesno question 'Expand' 'Cancel' cli_flag '--expand' force_interactive True return 'renew' cert else reporter_util zope component getUtility interfaces IReporter reporter_util add_message 'Toobtainanewcertificatethatcontainsthesenameswithoutreplacingyourexistingcertificatefor{0} youmustusethe--duplicateoption {br}{br}Forexample {br}{br}{1}--duplicate{2}' format existing sys argv[0] '' join sys argv[1 ] br os linesep reporter_util HIGH_PRIORITY raise errors Error USER_CANCELLED
def _handle_subset_cert_request config domains cert existing ' ' join cert names question 'Youhaveanexistingcertificatethatcontainsaportionofthedomainsyourequested ref {0} {br}{br}Itcontainsthesenames {1}{br}{br}Yourequestedthesenamesforthenewcertificate {2} {br}{br}Doyouwanttoexpandandreplacethisexistingcertificatewiththenewcertificate?' format cert configfile filename existing ' ' join domains br os linesep if config expand or config renew_by_default or zope component getUtility interfaces IDisplay yesno question 'Expand' 'Cancel' cli_flag '--expand' force_interactive True return 'renew' cert else reporter_util zope component getUtility interfaces IReporter reporter_util add_message 'Toobtainanewcertificatethatcontainsthesenameswithoutreplacingyourexistingcertificatefor{0} youmustusethe--duplicateoption {br}{br}Forexample {br}{br}{1}--duplicate{2}' format existing sys argv[0] '' join sys argv[1 ] br os linesep reporter_util HIGH_PRIORITY raise errors Error USER_CANCELLED
def tabulate_summary certificates kubeconfigs etcd_certs router_certs registry_certs items certificates + kubeconfigs + etcd_certs + router_certs + registry_certs summary_results {'system_certificates' len certificates 'kubeconfig_certificates' len kubeconfigs 'etcd_certificates' len etcd_certs 'router_certs' len router_certs 'registry_certs' len registry_certs 'total' len items 'ok' 0 'warning' 0 'expired' 0}summary_results['expired'] len [c for c in items if c['health'] 'expired' ] summary_results['warning'] len [c for c in items if c['health'] 'warning' ] summary_results['ok'] len [c for c in items if c['health'] 'ok' ] return summary_results
def tabulate_summary certificates kubeconfigs etcd_certs router_certs registry_certs items certificates + kubeconfigs + etcd_certs + router_certs + registry_certs summary_results {'system_certificates' len certificates 'kubeconfig_certificates' len kubeconfigs 'etcd_certificates' len etcd_certs 'router_certs' len router_certs 'registry_certs' len registry_certs 'total' len items 'ok' 0 'warning' 0 'expired' 0}summary_results['expired'] len [c for c in items if c['health'] 'expired' ] summary_results['warning'] len [c for c in items if c['health'] 'warning' ] summary_results['ok'] len [c for c in items if c['health'] 'ok' ] return summary_results
def cxSet ind1 ind2 temp set ind1 ind1 & ind2ind2 ^ tempreturn ind1 ind2
@register u'prefix-meta' def prefix_meta event event cli input_processor feed KeyPress Keys Escape
def rgb_to_256 rgb rgb rgb lstrip '#' if len rgb 0 return '0' '000000' incs 0 95 135 175 215 255 parts rgb_to_ints rgb res []for part in parts i 0while i < len incs - 1 s b incs[i] incs[ i + 1 ] if s < part < b s1 abs s - part b1 abs b - part if s1 < b1 closest selse closest bres append closest breaki + 1res '' join [ '%02 x' % i for i in res] equiv RGB_256[res]return equiv res
def add_enabled_equivalencies equivalencies context _UnitContext get_current_unit_registry get_current_unit_registry add_enabled_equivalencies equivalencies return context
def load_apps app_blacklist global DESKTOP_MODULESglobal DESKTOP_APPSif DESKTOP_APPS is not None raise Exception _ 'load_appshasalreadybeencalled ' DESKTOP_APPS []for sdk_app in pkg_resources iter_entry_points 'desktop sdk application' if sdk_app name not in app_blacklist if 'oozie' in app_blacklist and sdk_app name in 'pig' 'jobsub' LOG warn '%sdependsonooziewhichisblacklisted willskiploading%sapp ' % sdk_app name sdk_app name else m sdk_app load dmi DesktopModuleInfo m DESKTOP_APPS append dmi LOG debug 'LoadedDesktopApplications ' + ' ' join a name for a in DESKTOP_APPS DESKTOP_MODULES + DESKTOP_APPS
def starting_offset source_code offset word_finder worder Worder source_code True expression starting starting_offset word_finder get_splitted_primary_before offset return starting_offset
def starting_offset source_code offset word_finder worder Worder source_code True expression starting starting_offset word_finder get_splitted_primary_before offset return starting_offset
def get_temp_filename with NamedTemporaryFile as tempfile return tempfile name
def document_nav_links obj return combine_funcs obj parent_document_link topic_parent_document_link topic_sibling_documents_link topic_children_documents_link
def changes_from_tree names lookup_entry object_store tree want_unchanged False other_names set names if tree is not None for name mode sha in object_store iter_tree_contents tree try other_sha other_mode lookup_entry name except KeyError yield name None mode None sha None else other_names remove name if want_unchanged or other_sha sha or other_mode mode yield name name mode other_mode sha other_sha for name in other_names try other_sha other_mode lookup_entry name except KeyError passelse yield None name None other_mode None other_sha
def aware_to_naive d offset d utcoffset if offset d d replace tzinfo None d d - offset return d
def _install modules result {}_makePackages None modules result sys modules update result
def validate_css stylesheet images assert isinstance stylesheet unicode validator StylesheetValidator images return validator parse_and_validate stylesheet
def MarkFlagAsRequired flag_name flag_values FLAGS RegisterValidator flag_name lambda value value is not None message 'Flag--%smustbespecified ' % flag_name flag_values flag_values
def MarkFlagAsRequired flag_name flag_values FLAGS RegisterValidator flag_name lambda value value is not None message 'Flag--%smustbespecified ' % flag_name flag_values flag_values
def _soft_validate_additional_properties validator additional_properties_value instance schema if not validator is_type instance 'object' or additional_properties_value returnproperties schema get 'properties' {} patterns ' ' join schema get 'patternProperties' {} extra_properties set for prop in instance if prop not in properties if patterns if not re search patterns prop extra_properties add prop else extra_properties add prop if not extra_properties returnif patterns error 'Additionalpropertiesarenotallowed %s%sunexpected 'if len extra_properties 1 verb 'was'else verb 'were' yield jsonschema_exc ValidationError error % ' ' join repr extra for extra in extra_properties verb else for prop in extra_properties del instance[prop]
def _soft_validate_additional_properties validator additional_properties_value instance schema if not validator is_type instance 'object' or additional_properties_value returnproperties schema get 'properties' {} patterns ' ' join schema get 'patternProperties' {} extra_properties set for prop in instance if prop not in properties if patterns if not re search patterns prop extra_properties add prop else extra_properties add prop if not extra_properties returnif patterns error 'Additionalpropertiesarenotallowed %s%sunexpected 'if len extra_properties 1 verb 'was'else verb 'were' yield jsonschema_exc ValidationError error % ' ' join repr extra for extra in extra_properties verb else for prop in extra_properties del instance[prop]
def merge_dicts dict1 dict2 append_lists False for key in dict2 if isinstance dict2[key] dict if key in dict1 and key in dict2 merge_dicts dict1[key] dict2[key] else dict1[key] dict2[key]elif isinstance dict2[key] list and append_lists if key in dict1 and isinstance dict1[key] list dict1[key] extend dict2[key] else dict1[key] dict2[key]else dict1[key] dict2[key]
def get_stdlib_modules modules list sys builtin_module_names for path in sys path[1 ] if 'site-packages' not in path modules + module_list path modules set modules if '__init__' in modules modules remove '__init__' modules list modules return modules
@pytest fixturedef if_graphviz_found app graphviz_dot getattr app config 'graphviz_dot' '' try if graphviz_dot dot subprocess Popen [graphviz_dot '-V'] stdout subprocess PIPE stderr subprocess PIPE dot communicate returnexcept OSError passpytest skip 'graphviz"dot"isnotavailable'
def wait_until predicate success_description timeout 10 start time time while True retval predicate if retval return retvalif time time - start > timeout raise AssertionError "Didn'tever%s" % success_description time sleep 0 1
def _add_node_class_names names for _name in names setattr GenericNodeVisitor 'visit_' + _name _call_default_visit setattr GenericNodeVisitor 'depart_' + _name _call_default_departure setattr SparseNodeVisitor 'visit_' + _name _nop setattr SparseNodeVisitor 'depart_' + _name _nop
def is_macports_env env_prefix get_macports_prefix if env_prefix and base_prefix startswith env_prefix return Truereturn False
def readmodule_ex module path None return _readmodule module path or []
def readmodule_ex module path None return _readmodule module path or []
def sqeuclidean u v utype vtype None None if not hasattr u 'dtype' and np issubdtype u dtype np inexact utype np float64if not hasattr v 'dtype' and np issubdtype v dtype np inexact vtype np float64u _validate_vector u dtype utype v _validate_vector v dtype vtype u_v u - v return np dot u_v u_v
def find_missing_children filters None dryrun False errors []fixed []query Q 'nodes 0' 'exists' True if filters query query & filters with_children models Node find query for parent in with_children for child in parent nodes if not child node__parent msg u'Inconsistency Child{} {} doesnotpointtoparent{} {} Attemptingtofix \n' format child title child _primary_key parent title parent _primary_key logger info msg errors append child if dryrun is False child node__parent append parent child save msg u'Fixedinconsistency Child{} {} doesnotpointtoparent{} {} \n' format child title child _primary_key parent title parent _primary_key logger info msg fixed append child return errors fixed
def list_with_level course level return ROLES[level] course id users_with_role
def get_repository_dependencies app metadata_id sa_session app model context currentreturn sa_session query app model RepositoryDependency filter app model RepositoryDependency table c parent_metadata_id metadata_id all
def get_repository_dependencies app metadata_id sa_session app model context currentreturn sa_session query app model RepositoryDependency filter app model RepositoryDependency table c parent_metadata_id metadata_id all
def get_repository_dependencies app metadata_id sa_session app model context currentreturn sa_session query app model RepositoryDependency filter app model RepositoryDependency table c parent_metadata_id metadata_id all
def sca ax managers _pylab_helpers Gcf get_all_fig_managers for m in managers if ax in m canvas figure axes _pylab_helpers Gcf set_active m m canvas figure sca ax returnraise ValueError u'Axesinstanceargumentwasnotfoundinafigure '
def fixed_shortcut keystr parent action sc QShortcut QKeySequence keystr parent action sc setContext Qt WidgetWithChildrenShortcut return sc
def desaturate color percent return adjust color 1 - percent
def _shuffle y groups random_state if groups is None indices random_state permutation len y else indices np arange len groups for group in np unique groups this_mask groups group indices[this_mask] random_state permutation indices[this_mask] return safe_indexing y indices
def _shuffle y groups random_state if groups is None indices random_state permutation len y else indices np arange len groups for group in np unique groups this_mask groups group indices[this_mask] random_state permutation indices[this_mask] return safe_indexing y indices
def scan_postgrey_line date log collector m re match 'action greylist pass reason *? ? delay \\d+ ?client_name * client_address * sender * recipient * ' log if m action reason client_name client_address sender recipient m groups key client_address sender if action 'greylist' and reason 'new' collector['postgrey'] setdefault recipient {} [key] date None elif action 'pass' and reason 'tripletfound' and key in collector['postgrey'] get recipient {} collector['postgrey'][recipient][key] collector['postgrey'][recipient][key][0] date
def test_empty_monitoring_datasets learning_rate 0 001batch_size 5dim 3rng np random RandomState [25 9 2012] train_dataset DenseDesignMatrix X rng randn 10 dim model SoftmaxModel dim cost DummyCost algorithm SGD learning_rate cost batch_size batch_size monitoring_dataset {} termination_criterion EpochCounter 2 train Train train_dataset model algorithm save_path None save_freq 0 extensions None train main_loop
def cuirfft inp norm None is_odd False if is_odd not in True False raise ValueError 'Invalidvalue%sforid_odd mustbeTrueorFalse' % is_odd s inp shape[1 -1 ]if is_odd s T set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 + 1 else s T set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 cond_norm _unitary norm scaling 1if cond_norm is None scaling s prod astype 'float32' elif cond_norm 'ortho' scaling T sqrt s prod astype 'float32' return cuirfft_op inp s / scaling
@support_nddatadef block_reduce data block_size func np sum from skimage measure import block_reducedata np asanyarray data block_size np atleast_1d block_size if data ndim > 1 and len block_size 1 block_size np repeat block_size data ndim if len block_size data ndim raise ValueError u'`block_size`mustbeascalarorhavethesamelengthas`data shape`' block_size np array [int i for i in block_size] size_resampled np array data shape // block_size size_init size_resampled * block_size for i in range data ndim if data shape[i] size_init[i] data data swapaxes 0 i data data[ size_init[i]]data data swapaxes 0 i return block_reduce data tuple block_size func func
def get_component_review_by_repository_review_id_component_id app repository_review_id component_id sa_session app model context currentreturn sa_session query app model ComponentReview filter and_ app model ComponentReview table c repository_review_id app security decode_id repository_review_id app model ComponentReview table c component_id app security decode_id component_id first
def _reverse_url_pattern url_pattern *args group_index [0]def expand_group match group match group 1 try value str args[group_index[0]] group_index[0] + 1except IndexError raise CannotReversePattern 'Notenoughargumentsinurltag' if not re match group + '$' value raise CannotReversePattern "Value%rdoesn'tmatch %r " % value group return valueresult re sub '\\ [^ ]+ \\ ' expand_group url_pattern pattern result result replace '^' '' result result replace '$' '' return result
def _reverse_url_pattern url_pattern *args group_index [0]def expand_group match group match group 1 try value str args[group_index[0]] group_index[0] + 1except IndexError raise CannotReversePattern 'Notenoughargumentsinurltag' if not re match group + '$' value raise CannotReversePattern "Value%rdoesn'tmatch %r " % value group return valueresult re sub '\\ [^ ]+ \\ ' expand_group url_pattern pattern result result replace '^' '' result result replace '$' '' return result
def is_super node if getattr node 'name' None 'super' and node root name BUILTINS_NAME return Truereturn False
def build_preprocessors md_instance **kwargs preprocessors odict OrderedDict preprocessors[u'normalize_whitespace'] NormalizeWhitespace md_instance if md_instance safeMode u'escape' preprocessors[u'html_block'] HtmlBlockPreprocessor md_instance preprocessors[u'reference'] ReferencePreprocessor md_instance return preprocessors
def fix_broken_encoding value if isinstance value six text_type value value encode 'utf8' errors 'replace' if isinstance value six binary_type value value decode 'utf8' errors 'replace' return value
def fix_broken_encoding value if isinstance value six text_type value value encode 'utf8' errors 'replace' if isinstance value six binary_type value value decode 'utf8' errors 'replace' return value
def fix_broken_encoding value if isinstance value six text_type value value encode 'utf8' errors 'replace' if isinstance value six binary_type value value decode 'utf8' errors 'replace' return value
def fix_broken_encoding value if isinstance value six text_type value value encode 'utf8' errors 'replace' if isinstance value six binary_type value value decode 'utf8' errors 'replace' return value
def get_default_contact doctype name out frappe db sql u'selectparent \n DCTB DCTB DCTB selectis_primary_contactfromtabContactcwherec name dl parent \n DCTB DCTB DCTB DCTB asis_primary_contact\n DCTB DCTB from\n DCTB DCTB DCTB `tabDynamicLink`dl\n DCTB DCTB where\n DCTB DCTB DCTB dl link_doctype %sand\n DCTB DCTB DCTB dl link_name %sand\n DCTB DCTB DCTB dl parenttype "Contact"' doctype name if out return sorted out lambda x y cmp y[1] x[1] [0][0]else return None
def secure_required view_func def _wrapped_view request *args **kwargs if not request is_secure if getattr settings 'USERENA_USE_HTTPS' userena_settings DEFAULT_USERENA_USE_HTTPS request_url request build_absolute_uri request get_full_path secure_url request_url replace 'http //' 'https //' return HttpResponsePermanentRedirect secure_url return view_func request *args **kwargs return wraps view_func assigned available_attrs view_func _wrapped_view
def f_classif X y X y check_X_y X y ['csr' 'csc' 'coo'] args [X[safe_mask X y k ] for k in np unique y ]return f_oneway *args
def with_rw_directory func @wraps func def wrapper self path tempfile mktemp prefix func __name__ os mkdir path keep Falsetry return func self path except Exception log info 'Test%s %sfailed outputisat%r\n' type self __name__ func __name__ path keep Trueraisefinally import gcgc collect if not keep rmtree path return wrapper
def find_field name field_list related_query if related_query matches [f for f in field_list if f field related_query_name name ]else matches [f for f in field_list if f name name ]if len matches 1 return Nonereturn matches[0]
def transform_soups config soups precomputed fixup_internal_links config soups ensure_headings_linkable soups generate_page_tocs soups precomputed link_pantsrefs soups precomputed
def transform_soups config soups precomputed fixup_internal_links config soups ensure_headings_linkable soups generate_page_tocs soups precomputed link_pantsrefs soups precomputed
def transform_soups config soups precomputed fixup_internal_links config soups ensure_headings_linkable soups generate_page_tocs soups precomputed link_pantsrefs soups precomputed
def _is_safe_size n n int n if n 0 return Truefor c in 3 5 while n % c 0 n // creturn not n & n - 1
def _is_safe_size n n int n if n 0 return Truefor c in 3 5 while n % c 0 n // creturn not n & n - 1
def str_startswith arr pat na np nan f lambda x x startswith pat return _na_map f arr na dtype bool
def str_startswith arr pat na np nan f lambda x x startswith pat return _na_map f arr na dtype bool
def xl_cell_to_rowcol cell_str if not cell_str return 0 0 match range_parts match cell_str col_str match group 2 row_str match group 4 expn 0col 0for char in reversed col_str col + ord char - ord 'A' + 1 * 26 ** expn expn + 1row int row_str - 1 col - 1return row col
def attachment_specs_get context attachment_id return IMPL attachment_specs_get context attachment_id
def slide_in clip duration side w h clip sizepos_dict {'left' lambda t min 0 w * t / duration - 1 'center' 'right' lambda t max 0 w * 1 - t / duration 'center' 'top' lambda t 'center' min 0 h * t / duration - 1 'bottom' lambda t 'center' max 0 h * 1 - t / duration }return clip set_pos pos_dict[side]
def test_skip_dt_decorator2 dtargs ['x' 'y'] None 'k' 1 dtargsr getargspec doctest_bad assert dtargsr dtargs 'Incorrectlyreconstructedargsfordoctest_bad %s' % dtargsr
def init image root None nbd connect image if not nbd return ''return mount nbd root
def init image root None nbd connect image if not nbd return ''return mount nbd root
def init image root None nbd connect image if not nbd return ''return mount nbd root
def checkMatch input prediction sparse True verbosity 0 if sparse activeElementsInInput set input activeElementsInPrediction set prediction else activeElementsInInput set input nonzero [0] activeElementsInPrediction set prediction nonzero [0] totalActiveInPrediction len activeElementsInPrediction totalActiveInInput len activeElementsInInput foundInInput len activeElementsInPrediction intersection activeElementsInInput missingFromInput len activeElementsInPrediction difference activeElementsInInput missingFromPrediction len activeElementsInInput difference activeElementsInPrediction if verbosity > 1 print 'preds foundininput ' foundInInput 'outof' totalActiveInPrediction print ' preds missingfrominput ' missingFromInput 'outof' totalActiveInPrediction print ' unexpectedactiveininput ' missingFromPrediction 'outof' totalActiveInInputreturn foundInInput totalActiveInInput missingFromInput totalActiveInPrediction
def norm_open path return open path 'U'
@contextmanagerdef collect_profile file_prefix import cProfileimport uuidprofiler cProfile Profile profiler enable try yield finally profiler disable profiler dump_stats '{0}_{1}_master profile' format file_prefix uuid uuid4
def get_ldev obj if not obj return Noneldev obj get 'provider_location' if not ldev or not ldev isdigit return Nonereturn int ldev
def _replacer x try hexin ord x except TypeError hexin xreturn hex hexin
def _arity f if sys version_info < 3 return len inspect getargspec f [0] else param inspect signature f parameters values return len [p for p in param if p kind p POSITIONAL_OR_KEYWORD ]
def _arity f if sys version_info < 3 return len inspect getargspec f [0] else param inspect signature f parameters values return len [p for p in param if p kind p POSITIONAL_OR_KEYWORD ]
def _arity f if sys version_info < 3 return len inspect getargspec f [0] else param inspect signature f parameters values return len [p for p in param if p kind p POSITIONAL_OR_KEYWORD ]
def create_logger path None format_ None name None global loggerlogger getLogger name or DEFAULT_LOGGER_NAME logger propagate Falseif not logger handlers formatter Formatter fmt format_ or DEFAULT_FORMAT if path handler FileHandler path else handler StreamHandler handler setFormatter formatter logger addHandler handler return logger
def init_params options params OrderedDict params['Wemb'] norm_weight options['n_words_src'] options['dim_word'] params get_layer options['encoder'] [0] options params prefix 'encoder' nin options['dim_word'] dim options['dim'] return params
def init_params options params OrderedDict params['Wemb'] norm_weight options['n_words_src'] options['dim_word'] params get_layer options['encoder'] [0] options params prefix 'encoder' nin options['dim_word'] dim options['dim'] return params
def render template_file saltenv 'base' sls '' argline '' context None **kws tmp_data salt utils templates WEMPY template_file to_str True salt __salt__ grains __grains__ opts __opts__ pillar __pillar__ saltenv saltenv sls sls context context **kws if not tmp_data get 'result' False raise SaltRenderError tmp_data get 'data' 'Unknownrendererrorinthewempyrenderer' return six moves StringIO tmp_data['data']
def render template_file saltenv 'base' sls '' argline '' context None **kws tmp_data salt utils templates WEMPY template_file to_str True salt __salt__ grains __grains__ opts __opts__ pillar __pillar__ saltenv saltenv sls sls context context **kws if not tmp_data get 'result' False raise SaltRenderError tmp_data get 'data' 'Unknownrendererrorinthewempyrenderer' return six moves StringIO tmp_data['data']
def tty *args **kwargs return 'ERROR Thisfunctionhasbeenmovedtocmd tty'
def tty *args **kwargs return 'ERROR Thisfunctionhasbeenmovedtocmd tty'
def itemlist tparams return [vv for kk vv in tparams iteritems ]
def txt_records_for_name name if not DNS_AVAILABLE raise errors DependencyError '{0}isrequiredtousethisfunction' format DNS_REQUIREMENT try dns_response dns resolver query name 'TXT' except dns resolver NXDOMAIN as error return []except dns exception DNSException as error logger error 'Errorresolving%s %s' name str error return []return [txt_rec decode 'utf-8' for rdata in dns_response for txt_rec in rdata strings]
def _validate_device_list data valid_values None if not data msg _ 'Cannotcreateagatewaywithanemptydevicelist' return msgtry for device in data err_msg attributes _validate_dict device key_specs {DEVICE_ID_ATTR {'type regex' attributes UUID_PATTERN 'required' True} IFACE_NAME_ATTR {'type string' None 'required' False}} if err_msg return err_msgexcept TypeError return _ '%s provideddataarenotiterable' % _validate_device_list __name__
def windowdiff seg1 seg2 k boundary '1' weighted False if len seg1 len seg2 raise ValueError 'Segmentationshaveunequallength' if k > len seg1 raise ValueError 'Windowwidthkshouldbesmallerorequalthansegmentationlengths' wd 0for i in range len seg1 - k + 1 ndiff abs seg1[i i + k ] count boundary - seg2[i i + k ] count boundary if weighted wd + ndiffelse wd + min 1 ndiff return wd / len seg1 - k + 1 0
def distributed_server_test f return x_server_test f not settings CENTRAL_SERVER 'Distributedservertest'
def test_content_type transformer hug transform content_type {'application/json' int 'text/plain' str} class FakeRequest object content_type 'application/json'request FakeRequest assert transformer '1' request 1 request content_type 'text/plain'assert transformer 2 request '2' request content_type 'undefined' transformer {'data' 'value'} request {'data' 'value'}
def kaiser_atten numtaps width a 2 285 * numtaps - 1 * np pi * width + 7 95 return a
def get_accumulator_dir cachedir fn_ os path join cachedir 'accumulator' if not os path isdir fn_ os makedirs fn_ return fn_
def check_param trans param incoming_value param_values value incoming_valueerror Nonetry if trans workflow_building_mode if isinstance value RuntimeValue return [{'__class__' 'RuntimeValue'} None]if isinstance value dict if value get '__class__' 'RuntimeValue' return [value None]value param from_json value trans param_values param validate value trans except ValueError as e error str e return value error
def get_explore_recommendations user request data generate_recommendation_data exercise_parents_table get_exercise_parents_lookup_table recent_exercises get_most_recent_exercises user recent_subtopics list set [exercise_parents_table[ex]['subtopic_id'] for ex in recent_exercises if ex in exercise_parents_table ] sampleNum min len recent_subtopics settings TOPIC_RECOMMENDATION_DEPTH random_subtopics random sample recent_subtopics sampleNum added []final []for subtopic_id in random_subtopics related_subtopics data[subtopic_id]['related_subtopics'][2 7]recommended_topic next topic for topic in related_subtopics if topic not in added and topic not in recent_subtopics if recommended_topic final append {'suggested_topic' get_content_item language request language content_id recommended_topic topic True or {} 'interest_topic' get_content_item language request language content_id subtopic_id topic True or {} } added append recommended_topic return final
def make_context context request None **kwargs if context is not None and not isinstance context dict raise TypeError 'contextmustbeadictratherthan%s ' % context __class__ __name__ if request is None context Context context **kwargs else original_context contextcontext RequestContext request **kwargs if original_context context push original_context return context
def test_raise_exception_spatial sbn1 SpatialBatchNormalization 5 yield assert_raises ValueError sbn1 allocate sbn2 SpatialBatchNormalization 3 yield assert_raises ValueError sbn2 allocate def do_not_fail *input_dim try sbn SpatialBatchNormalization input_dim sbn allocate except ValueError assert False yield do_not_fail 5 4 3 yield do_not_fail 7 6 yield do_not_fail 3 9 2 3
def test_raise_exception_spatial sbn1 SpatialBatchNormalization 5 yield assert_raises ValueError sbn1 allocate sbn2 SpatialBatchNormalization 3 yield assert_raises ValueError sbn2 allocate def do_not_fail *input_dim try sbn SpatialBatchNormalization input_dim sbn allocate except ValueError assert False yield do_not_fail 5 4 3 yield do_not_fail 7 6 yield do_not_fail 3 9 2 3
def showFPS texw texh global frames t0t time time if t - t0 > 1 0 fps frames / t - t0 titlestr '%sx%stexture % 1fFPS' % texw texh fps glfw glfwSetWindowTitle window titlestr t0 tframes 0frames + 1
def showFPS texw texh global frames t0t time time if t - t0 > 1 0 fps frames / t - t0 titlestr '%sx%stexture % 1fFPS' % texw texh fps glfw glfwSetWindowTitle window titlestr t0 tframes 0frames + 1
def SampleRows df nrows replace False indices np random choice df index nrows replace replace sample df loc[indices]return sample
def flushall host None port None db None password None server _connect host port db password return server flushall
def kivy_register_post_configuration callback __kivy_post_configuration append callback
def _process_match rule syms subs {}varlist rule _varlistif not len varlist len syms raise RuntimeError "lengthofvarlistdoesn'tmatchlengthofsyms " for v s in zip varlist syms if v in subs and subs[v] s return Noneelse subs[v] sreturn subs
def toUnicode articles return tuple [art decode 'utf_8' for art in articles]
def incr_ratelimit user domain 'all' list_key set_key _ redis_key user domain now time time if len rules 0 returnwith client pipeline as pipe count 0while True try pipe watch list_key last_val pipe lindex list_key max_api_calls user - 1 pipe multi pipe lpush list_key now pipe ltrim list_key 0 max_api_calls user - 1 pipe zadd set_key now now if last_val is not None pipe zrem set_key last_val api_window max_api_window user pipe expire list_key api_window pipe expire set_key api_window pipe execute breakexcept redis WatchError if count > 10 logging error 'Failedtocompleteincr_ratelimittransactionwithoutinterference10timesinarow Abortingrate-limitincrement' breakcount + 1continue
def process_npm_assets def copy_vendor_library library skip_if_missing False '\nCopiesavendorlibrarytothesharedvendordirectory \n'library_path 'node_modules/{library}' format library library if os path exists library_path sh '/bin/cp-rf{library_path}{vendor_dir}' format library_path library_path vendor_dir NPM_VENDOR_DIRECTORY elif not skip_if_missing raise Exception 'Missingvendorfile{library_path}' format library_path library_path if tasks environment dry_run tasks environment info 'installnpm_assets' returnNPM_VENDOR_DIRECTORY mkdir_p print 'Copyingvendorfilesintostaticdirectory' for library in NPM_INSTALLED_LIBRARIES copy_vendor_library library print 'Copyingdevelopervendorfilesintostaticdirectory' for library in NPM_INSTALLED_DEVELOPER_LIBRARIES copy_vendor_library library skip_if_missing True
def sanitize_win_path_string winpath intab '<> ?*'outtab '_' * len intab trantab '' maketrans intab outtab if six PY3 else string maketrans intab outtab if isinstance winpath str winpath winpath translate trantab elif isinstance winpath six text_type winpath winpath translate dict ord c u'_' for c in intab return winpath
def num_obs_dm d d np asarray d order 'c' is_valid_dm d tol np inf throw True name 'd' return d shape[0]
def log_event event tracker send event
@task base BaseInstructorTask def course_survey_report_csv entry_id xmodule_instance_args action_name ugettext_noop 'generated' task_fn partial upload_course_survey_report xmodule_instance_args return run_main_task entry_id task_fn action_name
@task base BaseInstructorTask def course_survey_report_csv entry_id xmodule_instance_args action_name ugettext_noop 'generated' task_fn partial upload_course_survey_report xmodule_instance_args return run_main_task entry_id task_fn action_name
def render_panel request toolbar DebugToolbar fetch request GET[u'store_id'] if toolbar is None content _ u"Dataforthispanelisn'tavailableanymore Pleasereloadthepageandretry " content u'<p>%s</p>' % escape content else panel toolbar get_panel_by_id request GET[u'panel_id'] content panel contentreturn HttpResponse content
def last_modified_time path return pd Timestamp os path getmtime path unit 's' tz 'UTC'
def get_node_cpu_times reactor runner node known_name processes process_list list processes if known_name in processes delete_known_name Falseelse process_list append known_name delete_known_name Trueparser CPUParser reactor d runner run node _GET_CPUTIME_COMMAND + [' ' join process_list ] handle_stdout parser lineReceived def get_parser_result ignored result parser resultif delete_known_name and known_name in result del result[known_name]return resultd addCallback get_parser_result return d
def _list_hosts count 0hfn __get_hosts_filename ret odict OrderedDict if not os path isfile hfn return retwith salt utils fopen hfn as ifile for line in ifile line line strip if not line continueif line startswith '#' ret setdefault 'comment-{0}' format count [] extend line count + 1continueif '#' in line line line[ line index '#' ] strip comps line split ip comps pop 0 ret setdefault ip [] extend comps return ret
def types_msg instance types reprs []for type in types try reprs append repr type['name'] except Exception reprs append repr type return '%risnotoftype%s' % instance ' ' join reprs
def create_cmd args basename_binary False if basename_binary args[0] os path basename args[0] if os name 'nt' return subprocess list2cmdline args else escaped_args []for arg in args if re search '^[a-zA-Z0-9/_^\\-\\ ]+$' arg is None arg u"'" + arg replace u"'" u"'\\''" + u"'" escaped_args append arg return u'' join escaped_args
def create_cmd args basename_binary False if basename_binary args[0] os path basename args[0] if os name 'nt' return subprocess list2cmdline args else escaped_args []for arg in args if re search '^[a-zA-Z0-9/_^\\-\\ ]+$' arg is None arg u"'" + arg replace u"'" u"'\\''" + u"'" escaped_args append arg return u'' join escaped_args
def get_gating_milestone course_key content_key relationship try return find_gating_milestones course_key content_key relationship [0]except IndexError return None
def read file format **kwargs try tree_gen parse file format **kwargs tree next tree_gen except StopIteration raise ValueError 'Therearenotreesinthisfile ' try next tree_gen except StopIteration return treeelse raise ValueError 'Therearemultipletreesinthisfile useparse instead '
def list_role_policies role_name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile try response conn list_role_policies role_name _list response list_role_policies_response list_role_policies_resultreturn _list policy_namesexcept boto exception BotoServerError as e log debug e return []
def set_default_keychain keychain domain 'user' user None cmd 'securitydefault-keychain-d{0}-s{1}' format domain keychain return __salt__['cmd run'] cmd runas user
def set_default_keychain keychain domain 'user' user None cmd 'securitydefault-keychain-d{0}-s{1}' format domain keychain return __salt__['cmd run'] cmd runas user
def f4 t if t x 1else y 2print sorted locals items print sorted vars items
def open_stream stream global stream_fdtry stream_fd stream open except StreamError as err raise StreamError 'Couldnotopenstream {0}' format err try console logger debug 'Pre-buffering8192bytes' prebuffer stream_fd read 8192 except IOError as err raise StreamError 'Failedtoreaddatafromstream {0}' format err if not prebuffer raise StreamError 'Nodatareturnedfromstream' return stream_fd prebuffer
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def file_delete path return os unlink path
def cell_create context values return IMPL cell_create context values
def network_get_by_uuid context uuid return IMPL network_get_by_uuid context uuid
def tuple_factory colnames rows return rows
def split_lines tokenlist line []for item in tokenlist if len item 2 token string itemparts string split u'\n' for part in parts[ -1 ] if part line append token part yield line line []line append token parts[ -1 ] else token string mouse_handler itemparts string split u'\n' for part in parts[ -1 ] if part line append token part mouse_handler yield line line []line append token parts[ -1 ] mouse_handler yield line
def split_lines tokenlist line []for item in tokenlist if len item 2 token string itemparts string split u'\n' for part in parts[ -1 ] if part line append token part yield line line []line append token parts[ -1 ] else token string mouse_handler itemparts string split u'\n' for part in parts[ -1 ] if part line append token part mouse_handler yield line line []line append token parts[ -1 ] mouse_handler yield line
def canberra u v u _validate_vector u v _validate_vector v dtype np float64 olderr np seterr invalid 'ignore' try d np nansum abs u - v / abs u + abs v finally np seterr **olderr return d
def _ros_plot_pos row censorship cohn DL_index row['det_limit_index']rank row['rank']censored row[censorship]dl_1 cohn iloc[DL_index]dl_2 cohn iloc[ DL_index + 1 ]if censored return 1 - dl_1['prob_exceedance'] * rank / dl_1['ncen_equal'] + 1 else return 1 - dl_1['prob_exceedance'] + dl_1['prob_exceedance'] - dl_2['prob_exceedance'] * rank / dl_1['nuncen_above'] + 1
def test_settings env testval 'outervalue'with settings testval 'innervalue' eq_ env testval 'innervalue' eq_ env testval 'outervalue'
def shadow_hash crypt_salt None password None algorithm 'sha512' return salt utils pycrypto gen_hash crypt_salt password algorithm
def detect byte_string if not isinstance byte_string byte_cls raise TypeError unwrap u'\nbyte_stringmustbeabytestring not%s\n' type_name byte_string return byte_string find '-----BEGIN' -1 or byte_string find '----BEGIN' -1
def add_from_csv csv_file version None overwrite False diagnostic_messages []for module_name new_metadata in parse_assigned_metadata_initial csv_file filename module_loader find_plugin module_name mod_type ' py' if filename is None diagnostic_messages append 'Unabletofindthemodulefilefor{}' format module_name continuetry write_metadata filename new_metadata version overwrite except ParseError as e diagnostic_messages append e args[0] continueif diagnostic_messages pprint diagnostic_messages return 0
def read_random_int nbits randomdata read_random_bits nbits value transform bytes2int randomdata value 1 << nbits - 1 return value
def _prune_blobs blobs_array overlap for blob1 blob2 in itt combinations blobs_array 2 if _blob_overlap blob1 blob2 > overlap if blob1[2] > blob2[2] blob2[2] -1 else blob1[2] -1 return np array [b for b in blobs_array if b[2] > 0 ]
def get_domainvalue link z - np log np random uniform 0 1 if type link type cloglog z min z 3 elif type link type negbinom z - z return z
def metric_to_Ricci_components expr riemann metric_to_Riemann_components expr coord_sys expr atoms CoordSystem pop indices list range coord_sys dim ricci [[Add *[riemann[ k i k j ] for k in indices] for j in indices] for i in indices]return ImmutableDenseNDimArray ricci
@loader_option def raiseload loadopt attr sql_only False return loadopt set_relationship_strategy attr {'lazy' 'raise_on_sql' if sql_only else 'raise' }
@loader_option def raiseload loadopt attr sql_only False return loadopt set_relationship_strategy attr {'lazy' 'raise_on_sql' if sql_only else 'raise' }
def unique seq seen set seen_add seen addreturn [x for x in seq if not x in seen or seen_add x ]
def unique seq seen set seen_add seen addreturn [x for x in seq if not x in seen or seen_add x ]
def unique seq seen set seen_add seen addreturn [x for x in seq if not x in seen or seen_add x ]
def merge_dict d1 d2 d d1 copy for k v in iteritems d2 if k in d d[k] + velse d[k] vreturn d
@task@needs 'pavelib i18n i18n_extract' @cmdopts [ 'settings ' 's' 'Thesettingstouse defaultstodevstack ' ] @timeddef i18n_dummy options settings options get 'settings' DEFAULT_SETTINGS sh 'i18n_tooldummy' sh 'i18n_toolgenerate' for system in ['lms' 'cms'] sh django_cmd system settings 'compilejsi18n'
def test_ast_bad_cut cant_compile u' cut ' cant_compile u' cut12345 '
def test_ast_bad_cut cant_compile u' cut ' cant_compile u' cut12345 '
def test_ast_bad_cut cant_compile u' cut ' cant_compile u' cut12345 '
def test_ast_bad_cut cant_compile u' cut ' cant_compile u' cut12345 '
def new_private_link name user nodes anonymous key str uuid uuid4 replace '-' '' if name name strip_html name if name is None or not name strip raise ValidationValueError 'Invalidlinkname ' else name 'Sharedprojectlink'private_link PrivateLink key key name name creator user anonymous anonymous private_link save private_link nodes add *nodes private_link save return private_link
def set_var var value makeconf _get_makeconf old_value get_var var if old_value is not None __salt__['file sed'] makeconf '^{0} *' format var '{0} "{1}"' format var value else _add_var var value new_value get_var var return {var {'old' old_value 'new' new_value}}
def save_config **kwargs if kwargs {} kwargs config _configcurrent_config _load_config current_config update **kwargs fname _get_config_fname if fname is None raise RuntimeError 'configfilenamecouldnotbedetermined' if not op isdir op dirname fname os mkdir op dirname fname with open fname 'w' as fid json dump current_config fid sort_keys True indent 0
def save_config **kwargs if kwargs {} kwargs config _configcurrent_config _load_config current_config update **kwargs fname _get_config_fname if fname is None raise RuntimeError 'configfilenamecouldnotbedetermined' if not op isdir op dirname fname os mkdir op dirname fname with open fname 'w' as fid json dump current_config fid sort_keys True indent 0
@login_requireddef delete_answer request question_id answer_id answer get_object_or_404 Answer pk answer_id question question_id if not answer allows_delete request user raise PermissionDeniedif request method 'GET' return render request 'questions/confirm_answer_delete html' {'answer' answer} log warning 'User%sisdeletinganswerwithid %s' % request user answer id answer delete statsd incr 'questions delete_answer' return HttpResponseRedirect reverse 'questions details' args [question_id]
def force_bytes s encoding 'utf-8' if isinstance s binary_type return selif isinstance s Text return s encode encoding else raise TypeError 'force_bytesexpectsastringtype'
def send_post_signup_email user_id for key content in SIGNUP_EMAIL_CONTENT value iteritems if content SIGNUP_EMAIL_CONTENT default_value[key] log_new_error 'PleaseensurethatthevaluefortheadminconfigpropertySIGNUP_EMAIL_CONTENTisset beforeallowingpost-signupemailstobesent ' returnuser_settings user_services get_user_settings user_id email_subject SIGNUP_EMAIL_CONTENT value['subject']email_body 'Hi%s <br><br>%s<br><br>%s' % user_settings username SIGNUP_EMAIL_CONTENT value['html_body'] EMAIL_FOOTER value _send_email user_id feconf SYSTEM_COMMITTER_ID feconf EMAIL_INTENT_SIGNUP email_subject email_body feconf NOREPLY_EMAIL_ADDRESS
def check table 'filter' chain None rule None family 'ipv4' if not chain return 'Error Chainneedstobespecified'if not rule return 'Error Ruleneedstobespecified'if not check_table table family family return 'Error table{0}infamily{1}doesnotexist' format table family if not check_chain table chain family family return 'Error chain{0}intable{1}infamily{2}doesnotexist' format chain table family nft_family _NFTABLES_FAMILIES[family]cmd '{0}--handle--numeric--numeric--numericlistchain{1}{2}{3}' format _nftables_cmd nft_family table chain search_rule '{0}#' format rule out __salt__['cmd run'] cmd python_shell False find search_rule if out -1 out ''else return Falseif not out return Truereturn out
def circmean data axis None weights None return _angle data 1 0 0 axis weights
@pytest mark cmddef test_test_checks_noargs with pytest raises CommandError as e call_command 'test_checks' assert 'Either--unitorapairof--sourceand--targetmustbeprovided ' in str e
@util positional 1 def command name required optional def check_params_decorator function def check_params_wrapper options *args if not len required < len args < len required + len optional sys stderr write "Incorrectusageforcommand'%s'\n\n" % name usage function options *args check_params_wrapper required requiredcheck_params_wrapper optional optionalcommands[name] check_params_wrapperreturn check_params_wrapperreturn check_params_decorator
def has_identity object state attributes instance_state object return state has_identity
def add_method func *combined_args def wrapper cls for combined_arg in combined_args if len combined_arg 2 args combined_arg[0]kwargs combined_arg[1]elif isinstance combined_arg[0] Mapping args []kwargs combined_arg[0]else args combined_arg[0]kwargs {}test_method make_method func args kwargs setattr cls test_method __name__ test_method return clsreturn wrapper
def native_value value if isinstance value six string_types if value lower in ['on' 'true' 'yes'] value Trueelif value lower in ['off' 'false' 'no'] value Falsetry return ast literal_eval value except TypeError ValueError SyntaxError passreturn value
def is_vulnerable host timeout port 443 s socket socket socket AF_INET socket SOCK_STREAM s settimeout int timeout try s connect host int port except Exception as e return Nones send hello while True typ ver pay recvmsg s if typ is None return Noneif typ 22 payarr unpack_handshake pay finddone [t for t l p in payarr if t 14 ]if len finddone > 0 breakver_chr chr ver & 255 hb h2bin '1803' + ver_chr + h2bin '4000013ffd' + '\x01' * 16381 hb + h2bin '1803' + ver_chr + h2bin '0003010000' s send hb return hit_hb s
def generatedPointGrid pixel_width pixel_height width_scalar 1 0 height_scalar 1 0 horiz_points 5 vert_points 5 swidth pixel_width * width_scalar sheight pixel_height * height_scalar x y np meshgrid np linspace - swidth / 2 0 swidth / 2 0 horiz_points np linspace - sheight / 2 0 sheight / 2 0 vert_points points np column_stack x flatten y flatten return points
@task@cmdopts [BOKCHOY_COVERAGERC BOKCHOY_DEFAULT_STORE BOKCHOY_DEFAULT_STORE_DEPR] @timeddef start_servers options coveragerc options get 'coveragerc' Env BOK_CHOY_COVERAGERC def start_server cmd logfile cwd None '\nStartsasingleserver \n'print cmd logfilerun_background_process cmd out_log logfile err_log logfile cwd cwd for service info in Env BOK_CHOY_SERVERS iteritems address '0 0 0 0 {}' format info['port'] cmd 'DEFAULT_STORE {default_store}coveragerun--rcfile {coveragerc}-mmanage{service}--settingsbok_choyrunserver{address}--traceback--noreload' format default_store options default_store coveragerc coveragerc service service address address start_server cmd info['log'] for service info in Env BOK_CHOY_STUBS iteritems cmd 'python-mstubs start{service}{port}{config}' format service service port info['port'] config info get 'config' '' start_server cmd info['log'] cwd Env BOK_CHOY_STUB_DIR
@task@cmdopts [BOKCHOY_COVERAGERC BOKCHOY_DEFAULT_STORE BOKCHOY_DEFAULT_STORE_DEPR] @timeddef start_servers options coveragerc options get 'coveragerc' Env BOK_CHOY_COVERAGERC def start_server cmd logfile cwd None '\nStartsasingleserver \n'print cmd logfilerun_background_process cmd out_log logfile err_log logfile cwd cwd for service info in Env BOK_CHOY_SERVERS iteritems address '0 0 0 0 {}' format info['port'] cmd 'DEFAULT_STORE {default_store}coveragerun--rcfile {coveragerc}-mmanage{service}--settingsbok_choyrunserver{address}--traceback--noreload' format default_store options default_store coveragerc coveragerc service service address address start_server cmd info['log'] for service info in Env BOK_CHOY_STUBS iteritems cmd 'python-mstubs start{service}{port}{config}' format service service port info['port'] config info get 'config' '' start_server cmd info['log'] cwd Env BOK_CHOY_STUB_DIR
def build_list context builder list_type items nitems len items inst ListInstance allocate context builder list_type nitems inst size context get_constant types intp nitems for i val in enumerate items inst setitem context get_constant types intp i val return impl_ret_new_ref context builder list_type inst value
def get_total_open_threads feedback_thread_analytics return sum feedback num_open_threads for feedback in feedback_thread_analytics
def example_number_for_type region_code num_type if region_code is None return _example_number_anywhere_for_type num_type if not _is_valid_region_code region_code return Nonemetadata PhoneMetadata metadata_for_region region_code upper desc _number_desc_for_type metadata num_type if desc example_number is not None try return parse desc example_number region_code except NumberParseException passreturn None
def formatRecords records heading answers authority additional recordslines [ '#' + heading ]for a in answers line [a name dns QUERY_CLASSES get a cls 'UNKNOWN %d ' % a cls a payload]lines append '' join str word for word in line return '\n' join line for line in lines
def formatRecords records heading answers authority additional recordslines [ '#' + heading ]for a in answers line [a name dns QUERY_CLASSES get a cls 'UNKNOWN %d ' % a cls a payload]lines append '' join str word for word in line return '\n' join line for line in lines
def formatRecords records heading answers authority additional recordslines [ '#' + heading ]for a in answers line [a name dns QUERY_CLASSES get a cls 'UNKNOWN %d ' % a cls a payload]lines append '' join str word for word in line return '\n' join line for line in lines
def wep_send_deauths iface target clients global RUN_CONFIGcmd ['aireplay-ng' '--ignore-negative-one' '--deauth' str RUN_CONFIG WPA_DEAUTH_COUNT '-a' target bssid iface]call cmd stdout DN stderr DN for client in clients cmd ['aireplay-ng' '--ignore-negative-one' '--deauth' str RUN_CONFIG WPA_DEAUTH_COUNT '-a' target bssid '-h' client bssid iface]call cmd stdout DN stderr DN
def wep_send_deauths iface target clients global RUN_CONFIGcmd ['aireplay-ng' '--ignore-negative-one' '--deauth' str RUN_CONFIG WPA_DEAUTH_COUNT '-a' target bssid iface]call cmd stdout DN stderr DN for client in clients cmd ['aireplay-ng' '--ignore-negative-one' '--deauth' str RUN_CONFIG WPA_DEAUTH_COUNT '-a' target bssid '-h' client bssid iface]call cmd stdout DN stderr DN
@contextlib contextmanagerdef assure_cleanup enter_func exit_func use_enter_return enter_return Nonetry if isinstance enter_func functools partial enter_func_name enter_func func __name__else enter_func_name enter_func __name__LOG debug 'Enteringcontext Function % func_name s use_enter_return % use s ' {'func_name' enter_func_name 'use' use_enter_return} enter_return enter_func yield enter_return finally if isinstance exit_func functools partial exit_func_name exit_func func __name__else exit_func_name exit_func __name__LOG debug 'Exitingcontext Function % func_name s use_enter_return % use s ' {'func_name' exit_func_name 'use' use_enter_return} if enter_return is not None if use_enter_return ignore_exception exit_func enter_return else ignore_exception exit_func
def s3_decode_iso_datetime dtstr DEFAULT datetime datetime utcnow replace second 0 microsecond 0 dt dateutil parser parse dtstr default DEFAULT if dt tzinfo is None try dt dateutil parser parse dtstr + '+0000' default DEFAULT except dt dateutil parser parse dtstr + '00 00 00+0000' default DEFAULT return dt
def s3_decode_iso_datetime dtstr DEFAULT datetime datetime utcnow replace second 0 microsecond 0 dt dateutil parser parse dtstr default DEFAULT if dt tzinfo is None try dt dateutil parser parse dtstr + '+0000' default DEFAULT except dt dateutil parser parse dtstr + '00 00 00+0000' default DEFAULT return dt
def s3_decode_iso_datetime dtstr DEFAULT datetime datetime utcnow replace second 0 microsecond 0 dt dateutil parser parse dtstr default DEFAULT if dt tzinfo is None try dt dateutil parser parse dtstr + '+0000' default DEFAULT except dt dateutil parser parse dtstr + '00 00 00+0000' default DEFAULT return dt
def delete_thumbnails relative_source_path root None basedir None subdir None prefix None thumbs thumbnails_for_file relative_source_path root basedir subdir prefix return _delete_using_thumbs_list thumbs
def delete_thumbnails relative_source_path root None basedir None subdir None prefix None thumbs thumbnails_for_file relative_source_path root basedir subdir prefix return _delete_using_thumbs_list thumbs
def update collection_name upsert multi spec doc safe last_error_args check_keys opts options 0if upsert options + 1if multi options + 2data _ZERO_32data + bson _make_c_string collection_name data + struct pack '<i' options data + bson BSON encode spec False opts encoded bson BSON encode doc check_keys opts data + encodedif safe _ update_message __pack_message 2001 data request_id error_message _ __last_error collection_name last_error_args return request_id update_message + error_message len encoded else request_id update_message __pack_message 2001 data return request_id update_message len encoded
def to_node node_state return Node uuid node_state uuid hostname node_state hostname applications node_state applications or {} manifestations node_state manifestations or {}
def _get_filter_query args query Q if 'datefrom' in args and 'dateto' in args and args['datefrom'] and args['dateto'] datefrom datetime date datetime strptime args['datefrom'] '%m/%d/%Y' dateto datetime date datetime strptime args['dateto'] '%m/%d/%Y' dateto datetime year dateto year month dateto month day dateto day hour 23 minute 59 second 59 query Q end__gte datefrom query query & Q Q start__isnull True Q start__lte dateto return query
def to_int *names **kwargs return reduce lambda prev next prev SCOPE_NAME_DICT get next 0 names kwargs pop 'default' 0
def current_resource_name request service current_service request resource_name service viewset get_name service resource return resource_name
def proc_exists pid if not os path exists '/proc/%s' % pid raise NoSuchProcess
def proc_exists pid if not os path exists '/proc/%s' % pid raise NoSuchProcess
def check_that_blanks_fail problem blank_answers dict answer_id u'' for answer_id in problem get_question_answers grading_results problem grade_answers blank_answers try assert all result u'incorrect' for result in grading_results values except AssertionError log error u'Blankacceptedascorrectanswerin{0}for{1}' format problem [answer_id for answer_id result in sorted grading_results items if result u'incorrect' ]
def open name mode 'r' bufsize -1 return _posixfile_ open name mode bufsize
def mainloop n 0 _default_root tk mainloop n
def _dump_event event dump {}dump['summary'] event titledump['description'] event descriptiondump['location'] event locationdump['transparency'] 'opaque' if event busy else 'transparent' if event all_day dump['start'] {'date' event start strftime '%Y-%m-%d' }dump['end'] {'date' event end strftime '%Y-%m-%d' }else dump['start'] {'dateTime' event start isoformat 'T' 'timeZone' 'UTC'}dump['end'] {'dateTime' event end isoformat 'T' 'timeZone' 'UTC'}if event participants dump['attendees'] []inverse_status_map {value key for key value in STATUS_MAP items }for participant in event participants attendee {}if 'name' in participant attendee['displayName'] participant['name']if 'status' in participant attendee['responseStatus'] inverse_status_map[participant['status']]if 'email' in participant attendee['email'] participant['email']if 'guests' in participant attendee['additionalGuests'] participant['guests']if attendee dump['attendees'] append attendee return dump
def _maybe_convert_string_to_object values if isinstance values string_types values np array [values] dtype object elif isinstance values np ndarray and issubclass values dtype type np string_ np unicode_ values values astype object return values
def _convert_to_standard_attr attr ret_attr ATTR_MAP get attr None if ret_attr is None return attr lower return ret_attr
def _convert_to_standard_attr attr ret_attr ATTR_MAP get attr None if ret_attr is None return attr lower return ret_attr
def _convert_to_standard_attr attr ret_attr ATTR_MAP get attr None if ret_attr is None return attr lower return ret_attr
def _convert_to_standard_attr attr ret_attr ATTR_MAP get attr None if ret_attr is None return attr lower return ret_attr
def enable name **kwargs stat_cmd '{0}set{1}statuson' format _cmd name stat_retcode __salt__['cmd retcode'] stat_cmd flag_retcode Noneif os path exists '/etc/rc d/{0}' format name flags _get_flags **kwargs flag_cmd '{0}set{1}flags{2}' format _cmd name flags flag_retcode __salt__['cmd retcode'] flag_cmd return not any [stat_retcode flag_retcode]
def get_rarefaction_data rarefaction_data col_headers rare_mat_raw array rarefaction_data rare_mat_min [rare_mat_raw[x][2 ] for x in range 0 len rare_mat_raw ]seqs_per_samp [rare_mat_raw[x][0] for x in range 0 len rare_mat_raw ]sampleIDs col_headers[3 ]rare_mat_trans transpose array rare_mat_min tolist return rare_mat_trans seqs_per_samp sampleIDs
def flatten_tree elem path branches if not path path []if isinstance elem dict for k v in elem items flatten_tree v path + [k] branches elif isinstance elem list for sub in elem flatten_tree sub path branches else branches append path + [six text_type elem ]
def flatten_tree elem path branches if not path path []if isinstance elem dict for k v in elem items flatten_tree v path + [k] branches elif isinstance elem list for sub in elem flatten_tree sub path branches else branches append path + [six text_type elem ]
def find_sr_from_vdi session vdi_ref try sr_ref session call_xenapi 'VDI get_SR' vdi_ref except session XenAPI Failure LOG exception _LE 'UnabletofindSRfromVDI' raise exception StorageError reason _ 'UnabletofindSRfromVDI%s' % vdi_ref return sr_ref
def create_consistencygroup ctxt host 'test_host@fakedrv#fakepool' name 'test_cg' description 'thisisatestcg' status fields ConsistencyGroupStatus AVAILABLE availability_zone 'fake_az' volume_type_id None cgsnapshot_id None source_cgid None **kwargs cg objects ConsistencyGroup ctxt cg host hostcg user_id ctxt user_id or fake USER_ID cg project_id ctxt project_id or fake PROJECT_ID cg status statuscg name namecg description descriptioncg availability_zone availability_zoneif volume_type_id cg volume_type_id volume_type_idcg cgsnapshot_id cgsnapshot_idcg source_cgid source_cgidnew_id kwargs pop 'id' None cg update kwargs cg create if new_id and new_id cg id db consistencygroup_update ctxt cg id {'id' new_id} cg objects ConsistencyGroup get_by_id ctxt new_id return cg
def xml_summary registry xml_parent data summary XML SubElement xml_parent 'hudson plugins summary__report ACIPluginPublisher' summary set 'plugin' 'summary_report' mapping [ 'files' 'name' None 'shown-on-project-page' 'shownOnProjectPage' False ]helpers convert_mapping_to_xml summary data mapping fail_required True
def xml_summary registry xml_parent data summary XML SubElement xml_parent 'hudson plugins summary__report ACIPluginPublisher' summary set 'plugin' 'summary_report' mapping [ 'files' 'name' None 'shown-on-project-page' 'shownOnProjectPage' False ]helpers convert_mapping_to_xml summary data mapping fail_required True
def xml_summary registry xml_parent data summary XML SubElement xml_parent 'hudson plugins summary__report ACIPluginPublisher' summary set 'plugin' 'summary_report' mapping [ 'files' 'name' None 'shown-on-project-page' 'shownOnProjectPage' False ]helpers convert_mapping_to_xml summary data mapping fail_required True
def getAlterationFileLines fileName lines getAlterationLines fileName if len lines 0 return []return [getAlterationFileLineBlindly fileName ] + lines
def send event **arguments log debug u'Sendingevent {0}' format event for handler in event_handlers [event] argspec inspect getargspec handler argsargs dict k v for k v in arguments items if k in argspec handler **args
def _sanitize migrate_engine table session orm sessionmaker bind migrate_engine qry session query table c image_id table c member group_by table c image_id table c member having func count > 1 for image_id member in qry d table delete where and_ table c deleted True table c image_id image_id table c member member d execute session close
def _sanitize migrate_engine table session orm sessionmaker bind migrate_engine qry session query table c image_id table c member group_by table c image_id table c member having func count > 1 for image_id member in qry d table delete where and_ table c deleted True table c image_id image_id table c member member d execute session close
@contextlib contextmanagerdef kill_on_error proc with proc try yield proc except proc kill raise
def append_PKCS7_padding b numpads 16 - len b % 16 return b + numpads * bytes chr numpads encoding u'ascii'
def _gather_pillar pillarenv pillar_override **grains pillar salt pillar get_pillar __opts__ grains __opts__['id'] __opts__['environment'] pillar pillar_override pillarenv pillarenv ret pillar compile_pillar if pillar_override and isinstance pillar_override dict ret update pillar_override return ret
def test_create_user_story_attachment_without_file client us f UserStoryFactory create f MembershipFactory project us project user us owner is_admin True attachment_data {'description' 'test' 'attached_file' None 'project' us project_id}url reverse 'userstory-attachments-list' client login us owner response client post url attachment_data assert response status_code 400
def test_get_set_vector rng np random RandomState [2014 5 8] class DummyModel Model "\nAModelthatexercisesthistestbyhavingafewdifferent\nparameterswithdifferentshapesanddimensionalities \n\nDon'tinstantiatemorethanoneofthesebecausetheparameters\nareclass-levelattributes \n"_params [sharedX rng randn 5 sharedX rng randn 5 3 sharedX rng randn 4 4 4 ]model DummyModel vector model get_param_vector model set_param_vector 0 0 * vector assert np allclose 0 0 * vector model get_param_vector model set_param_vector vector assert np allclose model get_param_vector vector
def test_get_set_vector rng np random RandomState [2014 5 8] class DummyModel Model "\nAModelthatexercisesthistestbyhavingafewdifferent\nparameterswithdifferentshapesanddimensionalities \n\nDon'tinstantiatemorethanoneofthesebecausetheparameters\nareclass-levelattributes \n"_params [sharedX rng randn 5 sharedX rng randn 5 3 sharedX rng randn 4 4 4 ]model DummyModel vector model get_param_vector model set_param_vector 0 0 * vector assert np allclose 0 0 * vector model get_param_vector model set_param_vector vector assert np allclose model get_param_vector vector
def _straight_line_vertices adjacency_mat node_coords directed False if not issparse adjacency_mat adjacency_mat np asarray adjacency_mat float if adjacency_mat ndim 2 or adjacency_mat shape[0] adjacency_mat shape[1] raise ValueError 'Adjacencymatrixshouldbesquare ' arrow_vertices np array [] edges _get_edges adjacency_mat line_vertices node_coords[edges ravel ]if directed arrows np array list _get_directed_edges adjacency_mat arrow_vertices node_coords[arrows ravel ]arrow_vertices arrow_vertices reshape len arrow_vertices / 2 4 return line_vertices arrow_vertices
@hgcommanddef undo ui repo clname **opts if not workbranch repo[None] branch raise hg_util Abort 'cannotrunhgundooutsidedefaultbranch' err clpatch_or_undo ui repo clname opts mode 'undo' if err raise hg_util Abort err
@hgcommanddef undo ui repo clname **opts if not workbranch repo[None] branch raise hg_util Abort 'cannotrunhgundooutsidedefaultbranch' err clpatch_or_undo ui repo clname opts mode 'undo' if err raise hg_util Abort err
@hgcommanddef undo ui repo clname **opts if not workbranch repo[None] branch raise hg_util Abort 'cannotrunhgundooutsidedefaultbranch' err clpatch_or_undo ui repo clname opts mode 'undo' if err raise hg_util Abort err
def _renameColumn cname cname cname replace 'ID' 'Id' return _renameTable cname
def dereference_type t if t strip in ['void*' 'char*'] return t strip try return t[ t rindex '*' ] strip except return t strip
def dereference_type t if t strip in ['void*' 'char*'] return t strip try return t[ t rindex '*' ] strip except return t strip
def axes *args **kwargs nargs len args if len args 0 return subplot 111 **kwargs if nargs > 1 raise TypeError 'Onlyonenonkeywordargtoaxesallowed' arg args[0]if isinstance arg Axes a gcf sca arg else rect arga gcf add_axes rect **kwargs draw_if_interactive return a
def axes *args **kwargs nargs len args if len args 0 return subplot 111 **kwargs if nargs > 1 raise TypeError 'Onlyonenonkeywordargtoaxesallowed' arg args[0]if isinstance arg Axes a gcf sca arg else rect arga gcf add_axes rect **kwargs draw_if_interactive return a
def enabled name **kwargs ret {'name' name 'result' True 'changes' {} 'comment' []}current_schedule __salt__['schedule list'] show_all True return_yaml False if name in current_schedule if 'test' in __opts__ and __opts__['test'] kwargs['test'] Trueresult __salt__['schedule enable_job'] name **kwargs ret['comment'] append result['comment'] else result __salt__['schedule enable_job'] name **kwargs if not result['result'] ret['result'] result['result']ret['comment'] result['comment']return retelse ret['comment'] append 'Enabledjob{0}fromschedule' format name else ret['comment'] append 'Job{0}notpresentinschedule' format name ret['comment'] '\n' join ret['comment'] return ret
def create_location org course run block_type block_id return modulestore make_course_key org course run make_usage_key block_type block_id
def renderSymbol symbol size pen brush device None penPxWidth max np ceil pen widthF 1 if device is None device QtGui QImage int size + penPxWidth int size + penPxWidth QtGui QImage Format_ARGB32 device fill 0 p QtGui QPainter device try p setRenderHint p Antialiasing p translate device width * 0 5 device height * 0 5 drawSymbol p symbol size pen brush finally p end return device
def _fast_cross_3d x y assert x ndim 2 assert y ndim 2 assert x shape[1] 3 assert y shape[1] 3 assert x shape[0] 1 or y shape[0] 1 or x shape[0] y shape[0] if max [x shape[0] y shape[0]] > 500 return np c_[ x[ 1] * y[ 2] - x[ 2] * y[ 1] x[ 2] * y[ 0] - x[ 0] * y[ 2] x[ 0] * y[ 1] - x[ 1] * y[ 0] ]else return np cross x y
def submit_reset_problem_attempts_in_entrance_exam request usage_key student modulestore get_item usage_key task_type 'reset_problem_attempts'task_class reset_problem_attempts task_input task_key encode_entrance_exam_and_student_input usage_key student return submit_task request task_type task_class usage_key course_key task_input task_key
def _json_convert obj json_options DEFAULT_JSON_OPTIONS if hasattr obj 'iteritems' or hasattr obj 'items' return SON k _json_convert v json_options for k v in iteritems obj elif hasattr obj '__iter__' and not isinstance obj text_type bytes return list _json_convert v json_options for v in obj try return default obj json_options except TypeError return obj
def _json_convert obj json_options DEFAULT_JSON_OPTIONS if hasattr obj 'iteritems' or hasattr obj 'items' return SON k _json_convert v json_options for k v in iteritems obj elif hasattr obj '__iter__' and not isinstance obj text_type bytes return list _json_convert v json_options for v in obj try return default obj json_options except TypeError return obj
def _json_convert obj json_options DEFAULT_JSON_OPTIONS if hasattr obj 'iteritems' or hasattr obj 'items' return SON k _json_convert v json_options for k v in iteritems obj elif hasattr obj '__iter__' and not isinstance obj text_type bytes return list _json_convert v json_options for v in obj try return default obj json_options except TypeError return obj
def get_hash path form 'sha256' chunk_size 65536 hash_type hasattr hashlib form and getattr hashlib form or None if hash_type is None raise ValueError 'Invalidhashtype {0}' format form with salt utils fopen path 'rb' as ifile hash_obj hash_type for chunk in iter lambda ifile read chunk_size '' hash_obj update chunk return hash_obj hexdigest
def get_hash path form 'sha256' chunk_size 65536 hash_type hasattr hashlib form and getattr hashlib form or None if hash_type is None raise ValueError 'Invalidhashtype {0}' format form with salt utils fopen path 'rb' as ifile hash_obj hash_type for chunk in iter lambda ifile read chunk_size '' hash_obj update chunk return hash_obj hexdigest
def get_hash path form 'sha256' chunk_size 65536 hash_type hasattr hashlib form and getattr hashlib form or None if hash_type is None raise ValueError 'Invalidhashtype {0}' format form with salt utils fopen path 'rb' as ifile hash_obj hash_type for chunk in iter lambda ifile read chunk_size '' hash_obj update chunk return hash_obj hexdigest
def get_hash path form 'sha256' chunk_size 65536 hash_type hasattr hashlib form and getattr hashlib form or None if hash_type is None raise ValueError 'Invalidhashtype {0}' format form with salt utils fopen path 'rb' as ifile hash_obj hash_type for chunk in iter lambda ifile read chunk_size '' hash_obj update chunk return hash_obj hexdigest
def get_hash path form 'sha256' chunk_size 65536 hash_type hasattr hashlib form and getattr hashlib form or None if hash_type is None raise ValueError 'Invalidhashtype {0}' format form with salt utils fopen path 'rb' as ifile hash_obj hash_type for chunk in iter lambda ifile read chunk_size '' hash_obj update chunk return hash_obj hexdigest
def joinall threads for t in threads t join 300 assert not t isAlive 'Thread%shung' % t
def TCVoltsToTemp TCType TCVolts CJTempK if os name 'nt' staticLib ctypes windll LoadLibrary 'labjackud' pTCTempK ctypes c_double ec staticLib TCVoltsToTemp ctypes c_long TCType ctypes c_double TCVolts ctypes c_double CJTempK ctypes byref pTCTempK if ec 0 raise LabJackException ec return pTCTempK valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def TCVoltsToTemp TCType TCVolts CJTempK if os name 'nt' staticLib ctypes windll LoadLibrary 'labjackud' pTCTempK ctypes c_double ec staticLib TCVoltsToTemp ctypes c_long TCType ctypes c_double TCVolts ctypes c_double CJTempK ctypes byref pTCTempK if ec 0 raise LabJackException ec return pTCTempK valueelse raise LabJackException 0 'FunctiononlysupportedforWindows'
def write_git_file gitstr _git_str if gitstr is None gitstr ''path os path join BASEDIR 'qutebrowser' 'git-commit-id' with _open path 'w' encoding 'ascii' as f f write gitstr
def write_git_file gitstr _git_str if gitstr is None gitstr ''path os path join BASEDIR 'qutebrowser' 'git-commit-id' with _open path 'w' encoding 'ascii' as f f write gitstr
def get_mock_hadoop_output output_dir get_mock_dir 'output' dirnames sorted os listdir output_dir if dirnames return os path join output_dir dirnames[0] else return None
def get_mock_hadoop_output output_dir get_mock_dir 'output' dirnames sorted os listdir output_dir if dirnames return os path join output_dir dirnames[0] else return None
def _get_bench_name bench_func return bench_func __name__[ len BENCH_METHOD_PREFIX + 1 ]
def setup_platform hass config add_devices discovery_info None if not int hub config get CONF_SMARTPLUGS 1 return Falsehub update_smartplugs switches []switches extend [VerisureSmartplug value deviceLabel for value in hub smartplug_status values ] add_devices switches
def remove_entity_headers headers allowed 'expires' 'content-location' allowed set x lower for x in allowed headers[ ] [ key value for key value in headers if not is_entity_header key or key lower in allowed ]
def unique_slug queryset slug_field slug i 0while True if i > 0 if i > 1 slug slug rsplit u'-' 1 [0]slug u'%s-%s' % slug i try queryset get **{slug_field slug} except ObjectDoesNotExist breaki + 1return slug
def build_request url data None headers None bump '' if not USER_AGENT build_user_agent if not headers headers {}if url[0] ' ' schemed_url '%s%s' % SCHEME url else schemed_url urlif '?' in url delim '&'else delim '?'final_url '%s%sx %s %s' % schemed_url delim int timeit time time * 1000 bump headers update {'User-Agent' USER_AGENT 'Cache-Control' 'no-cache'} printer '%s%s' % 'GET' 'POST' [bool data ] final_url debug True return Request final_url data data headers headers
def build_request url data None headers None bump '' if not USER_AGENT build_user_agent if not headers headers {}if url[0] ' ' schemed_url '%s%s' % SCHEME url else schemed_url urlif '?' in url delim '&'else delim '?'final_url '%s%sx %s %s' % schemed_url delim int timeit time time * 1000 bump headers update {'User-Agent' USER_AGENT 'Cache-Control' 'no-cache'} printer '%s%s' % 'GET' 'POST' [bool data ] final_url debug True return Request final_url data data headers headers
def getText node recursive False L [u'']for n in node childNodes if n nodeType in node TEXT_NODE node CDATA_SECTION_NODE L append n data elif not recursive return NoneL append getText n return u'' join L
def getEndIndexConvertEquationValue bracketEndIndex evaluatorIndex evaluators evaluator evaluators[evaluatorIndex]if evaluator __class__ EvaluatorValue return bracketEndIndexif not evaluator word startswith 'equation ' return bracketEndIndexif evaluators[ evaluatorIndex + 1 ] word ' ' return bracketEndIndexvalueBeginIndex evaluatorIndex + 2 equationValueString ''for valueEvaluatorIndex in xrange valueBeginIndex len evaluators valueEvaluator evaluators[valueEvaluatorIndex]if valueEvaluator word ' ' or valueEvaluator word '}' if equationValueString '' return bracketEndIndexelse evaluators[valueBeginIndex] EvaluatorValue equationValueString valueDeleteIndex valueBeginIndex + 1 del evaluators[valueDeleteIndex valueEvaluatorIndex]return bracketEndIndex - valueEvaluatorIndex + valueDeleteIndex equationValueString + valueEvaluator wordreturn bracketEndIndex
def getEndIndexConvertEquationValue bracketEndIndex evaluatorIndex evaluators evaluator evaluators[evaluatorIndex]if evaluator __class__ EvaluatorValue return bracketEndIndexif not evaluator word startswith 'equation ' return bracketEndIndexif evaluators[ evaluatorIndex + 1 ] word ' ' return bracketEndIndexvalueBeginIndex evaluatorIndex + 2 equationValueString ''for valueEvaluatorIndex in xrange valueBeginIndex len evaluators valueEvaluator evaluators[valueEvaluatorIndex]if valueEvaluator word ' ' or valueEvaluator word '}' if equationValueString '' return bracketEndIndexelse evaluators[valueBeginIndex] EvaluatorValue equationValueString valueDeleteIndex valueBeginIndex + 1 del evaluators[valueDeleteIndex valueEvaluatorIndex]return bracketEndIndex - valueEvaluatorIndex + valueDeleteIndex equationValueString + valueEvaluator wordreturn bracketEndIndex
def remove_task_app project_directory task_app_location os path join PROJECT_DIRECTORY '{{cookiecutter project_slug}}/taskapp' shutil rmtree task_app_location
def _getAPI node base ''if node hasAttribute 'base' base node getAttribute 'base' + ' ' return base + node childNodes[0] nodeValue
def obj_equal_prims obj_1 obj_2 ignore None def _strip prim keys if isinstance prim dict for k in keys prim pop k None for v in prim values _strip v keys if isinstance prim list for v in prim _strip v keys return primif ignore is not None keys ['nova_object changes'] + ignore else keys ['nova_object changes']prim_1 _strip obj_1 obj_to_primitive keys prim_2 _strip obj_2 obj_to_primitive keys return prim_1 prim_2
def obj_equal_prims obj_1 obj_2 ignore None def _strip prim keys if isinstance prim dict for k in keys prim pop k None for v in prim values _strip v keys if isinstance prim list for v in prim _strip v keys return primif ignore is not None keys ['nova_object changes'] + ignore else keys ['nova_object changes']prim_1 _strip obj_1 obj_to_primitive keys prim_2 _strip obj_2 obj_to_primitive keys return prim_1 prim_2
def idrac_general blade_name command idrac_password None host None admin_username None admin_password None module_network network_info host admin_username admin_password blade_name if idrac_password is not None password idrac_passwordelse password admin_passwordidrac_ip module_network['Network']['IPAddress']ret __execute_ret command host idrac_ip admin_username 'root' admin_password password if ret['retcode'] 0 return ret['stdout']else return ret
@not_implemented_for 'directed' def min_weighted_dominating_set G weight None if len G 0 return set dom_set set def _cost node_and_neighborhood 'Returnsthecost-effectivenessofgreedilychoosingthegiven\nnode \n\n`node_and_neighborhood`isatwo-tuplecomprisinganodeandits\nclosedneighborhood \n\n' v neighborhood node_and_neighborhoodreturn G node[v] get weight 1 / len neighborhood - dom_set vertices set G neighborhoods {v {v} set G[v] for v in G}while vertices dom_node min_set min neighborhoods items key _cost dom_set add dom_node del neighborhoods[dom_node]vertices - min_setreturn dom_set
@not_implemented_for 'directed' def min_weighted_dominating_set G weight None if len G 0 return set dom_set set def _cost node_and_neighborhood 'Returnsthecost-effectivenessofgreedilychoosingthegiven\nnode \n\n`node_and_neighborhood`isatwo-tuplecomprisinganodeandits\nclosedneighborhood \n\n' v neighborhood node_and_neighborhoodreturn G node[v] get weight 1 / len neighborhood - dom_set vertices set G neighborhoods {v {v} set G[v] for v in G}while vertices dom_node min_set min neighborhoods items key _cost dom_set add dom_node del neighborhoods[dom_node]vertices - min_setreturn dom_set
def package_version package local False npm 'npm' options ['--jsontrue' '--silent']if local options append '-l' else options append '-g' options '' join options with hide 'running' 'stdout' res run '% npm slist% options s' % locals pty False dependencies json loads res get 'dependencies' {} pkg_data dependencies get package if pkg_data return pkg_data['version']else return None
def __getLocation__ **kwargs global CURRENT_LATglobal CURRENT_LONif kwargs is not None CURRENT_LAT kwargs['lat']CURRENT_LON kwargs['lon']
def __getLocation__ **kwargs global CURRENT_LATglobal CURRENT_LONif kwargs is not None CURRENT_LAT kwargs['lat']CURRENT_LON kwargs['lon']
def __getLocation__ **kwargs global CURRENT_LATglobal CURRENT_LONif kwargs is not None CURRENT_LAT kwargs['lat']CURRENT_LON kwargs['lon']
def wrapClientTLS connectionCreator wrappedEndpoint if TLSMemoryBIOFactory is None raise NotImplementedError 'OpenSSLnotavailable Try`pipinstalltwisted[tls]` ' return _WrapperEndpoint wrappedEndpoint lambda protocolFactory TLSMemoryBIOFactory connectionCreator True protocolFactory
def wrapClientTLS connectionCreator wrappedEndpoint if TLSMemoryBIOFactory is None raise NotImplementedError 'OpenSSLnotavailable Try`pipinstalltwisted[tls]` ' return _WrapperEndpoint wrappedEndpoint lambda protocolFactory TLSMemoryBIOFactory connectionCreator True protocolFactory
def _get_image_blob roidb scale_inds num_images len roidb processed_ims []im_scales []for i in xrange num_images im cv2 imread roidb[i]['image'] if roidb[i]['flipped'] im im[ -1 ]target_size cfg TRAIN SCALES[scale_inds[i]] im im_scale prep_im_for_blob im cfg PIXEL_MEANS target_size cfg TRAIN MAX_SIZE im_scales append im_scale processed_ims append im blob im_list_to_blob processed_ims return blob im_scales
def _get_image_blob roidb scale_inds num_images len roidb processed_ims []im_scales []for i in xrange num_images im cv2 imread roidb[i]['image'] if roidb[i]['flipped'] im im[ -1 ]target_size cfg TRAIN SCALES[scale_inds[i]] im im_scale prep_im_for_blob im cfg PIXEL_MEANS target_size cfg TRAIN MAX_SIZE im_scales append im_scale processed_ims append im blob im_list_to_blob processed_ims return blob im_scales
def _get_image_blob roidb scale_inds num_images len roidb processed_ims []im_scales []for i in xrange num_images im cv2 imread roidb[i]['image'] if roidb[i]['flipped'] im im[ -1 ]target_size cfg TRAIN SCALES[scale_inds[i]] im im_scale prep_im_for_blob im cfg PIXEL_MEANS target_size cfg TRAIN MAX_SIZE im_scales append im_scale processed_ims append im blob im_list_to_blob processed_ims return blob im_scales
def rainbow n from matplotlib import colorsR np ones 1 n 3 R[0 0] np linspace 0 1 n endpoint False return colors hsv_to_rgb R squeeze
def rainbow n from matplotlib import colorsR np ones 1 n 3 R[0 0] np linspace 0 1 n endpoint False return colors hsv_to_rgb R squeeze
def _ordered_dict_to_dict config return loads dumps config
def solve_poly_system seq *gens **args try polys opt parallel_poly_from_expr seq *gens **args except PolificationFailed as exc raise ComputationFailed 'solve_poly_system' len seq exc if len polys len opt gens 2 f g polys a b f degree_list c d g degree_list if a < 2 and b < 2 and c < 2 and d < 2 try return solve_biquadratic f g opt except SolveFailed passreturn solve_generic polys opt
def GetAllClientLabels token include_catchall False labels_index aff4 FACTORY Create standard LabelSet CLIENT_LABELS_URN standard LabelSet mode 'r' token token labels set labels_index ListLabels if include_catchall labels add ALL_CLIENTS_LABEL return labels
def with_app *args **kwargs def generator func @wraps func def deco *args2 **kwargs2 app TestApp *args **kwargs func app *args2 **kwargs2 app cleanup return decoreturn generator
def getCenterByPaths elementNode transformedPaths elementNode xmlObject getTransformedPaths return 0 5 * euclidean getMaximumByVector3Paths transformedPaths + euclidean getMinimumByVector3Paths transformedPaths
def polynomial_kernel X Y None degree 3 gamma None coef0 1 X Y check_pairwise_arrays X Y if gamma is None gamma 1 0 / X shape[1] K safe_sparse_dot X Y T dense_output True K * gammaK + coef0K ** degreereturn K
def generate_certificates cluster_name cluster_id nodes cert_path print 'Generatingcertificatesin {}' format cert_path path certificates Certificates generate cert_path nodes[0] address len nodes cluster_name cluster_name cluster_id cluster_id return certificates
def privileges_get cursor user host output {}cursor execute 'SHOWGRANTSFOR%s@%s' user host grants cursor fetchall def pick x if x 'ALLPRIVILEGES' return 'ALL'else return xfor grant in grants res re match "GRANT + ON + TO' *'@' +' IDENTIFIEDBYPASSWORD' +' ?? * " grant[0] if res is None raise InvalidPrivsError 'unabletoparsetheMySQLgrantstring %s' % grant[0] privileges res group 1 split ' ' privileges [pick x for x in privileges]if 'WITHGRANTOPTION' in res group 4 privileges append 'GRANT' if 'REQUIRESSL' in res group 4 privileges append 'REQUIRESSL' db res group 2 output[db] privilegesreturn output
def privileges_get cursor user host output {}cursor execute 'SHOWGRANTSFOR%s@%s' user host grants cursor fetchall def pick x if x 'ALLPRIVILEGES' return 'ALL'else return xfor grant in grants res re match "GRANT + ON + TO' *'@' +' IDENTIFIEDBYPASSWORD' +' ?? * " grant[0] if res is None raise InvalidPrivsError 'unabletoparsetheMySQLgrantstring %s' % grant[0] privileges res group 1 split ' ' privileges [pick x for x in privileges]if 'WITHGRANTOPTION' in res group 4 privileges append 'GRANT' if 'REQUIRESSL' in res group 4 privileges append 'REQUIRESSL' db res group 2 output[db] privilegesreturn output
def privileges_get cursor user host output {}cursor execute 'SHOWGRANTSFOR%s@%s' user host grants cursor fetchall def pick x if x 'ALLPRIVILEGES' return 'ALL'else return xfor grant in grants res re match "GRANT + ON + TO' *'@' +' IDENTIFIEDBYPASSWORD' +' ?? * " grant[0] if res is None raise InvalidPrivsError 'unabletoparsetheMySQLgrantstring %s' % grant[0] privileges res group 1 split ' ' privileges [pick x for x in privileges]if 'WITHGRANTOPTION' in res group 4 privileges append 'GRANT' if 'REQUIRESSL' in res group 4 privileges append 'REQUIRESSL' db res group 2 output[db] privilegesreturn output
def latest_package_name distro 'trusty' latest_minor_version latest_release_version [ 3]return 'python-ckan_{version}-{distro}_amd64 deb' format version latest_minor_version distro distro
def get_init_version abs_path None if abs_path is None abs_path find_repo LEGACY_REPO repo migrate versioning repository Repository abs_path oldest int min repo versions versions if oldest < 1 return Nonereturn oldest - 1
def _AddRateToSummary tag rate step sw sw add_summary summary_pb2 Summary value [summary_pb2 Summary Value tag tag simple_value rate ] step
def infer_name self context None frame stmts self lookup self name if not stmts parent_function _higher_function_scope self scope if parent_function _ stmts parent_function lookup self name if not stmts raise UnresolvableName self name context context clone context lookupname self namereturn _infer_stmts stmts context frame
def _mkfs root fs_format fs_opts None if fs_opts is None fs_opts {}if fs_format in 'ext2' 'ext3' 'ext4' __salt__['extfs mkfs'] root fs_format **fs_opts elif fs_format in 'btrfs' __salt__['btrfs mkfs'] root **fs_opts elif fs_format in 'xfs' __salt__['xfs mkfs'] root **fs_opts
def _mkfs root fs_format fs_opts None if fs_opts is None fs_opts {}if fs_format in 'ext2' 'ext3' 'ext4' __salt__['extfs mkfs'] root fs_format **fs_opts elif fs_format in 'btrfs' __salt__['btrfs mkfs'] root **fs_opts elif fs_format in 'xfs' __salt__['xfs mkfs'] root **fs_opts
@task@needs 'pavelib prereqs install_node_prereqs' @cmdopts [ 'limit ' 'l' 'limitfornumberofacceptableviolations' ] @timeddef run_eslint options eslint_report_dir Env REPORT_DIR / 'eslint' eslint_report eslint_report_dir / 'eslint report' _prepare_report_dir eslint_report_dir violations_limit int getattr options 'limit' -1 sh 'eslint--format compact tee{eslint_report}' format eslint_report eslint_report ignore_error True try num_violations int _get_count_from_last_line eslint_report 'eslint' except TypeError raise BuildFailure 'Error Numberofeslintviolationscouldnotbefoundin{eslint_report}' format eslint_report eslint_report _write_metric num_violations Env METRICS_DIR / 'eslint' if num_violations > violations_limit > -1 raise BuildFailure 'ESLintFailed Toomanyviolations {count} \nThelimitis{violations_limit} ' format count num_violations violations_limit violations_limit
@task@needs 'pavelib prereqs install_node_prereqs' @cmdopts [ 'limit ' 'l' 'limitfornumberofacceptableviolations' ] @timeddef run_eslint options eslint_report_dir Env REPORT_DIR / 'eslint' eslint_report eslint_report_dir / 'eslint report' _prepare_report_dir eslint_report_dir violations_limit int getattr options 'limit' -1 sh 'eslint--format compact tee{eslint_report}' format eslint_report eslint_report ignore_error True try num_violations int _get_count_from_last_line eslint_report 'eslint' except TypeError raise BuildFailure 'Error Numberofeslintviolationscouldnotbefoundin{eslint_report}' format eslint_report eslint_report _write_metric num_violations Env METRICS_DIR / 'eslint' if num_violations > violations_limit > -1 raise BuildFailure 'ESLintFailed Toomanyviolations {count} \nThelimitis{violations_limit} ' format count num_violations violations_limit violations_limit
@handle_response_format@treeio_login_required@_process_mass_formdef index_inbox request response_format 'html' query Q reply_to__isnull True & ~ Q author request user profile get_contact if request GET query query & _get_filter_query request GET objects Object filter_by_request request Message objects filter query else objects Object filter_by_request request Message objects filter query filters FilterForm request user profile 'title' request GET context _get_default_context request context update {'filters' filters 'messages' objects} return render_to_response 'messaging/index_inbox' context context_instance RequestContext request response_format response_format
@hook command 'tell' def tell_cmd text nick db notice conn query text split '' 1 if len query 2 notice conn config 'command_prefix' + tell_cmd __doc__ returntarget query[0] lower message query[1] strip sender nickif target sender lower notice 'Haveyoulookedinamirrorlately?' returnif target lower conn nick lower notice "Invalidnick'{}' " format target returnif not re match '^[a-z0-9_ \\-\\]\\[]*$' target lower notice "Invalidnick'{}' " format target returnif count_unread db conn name target > 10 notice 'Sorry {}hastoomanymessagesqueuedalready ' format target returnadd_tell db conn name sender target message notice 'Yourmessagehasbeensaved and{}willbenotifiedoncetheyareactive ' format target
def cache_path paths environ None return zipline_path ['cache'] + list paths environ environ
def relative_distance a_str b_str set_a set a_str split '' set_b set b_str split '' if min len set_a len set_b in 0 1 return difflib SequenceMatcher None a_str b_str quick_ratio return 1 0 * len set_a intersection set_b / max len set_a len set_b
def setup_platform hass config add_devices discovery_info None import radiothermhosts []if CONF_HOST in config hosts config[CONF_HOST]else hosts append radiotherm discover discover_address if hosts is None _LOGGER error 'NoRadiothermThermostatsdetected' return Falsehold_temp config get CONF_HOLD_TEMP away_temps [config get CONF_AWAY_TEMPERATURE_HEAT config get CONF_AWAY_TEMPERATURE_COOL ]tstats []for host in hosts try tstat radiotherm get_thermostat host tstats append RadioThermostat tstat hold_temp away_temps except OSError _LOGGER exception 'UnabletoconnecttoRadioThermostat %s' host add_devices tstats
def generate_password_hash password rounds None if rounds is None rounds settings BCRYPT_LOG_ROUNDSif not password raise ValueError 'Passwordmustbenon-empty ' pw_hash bcrypt hashpw unicode password encode 'utf-8' bcrypt gensalt rounds return pw_hash
def contains_feat title return bool re search plugins feat_tokens title flags re IGNORECASE
def contains_feat title return bool re search plugins feat_tokens title flags re IGNORECASE
def HeaderPrintGenericDetails message which MUA_HP_HEADERS return [k for k v in message items if k lower in which ]
def HeaderPrintGenericDetails message which MUA_HP_HEADERS return [k for k v in message items if k lower in which ]
def pre_hook config cmd config pre_hookif cmd and cmd not in pre_hook already logger info 'Runningpre-hookcommand %s' cmd _run_hook cmd pre_hook already add cmd elif cmd logger info 'Pre-hookcommandalreadyrun skipping %s' cmd
def stop_service service_name os_cmd ['/usr/bin/openstack-service' 'stop' service_name]return __salt__['cmd retcode'] os_cmd 0
def parse_fuzzy_item source constraints saved_pos source postry parse_cost_constraint source constraints except ParseError source pos saved_posparse_cost_equation source constraints
@not_implemented_for 'undirected' 'multigraph' def overall_reciprocity G n_all_edge G number_of_edges n_overlap_edge n_all_edge - G to_undirected number_of_edges * 2 if n_all_edge 0 raise NetworkXError 'Notdefinedforemptygraphs' return float n_overlap_edge / float n_all_edge
def run host port api_key auth_token timeout channel grpc insecure_channel '{} {}' format host port stub bookstore_pb2 BookstoreStub channel metadata []if api_key metadata append 'x-api-key' api_key if auth_token metadata append 'authorization' 'Bearer' + auth_token shelves stub ListShelves empty_pb2 Empty timeout metadata metadata print 'ListShelves {}' format shelves
def mail_reply reply user review reply base_reply_toreview_request review review_requestif not review_request public returnextra_context {u'user' reply user u'review' review u'reply' reply} has_error extra_context[u'comment_entries'] build_diff_comment_fragments reply comments order_by u'filediff' u'first_line' extra_context u'notifications/email_diff_comment_fragment html' reviewer reply user to_field cc_field build_recipients reviewer review_request review_request participants to_field cc_field filter_email_recipients_from_hooks to_field cc_field reply_published reply reply user user review review review_request review_request summary _ensure_unicode review_request summary reply email_message_id send_review_mail user review_request u'Re ReviewRequest%d %s' % review_request display_id summary review email_message_id to_field cc_field u'notifications/reply_email txt' u'notifications/reply_email html' extra_context reply time_emailed timezone now reply save
def mail_reply reply user review reply base_reply_toreview_request review review_requestif not review_request public returnextra_context {u'user' reply user u'review' review u'reply' reply} has_error extra_context[u'comment_entries'] build_diff_comment_fragments reply comments order_by u'filediff' u'first_line' extra_context u'notifications/email_diff_comment_fragment html' reviewer reply user to_field cc_field build_recipients reviewer review_request review_request participants to_field cc_field filter_email_recipients_from_hooks to_field cc_field reply_published reply reply user user review review review_request review_request summary _ensure_unicode review_request summary reply email_message_id send_review_mail user review_request u'Re ReviewRequest%d %s' % review_request display_id summary review email_message_id to_field cc_field u'notifications/reply_email txt' u'notifications/reply_email html' extra_context reply time_emailed timezone now reply save
def test_read_types t1 ascii read 'abc\n123\n456' format 'fast_basic' guess False t2 ascii read StringIO 'abc\n123\n456' format 'fast_basic' guess False t3 ascii read ['abc' '123' '456'] format 'fast_basic' guess False assert_table_equal t1 t2 assert_table_equal t2 t3
def test_read_types t1 ascii read 'abc\n123\n456' format 'fast_basic' guess False t2 ascii read StringIO 'abc\n123\n456' format 'fast_basic' guess False t3 ascii read ['abc' '123' '456'] format 'fast_basic' guess False assert_table_equal t1 t2 assert_table_equal t2 t3
def is_user_lockable request try field getattr User 'USERNAME_FIELD' 'username' kwargs {field request POST get USERNAME_FORM_FIELD }user User objects get **kwargs except User DoesNotExist return Trueif hasattr user 'nolockout' return not user nolockout elif hasattr settings 'AUTH_PROFILE_MODULE' try profile user get_profile if hasattr profile 'nolockout' return not profile nolockout except SiteProfileNotAvailable ObjectDoesNotExist AttributeError return Truereturn True
def notify context message if not _notification_manager _load_notification_manager if not _pipeline_manager _load_pipeline_manager _notification_manager map _process_notification_for_ext context context or req_context get_admin_context notification message
def notify context message if not _notification_manager _load_notification_manager if not _pipeline_manager _load_pipeline_manager _notification_manager map _process_notification_for_ext context context or req_context get_admin_context notification message
def notify context message if not _notification_manager _load_notification_manager if not _pipeline_manager _load_pipeline_manager _notification_manager map _process_notification_for_ext context context or req_context get_admin_context notification message
def get_mapnikMap mapfile mmap mapnik Map 0 0 if exists mapfile mapnik load_map mmap str mapfile else handle filename mkstemp os write handle urlopen mapfile read os close handle mapnik load_map mmap filename os unlink filename return mmap
def generateClassificationData size nClasses 3 if nClasses 3 means [ -1 0 2 4 3 1 ]else means [ -2 0 2 1 6 0 ]cov [diag [1 1] diag [0 5 1 2] diag [1 5 0 7] ]dataset ClassificationDataSet 2 1 nb_classes nClasses for _ in range size for c in range 3 input multivariate_normal means[c] cov[c] dataset addSample input [ c % nClasses ] dataset assignClasses return dataset
def test_import_gzip_reader data file __file__ read data_gz_sio cStringIO StringIO gz gzip GzipFile fileobj data_gz_sio mode 'wb' gz write data gz close data_gz data_gz_sio getvalue old_peek_size beeswax create_table IMPORT_PEEK_SIZEbeeswax create_table IMPORT_PEEK_SIZE len data_gz - 1024 try reader beeswax create_table GzipFileReaderlines reader readlines data_gz_sio 'utf-8' assert_true lines is not None lines_joined '\n' join lines assert_equal data[ len lines_joined ] lines_joined finally beeswax create_table IMPORT_PEEK_SIZE old_peek_size
def response_namespace k v if k[ 8] 'headers ' cherrypy serving response headers[k split ' ' 1 [1]] velse setattr cherrypy serving response k v
def restart_with_reloader while 1 _log 'info' '*Restartingwithreloader' args [sys executable] + sys argv new_environ os environ copy new_environ['WERKZEUG_RUN_MAIN'] 'true'if os name 'nt' for key value in new_environ iteritems if isinstance value unicode new_environ[key] value encode 'iso-8859-1' exit_code subprocess call args env new_environ if exit_code 3 return exit_code
def _populate_unknown_statuses set_tasks visited set for task in set_tasks['still_pending_not_ext'] _depth_first_search set_tasks task visited
def _populate_unknown_statuses set_tasks visited set for task in set_tasks['still_pending_not_ext'] _depth_first_search set_tasks task visited
def create_finder project name pyname only_calls False imports True unsure None docs False instance None in_hierarchy False keywords True pynames_ set [pyname] filters []if only_calls filters append CallsFilter if not imports filters append NoImportsFilter if not keywords filters append NoKeywordsFilter if isinstance instance pynames ParameterName for pyobject in instance get_objects try pynames_ add pyobject[name] except exceptions AttributeNotFoundError passfor pyname in pynames_ filters append PyNameFilter pyname if in_hierarchy filters append InHierarchyFilter pyname if unsure filters append UnsureFilter unsure return Finder project name filters filters docs docs
def rst_add_mathjax content _ ext os path splitext os path basename content source_path if ext ' rst' returnif 'class "math"' in content _content content _content + "<scripttype 'text/javascript'>%s</script>" % rst_add_mathjax mathjax_script
@removals remove message 'Useensure_tree path 0o755 fromoslo_utils fileutils' def ensure_dir dir_path fileutils ensure_tree dir_path mode 493
def arg_lookup fun aspec None ret {'kwargs' {}}if aspec is None aspec salt utils args get_function_argspec fun if aspec defaults ret['kwargs'] dict zip aspec args[ -1 ] aspec defaults[ -1 ] ret['args'] [arg for arg in aspec args if arg not in ret['kwargs'] ]return ret
def _coord_byval coord return c_long coord Y * 65536 coord X & 65535
def isFirstBestMatch result sickrage srCore srLogger debug u'Checkingifweshouldarchiveourfirstbestqualitymatchforepisode' + result name show_obj result episodes[0] show any_qualities best_qualities Quality splitQuality show_obj quality if best_qualities and show_obj archive_firstmatch and result quality in best_qualities return Truereturn False
def isFirstBestMatch result sickrage srCore srLogger debug u'Checkingifweshouldarchiveourfirstbestqualitymatchforepisode' + result name show_obj result episodes[0] show any_qualities best_qualities Quality splitQuality show_obj quality if best_qualities and show_obj archive_firstmatch and result quality in best_qualities return Truereturn False
def at_server_reload_start pass
def at_server_reload_start pass
def task_install_ssh_key return sequence [sudo_from_args ['cp' ' ssh/authorized_keys' '/root/ ssh/authorized_keys'] ]
def task_install_ssh_key return sequence [sudo_from_args ['cp' ' ssh/authorized_keys' '/root/ ssh/authorized_keys'] ]
@when u'wesend"ctrl+d"' def step_ctrl_d context context cli sendcontrol u'd' context exit_sent True
@when u'wesend"ctrl+d"' def step_ctrl_d context context cli sendcontrol u'd' context exit_sent True
def inet_ntop family address if family AF_INET return dns ipv4 inet_ntoa address elif family AF_INET6 return dns ipv6 inet_ntoa address else raise NotImplementedError
def load_data schema_path data_path project_id dataset_id table_id credentials GoogleCredentials get_application_default bigquery discovery build 'bigquery' 'v2' credentials credentials source_format 'CSV'if data_path[ -5 ] lower ' json' source_format 'NEWLINE_DELIMITED_JSON'insert_request bigquery jobs insert projectId project_id body {'configuration' {'load' {'schema' {'fields' json load open schema_path 'r' } 'destinationTable' {'projectId' project_id 'datasetId' dataset_id 'tableId' table_id} 'sourceFormat' source_format}}} media_body MediaFileUpload data_path mimetype 'application/octet-stream' job insert_request execute print 'Waitingforjobtofinish 'status_request bigquery jobs get projectId job['jobReference']['projectId'] jobId job['jobReference']['jobId'] while True result status_request execute num_retries 2 if result['status']['state'] 'DONE' if result['status'] get 'errors' raise RuntimeError '\n' join e['message'] for e in result['status']['errors'] print 'Jobcomplete 'returntime sleep 1
def post api_key url data url make_url api_key url req Request url headers {'Content-Type' 'application/json'} data json dumps data return json loads urlopen req read
def lv_absent name vgname None ret {'changes' {} 'comment' '' 'name' name 'result' True}lvpath '/dev/{0}/{1}' format vgname name if not __salt__['lvm lvdisplay'] lvpath ret['comment'] 'LogicalVolume{0}alreadyabsent' format name elif __opts__['test'] ret['comment'] 'LogicalVolume{0}issettoberemoved' format name ret['result'] Nonereturn retelse changes __salt__['lvm lvremove'] name vgname if not __salt__['lvm lvdisplay'] lvpath ret['comment'] 'RemovedLogicalVolume{0}' format name ret['changes']['removed'] changeselse ret['comment'] 'FailedtoremoveLogicalVolume{0}' format name ret['result'] Falsereturn ret
def violations registry xml_parent data violations XML SubElement xml_parent 'hudson plugins violations ViolationsPublisher' config XML SubElement violations 'config' suppressions XML SubElement config 'suppressions' {'class' 'tree-set'} XML SubElement suppressions 'no-comparator' configs XML SubElement config 'typeConfigs' XML SubElement configs 'no-comparator' for name in ['checkstyle' 'codenarc' 'cpd' 'cpplint' 'csslint' 'findbugs' 'fxcop' 'gendarme' 'jcreport' 'jslint' 'pep8' 'perlcritic' 'pmd' 'pylint' 'simian' 'stylecop'] _violations_add_entry configs name data get name {} XML SubElement config 'limit' text '100'XML SubElement config 'sourcePathPattern' XML SubElement config 'fauxProjectPath' XML SubElement config 'encoding' text 'default'
def violations registry xml_parent data violations XML SubElement xml_parent 'hudson plugins violations ViolationsPublisher' config XML SubElement violations 'config' suppressions XML SubElement config 'suppressions' {'class' 'tree-set'} XML SubElement suppressions 'no-comparator' configs XML SubElement config 'typeConfigs' XML SubElement configs 'no-comparator' for name in ['checkstyle' 'codenarc' 'cpd' 'cpplint' 'csslint' 'findbugs' 'fxcop' 'gendarme' 'jcreport' 'jslint' 'pep8' 'perlcritic' 'pmd' 'pylint' 'simian' 'stylecop'] _violations_add_entry configs name data get name {} XML SubElement config 'limit' text '100'XML SubElement config 'sourcePathPattern' XML SubElement config 'fauxProjectPath' XML SubElement config 'encoding' text 'default'
def _requires_alpn func @wraps func def wrapper *args **kwargs if not _lib Cryptography_HAS_ALPN raise NotImplementedError 'ALPNnotavailable ' return func *args **kwargs return wrapper
def check_job_permission view_func def decorate request *args **kwargs jobid kwargs['job']try job get_job request job_id jobid except ApplicationNotRunning as e LOG warn 'Job%shasnotyetbeenacceptedbytheRM willpollforstatus ' % jobid return job_not_assigned request jobid request path if not SHARE_JOBS get and not request user is_superuser and job user request user username and not can_view_job request user username job raise PopupException _ "Youdon'thavepermissiontoaccessjob% id s " % {'id' jobid} kwargs['job'] jobreturn view_func request *args **kwargs return wraps view_func decorate
def check_job_permission view_func def decorate request *args **kwargs jobid kwargs['job']try job get_job request job_id jobid except ApplicationNotRunning as e LOG warn 'Job%shasnotyetbeenacceptedbytheRM willpollforstatus ' % jobid return job_not_assigned request jobid request path if not SHARE_JOBS get and not request user is_superuser and job user request user username and not can_view_job request user username job raise PopupException _ "Youdon'thavepermissiontoaccessjob% id s " % {'id' jobid} kwargs['job'] jobreturn view_func request *args **kwargs return wraps view_func decorate
def describe_domain domain def clip_attrs items s return clipped_list [a name for a in items] 1000 total_min 10 total ' total {{}}{} ' format s return OrderedDict [ 'Features' clip_attrs domain attributes 'features' 'Metaattributes' bool domain metas and clip_attrs domain metas 'metaattributes' 'Target' bool domain class_vars and clip_attrs domain class_vars 'targetsvariables' ]
def describe_domain domain def clip_attrs items s return clipped_list [a name for a in items] 1000 total_min 10 total ' total {{}}{} ' format s return OrderedDict [ 'Features' clip_attrs domain attributes 'features' 'Metaattributes' bool domain metas and clip_attrs domain metas 'metaattributes' 'Target' bool domain class_vars and clip_attrs domain class_vars 'targetsvariables' ]
def describe_domain domain def clip_attrs items s return clipped_list [a name for a in items] 1000 total_min 10 total ' total {{}}{} ' format s return OrderedDict [ 'Features' clip_attrs domain attributes 'features' 'Metaattributes' bool domain metas and clip_attrs domain metas 'metaattributes' 'Target' bool domain class_vars and clip_attrs domain class_vars 'targetsvariables' ]
def db_create name user None password None host None port None if db_exists name user password host port log info "DB'{0}'alreadyexists" format name return Falseclient _client user user password password host host port port client create_database name return True
def cache_available config if config has_option 'cache' 'cache_dir' dpath config get 'cache' 'cache_dir' try existing os stat '/' join [dpath 'inventory'] except return Falseif config has_option 'cache' 'cache_max_age' maxage config get 'cache' 'cache_max_age' if int time time - int existing st_mtime < int maxage return Truereturn False
def patch_ast node source sorted_children False if hasattr node 'region' return nodewalker _PatchingASTWalker source children sorted_children ast call_for_nodes node walker return node
def prlsrvctl sub_cmd args None runas None cmd ['prlsrvctl' sub_cmd]if args cmd extend _normalize_args args return __salt__['cmd run'] cmd runas runas
def InvokeCommand _cmdName _input None *args **kws cmd Command _cmdName for arg in args cmd Parameters Add CommandParameter None fix_arg arg for name value in kws items cmd Parameters Add CommandParameter name fix_arg value pipeline _runspace CreatePipeline pipeline Commands Add cmd if _input ret pipeline Invoke fix_arg _input else ret pipeline Invoke return ShellOutput ret
def tar_stream store tree mtime format '' buf BytesIO with closing tarfile open None 'w %s' % format buf as tar for entry_abspath entry in _walk_tree store tree try blob store[entry sha]except KeyError continuedata ChunkedBytesIO blob chunked info tarfile TarInfo info name entry_abspath decode 'ascii' info size blob raw_length info mode entry modeinfo mtime mtimetar addfile info data yield buf getvalue buf truncate 0 buf seek 0 yield buf getvalue
def clean_headers status import cherrypyresponse cherrypy serving responserespheaders response headersfor key in ['Accept-Ranges' 'Age' 'ETag' 'Location' 'Retry-After' 'Vary' 'Content-Encoding' 'Content-Length' 'Expires' 'Content-Location' 'Content-MD5' 'Last-Modified'] if key in respheaders del respheaders[key]if status 416 if 'Content-Range' in respheaders del respheaders['Content-Range']
def mkdir dir_path user None group None mode None dir_path os path expanduser dir_path directory os path normpath dir_path if not os path isdir directory makedirs_perms directory user group mode return True
def make_tag target **attrs target_id target idtarget_type object_class target type_name default_time int time mktime datetime datetime 2010 1 1 timetuple all_attrs {'tagger' 'TestAuthor<test@nodomain com>' 'tag_time' default_time 'tag_timezone' 0 'message' 'Testmessage ' 'object' target_type target_id 'name' 'TestTag'}all_attrs update attrs return make_object Tag **all_attrs
def NDP_Attack_Fake_Router ra iface None mac_src_filter None ip_src_filter None def is_request req mac_src_filter ip_src_filter '\nCheckifpacketreqisarequest\n'if not Ether in req and IPv6 in req and ICMPv6ND_RS in req return 0mac_src req[Ether] srcif mac_src_filter and mac_src mac_src_filter return 0ip_src req[IPv6] srcif ip_src_filter and ip_src ip_src_filter return 0return 1def ra_reply_callback req iface '\nCallbackthatsendsanRAinreplytoanRS\n'src req[IPv6] srcsendp ra iface iface verbose 0 print 'FakeRAsentinresponsetoRSfrom%s' % src if not iface iface conf ifacesniff_filter 'icmp6'sniff store 0 filter sniff_filter lfilter lambda x is_request x mac_src_filter ip_src_filter prn lambda x ra_reply_callback x iface iface iface
def NDP_Attack_Fake_Router ra iface None mac_src_filter None ip_src_filter None def is_request req mac_src_filter ip_src_filter '\nCheckifpacketreqisarequest\n'if not Ether in req and IPv6 in req and ICMPv6ND_RS in req return 0mac_src req[Ether] srcif mac_src_filter and mac_src mac_src_filter return 0ip_src req[IPv6] srcif ip_src_filter and ip_src ip_src_filter return 0return 1def ra_reply_callback req iface '\nCallbackthatsendsanRAinreplytoanRS\n'src req[IPv6] srcsendp ra iface iface verbose 0 print 'FakeRAsentinresponsetoRSfrom%s' % src if not iface iface conf ifacesniff_filter 'icmp6'sniff store 0 filter sniff_filter lfilter lambda x is_request x mac_src_filter ip_src_filter prn lambda x ra_reply_callback x iface iface iface
def AsIter arg if isinstance arg basestring rslt [arg]elif isinstance arg collections Iterable rslt argelif not arg rslt []else rslt [arg]return tuple rslt
def _gluster_output_cleanup result ret ''for line in result splitlines if line startswith 'gluster>' ret + line[9 ] strip else ret + line strip return ret
def _gluster_output_cleanup result ret ''for line in result splitlines if line startswith 'gluster>' ret + line[9 ] strip else ret + line strip return ret
def _gluster_output_cleanup result ret ''for line in result splitlines if line startswith 'gluster>' ret + line[9 ] strip else ret + line strip return ret
def get_vol_list ip user passwd cmd 'showvv'showvv_list run_ssh_thread ip user passwd cmd vol_list []line_num 0for line in showvv_list line_num + 1if '-------------------------' in line breakif '-----' in line or 'rcpy ' in line or ' srdata' in line or '0admin' in line continueif line_num > 4 vol_stats line split vol_list append vol_stats[1] return vol_list
def mutagen_call action path func *args **kwargs try return func *args **kwargs except mutagen MutagenError as exc log debug u'%sfailed %s' action six text_type exc raise UnreadableFileError path six text_type exc except Exception as exc log debug u'%s' traceback format_exc log error u'uncaughtMutagenexceptionin%s %s' action exc raise MutagenError path exc
def set_policy vhost name pattern definition priority None runas None if runas is None and not salt utils is_windows runas salt utils get_user if isinstance definition dict definition json dumps definition if not isinstance definition six string_types raise SaltInvocationError "The'definition'argumentmustbeadictionaryorJSONstring" cmd [__context__['rabbitmqctl'] 'set_policy' '-p' vhost]if priority cmd extend ['--priority' priority] cmd extend [name pattern definition] res __salt__['cmd run_all'] cmd runas runas python_shell False log debug 'Setpolicy {0}' format res['stdout'] return _format_response res 'Set'
@FileSystem in_directory current_directory 'django' 'couves' def test_django_agains_couves_nohooks status out run_scenario **{'--tags' 'nothingwillbefound'} expect 'Couvesbeforeall' to not_be within out expect 'Couvesafterall' to not_be within out
def quota_class_destroy context class_name resource return IMPL quota_class_destroy context class_name resource
def _from_dict entry name entry get 'name' code entry get 'code' message entry get 'message' return name ErrorCode code message
def compare_multiset_w_baseline multiplicities letters 'abcdefghijklmnopqrstuvwxyz'bl_partitions multiset_partitions_baseline multiplicities letters aocp_partitions set for state in multiset_partitions_taocp multiplicities p1 tuple sorted [tuple p for p in list_visitor state letters ] aocp_partitions add p1 assert bl_partitions aocp_partitions
def modify_group group params immediate False changed {}new_params dict params for key in new_params keys if key in group param group[key]new_value new_params[key]try old_value param valueexcept ValueError old_value param _valueif old_value new_value if not param is_modifiable raise NotModifiableError 'Parameter%sisnotmodifiable ' % key changed[key] {'old' old_value 'new' new_value}set_parameter param new_value immediate del new_params[key]return changed new_params
def register_access_role cls try role_name cls ROLEREGISTERED_ACCESS_ROLES[role_name] clsexcept AttributeError log exception u"UnabletoregisterAccessRolewithattribute'ROLE' " return cls
def register_access_role cls try role_name cls ROLEREGISTERED_ACCESS_ROLES[role_name] clsexcept AttributeError log exception u"UnabletoregisterAccessRolewithattribute'ROLE' " return cls
def create_mock_connection token 'snowman-frosty' if not token 'snowman-frosty' return Nonemock_connection mock create_autospec Connection mock_connection token tokenmock_connection get_dataverses return_value [create_mock_dataverse 'Example1' create_mock_dataverse 'Example2' create_mock_dataverse 'Example3' ]def _get_dataverse alias return next dataverse for dataverse in mock_connection get_dataverses if alias is not None and dataverse title[ -1 ] alias[ -1 ] None mock_connection get_dataverse mock MagicMock side_effect _get_dataverse mock_connection get_dataverse return_value create_mock_dataverse return mock_connection
def digest_password realm username password content '%s %s %s' % username realm password if six PY3 content content encode 'utf8' return md5 content hexdigest
def simulate_delete app path **kwargs return simulate_request app 'DELETE' path **kwargs
def _fix_up_media_upload method_desc root_desc path_url parameters media_upload method_desc get 'mediaUpload' {} accept media_upload get 'accept' [] max_size _media_size_to_long media_upload get 'maxSize' '' media_path_url Noneif media_upload media_path_url _media_path_url_from_info root_desc path_url parameters['media_body'] MEDIA_BODY_PARAMETER_DEFAULT_VALUE copy parameters['media_mime_type'] MEDIA_MIME_TYPE_PARAMETER_DEFAULT_VALUE copy if 'body' in parameters parameters['body']['required'] Falsereturn accept max_size media_path_url
def user name password superuser False createdb False createrole False inherit True login True connection_limit None encrypted_password False if not user_exists name create_user name password superuser createdb createrole inherit login connection_limit encrypted_password
def containsAny str set return 1 in [ c in str for c in set]
def quantiles data nbins_or_partition_bounds return apply_along_axis qcut 1 data q nbins_or_partition_bounds labels False
def quantiles data nbins_or_partition_bounds return apply_along_axis qcut 1 data q nbins_or_partition_bounds labels False
def _get_blob_file_index_key_name creation_handle if len creation_handle < _DATASTORE_MAX_PROPERTY_SIZE return creation_handlereturn hashlib sha512 creation_handle hexdigest
def avg_pool2d input kernel_size stride None padding 0 ceil_mode False count_include_pad True return _functions thnn AvgPool2d kernel_size stride padding ceil_mode count_include_pad input
def get_validation_digit number sum 0dvs [4 3 6 7 8 9 2]number str number for i in range 0 len number sum int number[ -1 - i ] * dvs[i] + sum % 10 return 10 - sum % 10
def clause_is_present clause search for elem in surface_selectables search if clause elem return Trueelse return False
def save_load jid clear_load minions None for returner_ in __opts__[CONFIG_KEY] _mminion returners['{0} save_load' format returner_ ] jid clear_load
def get_service hass config discovery_info None consumer_key config get CONF_CONSUMER_KEY consumer_secret config get CONF_CONSUMER_SECRET phone_number config get CONF_PHONE_NUMBER if _authenticate consumer_key consumer_secret is False _LOGGER exception 'ErrorobtainingauthorizationfromTelstraAPI' return Nonereturn TelstraNotificationService consumer_key consumer_secret phone_number
@register inclusion_tag 'test_incl_tag_use_l10n html' takes_context True def inclusion_tag_use_l10n context return {}
def get_package_directories ls_tree_out check_output 'git' 'ls-tree' '-d' '--name-only' '--full-name' 'HEAD' PROJECT_ROOT result []for package in ls_tree_out split '\n' if package not in IGNORED_DIRECTORIES result append package return result
def get_package_directories ls_tree_out check_output 'git' 'ls-tree' '-d' '--name-only' '--full-name' 'HEAD' PROJECT_ROOT result []for package in ls_tree_out split '\n' if package not in IGNORED_DIRECTORIES result append package return result
def test_guess_with_names_arg dat ascii read ['1 2' '3 4'] names 'a' 'b' assert len dat 2 assert dat colnames ['a' 'b'] dat ascii read ['c d' '3 4'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b'] dat ascii read ['cd' 'ef'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b']
def test_guess_with_names_arg dat ascii read ['1 2' '3 4'] names 'a' 'b' assert len dat 2 assert dat colnames ['a' 'b'] dat ascii read ['c d' '3 4'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b'] dat ascii read ['cd' 'ef'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b']
def test_guess_with_names_arg dat ascii read ['1 2' '3 4'] names 'a' 'b' assert len dat 2 assert dat colnames ['a' 'b'] dat ascii read ['c d' '3 4'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b'] dat ascii read ['cd' 'ef'] names 'a' 'b' assert len dat 1 assert dat colnames ['a' 'b']
def create_message senderobj message channels None receivers None locks None header None global _Msgif not _Msg from evennia comms models import Msg as _Msgif not message returnnew_message _Msg db_message message new_message save for sender in make_iter senderobj new_message senders sendernew_message header headerfor channel in make_iter channels new_message channels channelfor receiver in make_iter receivers new_message receivers receiverif locks new_message locks add locks new_message save return new_message
@contextmanagerdef project with virtualenv with cd env proj_path yield
def setup_platform hass config add_devices discovery_info None username config get CONF_USERNAME password config get CONF_PASSWORD host config get CONF_HOST import proliphixpdp proliphix PDP host username password add_devices [ProliphixThermostat pdp ]
def import_pyside from PySide import QtGui QtCore QtSvgreturn QtCore QtGui QtSvg QT_API_PYSIDE
def in6_ismnladdr str return in6_isincluded str 'ff01 ' 16
def remove_dir path if sabnzbd WIN32 retries 15while retries > 0 try os rmdir path returnexcept WindowsError as err if err[0] 32 logging debug 'Retrydelete%s' path retries - 1else raise WindowsError err time sleep 3 raise WindowsError err else os rmdir path
def extract_patches arr patch_shape 8 extraction_step 1 arr_ndim arr ndimif isinstance patch_shape numbers Number patch_shape tuple [patch_shape] * arr_ndim if isinstance extraction_step numbers Number extraction_step tuple [extraction_step] * arr_ndim patch_strides arr stridesslices [slice None None st for st in extraction_step]indexing_strides arr[slices] stridespatch_indices_shape np array arr shape - np array patch_shape // np array extraction_step + 1 shape tuple list patch_indices_shape + list patch_shape strides tuple list indexing_strides + list patch_strides patches as_strided arr shape shape strides strides return patches
def extract_patches arr patch_shape 8 extraction_step 1 arr_ndim arr ndimif isinstance patch_shape numbers Number patch_shape tuple [patch_shape] * arr_ndim if isinstance extraction_step numbers Number extraction_step tuple [extraction_step] * arr_ndim patch_strides arr stridesslices [slice None None st for st in extraction_step]indexing_strides arr[slices] stridespatch_indices_shape np array arr shape - np array patch_shape // np array extraction_step + 1 shape tuple list patch_indices_shape + list patch_shape strides tuple list indexing_strides + list patch_strides patches as_strided arr shape shape strides strides return patches
def decode string try return string decode 'utf8' 'replace' except return string
def reset ip None username None count 0attempts AccessAttempt objects all if ip attempts attempts filter ip_address ip if username attempts attempts filter username username if attempts count attempts count attempts delete return count
def _mod_repo_in_file alias repostr filepath with open filepath as fhandle output []for line in fhandle if alias not in line output append line else output append repostr + '\n' with open filepath 'w' as fhandle fhandle writelines output
@task base BaseInstructorTask def delete_problem_state entry_id xmodule_instance_args action_name ugettext_noop 'deleted' update_fcn partial delete_problem_module_state xmodule_instance_args visit_fcn partial perform_module_state_update update_fcn None return run_main_task entry_id visit_fcn action_name
@register_canonicalize@gof local_optimizer [Elemwise] def local_useless_composite node if not isinstance node op Elemwise or not isinstance node op scalar_op scalar Composite returncomp node op scalar_opidx [i for i o_extern in enumerate node outputs if o_extern clients]if len idx < len node outputs new_outputs [comp outputs[i] for i in idx]c scalar Composite inputs comp inputs outputs new_outputs e Elemwise scalar_op c return_list True *node inputs return dict zip [node outputs[i] for i in idx] e
@register_canonicalize@gof local_optimizer [Elemwise] def local_useless_composite node if not isinstance node op Elemwise or not isinstance node op scalar_op scalar Composite returncomp node op scalar_opidx [i for i o_extern in enumerate node outputs if o_extern clients]if len idx < len node outputs new_outputs [comp outputs[i] for i in idx]c scalar Composite inputs comp inputs outputs new_outputs e Elemwise scalar_op c return_list True *node inputs return dict zip [node outputs[i] for i in idx] e
def set_sleep_on_power_button enabled state salt utils mac_utils validate_enabled enabled cmd 'systemsetup-setallowpowerbuttontosleepcomputer{0}' format state salt utils mac_utils execute_return_success cmd return salt utils mac_utils confirm_updated state get_sleep_on_power_button
def set_sleep_on_power_button enabled state salt utils mac_utils validate_enabled enabled cmd 'systemsetup-setallowpowerbuttontosleepcomputer{0}' format state salt utils mac_utils execute_return_success cmd return salt utils mac_utils confirm_updated state get_sleep_on_power_button
def sigmoid x return theano tensor nnet sigmoid x
def robust_scale X axis 0 with_centering True with_scaling True quantile_range 25 0 75 0 copy True s RobustScaler with_centering with_centering with_scaling with_scaling quantile_range quantile_range copy copy if axis 0 return s fit_transform X else return s fit_transform X T T
def robust_scale X axis 0 with_centering True with_scaling True quantile_range 25 0 75 0 copy True s RobustScaler with_centering with_centering with_scaling with_scaling quantile_range quantile_range copy copy if axis 0 return s fit_transform X else return s fit_transform X T T
def fix_win_pythonw_std_stream if sys platform 'win32' and os path basename sys executable 'pythonw exe' if sys stdout is None sys stdout open os devnull 'w' if sys stderr is None sys stderr open os devnull 'w'
def environmentfunction f f environmentfunction Truereturn f
def set_cxxflags value return set_var 'CXXFLAGS' value
def fstab jail ret []config show_config jail if 'fstab' in config c_fstab config['fstab']elif 'mount fstab' in config c_fstab config['mount fstab']if 'fstab' in config or 'mount fstab' in config if os access c_fstab os R_OK with salt utils fopen c_fstab 'r' as _fp for line in _fp line line strip if not line continueif line startswith '#' continuetry device mpoint fstype opts dump pas_ line split except ValueError continueret append {'device' device 'mountpoint' mpoint 'fstype' fstype 'options' opts 'dump' dump 'pass' pas_} if not ret ret Falsereturn ret
def fstab jail ret []config show_config jail if 'fstab' in config c_fstab config['fstab']elif 'mount fstab' in config c_fstab config['mount fstab']if 'fstab' in config or 'mount fstab' in config if os access c_fstab os R_OK with salt utils fopen c_fstab 'r' as _fp for line in _fp line line strip if not line continueif line startswith '#' continuetry device mpoint fstype opts dump pas_ line split except ValueError continueret append {'device' device 'mountpoint' mpoint 'fstype' fstype 'options' opts 'dump' dump 'pass' pas_} if not ret ret Falsereturn ret
def make_iprofiledblockdeviceapi_tests profiled_blockdevice_api_factory dataset_size class Tests IProfiledBlockDeviceAPITestsMixin TestCase def setUp self super Tests self setUp self api profiled_blockdevice_api_factory self self dataset_size dataset_sizereturn Tests
def makeStack element layers []for child in element childNodes if child nodeType child ELEMENT_NODE if child tagName 'stack' stack makeStack child layers append stack elif child tagName 'layer' layer makeLayer child layers append layer else raise Exception 'Unknownelement"%s"' % child tagName print >>sys stderr 'Makingastackwith%dlayers' % len layers return Stack layers
def role_remove role **kwargs try conn _get_connection **kwargs conn autocommit True cur conn cursor cur execute 'DROPROLE{0}' format role conn autocommit True conn close return Trueexcept Exception as e return 'Couldnotcreatetherole {0}' format e
def stop name call None if call 'action' raise SaltCloudSystemExit 'Theinstanceactionmustbecalledwith-aor--action ' log info 'Stoppingmachine %s' name vb_stop_vm name machine vb_get_machine name del machine['name']return treat_machine_dict machine
def test_mapnode_json tmpdir wd str tmpdir os chdir wd from nipype import MapNode Function Workflowdef func1 in1 return in1 + 1 n1 MapNode Function input_names [u'in1'] output_names [u'out'] function func1 iterfield [u'in1'] name u'n1' n1 inputs in1 [1]w1 Workflow name u'test' w1 base_dir wdw1 config[u'execution'][u'crashdump_dir'] wdw1 add_nodes [n1] w1 run n1 inputs in1 [2]w1 run n1 inputs in1 [1]eg w1 run node eg nodes [0]outjson glob os path join node output_dir u'_0x* json' assert len outjson 1 with open os path join node output_dir u'test json' u'wt' as fp fp write u'dummyfile' w1 config[u'execution'] update **{u'stop_on_first_rerun' True} w1 run
def test_mapnode_json tmpdir wd str tmpdir os chdir wd from nipype import MapNode Function Workflowdef func1 in1 return in1 + 1 n1 MapNode Function input_names [u'in1'] output_names [u'out'] function func1 iterfield [u'in1'] name u'n1' n1 inputs in1 [1]w1 Workflow name u'test' w1 base_dir wdw1 config[u'execution'][u'crashdump_dir'] wdw1 add_nodes [n1] w1 run n1 inputs in1 [2]w1 run n1 inputs in1 [1]eg w1 run node eg nodes [0]outjson glob os path join node output_dir u'_0x* json' assert len outjson 1 with open os path join node output_dir u'test json' u'wt' as fp fp write u'dummyfile' w1 config[u'execution'] update **{u'stop_on_first_rerun' True} w1 run
def test_mapnode_json tmpdir wd str tmpdir os chdir wd from nipype import MapNode Function Workflowdef func1 in1 return in1 + 1 n1 MapNode Function input_names [u'in1'] output_names [u'out'] function func1 iterfield [u'in1'] name u'n1' n1 inputs in1 [1]w1 Workflow name u'test' w1 base_dir wdw1 config[u'execution'][u'crashdump_dir'] wdw1 add_nodes [n1] w1 run n1 inputs in1 [2]w1 run n1 inputs in1 [1]eg w1 run node eg nodes [0]outjson glob os path join node output_dir u'_0x* json' assert len outjson 1 with open os path join node output_dir u'test json' u'wt' as fp fp write u'dummyfile' w1 config[u'execution'] update **{u'stop_on_first_rerun' True} w1 run
def initialize_container path_to_container opf_name 'metadata opf' extra_entries [] rootfiles ''for path mimetype _ in extra_entries rootfiles + u'<rootfilefull-path "{0}"media-type "{1}"/>' format path mimetype CONTAINER u'<?xmlversion "1 0"?>\n<containerversion "1 0"xmlns "urn oasis names tc opendocument xmlns container">\n<rootfiles>\n<rootfilefull-path "{0}"media-type "application/oebps-package+xml"/>\n{extra_entries}\n</rootfiles>\n</container>\n' format opf_name extra_entries rootfiles encode 'utf-8' zf ZipFile path_to_container 'w' zf writestr 'mimetype' 'application/epub+zip' compression ZIP_STORED zf writestr 'META-INF/' '' 493 zf writestr 'META-INF/container xml' CONTAINER for path _ data in extra_entries zf writestr path data return zf
def setup_platform hass config add_devices discovery_info None host config get CONF_HOST port config get CONF_PORT keypad config get 'keypad' '70' if host is None or port is None _LOGGER error 'Invalidconfig Expected%sand%s' CONF_HOST CONF_PORT return Falsefrom russound import russoundruss russound Russound host port russ connect keypad sources []for source in config[CONF_SOURCES] sources append source['name'] if russ is_connected for zone_id extra in config[CONF_ZONES] items add_devices [RussoundRNETDevice hass russ sources zone_id extra ] else _LOGGER error 'Notconnectedto%s %s' host port
def resolve d tag get_tag d try resolver resolvers[tag]except KeyError reraise_as TypeError 'configdoesnotknowofanyobjecttype"' + tag + '"' return resolver d
def setegid gid gid parse_gid gid if gid os getgid os setegid gid
def get_snapshot number 0 config 'root' try snapshot snapper GetSnapshot config int number return _snapshot_to_data snapshot except dbus DBusException as exc raise CommandExecutionError 'Errorencounteredwhileretrievingsnapshot {0}' format _dbus_exception_to_reason exc locals
@pytest fixture autouse True def _annotate_environment request environment getattr request config '_environment' None if environment behave_version behave __version__environment append 'behave' behave_version
def test_stratified_table_cube tab1 [[[8 9] [6 7]] [[4 9] [5 5]] [[8 8] [9 11]]]tab2 np asarray tab1 Tct1 ctab StratifiedTable tab1 ct2 ctab StratifiedTable tab2 assert_allclose ct1 oddsratio_pooled ct2 oddsratio_pooled assert_allclose ct1 logodds_pooled ct2 logodds_pooled
def test_stratified_table_cube tab1 [[[8 9] [6 7]] [[4 9] [5 5]] [[8 8] [9 11]]]tab2 np asarray tab1 Tct1 ctab StratifiedTable tab1 ct2 ctab StratifiedTable tab2 assert_allclose ct1 oddsratio_pooled ct2 oddsratio_pooled assert_allclose ct1 logodds_pooled ct2 logodds_pooled
def update_live_symlinks config for renewal_file in storage renewal_conf_files config storage RenewableCert renewal_file config update_symlinks True
def irfft inp norm None is_odd False if is_odd not in True False raise ValueError 'Invalidvalue%sforid_odd mustbeTrueorFalse' % is_odd s inp shape[1 -1 ]if is_odd s T set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 + 1 else s T set_subtensor s[ -1 ] s[ -1 ] - 1 * 2 cond_norm _unitary norm scaling 1if cond_norm is None scaling s prod astype inp dtype elif cond_norm 'ortho' scaling T sqrt s prod astype inp dtype return irfft_op inp s / scaling
def _callback_argspec callback if not callable callback raise ValueError 'Callbacksmustbecallables' if isfunction callback or ismethod callback return getargspec callback elif isinstance callback partial return getargspec callback func else return getargspec callback __call__
def _callback_argspec callback if not callable callback raise ValueError 'Callbacksmustbecallables' if isfunction callback or ismethod callback return getargspec callback elif isinstance callback partial return getargspec callback func else return getargspec callback __call__
def dist_point_to_segment p s0 s1 p np asarray p float s0 np asarray s0 float s1 np asarray s1 float v s1 - s0 w p - s0 c1 np dot w v if c1 < 0 return dist p s0 c2 np dot v v if c2 < c1 return dist p s1 b c1 / c2 pb s0 + b * v return dist p pb
def reverse_course_url handler_name course_key kwargs None return reverse_url handler_name 'course_key_string' course_key kwargs
def reverse_course_url handler_name course_key kwargs None return reverse_url handler_name 'course_key_string' course_key kwargs
def FindMissingAndroidPlainAssets referenced_images android_assets for name inset in referenced_images iteritems if inset is not None continueif name in SKIP_PLAIN print 'WARNING %s skippingduetohard-codedexclusioninassets-tool py' % name continueandroid_name ImageNameAndroid name if android_name not in android_assets name_2x ImageName2X name shutil copyfile os path join IOS_IMAGES_DIR name_2x os path join ANDROID_IMAGES_DIR android_name print '%s notinandroidassets copied%s->%s' % name name_2x android_name elif options options v print '%s OK' % name
def FindMissingAndroidPlainAssets referenced_images android_assets for name inset in referenced_images iteritems if inset is not None continueif name in SKIP_PLAIN print 'WARNING %s skippingduetohard-codedexclusioninassets-tool py' % name continueandroid_name ImageNameAndroid name if android_name not in android_assets name_2x ImageName2X name shutil copyfile os path join IOS_IMAGES_DIR name_2x os path join ANDROID_IMAGES_DIR android_name print '%s notinandroidassets copied%s->%s' % name name_2x android_name elif options options v print '%s OK' % name
def get_sample_ids map_data map_header states name_to_col dict [ s map_header index s for s in states] good_ids []for row in map_data include Truefor s vals in states items curr_state row[name_to_col[s]]include include and curr_state in vals or '*' in vals and not ' ' + curr_state in vals if include good_ids append row[0] return good_ids
def get_sample_ids map_data map_header states name_to_col dict [ s map_header index s for s in states] good_ids []for row in map_data include Truefor s vals in states items curr_state row[name_to_col[s]]include include and curr_state in vals or '*' in vals and not ' ' + curr_state in vals if include good_ids append row[0] return good_ids
def get_body_barycentric_posvel body time ephemeris None return _get_body_barycentric_posvel body time ephemeris
def _prepare values clip True out None if clip return np clip values 0 0 1 0 out out elif out is None return np array values copy True else out[ ] np asarray values return out
def pool currentLimit threadFactory Thread def startThread target return threadFactory target target start def limitedWorkerCreator stats team statistics if stats busyWorkerCount + stats idleWorkerCount > currentLimit return Nonereturn ThreadWorker startThread Queue team Team coordinator LockWorker Lock LocalStorage createWorker limitedWorkerCreator logException err return team
def pool currentLimit threadFactory Thread def startThread target return threadFactory target target start def limitedWorkerCreator stats team statistics if stats busyWorkerCount + stats idleWorkerCount > currentLimit return Nonereturn ThreadWorker startThread Queue team Team coordinator LockWorker Lock LocalStorage createWorker limitedWorkerCreator logException err return team
def ask_for_port sys stderr write '\n---Availableports \n' ports []for n port desc hwid in enumerate sorted comports 1 sys stderr write '---{ 2} { 20}{}\n' format n port desc ports append port while True port raw_input '---Enterportindexorfullname ' try index int port - 1 if not 0 < index < len ports sys stderr write '---Invalidindex \n' continueexcept ValueError passelse port ports[index]return port
def normalize_data_query_bounds lower upper time tz lower - datetime timedelta days 1 if time is not None return normalize_data_query_time lower time tz normalize_data_query_time upper time tz return lower upper
def normalize_data_query_bounds lower upper time tz lower - datetime timedelta days 1 if time is not None return normalize_data_query_time lower time tz normalize_data_query_time upper time tz return lower upper
def normalize_data_query_bounds lower upper time tz lower - datetime timedelta days 1 if time is not None return normalize_data_query_time lower time tz normalize_data_query_time upper time tz return lower upper
def get_rdm_disk hardware_devices uuid if hardware_devices __class__ __name__ 'ArrayOfVirtualDevice' hardware_devices hardware_devices VirtualDevicefor device in hardware_devices if device __class__ __name__ 'VirtualDisk' and device backing __class__ __name__ 'VirtualDiskRawDiskMappingVer1BackingInfo' and device backing lunUuid uuid return device
def _patch_config_section_desc monkeypatch stubs symbol section_desc {'general' 'General/miscellaneousoptions ' 'ui' 'Generaloptionsrelatedtotheuserinterface ' 'searchengines' 'Definitionsofsearchengines '}monkeypatch setattr symbol section_desc
def update_static_names names_file files if os path exists names_file names json load open names_file else names {}base os path dirname names_file for path in files name os path relpath path base mangled_name generate_static_name name base names[name] mangled_nameif not os path islink path mangled_path os path join base mangled_name shutil move path mangled_path if os path exists path os unlink path os symlink mangled_name path json_enc json JSONEncoder indent 2 sort_keys True open names_file 'w' write json_enc encode names return names
def get_service hass config discovery_info None import telegramtry chat_id config get CONF_CHAT_ID api_key config get CONF_API_KEY bot telegram Bot token api_key username bot getMe ['username']_LOGGER info "Telegrambotis'%s'" username except urllib error HTTPError _LOGGER error 'Pleasecheckyouraccesstoken' return Nonereturn TelegramNotificationService api_key chat_id
def identity n dtype 'd' format None return eye n n dtype dtype format format
def identity n dtype 'd' format None return eye n n dtype dtype format format
def batch_fetch_art lib albums force maxwidth None for album in albums if album artpath and not force message 'hasalbumart'else local_paths None if force else [album path] path art_for_album album local_paths maxwidth if path album set_art path False album store message ui colorize 'green' 'foundalbumart' else message ui colorize 'red' 'noartfound' log info u'{0}-{1} {2}' format album albumartist album album message
def memory_usage return _GetSystemStats memory
def memory_usage return _GetSystemStats memory
def test_failed_dl_update config_stub basedir download_stub data_tmpdir tmpdir win_registry caplog dl_fail_blocklist QUrl create_blocklist tmpdir blocked_hosts CLEAN_HOSTS name 'download_will_fail' line_format 'one_per_line' hosts_to_block generic_blocklists tmpdir + [dl_fail_blocklist] config_stub data {'content' {'host-block-lists' hosts_to_block 'host-blocking-enabled' True 'host-blocking-whitelist' None}}host_blocker adblock HostBlocker host_blocker adblock_update while host_blocker _in_progress current_download host_blocker _in_progress[0]if current_download name dl_fail_blocklist path current_download successful Falsewith caplog at_level logging ERROR current_download finished emit host_blocker read_hosts assert_urls host_blocker whitelisted []
def test_float_number assert hug types float_number '1 1' 1 1 assert hug types float_number '1' float 1 assert hug types float_number 1 1 1 1 with pytest raises ValueError hug types float_number 'bacon'
def mksls fmt src dst None if fmt 'kickstart' return salt utils kickstart mksls src dst elif fmt 'preseed' return salt utils preseed mksls src dst elif fmt 'autoyast' return salt utils yast mksls src dst
def create_home_dir_structure for directory in HOME_NINJA_PATH EXTENSIONS_PATH PLUGINS EDITOR_SKINS LANGS NINJA_THEME_DOWNLOAD NINJA_KNOWLEDGE_PATH if not os path isdir directory os mkdir directory
def env_absent name user 'root' name name strip ret {'name' name 'result' True 'changes' {} 'comment' ''}if __opts__['test'] status _check_cron_env user name ret['result'] Noneif status 'absent' ret['result'] Trueret['comment'] 'Cronenv{0}isabsent' format name elif status 'present' or status 'update' ret['comment'] 'Cronenv{0}issettoberemoved' format name return retdata __salt__['cron rm_env'] user name if data 'absent' ret['comment'] 'Cronenv{0}alreadyabsent' format name return retif data 'removed' ret['comment'] "Cronenv{0}removedfrom{1}'scrontab" format name user ret['changes'] {user name}return retret['comment'] 'Cronenv{0}foruser{1}failedtocommitwitherror{2}' format name user data ret['result'] Falsereturn ret
def env_absent name user 'root' name name strip ret {'name' name 'result' True 'changes' {} 'comment' ''}if __opts__['test'] status _check_cron_env user name ret['result'] Noneif status 'absent' ret['result'] Trueret['comment'] 'Cronenv{0}isabsent' format name elif status 'present' or status 'update' ret['comment'] 'Cronenv{0}issettoberemoved' format name return retdata __salt__['cron rm_env'] user name if data 'absent' ret['comment'] 'Cronenv{0}alreadyabsent' format name return retif data 'removed' ret['comment'] "Cronenv{0}removedfrom{1}'scrontab" format name user ret['changes'] {user name}return retret['comment'] 'Cronenv{0}foruser{1}failedtocommitwitherror{2}' format name user data ret['result'] Falsereturn ret
def isBin s for i in s i ord i if i < 9 return Trueelif i > 13 and i < 32 return Trueelif i > 126 return Truereturn False
def skipUnlessAnyDBFeature *features return _deferredSkip lambda not any getattr connection features feature False for feature in features "Databasedoesn'tsupportanyofthefeature s %s" % ' ' join features
def get_hash_from_file hash_path dvd_basename hash_file open hash_path 'r' for line in hash_file readlines if dvd_basename in line return line split [0]
@register simple_tag takes_context False def explicit_no_context arg return 'explicit_no_context-Expectedresult %s' % arg
def nsmallest arr n keep 'first' if keep 'last' arr arr[ -1 ]narr len arr n min n narr sdtype str arr dtype arr arr view _dtype_map get sdtype sdtype kth_val algos kth_smallest arr copy n - 1 return _finalize_nsmallest arr kth_val n keep narr
def _get_default_route version subnet if subnet get 'gateway' and subnet['gateway'] get 'address' gateway subnet['gateway']['address']else return []if version 4 return [{'network' '0 0 0 0' 'netmask' '0 0 0 0' 'gateway' gateway}]elif version 6 return [{'network' ' ' 'netmask' ' ' 'gateway' gateway}]
def parse_keqv_list l parsed {}for elt in l k v elt split ' ' 1 if v[0] '"' and v[ -1 ] '"' v v[1 -1 ]parsed[k] vreturn parsed
def parse_keqv_list l parsed {}for elt in l k v elt split ' ' 1 if v[0] '"' and v[ -1 ] '"' v v[1 -1 ]parsed[k] vreturn parsed
def parse_keqv_list l parsed {}for elt in l k v elt split ' ' 1 if v[0] '"' and v[ -1 ] '"' v v[1 -1 ]parsed[k] vreturn parsed
def basic_extractor document train_set word_features _get_words_from_dataset train_set tokens _get_document_tokens document features dict u'contains {0} ' format word word in tokens for word in word_features return features
def basic_extractor document train_set word_features _get_words_from_dataset train_set tokens _get_document_tokens document features dict u'contains {0} ' format word word in tokens for word in word_features return features
def copy_current_request_context f top _request_ctx_stack topif top is None raise RuntimeError 'Thisdecoratorcanonlybeusedatlocalscopeswhenarequestcontextisonthestack Forinstancewithinviewfunctions ' reqctx top copy def wrapper *args **kwargs with reqctx return f *args **kwargs return update_wrapper wrapper f
def transform_xy_coords xy_coords sc_plot sorted_keys xy_coords keys all_cids []all_xcoords []all_ycoords []sc_plot set_transform sc_plot axes transData trans sc_plot get_transform for s_label in sorted_keys s_data xy_coords[s_label]if s_data[0] [] passelse icoords trans transform zip s_data[0] s_data[1] xcoords ycoords zip *icoords all_cids extend s_data[2] all_xcoords extend xcoords all_ycoords extend ycoords return all_cids all_xcoords all_ycoords
def transform_xy_coords xy_coords sc_plot sorted_keys xy_coords keys all_cids []all_xcoords []all_ycoords []sc_plot set_transform sc_plot axes transData trans sc_plot get_transform for s_label in sorted_keys s_data xy_coords[s_label]if s_data[0] [] passelse icoords trans transform zip s_data[0] s_data[1] xcoords ycoords zip *icoords all_cids extend s_data[2] all_xcoords extend xcoords all_ycoords extend ycoords return all_cids all_xcoords all_ycoords
def transform_xy_coords xy_coords sc_plot sorted_keys xy_coords keys all_cids []all_xcoords []all_ycoords []sc_plot set_transform sc_plot axes transData trans sc_plot get_transform for s_label in sorted_keys s_data xy_coords[s_label]if s_data[0] [] passelse icoords trans transform zip s_data[0] s_data[1] xcoords ycoords zip *icoords all_cids extend s_data[2] all_xcoords extend xcoords all_ycoords extend ycoords return all_cids all_xcoords all_ycoords
def get_music_section host port token library_name api_endpoint append_token 'library/sections' token url urljoin 'http //{0} {1}' format host port api_endpoint r requests get url tree ET fromstring r content for child in tree findall 'Directory' if child get 'title' library_name return child get 'key'
@hello get permission NO_PERMISSION_REQUIRED def get_hello request settings request registry settingsproject_name settings['project_name']project_version settings['project_version']data dict project_name project_name project_version project_version http_api_version settings['http_api_version'] project_docs settings['project_docs'] url request route_url hello name eos get_eos request if eos data['eos'] eosdata['settings'] {}public_settings request registry public_settingsfor setting in list public_settings data['settings'][setting] settings[setting]if Authenticated in request effective_principals data['user'] request get_user_info data['capabilities'] request registry api_capabilitiesreturn data
def _declarative_constructor self **kwargs cls_ type self for k in kwargs if not hasattr cls_ k raise TypeError '%risaninvalidkeywordargumentfor%s' % k cls_ __name__ setattr self k kwargs[k]
def _declarative_constructor self **kwargs cls_ type self for k in kwargs if not hasattr cls_ k raise TypeError '%risaninvalidkeywordargumentfor%s' % k cls_ __name__ setattr self k kwargs[k]
@open_file 1 mode 'wb' def write_multiline_adjlist G path delimiter '' comments '#' encoding 'utf-8' import sysimport timepargs comments + '' join sys argv header '{}\n' format pargs + comments + 'GMT{}\n' format time asctime time gmtime + comments + '{}\n' format G name path write header encode encoding for multiline in generate_multiline_adjlist G delimiter multiline + '\n'path write multiline encode encoding
@open_file 1 mode 'wb' def write_multiline_adjlist G path delimiter '' comments '#' encoding 'utf-8' import sysimport timepargs comments + '' join sys argv header '{}\n' format pargs + comments + 'GMT{}\n' format time asctime time gmtime + comments + '{}\n' format G name path write header encode encoding for multiline in generate_multiline_adjlist G delimiter multiline + '\n'path write multiline encode encoding
def get_referent_by_identifier category value try identifier Identifier find_one Q 'category' 'eq' category & Q 'value' 'eq' value except NoResultsFound raise HTTPError http NOT_FOUND if identifier referent url return redirect identifier referent url raise HTTPError http NOT_FOUND
def get_dict name default None default default or {} if is_site_configuration_enabled return get_configuration_dict name default else return microsite get_dict name default
def _quit_editor caller del caller db _multidesc_editkeycaller msg 'Exitededitor '
def get_request_body text syntax True entities True sentiment True body {'document' {'type' 'PLAIN_TEXT' 'content' text} 'features' {'extract_syntax' syntax 'extract_entities' entities 'extract_document_sentiment' sentiment} 'encoding_type' 'UTF32'}return body
def get_request_body text syntax True entities True sentiment True body {'document' {'type' 'PLAIN_TEXT' 'content' text} 'features' {'extract_syntax' syntax 'extract_entities' entities 'extract_document_sentiment' sentiment} 'encoding_type' 'UTF32'}return body
def get_tox_env parser get_parser args parser parse_args if args tox_env is not None tox_env args tox_envelif TOX_ENV_VAR in os environ tox_env os environ[TOX_ENV_VAR]else tox_env get_tox_env_from_version return tox_env
def get_tox_env parser get_parser args parser parse_args if args tox_env is not None tox_env args tox_envelif TOX_ENV_VAR in os environ tox_env os environ[TOX_ENV_VAR]else tox_env get_tox_env_from_version return tox_env
def _send_email from_email to_email msg global _smtptry _smtp sendmail from_email to_email msg except smtplib SMTPServerDisconnected _smtp _smtp_connect _smtp sendmail from_email to_email msg
def longTest testMethod def newTestMethod *args **kwargs if TestOptionParser __long__ is None raise Exception 'TestOptionParsermustbeusedinordertouse@longTestdecorator ' if TestOptionParser __long__ return testMethod *args **kwargs else msg 'Skippinglongtest %s' % testMethod __name__ return unittest skip msg testMethod *args **kwargs return newTestMethod
def _get_all_eip_addresses addresses None allocation_ids None region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile try return conn get_all_addresses addresses addresses allocation_ids allocation_ids except boto exception BotoServerError as e log error e return []
def add_prerequisite course_key prereq_content_key milestone milestones_api add_milestone {'name' _ 'Gatingmilestonefor{usage_key}' format usage_key unicode prereq_content_key 'namespace' '{usage_key}{qualifier}' format usage_key prereq_content_key qualifier GATING_NAMESPACE_QUALIFIER 'description' _ 'Systemdefinedmilestone' } propagate False milestones_api add_course_content_milestone course_key prereq_content_key 'fulfills' milestone
def get_value_for_org org val_name default None return BACKEND get_value_for_org org val_name default
def get_value_for_org org val_name default None return BACKEND get_value_for_org org val_name default
def vector_mean vectors n len vectors return scalar_multiply 1 / n vector_sum vectors
def archiver typename archiver _ARCHIVER_BY_TYPE get typename if not archiver raise ValueError u'Noarchiverregisteredfor{ r}' format typename return archiver
def security_group_rule_get_by_security_group_grantee context security_group_id return IMPL security_group_rule_get_by_security_group_grantee context security_group_id
def security_group_rule_get_by_security_group_grantee context security_group_id return IMPL security_group_rule_get_by_security_group_grantee context security_group_id
def raise_if_duplicate_entry_error integrity_error engine_name def get_columns_from_uniq_cons_or_name columns uniqbase 'uniq_'if not columns startswith uniqbase if engine_name 'postgresql' return [columns[ columns index '_' + 1 columns rindex '_' ]]return [columns]return columns[len uniqbase ] split '_x_' if engine_name not in ['mysql' 'sqlite' 'postgresql'] returnm _DUP_KEY_RE_DB[engine_name] match integrity_error message if not m returncolumns m group 1 if engine_name 'sqlite' columns columns strip split ' ' else columns get_columns_from_uniq_cons_or_name columns raise exception DBDuplicateEntry columns integrity_error
def stack_sparse_frame frame lengths [s sp_index npoints for _ s in compat iteritems frame ]nobs sum lengths minor_labels np repeat np arange len frame columns lengths inds_to_concat []vals_to_concat []for _ series in compat iteritems frame if not np isnan series fill_value raise TypeError 'ThisroutineassumesNaNfillvalue' int_index series sp_index to_int_index inds_to_concat append int_index indices vals_to_concat append series sp_values major_labels np concatenate inds_to_concat stacked_values np concatenate vals_to_concat index MultiIndex levels [frame index frame columns] labels [major_labels minor_labels] verify_integrity False lp DataFrame stacked_values reshape nobs 1 index index columns ['foo'] return lp sort_index level 0
def requires_json_api_mimetype func @wraps func def new_func *args **kw 'Executes``func *args **kw ``onlyaftercheckingforthe\ncorrectJSONAPI http header `Content-Type`header \n\n'if request method not in 'PATCH' 'POST' return func *args **kw header request headers get 'Content-Type' content_type extra parse_options_header header content_is_json content_type startswith JSONAPI_MIMETYPE is_msie _is_msie8or9 if not is_msie and not content_is_json detail 'Requestmusthave"Content-Type {0}"header' format JSONAPI_MIMETYPE return error_response 415 detail detail if extra detail 'Content-Typeheadermustnothaveanymediatypeparametersbutfound{0}' format extra return error_response 415 detail detail return func *args **kw return new_func
@auth_decoratordef token_authenticated self if self get_current_user_token is None raise web HTTPError 403
def verify_signed_jwt_with_certs jwt certs audience None jwt _helpers _to_bytes jwt if jwt count ' ' 2 raise AppIdentityError 'Wrongnumberofsegmentsintoken {0}' format jwt header payload signature jwt split ' ' message_to_sign header + ' ' + payload signature _helpers _urlsafe_b64decode signature payload_bytes _helpers _urlsafe_b64decode payload try payload_dict json loads _helpers _from_bytes payload_bytes except raise AppIdentityError "Can'tparsetoken {0}" format payload_bytes _verify_signature message_to_sign signature certs values _verify_time_range payload_dict _check_audience payload_dict audience return payload_dict
def ip6_interfaces if salt utils is_proxy return {}ret {}ifaces _get_interfaces for face in ifaces iface_ips []for inet in ifaces[face] get 'inet6' [] if 'address' in inet iface_ips append inet['address'] for secondary in ifaces[face] get 'secondary' [] if 'address' in secondary iface_ips append secondary['address'] ret[face] iface_ipsreturn {'ip6_interfaces' ret}
@Profiler profiledef test_core_query_caching n cache {}ins Customer __table__ insert for i in range n with engine begin as conn conn execution_options compiled_cache cache execute ins dict name 'customername%d' % i description 'customerdescription%d' % i
@pytest mark networkdef test_no_clean_option_blocks_cleaning_after_wheel script data script pip 'install' 'wheel' build script venv_path / 'build' result script pip 'wheel' '--no-clean' '--no-index' '--build' build '--find-links %s' % data find_links 'simple' build build / 'simple' assert exists build 'build/simpleshouldstillexist%s' % str result
@decorators which 'dig' def dig host cmd 'dig{0}' format salt utils network sanitize_host host return __salt__['cmd run'] cmd
def trim line if not '#' in line return linereturn line split '#' [0]
def vibrate pattern repeat None PythonActivity jnius autoclass 'org renpy android PythonService' Context jnius autoclass 'android content Context' activity PythonActivity mServicevibrator activity getSystemService Context VIBRATOR_SERVICE if vibrator hasVibrator try if repeat vibrator vibrate list pattern repeat else vibrator vibrate list pattern -1 except KeyboardInterrupt vibrator cancel raiseelse raise RuntimeError 'Thedevicedoesnothaveavibrator'
def get_dataless_dataset model global yaml_parseglobal controlif yaml_parse is None from pylearn2 config import yaml_parseif control is None from pylearn2 datasets import controlcontrol push_load_data False try rval yaml_parse load model dataset_yaml_src finally control pop_load_data return rval
def test_proxy _test_function_names gl proxy _test_constant_names gl _constants
def generate_alias tbl return u'' join [l for l in tbl if l isupper ] or [l for l prev in zip tbl u'_' + tbl if prev u'_' and l u'_' ]
def check_and_decode_json result response_code def error body raise ResponseError result code body if result code response_code d content result d addCallback error return dreturn json_content result
def inplace_logistic_derivative Z delta delta * Zdelta * 1 - Z
def rcdefaults rcParams update rcParamsDefault
def rcdefaults rcParams update rcParamsDefault
def get_info dicom_files meta default_extractor read_file filename_to_list dicom_files [0] stop_before_pixels True force True return meta[u'RepetitionTime'] / 1000 0 meta[u'CsaImage MosaicRefAcqTimes'] meta[u'SpacingBetweenSlices']
@genericdef inspect_object obj raise TryNext
def sinc x N y np sin N * x / 2 / np sin x / 2 y[np isnan y ] Nreturn y
def set_user_tags name tags runas None if runas is None and not salt utils is_windows runas salt utils get_user if tags and isinstance tags list tuple tags '' join tags res __salt__['cmd run_all'] [__context__['rabbitmqctl'] 'set_user_tags' name tags] runas runas python_shell False msg 'Tag s set'return _format_response res msg
def set_user_tags name tags runas None if runas is None and not salt utils is_windows runas salt utils get_user if tags and isinstance tags list tuple tags '' join tags res __salt__['cmd run_all'] [__context__['rabbitmqctl'] 'set_user_tags' name tags] runas runas python_shell False msg 'Tag s set'return _format_response res msg
def create_zfs_pool test_case if os getuid 0 raise SkipTest 'Functionaltestsmustrunasroot ' pool_name 'testpool_%s' % uuid uuid4 pool_path FilePath test_case mktemp mount_path FilePath test_case mktemp with pool_path open 'wb' as f f truncate 100 * 1024 * 1024 test_case addCleanup pool_path remove try run_process ['zpool' 'create' '-m' mount_path path pool_name pool_path path] except OSError as e if e errno errno ENOENT raise SkipTest 'Installzpooltorunthesetests http //doc-dev clusterhq com/using/installing/index html#optional-zfs-backend-configuration' raisetest_case addCleanup run_process ['zpool' 'destroy' pool_name] return pool_name
def mutShrink individual if len individual < 3 or individual height < 1 return individual iprims []for i node in enumerate individual[1 ] 1 if isinstance node Primitive and node ret in node args iprims append i node if len iprims 0 index prim random choice iprims arg_idx random choice [i for i type_ in enumerate prim args if type_ prim ret ] rindex index + 1 for _ in range arg_idx + 1 rslice individual searchSubtree rindex subtree individual[rslice]rindex + len subtree slice_ individual searchSubtree index individual[slice_] subtreereturn individual
def mutShrink individual if len individual < 3 or individual height < 1 return individual iprims []for i node in enumerate individual[1 ] 1 if isinstance node Primitive and node ret in node args iprims append i node if len iprims 0 index prim random choice iprims arg_idx random choice [i for i type_ in enumerate prim args if type_ prim ret ] rindex index + 1 for _ in range arg_idx + 1 rslice individual searchSubtree rindex subtree individual[rslice]rindex + len subtree slice_ individual searchSubtree index individual[slice_] subtreereturn individual
@task rate_limit '120/m' def tidy_revision_content pk refresh True try revision Revision objects get pk pk except Revision DoesNotExist as exc log error 'Tidywasunabletogetrevisionid %d Retrying ' pk tidy_revision_content retry countdown 60 * 2 max_retries 5 exc exc else if revision tidied_content and not refresh return tidied_content errors tidy_content revision content if tidied_content revision tidied_content Revision objects filter pk pk update tidied_content tidied_content return errors
def leaves_list Z Z np asarray Z order 'c' is_valid_linkage Z throw True name 'Z' n Z shape[0] + 1 ML np zeros n dtype 'i' [Z] _copy_arrays_if_base_present [Z] _hierarchy prelist Z ML int n return ML
def leaves_list Z Z np asarray Z order 'c' is_valid_linkage Z throw True name 'Z' n Z shape[0] + 1 ML np zeros n dtype 'i' [Z] _copy_arrays_if_base_present [Z] _hierarchy prelist Z ML int n return ML
def _wrap_with_before action responder if 'resource' in get_argnames action shim actionelse def shim req resp resource kwargs action req resp kwargs @wraps responder def do_before self req resp **kwargs shim req resp self kwargs responder self req resp **kwargs return do_before
def hash_file filename size None method 'md5' chunksize 4096fsize os path getsize filename if not size or size > fsize size fsizef open filename 'rb' try hash utils hash method except ValueError logging error 'Unknownhashtype%s returningNone' % method while size > 0 if chunksize > size chunksize sizedata f read chunksize if len data 0 logging debug 'Nothinglefttoreadbutsize %d' % size breakhash update data size - len data f close return hash hexdigest
def exit_sab value sys stderr flush sys stdout flush if getattr sys 'frozen' None 'macosx_app' sabnzbd SABSTOP Truefrom PyObjCTools import AppHelperAppHelper stopEventLoop sys exit value
@lower_getattr_generic types BaseNamedTuple def namedtuple_getattr context builder typ value attr index typ fields index attr res builder extract_value value index return impl_ret_borrowed context builder typ[index] res
def _sanity_check _verify_default_drone_set_exists
def update_qq_api_request_data data {} defaults {'openid' session get 'qq_openid' 'access_token' session get 'qq_token' [0] 'oauth_consumer_key' QQ_APP_ID}defaults update data return defaults
def job_show context data_dict _check_access u'job_show' context data_dict id _get_or_bust data_dict u'id' try return jobs dictize_job jobs job_from_id id except KeyError raise NotFound
def source_read app docname source if docname 'extensions/plugins-toolkit' returnsource_ ''for name thing in inspect getmembers toolkit custom_docstring toolkit docstring_overrides get name if inspect isfunction thing source_ + format_function name thing docstring custom_docstring elif inspect ismethod thing source_ + format_function name thing docstring custom_docstring elif inspect isclass thing source_ + format_class name thing docstring custom_docstring elif isinstance thing types ObjectType source_ + format_object name thing docstring custom_docstring else assert False "Someoneadded{name} {thing}tothepluginstoolkitandthisSphinxextensiondoesn'tknowhowtodocumentthatyet Ifyou'rethatsomeone youneedtoaddanewformat_* functionforithereorthedocswon'tbuild " format name name thing thing source[0] + source_
def accept_singleton expected_type position 1 @decoratordef wrapper function *args **kw if isinstance args[position] expected_type args list args args[position] [args[position]]args tuple args return function *args **kw return wrapper
def accept_singleton expected_type position 1 @decoratordef wrapper function *args **kw if isinstance args[position] expected_type args list args args[position] [args[position]]args tuple args return function *args **kw return wrapper
def accept_singleton expected_type position 1 @decoratordef wrapper function *args **kw if isinstance args[position] expected_type args list args args[position] [args[position]]args tuple args return function *args **kw return wrapper
def filter_by_latest_metadata_changeset_revision_that_has_invalid_tools trans repository repository_metadata get_latest_repository_metadata_if_it_includes_invalid_tools trans repository if repository_metadata is not None return repository_metadata changeset_revisionreturn None
def filter_by_latest_metadata_changeset_revision_that_has_invalid_tools trans repository repository_metadata get_latest_repository_metadata_if_it_includes_invalid_tools trans repository if repository_metadata is not None return repository_metadata changeset_revisionreturn None
def ConvertToMSBuildSettings msvs_settings stderr sys stderr msbuild_settings {}for msvs_tool_name msvs_tool_settings in msvs_settings iteritems if msvs_tool_name in _msvs_to_msbuild_converters msvs_tool _msvs_to_msbuild_converters[msvs_tool_name]for msvs_setting msvs_value in msvs_tool_settings iteritems if msvs_setting in msvs_tool try msvs_tool[msvs_setting] msvs_value msbuild_settings except ValueError as e print >>stderr 'Warning whileconverting%s/%stoMSBuild %s' % msvs_tool_name msvs_setting e else _ValidateExclusionSetting msvs_setting msvs_tool 'Warning unrecognizedsetting%s/%swhileconvertingtoMSBuild ' % msvs_tool_name msvs_setting stderr else print >>stderr 'Warning unrecognizedtool%swhileconvertingtoMSBuild ' % msvs_tool_name return msbuild_settings
def ConvertToMSBuildSettings msvs_settings stderr sys stderr msbuild_settings {}for msvs_tool_name msvs_tool_settings in msvs_settings iteritems if msvs_tool_name in _msvs_to_msbuild_converters msvs_tool _msvs_to_msbuild_converters[msvs_tool_name]for msvs_setting msvs_value in msvs_tool_settings iteritems if msvs_setting in msvs_tool try msvs_tool[msvs_setting] msvs_value msbuild_settings except ValueError as e print >>stderr 'Warning whileconverting%s/%stoMSBuild %s' % msvs_tool_name msvs_setting e else _ValidateExclusionSetting msvs_setting msvs_tool 'Warning unrecognizedsetting%s/%swhileconvertingtoMSBuild ' % msvs_tool_name msvs_setting stderr else print >>stderr 'Warning unrecognizedtool%swhileconvertingtoMSBuild ' % msvs_tool_name return msbuild_settings
def _validator code_or_name validator_type if validator_type 'error' from errors import codesfrom errors import EXTelif validator_type 'warning' from warnings import codesfrom warnings import EXTelse passdef decorator func def wrapper *args **kw extra func *args **kw if extra is None return []if isinstance code_or_name string_types code EXTname codes[code][0] + ' ' + code_or_name else code code_or_namename codes[code][0]text codes[code][1]return [ code name text extra ]wrapper validator_type validator_typereturn wrapperreturn decorator
def _validator code_or_name validator_type if validator_type 'error' from errors import codesfrom errors import EXTelif validator_type 'warning' from warnings import codesfrom warnings import EXTelse passdef decorator func def wrapper *args **kw extra func *args **kw if extra is None return []if isinstance code_or_name string_types code EXTname codes[code][0] + ' ' + code_or_name else code code_or_namename codes[code][0]text codes[code][1]return [ code name text extra ]wrapper validator_type validator_typereturn wrapperreturn decorator
def read_env key value envkey key replace ' ' '_' replace '-' '_' upper return native_value os getenv envkey value
def environ_add_path env key path old env get key if old env[key] path + ' ' + old else env[key] path
@login_requireddef associate_success request identity_url openid_response redirect_field_name REDIRECT_FIELD_NAME send_email True **kwargs openid_ from_openid_response openid_response openids request session get 'openids' [] openids append openid_ request session['openids'] openidsuassoc UserAssociation openid_url str openid_ user_id request user id uassoc save send_email send_email redirect_to request GET get redirect_field_name '' if not redirect_to or '//' in redirect_to or '' in redirect_to redirect_to settings LOGIN_REDIRECT_URLreturn HttpResponseRedirect redirect_to
def is_online global _onlineif _online is None import sockettry socket gethostbyname u'google com' _online Trueexcept _online Falsereturn _online
def setup_module module import osimport numpy as npimport random_random_seed os environ get 'SKLEARN_SEED' None if _random_seed is None _random_seed np random uniform * 2 ** 31 - 1 _random_seed int _random_seed print 'I SeedingRNGswith%r' % _random_seed np random seed _random_seed random seed _random_seed
def test_start_overflow t usertypes Timer with pytest raises OverflowError t start 2 ** 64
@receiver [models signals post_delete models signals post_save] sender ExtensionVersion dispatch_uid 'extension_version_change' def update_extension_status_and_manifest_fields sender instance **kw instance extension update_status_according_to_versions if instance status STATUS_PUBLIC instance extension update_manifest_fields_from_latest_public_version
def check_derivative fun jac x0 bounds - np inf np inf args kwargs {} J_to_test jac x0 *args **kwargs if issparse J_to_test J_diff approx_derivative fun x0 bounds bounds sparsity J_to_test args args kwargs kwargs J_to_test csr_matrix J_to_test abs_err J_to_test - J_diff i j abs_err_data find abs_err J_diff_data np asarray J_diff[ i j ] ravel return np max np abs abs_err_data / np maximum 1 np abs J_diff_data else J_diff approx_derivative fun x0 bounds bounds args args kwargs kwargs abs_err np abs J_to_test - J_diff return np max abs_err / np maximum 1 np abs J_diff
def _read_dictionary_page file_obj schema_helper page_header column_metadata raw_bytes _read_page file_obj page_header column_metadata io_obj io BytesIO raw_bytes values encoding read_plain io_obj column_metadata type page_header dictionary_page_header num_values schema_element schema_helper schema_element column_metadata path_in_schema[ -1 ] return convert_column values schema_element if schema_element converted_type is not None else values
def _read_dictionary_page file_obj schema_helper page_header column_metadata raw_bytes _read_page file_obj page_header column_metadata io_obj io BytesIO raw_bytes values encoding read_plain io_obj column_metadata type page_header dictionary_page_header num_values schema_element schema_helper schema_element column_metadata path_in_schema[ -1 ] return convert_column values schema_element if schema_element converted_type is not None else values
def zipline_root environ None if environ is None environ os environroot environ get 'ZIPLINE_ROOT' None if root is None root expanduser '~/ zipline' return root
def pull cwd opts None user None identity None repository None cmd ['hg' 'pull']if identity cmd extend _ssh_flag identity if opts for opt in opts split cmd append opt if repository is not None cmd append repository ret __salt__['cmd run_all'] cmd cwd cwd runas user python_shell False if ret['retcode'] 0 raise CommandExecutionError 'Hgcommandfailed {0}' format ret get 'stderr' ret['stdout'] return ret['stdout']
def make_weighted_tree fn ls **kwargs if not ls raise ValueError 'Calledmake_weighted_treewithemptylist' ls sort while len ls > 1 a ls pop 0 b ls pop 0 insort ls a[0] + b[0] fn a[1] b[1] return ls[0][1]
def make_weighted_tree fn ls **kwargs if not ls raise ValueError 'Calledmake_weighted_treewithemptylist' ls sort while len ls > 1 a ls pop 0 b ls pop 0 insort ls a[0] + b[0] fn a[1] b[1] return ls[0][1]
def make_weighted_tree fn ls **kwargs if not ls raise ValueError 'Calledmake_weighted_treewithemptylist' ls sort while len ls > 1 a ls pop 0 b ls pop 0 insort ls a[0] + b[0] fn a[1] b[1] return ls[0][1]
def activate requirement try for distro in pkg_resources require requirement distro activate except pkg_resources DistributionNotFound pkg_resources VersionConflict raise errors DependencyError '{0}isunavailable' format requirement
def _make_entity_from_pb annotations return [EntityAnnotation from_pb annotation for annotation in annotations]
def beacon config ret []_validate __validate__ config if not _validate[0] return ret_refresh Falseif 'refresh' in config and config['refresh'] _refresh Truefor pkg in config['pkgs'] _installed __salt__['pkg version'] pkg _latest __salt__['pkg latest_version'] pkg refresh _refresh if _installed and _latest _pkg {'pkg' pkg 'version' _latest}ret append _pkg return ret
def beacon config ret []_validate __validate__ config if not _validate[0] return ret_refresh Falseif 'refresh' in config and config['refresh'] _refresh Truefor pkg in config['pkgs'] _installed __salt__['pkg version'] pkg _latest __salt__['pkg latest_version'] pkg refresh _refresh if _installed and _latest _pkg {'pkg' pkg 'version' _latest}ret append _pkg return ret
def get_dynamic_property vim mobj type property_name obj_content get_object_properties vim None mobj type [property_name] property_value Noneif obj_content dynamic_property obj_content[0] propSetif dynamic_property property_value dynamic_property[0] valreturn property_value
def CreateSitemapFromFile configpath suppress_notify num_errors output num_errorssitemap Sitemap suppress_notify try output Log 'Readingconfigurationfile %s' % configpath 0 xml sax parse configpath sitemap except IOError output Error 'Cannotreadconfigurationfile %s' % configpath except xml sax _exceptions SAXParseException as e output Error 'XMLerrorintheconfigfile line%d column%d %s' % e _linenum e _colnum e getMessage except xml sax _exceptions SAXReaderNotAvailable output Error 'SomeinstallsofPython2 2didnotincludecompletesupportforXML \nPleasetryupgradingyourversionofPythonandre-runningthescript ' if num_errors output num_errors return sitemapreturn None
def normalize_lat_lng arg if isinstance arg dict if 'lat' in arg and 'lng' in arg return arg['lat'] arg['lng'] if 'latitude' in arg and 'longitude' in arg return arg['latitude'] arg['longitude'] if _is_list arg return arg[0] arg[1] raise TypeError 'Expectedalat/lngdictortuple butgot%s' % type arg __name__
def qapplication translate True test_time 3 if running_in_mac_app SpyderApplication MacApplicationelse SpyderApplication QApplicationapp SpyderApplication instance if app is None app SpyderApplication ['Spyder'] app setApplicationName 'Spyder' if translate install_translator app test_ci os environ get 'TEST_CI_WIDGETS' None if test_ci is not None timer_shutdown QTimer app timer_shutdown timeout connect app quit timer_shutdown start test_time * 1000 return app
def create_event name details service_key profile ret {'name' name 'changes' {} 'result' None 'comment' ''}if __opts__['test'] ret['comment'] 'Needtocreateevent {0}' format name return ret__salt__['pagerduty create_event'] description name details details service_key service_key profile profile ret['result'] Trueret['comment'] 'Createdevent {0}' format name return ret
def grey_erosion input size None footprint None structure None output None mode 'reflect' cval 0 0 origin 0 if size is None and footprint is None and structure is None raise ValueError 'size footprintorstructuremustbespecified' return filters _min_or_max_filter input size footprint structure output mode cval origin 1
def fallback_trans x t _ x if t x l get_lang set_lang g lang graceful_fail True t _ x if l and l[0] g lang set_lang l[0] return t
def _out_file fn handle logSys debug handle '----' + fn + '----' for line in fileinput input fn line line rstrip '\n' handle line handle '-' * 30
def _out_file fn handle logSys debug handle '----' + fn + '----' for line in fileinput input fn line line rstrip '\n' handle line handle '-' * 30
def get_np_state_ptr context builder return get_state_ptr context builder 'np'
def get_conv_gradweights_shape_1axis image_shape top_shape border_mode subsample dilation if None in [image_shape top_shape border_mode subsample dilation] return Noneif subsample 1 or border_mode 'half' return Noneif border_mode 'full' kernel_shape top_shape - image_shape elif border_mode 'valid' kernel_shape image_shape - top_shape else if border_mode < 0 raise ValueError 'border_modemustbe> 0' kernel_shape image_shape + 2 * border_mode - top_shape if dilation > 1 kernel_shape kernel_shape / dilation return kernel_shape + 1
def get_conv_gradweights_shape_1axis image_shape top_shape border_mode subsample dilation if None in [image_shape top_shape border_mode subsample dilation] return Noneif subsample 1 or border_mode 'half' return Noneif border_mode 'full' kernel_shape top_shape - image_shape elif border_mode 'valid' kernel_shape image_shape - top_shape else if border_mode < 0 raise ValueError 'border_modemustbe> 0' kernel_shape image_shape + 2 * border_mode - top_shape if dilation > 1 kernel_shape kernel_shape / dilation return kernel_shape + 1
def _convert_to_jsonc x if isinstance x dict jsonc_obj Jsonc for key value in x iteritems jsonc_obj _dict[key] _convert_to_jsonc value return jsonc_objelif isinstance x list members []for item in x members append _convert_to_jsonc item return memberselse return x
def _convert_to_jsonc x if isinstance x dict jsonc_obj Jsonc for key value in x iteritems jsonc_obj _dict[key] _convert_to_jsonc value return jsonc_objelif isinstance x list members []for item in x members append _convert_to_jsonc item return memberselse return x
def _list_mock_games path files os listdir path return os path join path f for f in files if _is_sgf f
def get_setup_section app module label icon config get_config app module for section in config if section get u'label' _ u'Setup' return {u'label' label u'icon' icon u'items' section[u'items']}
def will_write fn def _fn *a **kw if disallow_db_writes raise CassandraException 'Notsofast DBwriteshavebeendisabled' return fn *a **kw return _fn
def will_write fn def _fn *a **kw if disallow_db_writes raise CassandraException 'Notsofast DBwriteshavebeendisabled' return fn *a **kw return _fn
def aes_cipher_from_key key return AES new key AES MODE_CBC generate_aes_iv key
def _clade_to_bitstr clade tree_term_names clade_term_names set term name for term in clade find_clades terminal True return _BitString from_bool name in clade_term_names for name in tree_term_names
def _clade_to_bitstr clade tree_term_names clade_term_names set term name for term in clade find_clades terminal True return _BitString from_bool name in clade_term_names for name in tree_term_names
def auto_delete_files cls pre_delete connect delete_files_for_obj sender cls return cls
def _makeFrame buf opcode fin mask None bufferLength len buf if mask is not None lengthMask 128else lengthMask 0if bufferLength > 65535 length '%s%s' % chr lengthMask 127 pack '>Q' bufferLength elif bufferLength > 125 length '%s%s' % chr lengthMask 126 pack '>H' bufferLength else length chr lengthMask bufferLength if fin header 128else header 1header chr header opcode value if mask is not None buf '%s%s' % mask _mask buf mask frame '%s%s%s' % header length buf return frame
def generate_bounding_box bottom_left top_right west lat_1 bottom_left get_coords east lat_2 top_right get_coords min_lat max_lat min lat_1 lat_2 max lat_1 lat_2 return min_lat west max_lat east
def generate_bounding_box bottom_left top_right west lat_1 bottom_left get_coords east lat_2 top_right get_coords min_lat max_lat min lat_1 lat_2 max lat_1 lat_2 return min_lat west max_lat east
def add_friend self userName status 2 verifyContent '' autoUpdate True url '%s/webwxverifyuser?r %s&pass_ticket %s' % self loginInfo['url'] int time time self loginInfo['pass_ticket'] data {'BaseRequest' self loginInfo['BaseRequest'] 'Opcode' status 'VerifyUserListSize' 1 'VerifyUserList' [{'Value' userName 'VerifyUserTicket' ''}] 'VerifyContent' verifyContent 'SceneListCount' 1 'SceneList' 33 'skey' self loginInfo['skey']}headers {'ContentType' 'application/json charset UTF-8' 'User-Agent' config USER_AGENT}r self s post url headers headers data json dumps data ensure_ascii False encode 'utf8' 'replace' if autoUpdate self update_friend userName return ReturnValue rawResponse r
def delete_website Bucket region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile conn delete_bucket_website Bucket Bucket return {'deleted' True 'name' Bucket}except ClientError as e return {'deleted' False 'error' __utils__['boto3 get_error'] e }
def chart_runner chart scales axes marks for i scale in enumerate scales nt assert_dict_equal chart scales[i] grammar scale for i axis in enumerate axes nt assert_dict_equal chart axes[i] grammar axis for i mark in enumerate marks nt assert_dict_equal chart marks[i] grammar mark
def get_related_models_recursive model seen set queue _get_related_models model for rel_mod in queue rel_app_label rel_model_name rel_mod _meta app_label rel_mod _meta model_name if rel_app_label rel_model_name in seen continueseen add rel_app_label rel_model_name queue extend _get_related_models rel_mod return seen - { model _meta app_label model _meta model_name }
def create_ngram_set input_list ngram_value 2 return set zip *[input_list[i ] for i in range ngram_value ]
def _count_replacement codon_set G from math import floorif len codon_set 1 return 0 0 elif len codon_set 2 codons list codon_set return floor G[codons[0]][codons[1]] else codons list codon_set return _prim G
def tree_to_stream entries write ord_zero ord '0' bit_mask 7for binsha mode name in entries mode_str ''for i in xrange 6 mode_str bchr mode >> i * 3 & bit_mask + ord_zero + mode_str if byte_ord mode_str[0] ord_zero mode_str mode_str[1 ]if isinstance name text_type name name encode defenc write '' join mode_str '' name '\x00' binsha
def tree_to_stream entries write ord_zero ord '0' bit_mask 7for binsha mode name in entries mode_str ''for i in xrange 6 mode_str bchr mode >> i * 3 & bit_mask + ord_zero + mode_str if byte_ord mode_str[0] ord_zero mode_str mode_str[1 ]if isinstance name text_type name name encode defenc write '' join mode_str '' name '\x00' binsha
@taskdef test_addons ctx test_module ctx module ADDON_TESTS
def construct_streamreader_callback process handler implied_arg 0partial_args 0handler_to_inspect handlerif isinstance handler partial partial_args len handler args handler_to_inspect handler funcif inspect ismethod handler_to_inspect implied_arg 1num_args get_num_args handler_to_inspect elif inspect isfunction handler_to_inspect num_args get_num_args handler_to_inspect else implied_arg 1num_args get_num_args handler_to_inspect __call__ net_args num_args - implied_arg - partial_args handler_args if net_args 1 handler_args if net_args 2 handler_args process stdin elif net_args 3 handler_args process stdin weakref ref process def fn chunk args handler_argsif len args 2 args handler_args[0] handler_args[1] return handler chunk *args return fn
def mutNodeReplacement individual pset if len individual < 2 return individual index random randrange 1 len individual node individual[index]if node arity 0 term random choice pset terminals[node ret] if isclass term term term individual[index] termelse prims [p for p in pset primitives[node ret] if p args node args ]individual[index] random choice prims return individual
def mutNodeReplacement individual pset if len individual < 2 return individual index random randrange 1 len individual node individual[index]if node arity 0 term random choice pset terminals[node ret] if isclass term term term individual[index] termelse prims [p for p in pset primitives[node ret] if p args node args ]individual[index] random choice prims return individual
def _mark_package_install module base pkg_spec try base install pkg_spec except dnf exceptions MarkingError module fail_json msg 'Nopackage{}available ' format pkg_spec
@webapi_decoratordef webapi_check_login_required view_func @webapi_response_errors NOT_LOGGED_IN def _check *args **kwargs siteconfig SiteConfiguration objects get_current request _find_httprequest args if siteconfig get u'auth_require_sitewide_login' or request user is_anonymous and u'HTTP_AUTHORIZATION' in request META return webapi_login_required view_func *args **kwargs else return view_func *args **kwargs _check checks_login_required Truereturn _check
@webapi_decoratordef webapi_check_login_required view_func @webapi_response_errors NOT_LOGGED_IN def _check *args **kwargs siteconfig SiteConfiguration objects get_current request _find_httprequest args if siteconfig get u'auth_require_sitewide_login' or request user is_anonymous and u'HTTP_AUTHORIZATION' in request META return webapi_login_required view_func *args **kwargs else return view_func *args **kwargs _check checks_login_required Truereturn _check
def get_static_index_page with_shutdown template '\n< DOCTYPEHTMLPUBLIC"-//W3C//DTDHTML4 01Frameset//EN""http //www w3 org/TR/html4/frameset dtd">\n<HTML>\n< --NaturalLanguageToolkit WordnetInterface GraphicalWordnetBrowser\nCopyright C 2001-2017NLTKProject\nAuthor JussiSalmela<jtsalmela@users sourceforge net>\nURL <http //nltk org/>\nForlicenseinformation seeLICENSE TXT-->\n<HEAD>\n<TITLE>NLTKWordnetBrowser</TITLE>\n</HEAD>\n\n<framesetrows "7%% 93%%">\n<framesrc "%s"name "header">\n<framesrc "start_page"name "body">\n</frameset>\n</HTML>\n'if with_shutdown upper_link 'upper html'else upper_link 'upper_2 html'return template % upper_link
def should_overwrite settings return settings get 'GZIP_CACHE_OVERWRITE' False
def should_overwrite settings return settings get 'GZIP_CACHE_OVERWRITE' False
@dual_decoratordef enforce_ids_param position 1 @decoratordef wrapper function *args **kw if not isinstance args[position] list tuple or not all [isinstance e basestring for e in args[position]] raise ValueError u'Invalidparamtypeinposition%s expectedids didyoupassdictionaries? ' % position return function *args **kw return wrapper
def list_tags_for_resource name region None key None keyid None profile None **args conn _get_conn region region key key keyid keyid profile profile if 'ResourceName' in args log info "'name {0}'parambeingoverriddenbyexplicitlyprovided'ResourceName {1}'" format name args['ResourceName'] name args['ResourceName']else args['ResourceName'] nameargs dict [ k v for k v in args items if not k startswith '_' ] try r conn list_tags_for_resource **args if r and 'Taglist' in r return r['TagList']return []except botocore exceptions ClientError as e log error 'Failedtolisttagsforresource{0} {1}' format name e return []
def runs_once func @wraps func def decorated *args **kwargs if not hasattr decorated 'return_value' decorated return_value func *args **kwargs return decorated return_valuedecorated _wrap_as_new func decorated return serial decorated
def _append_param_insert_pk_returning compiler stmt c values kw if c default is not None if c default is_sequence if compiler dialect supports_sequences and not c default optional or not compiler dialect sequences_optional proc compiler process c default **kw values append c proc compiler returning append c elif c default is_clause_element values append c compiler process c default arg self_group **kw compiler returning append c else values append c _create_insert_prefetch_bind_param compiler c elif c is stmt table _autoincrement_column or c server_default is not None compiler returning append c elif not c nullable _warn_pk_with_no_anticipated_value c
def _make_sync_method name def sync_wrapper self *args **kwds method getattr self name future method *args **kwds return future get_result return sync_wrapper
def _make_sync_method name def sync_wrapper self *args **kwds method getattr self name future method *args **kwds return future get_result return sync_wrapper
def content fid share_key None url build_url RESOURCE id fid route 'content' params make_params share_key share_key return request 'get' url params params
def get_package_version pypiConn pkg_name pkg_result [v for v in pypiConn package_releases pkg_name True if not PRE_RELEASE_RE search v ]if pkg_result pkg_version pkg_result[0]else pkg_version 'Notavailable 'return pkg_version
def get_all_orgs site_configuration_orgs SiteConfiguration get_all_orgs microsite_orgs microsite get_all_orgs return site_configuration_orgs union microsite_orgs
def get_all_orgs site_configuration_orgs SiteConfiguration get_all_orgs microsite_orgs microsite get_all_orgs return site_configuration_orgs union microsite_orgs
def get_all_orgs site_configuration_orgs SiteConfiguration get_all_orgs microsite_orgs microsite get_all_orgs return site_configuration_orgs union microsite_orgs
@verbosedef compare_fiff fname_1 fname_2 fname_out None show True indent '' read_limit np inf max_str 30 verbose None file_1 show_fiff fname_1 output list indent indent read_limit read_limit max_str max_str file_2 show_fiff fname_2 output list indent indent read_limit read_limit max_str max_str diff difflib HtmlDiff make_file file_1 file_2 fname_1 fname_2 if fname_out is not None f open fname_out 'wb' else f tempfile NamedTemporaryFile 'wb' delete False suffix ' html' fname_out f namewith f as fid fid write diff encode 'utf-8' if show is True webbrowser open_new_tab fname_out return fname_out
@verbosedef compare_fiff fname_1 fname_2 fname_out None show True indent '' read_limit np inf max_str 30 verbose None file_1 show_fiff fname_1 output list indent indent read_limit read_limit max_str max_str file_2 show_fiff fname_2 output list indent indent read_limit read_limit max_str max_str diff difflib HtmlDiff make_file file_1 file_2 fname_1 fname_2 if fname_out is not None f open fname_out 'wb' else f tempfile NamedTemporaryFile 'wb' delete False suffix ' html' fname_out f namewith f as fid fid write diff encode 'utf-8' if show is True webbrowser open_new_tab fname_out return fname_out
@verbosedef compare_fiff fname_1 fname_2 fname_out None show True indent '' read_limit np inf max_str 30 verbose None file_1 show_fiff fname_1 output list indent indent read_limit read_limit max_str max_str file_2 show_fiff fname_2 output list indent indent read_limit read_limit max_str max_str diff difflib HtmlDiff make_file file_1 file_2 fname_1 fname_2 if fname_out is not None f open fname_out 'wb' else f tempfile NamedTemporaryFile 'wb' delete False suffix ' html' fname_out f namewith f as fid fid write diff encode 'utf-8' if show is True webbrowser open_new_tab fname_out return fname_out
def int64_output func argtypes func argtypes argtypesfunc restype c_int64return func
def int64_output func argtypes func argtypes argtypesfunc restype c_int64return func
def test_docs_generated botocore_session botocore session get_session session boto3 Session region_name 'us-east-1' for service_name in session get_available_services generated_docs ServiceDocumenter service_name session session document_service generated_docs generated_docs decode 'utf-8' client boto3 client service_name 'us-east-1' yield _assert_has_title generated_docs client yield _assert_has_client_documentation generated_docs service_name client try paginator_model botocore_session get_paginator_model service_name yield _assert_has_paginator_documentation generated_docs service_name client sorted paginator_model _paginator_config except DataNotFoundError passif client waiter_names waiter_model botocore_session get_waiter_model service_name yield _assert_has_waiter_documentation generated_docs service_name client waiter_model if service_name in session get_available_resources resource boto3 resource service_name 'us-east-1' yield _assert_has_resource_documentation generated_docs service_name resource
def _send_request payload None session None stub sessionhost_port stub hosturl 'https //{0}/sdk' format host_port logging debug 'Sending{0}to{1}' format payload url res requests post url url data payload headers {'Cookie' stub cookie 'SOAPAction' 'urn vim25' 'Content-Type' 'application/xml'} verify False if res status_code 200 logging debug 'Failedtoresetalarm HTTPStatus {0}' format res status_code return Falsereturn True
def _send_request payload None session None stub sessionhost_port stub hosturl 'https //{0}/sdk' format host_port logging debug 'Sending{0}to{1}' format payload url res requests post url url data payload headers {'Cookie' stub cookie 'SOAPAction' 'urn vim25' 'Content-Type' 'application/xml'} verify False if res status_code 200 logging debug 'Failedtoresetalarm HTTPStatus {0}' format res status_code return Falsereturn True
def _send_request payload None session None stub sessionhost_port stub hosturl 'https //{0}/sdk' format host_port logging debug 'Sending{0}to{1}' format payload url res requests post url url data payload headers {'Cookie' stub cookie 'SOAPAction' 'urn vim25' 'Content-Type' 'application/xml'} verify False if res status_code 200 logging debug 'Failedtoresetalarm HTTPStatus {0}' format res status_code return Falsereturn True
def iglob path_glob if _CHECK_RECURSIVE_GLOB search path_glob msg 'invalidglob%r recursiveglob"**"mustbeusedalone'raise ValueError msg % path_glob if _CHECK_MISMATCH_SET search path_glob msg "invalidglob%r mismatchingsetmarker'{'or'}'"raise ValueError msg % path_glob return _iglob path_glob
def count_seqs_in_filepaths fasta_filepaths seq_counter count_seqs total 0counts []inaccessible_filepaths []for fasta_filepath in fasta_filepaths if fasta_filepath endswith ' fastq' or fasta_filepath endswith ' fq' parser partial parse_fastq enforce_qual_range False elif fasta_filepath endswith ' tre' or fasta_filepath endswith ' ph' or fasta_filepath endswith ' ntree' def parser f t DndParser f constructor PhyloNode return zip t iterTips repeat '' else parser parse_fastatry current_count seq_counter fasta_filepath parser parser counts append current_count fasta_filepath total + current_count[0]except IOError inaccessible_filepaths append fasta_filepath return counts total inaccessible_filepaths
def count_seqs_in_filepaths fasta_filepaths seq_counter count_seqs total 0counts []inaccessible_filepaths []for fasta_filepath in fasta_filepaths if fasta_filepath endswith ' fastq' or fasta_filepath endswith ' fq' parser partial parse_fastq enforce_qual_range False elif fasta_filepath endswith ' tre' or fasta_filepath endswith ' ph' or fasta_filepath endswith ' ntree' def parser f t DndParser f constructor PhyloNode return zip t iterTips repeat '' else parser parse_fastatry current_count seq_counter fasta_filepath parser parser counts append current_count fasta_filepath total + current_count[0]except IOError inaccessible_filepaths append fasta_filepath return counts total inaccessible_filepaths
def count_seqs_in_filepaths fasta_filepaths seq_counter count_seqs total 0counts []inaccessible_filepaths []for fasta_filepath in fasta_filepaths if fasta_filepath endswith ' fastq' or fasta_filepath endswith ' fq' parser partial parse_fastq enforce_qual_range False elif fasta_filepath endswith ' tre' or fasta_filepath endswith ' ph' or fasta_filepath endswith ' ntree' def parser f t DndParser f constructor PhyloNode return zip t iterTips repeat '' else parser parse_fastatry current_count seq_counter fasta_filepath parser parser counts append current_count fasta_filepath total + current_count[0]except IOError inaccessible_filepaths append fasta_filepath return counts total inaccessible_filepaths
@contextmanagerdef queries_captured include_savepoints False queries []def wrapper_execute self action sql params start time time try return action sql params finally stop time time duration stop - start if include_savepoints or 'SAVEPOINT' not in sql queries append {'sql' self mogrify sql params decode 'utf-8' 'time' '% 3f' % duration } old_execute TimeTrackingCursor executeold_executemany TimeTrackingCursor executemanydef cursor_execute self sql params return wrapper_execute self super TimeTrackingCursor self execute sql params TimeTrackingCursor execute cursor_executedef cursor_executemany self sql params return wrapper_execute self super TimeTrackingCursor self executemany sql params TimeTrackingCursor executemany cursor_executemany yield queries TimeTrackingCursor execute old_executeTimeTrackingCursor executemany old_executemany
@contextmanagerdef queries_captured include_savepoints False queries []def wrapper_execute self action sql params start time time try return action sql params finally stop time time duration stop - start if include_savepoints or 'SAVEPOINT' not in sql queries append {'sql' self mogrify sql params decode 'utf-8' 'time' '% 3f' % duration } old_execute TimeTrackingCursor executeold_executemany TimeTrackingCursor executemanydef cursor_execute self sql params return wrapper_execute self super TimeTrackingCursor self execute sql params TimeTrackingCursor execute cursor_executedef cursor_executemany self sql params return wrapper_execute self super TimeTrackingCursor self executemany sql params TimeTrackingCursor executemany cursor_executemany yield queries TimeTrackingCursor execute old_executeTimeTrackingCursor executemany old_executemany
def logstash registry xml_parent data logstash XML SubElement xml_parent 'jenkins plugins logstash LogstashNotifier' logstash set 'plugin' 'logstash' mapping [ 'max-lines' 'maxLines' 1000 'fail-build' 'failBuild' False ]helpers convert_mapping_to_xml logstash data mapping fail_required True
def logstash registry xml_parent data logstash XML SubElement xml_parent 'jenkins plugins logstash LogstashNotifier' logstash set 'plugin' 'logstash' mapping [ 'max-lines' 'maxLines' 1000 'fail-build' 'failBuild' False ]helpers convert_mapping_to_xml logstash data mapping fail_required True
def provider_handlers providers return _load_provider_feature 'default_handlers' providers
def provider_handlers providers return _load_provider_feature 'default_handlers' providers
def status stats False config False internals False superblock False alldevs False bdevs []for _ links _ in os walk '/sys/block/' for block in links if 'bcache' in block continuefor spath sdirs _ in os walk '/sys/block/{0}' format block followlinks False if 'bcache' in sdirs bdevs append os path basename spath statii {}for bcache in bdevs statii[bcache] device bcache stats config internals superblock cuuid uuid cdev _bdev if cdev count 0for dev in statii keys if dev cdev if statii[dev]['cache'] cuuid count + 1statii[cdev]['attached_backing_devices'] countif not alldevs statii statii[cdev]return statii
def pre_run_code_hook self return None
def load_formatter_class scoped_class_name if ' ' not in scoped_class_name message 'REQUIRE "module class" butwas "%s"' % scoped_class_name raise ValueError message module_name class_name parse_scoped_name scoped_class_name formatter_module load_module module_name formatter_class getattr formatter_module class_name None if formatter_class is None raise ImportError 'CLASSNOTFOUND %s' % scoped_class_name return formatter_class
def unpack4 v assert len v 4 return struct unpack '<I' v [0]
def test_outputs_taps_check x tensor fvector 'x' y tensor fvector 'y' f lambda x y [x] outputs_info {'initial' y 'taps' [0]}assert_raises ValueError theano scan f x outputs_info outputs_info {'initial' y 'taps' [ -1 -1 ]}assert_raises ValueError theano scan f x outputs_info print 'done'
def encipher_shift msg key symbols None msg _ A _prep msg '' symbols shift len A - key % len A key A[shift ] + A[ shift] return translate msg key A
def encipher_shift msg key symbols None msg _ A _prep msg '' symbols shift len A - key % len A key A[shift ] + A[ shift] return translate msg key A
def whitespace_around_comma logical_line line logical_linefor m in WHITESPACE_AFTER_COMMA_REGEX finditer line found m start + 1 if ' DCTB ' in m group yield found "E242tabafter'%s'" % m group [0] else yield found "E241multiplespacesafter'%s'" % m group [0]
def test_dicts objs tokenize '{foobarbarbaz}' assert objs [HyDict ['foo' 'bar' 'bar' 'baz'] ] objs tokenize ' bar{foobarbarbaz} ' assert objs [HyExpression [HySymbol 'bar' HyDict ['foo' 'bar' 'bar' 'baz'] ] ] objs tokenize '{ foobar bazquux }' assert objs [HyDict [HyExpression [HySymbol 'foo' HySymbol 'bar' ] HyExpression [HySymbol 'baz' HySymbol 'quux' ] ] ]
def object_name_to_class_name object_name if object_name in TRACE_NAMES return string_to_class_name object_name if object_name in OBJECT_NAME_TO_CLASS_NAME return OBJECT_NAME_TO_CLASS_NAME[object_name]if object_name in ARRAYS return 'list'else return 'dict'
def object_name_to_class_name object_name if object_name in TRACE_NAMES return string_to_class_name object_name if object_name in OBJECT_NAME_TO_CLASS_NAME return OBJECT_NAME_TO_CLASS_NAME[object_name]if object_name in ARRAYS return 'list'else return 'dict'
def test_stop ea def mock_loop for i in range 3 assert ea running yield ea stop with mock patch object ea 'sleep_for' return_value None with mock patch object ea 'run_all_rules' as mock_run mock_run side_effect mock_loop start_thread threading Thread target ea start start_thread daemon Truestart_thread start start_thread join 5 assert not ea running assert not start_thread is_alive assert mock_run call_count 4
def test_stop ea def mock_loop for i in range 3 assert ea running yield ea stop with mock patch object ea 'sleep_for' return_value None with mock patch object ea 'run_all_rules' as mock_run mock_run side_effect mock_loop start_thread threading Thread target ea start start_thread daemon Truestart_thread start start_thread join 5 assert not ea running assert not start_thread is_alive assert mock_run call_count 4
def addslash method @functools wraps method def wrapper self *args **kwargs if not self request path endswith '/' if self request method in 'GET' 'HEAD' uri self request path + '/' if self request query uri + '?' + self request query self redirect uri permanent True returnraise HTTPError 404 return method self *args **kwargs return wrapper
def get_database_string fname f open fname dtb f read f close return dtb
def make_remote_view data settings more_excluded_names None data get_remote_data data settings mode 'editable' more_excluded_names more_excluded_names remote {}for key value in list data items view value_to_display value minmax settings['minmax'] remote[key] {'type' get_human_readable_type value 'size' get_size value 'color' get_color_name value 'view' view}return remote
def find_toplevel_job_dir start_dir job_dir start_dirwhile not os path exists os path join job_dir ' autoserv_execute' if job_dir '/' return Nonejob_dir os path dirname job_dir return job_dir
def parse handle debug 0 if not hasattr handle 'read' if isinstance handle str handle StringIO handle else exc_txt 'AnXML-containinghandleoranXMLstring' + 'mustbeprovided' raise Exception exc_txt for event elem in ElementTree iterparse handle events 'start' 'end' if event 'end' and elem tag 'pathway' yield KGMLParser elem parse elem clear
def _ensure_loaded start_path for root folder files in os walk start_path for phile in fnmatch filter files '* py' path os path join root phile try __import__ path replace '/' ' ' [ -3 ] globals locals except Exception pass
def _get_ttl return __opts__ get 'couchbase ttl' 24 * 60 * 60
def generate parts data six StringIO for fpart in parts with open os path join OPENSHIFT_ANSIBLE_PATH fpart as pfd for idx line in enumerate pfd if idx in [0 1] and 'flake8 noqa' in line or 'pylint skip-file' in line continuedata write line return data
@register tagdef querystring parser token bits token split_contents tag bits pop 0 updates token_kwargs bits parser if bits and bits pop 0 u'without' raise TemplateSyntaxError u"Malformedargumentsto'%s'" % tag removals [parser compile_filter bit for bit in bits]return QuerystringNode updates removals
def _rearrange_args l if len l 1 return lx list l[ -1 ] x extend l[0 -1 ] return Mul *x args
def _rearrange_args l if len l 1 return lx list l[ -1 ] x extend l[0 -1 ] return Mul *x args
@mock_ec2def test_get_all_spot_instance_requests_filtering conn boto connect_ec2 request1 conn request_spot_instances price 0 5 image_id u'ami-abcd1234' request2 conn request_spot_instances price 0 5 image_id u'ami-abcd1234' conn request_spot_instances price 0 5 image_id u'ami-abcd1234' request1[0] add_tag u'tag1' u'value1' request1[0] add_tag u'tag2' u'value2' request2[0] add_tag u'tag1' u'value1' request2[0] add_tag u'tag2' u'wrong' requests conn get_all_spot_instance_requests filters {u'state' u'active'} requests should have length_of 0 requests conn get_all_spot_instance_requests filters {u'state' u'open'} requests should have length_of 3 requests conn get_all_spot_instance_requests filters {u'tag tag1' u'value1'} requests should have length_of 2 requests conn get_all_spot_instance_requests filters {u'tag tag1' u'value1' u'tag tag2' u'value2'} requests should have length_of 1
def linkify docs return [ DOC_SITE_ROOT + x for x in docs]
def handler_from_provider provider_name from inbox auth import module_registryauth_mod module_registry get provider_name if auth_mod is None info providers get provider_name None if info provider_type info get 'type' None if provider_type auth_mod module_registry get 'generic' if auth_mod is None raise NotSupportedError 'Nylasdoesnotsupporttheemailprovider ' auth_handler_class getattr auth_mod auth_mod AUTH_HANDLER_CLS auth_handler auth_handler_class provider_name provider_name return auth_handler
def group_types_get_by_name_or_id context group_type_list return IMPL group_types_get_by_name_or_id context group_type_list
def get_html_section name datetime time strftime '%a%b%d%y %H %M %S' return "<h1>{}<spanclass 'timestamp'>{}</h1>" format name datetime
def gauss_laguerre n n_digits x Dummy 'x' p laguerre_poly n x polys True p1 laguerre_poly n + 1 x polys True xi []w []for r in p real_roots if isinstance r RootOf r r eval_rational S 1 / 10 ** n_digits + 2 xi append r n n_digits w append r / n + 1 ** 2 * p1 subs x r ** 2 n n_digits return xi w
def about_dialog view AboutView qtutils active_window view show return view
def arrswapmid data assert len data % 2 0 ret [''] * len data ret[1 2] data[0 2]ret[0 2] data[1 2]return ret
def upgrade migrate_engine meta MetaData meta bind migrate_engineimage_cache Table 'image_volume_cache_entries' meta autoload True cluster_name Column 'cluster_name' String 255 nullable True image_cache create_column cluster_name
def upgrade migrate_engine meta MetaData meta bind migrate_engineimage_cache Table 'image_volume_cache_entries' meta autoload True cluster_name Column 'cluster_name' String 255 nullable True image_cache create_column cluster_name
@permission_required 'users add_userban' def ban_user_and_cleanup request username user get_object_or_404 User username username user_ban UserBan objects filter user user is_active True date_three_days_ago datetime now date - timedelta days 3 revisions user created_revisions prefetch_related 'document' revisions revisions defer 'content' 'summary' order_by '-id' revisions revisions filter created__gte date_three_days_ago revisions_not_spam revisions filter akismet_submissions None return render request 'users/ban_user_and_cleanup html' {'detail_user' user 'user_banned' user_ban 'revisions' revisions 'revisions_not_spam' revisions_not_spam 'on_ban_page' True}
@permission_required 'users add_userban' def ban_user_and_cleanup request username user get_object_or_404 User username username user_ban UserBan objects filter user user is_active True date_three_days_ago datetime now date - timedelta days 3 revisions user created_revisions prefetch_related 'document' revisions revisions defer 'content' 'summary' order_by '-id' revisions revisions filter created__gte date_three_days_ago revisions_not_spam revisions filter akismet_submissions None return render request 'users/ban_user_and_cleanup html' {'detail_user' user 'user_banned' user_ban 'revisions' revisions 'revisions_not_spam' revisions_not_spam 'on_ban_page' True}
def recompose_xfm in_bval in_xfms import numpy as npimport os path as opbvals np loadtxt in_bval out_matrix np array [np eye 4 ] * len bvals xfms iter [np loadtxt xfm for xfm in in_xfms] out_files []for i b in enumerate bvals if b 0 0 mat np eye 4 else mat next xfms out_name op abspath u'eccor_%04d mat' % i out_files append out_name np savetxt out_name mat return out_files
def runModuleTestSuite module suite TestSuite [TestLoader loadTestsFromModule module ] optionflags ELLIPSIS NORMALIZE_WHITESPACE REPORT_ONLY_FIRST_FAILURE IGNORE_EXCEPTION_DETAIL try suite addTest DocTestSuite module optionflags optionflags except ValueError passTextTestRunner run suite
def _autogen_docstring base msg u''addendum docstring Appender msg u'\n\n' return lambda func addendum docstring copy_dedent base func
def _autogen_docstring base msg u''addendum docstring Appender msg u'\n\n' return lambda func addendum docstring copy_dedent base func
def _find_common_roots paths paths [x split os path sep for x in paths]root {}for chunks in sorted paths key len reverse True node rootfor chunk in chunks node node setdefault chunk {} node clear rv set def _walk node path for prefix child in iteritems node _walk child path + prefix if not node rv add '/' join path _walk root return rv
def _find_common_roots paths paths [x split os path sep for x in paths]root {}for chunks in sorted paths key len reverse True node rootfor chunk in chunks node node setdefault chunk {} node clear rv set def _walk node path for prefix child in iteritems node _walk child path + prefix if not node rv add '/' join path _walk root return rv
def map_dict_keys dict_ key_map mapped {}for key value in dict_ iteritems mapped_key key_map[key] if key in key_map else key mapped[mapped_key] valuereturn mapped
def _check_valid_version npm_version distutils version LooseVersion salt modules cmdmod run 'npm--version' output_loglevel 'quiet' valid_version distutils version LooseVersion '1 2' if npm_version < valid_version raise CommandExecutionError "'npm'isnotrecentenough {0}<{1} PleaseUpgrade " format npm_version valid_version
def tmpdir global _tmpdirif not _tmpdir def cleanup shutil rmtree _tmpdir import atexitatexit register cleanup _tmpdir os path join tempfile gettempdir 'anki_temp' if not os path exists _tmpdir os mkdir _tmpdir return _tmpdir
def _createPublicKey key if not isinstance key RSAKey raise AssertionError return _createPublicRSAKey key n key e
def signin_redirect redirect None user None if redirect return redirectelif user is not None return userena_settings USERENA_SIGNIN_REDIRECT_URL % {'username' user username} else return settings LOGIN_REDIRECT_URL
def getIdleActivation **kwargs _gsession _GSettings user kwargs get 'user' schema 'org gnome desktop screensaver' key 'idle-activation-enabled' return _gsession _get
def generate_names adjectives ['Exquisite' 'Delicious' 'Elegant' 'Swanky' 'Spicy' 'FoodTruck' 'Artisanal' 'Tasty']nouns ['Sandwich' 'Pizza' 'Curry' 'Pierogi' 'Sushi' 'Salad' 'Stew' 'Pasta' 'Barbeque' 'Bacon' 'Pancake' 'Waffle' 'Chocolate' 'Gyro' 'Cookie' 'Burrito' 'Pie']return ['' join parts for parts in product adjectives nouns ]
def dark_palette color n_colors 6 reverse False as_cmap False input 'rgb' color _color_to_rgb color input gray '#222222'colors [color gray] if reverse else [gray color] return blend_palette colors n_colors as_cmap
def reset_vo_warnings from import converters xmlutilfor module in converters exceptions tree xmlutil if hasattr module u'__warningregistry__' del module __warningregistry__
@not_implemented_for 'undirected' 'multigraph' def reciprocity G nodes None if nodes is None return overall_reciprocity G if nodes in G reciprocity next _reciprocity_iter G nodes [1]if reciprocity is None raise NetworkXError 'Notdefinedforisolatednodes ' else return reciprocityreturn dict _reciprocity_iter G nodes
def libvlc_media_player_set_time p_mi i_time f _Cfunctions get 'libvlc_media_player_set_time' None or _Cfunction 'libvlc_media_player_set_time' 1 1 None None MediaPlayer ctypes c_longlong return f p_mi i_time
def import_status handler host None core_name None verbose False if not _is_master and _get_none_or_value host is None errors ['solr import_statuscanonlybecalledby"master"minions']return _get_return_dict False errors errors extra ['command status']if verbose extra append 'verbose true' url _format_url handler host host core_name core_name extra extra return _http_request url
def import_status handler host None core_name None verbose False if not _is_master and _get_none_or_value host is None errors ['solr import_statuscanonlybecalledby"master"minions']return _get_return_dict False errors errors extra ['command status']if verbose extra append 'verbose true' url _format_url handler host host core_name core_name extra extra return _http_request url
def compare_psnr im_true im_test data_range None dynamic_range None _assert_compatible im_true im_test if dynamic_range is not None warn '`dynamic_range`hasbeendeprecatedinfavorof`data_range` The`dynamic_range`keywordargumentwillberemovedinv0 14' skimage_deprecation data_range dynamic_rangeif data_range is None dmin dmax dtype_range[im_true dtype type] true_min true_max np min im_true np max im_true if true_max > dmax or true_min < dmin raise ValueError 'im_truehasintensityvaluesoutsidetherangeexpectedforitsdatatype Pleasemanuallyspecifythedata_range' if true_min > 0 data_range dmaxelse data_range dmax - dmin im_true im_test _as_floats im_true im_test err compare_mse im_true im_test return 10 * np log10 data_range ** 2 / err
def unregister_alias_type klass return ALIAS_TYPES pop klass None
def setTitle template title chapterNumber if numberer getNumberSections and chapterNumber titleNode dom Text titleNode ownerDocument template ownerDocumenttitleNode data '%s ' % chapterNumber title insert 0 titleNode for nodeList in domhelpers findNodesNamed template 'title' domhelpers findElementsWithAttribute template 'class' 'title' if nodeList for titleNode in title nodeList[0] appendChild titleNode cloneNode True
def find_blade_root_dir working_dir blade_root_dir working_dirif blade_root_dir endswith '/' blade_root_dir blade_root_dir[ -1 ]while blade_root_dir and blade_root_dir '/' if os path isfile os path join blade_root_dir 'BLADE_ROOT' breakblade_root_dir os path dirname blade_root_dir if not blade_root_dir or blade_root_dir '/' console error_exit "Can'tfindthefile'BLADE_ROOT'inthisoranyupperdirectory \nBladeneedthisfileasaplaceholdertolocatetherootsourcedirectory akathedirectorywhereyou#includestartfrom \nYoushouldcreateitmanuallyatthefirsttime " return blade_root_dir
def get_info certificate_id returncertificate False returntype None opts salt utils namecheap get_opts 'namecheap ssl getinfo' opts['certificateID'] certificate_idif returncertificate opts['returncertificate'] 'true'if returntype is None salt utils namecheap log error 'returntypemustbespecifiedwhenreturncertificateissettoTrue' raise Exception 'returntypemustbespecifiedwhenreturncertificateissettoTrue' if returntype not in ['Individual' 'PKCS7'] salt utils namecheap log error 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype raise Exception 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype opts['returntype'] returntyperesponse_xml salt utils namecheap get_request opts if response_xml is None return {}sslinforesult response_xml getElementsByTagName 'SSLGetInfoResult' [0]return salt utils namecheap xml_to_dict sslinforesult
def get_info certificate_id returncertificate False returntype None opts salt utils namecheap get_opts 'namecheap ssl getinfo' opts['certificateID'] certificate_idif returncertificate opts['returncertificate'] 'true'if returntype is None salt utils namecheap log error 'returntypemustbespecifiedwhenreturncertificateissettoTrue' raise Exception 'returntypemustbespecifiedwhenreturncertificateissettoTrue' if returntype not in ['Individual' 'PKCS7'] salt utils namecheap log error 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype raise Exception 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype opts['returntype'] returntyperesponse_xml salt utils namecheap get_request opts if response_xml is None return {}sslinforesult response_xml getElementsByTagName 'SSLGetInfoResult' [0]return salt utils namecheap xml_to_dict sslinforesult
def get_info certificate_id returncertificate False returntype None opts salt utils namecheap get_opts 'namecheap ssl getinfo' opts['certificateID'] certificate_idif returncertificate opts['returncertificate'] 'true'if returntype is None salt utils namecheap log error 'returntypemustbespecifiedwhenreturncertificateissettoTrue' raise Exception 'returntypemustbespecifiedwhenreturncertificateissettoTrue' if returntype not in ['Individual' 'PKCS7'] salt utils namecheap log error 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype raise Exception 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype opts['returntype'] returntyperesponse_xml salt utils namecheap get_request opts if response_xml is None return {}sslinforesult response_xml getElementsByTagName 'SSLGetInfoResult' [0]return salt utils namecheap xml_to_dict sslinforesult
def get_info certificate_id returncertificate False returntype None opts salt utils namecheap get_opts 'namecheap ssl getinfo' opts['certificateID'] certificate_idif returncertificate opts['returncertificate'] 'true'if returntype is None salt utils namecheap log error 'returntypemustbespecifiedwhenreturncertificateissettoTrue' raise Exception 'returntypemustbespecifiedwhenreturncertificateissettoTrue' if returntype not in ['Individual' 'PKCS7'] salt utils namecheap log error 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype raise Exception 'returntypemustbespecifiedasIndividualorPKCS7 not' + returntype opts['returntype'] returntyperesponse_xml salt utils namecheap get_request opts if response_xml is None return {}sslinforesult response_xml getElementsByTagName 'SSLGetInfoResult' [0]return salt utils namecheap xml_to_dict sslinforesult
def detect_language text translate_client translate Client result translate_client detect_language text print 'Text {}' format text print 'Confidence {}' format result['confidence'] print 'Language {}' format result['language']
def errfunc *args raise ValueError
def after_table_create event target bind tables None **kw if tables with flexget manager manager acquire_lock event False tables [table name for table in tables]for plugin info in plugin_schemas items if all table in tables for table in info[u'tables'] set_version plugin info[u'version']
def after_table_create event target bind tables None **kw if tables with flexget manager manager acquire_lock event False tables [table name for table in tables]for plugin info in plugin_schemas items if all table in tables for table in info[u'tables'] set_version plugin info[u'version']
def convert_to_camel data components data split '_' return components[0] + '' join x title for x in components[1 ]
def convert_to_camel data components data split '_' return components[0] + '' join x title for x in components[1 ]
def genslices_ndim ndim shape iterables [genslices shape[n] for n in range ndim ]return product *iterables
def isLoopIntersectingLoop anotherLoop loop for pointIndex in xrange len loop pointFirst loop[pointIndex]pointSecond loop[ pointIndex + 1 % len loop ]segment pointFirst - pointSecond normalizedSegment euclidean getNormalized segment segmentYMirror complex normalizedSegment real - normalizedSegment imag segmentFirstPoint segmentYMirror * pointFirst segmentSecondPoint segmentYMirror * pointSecond if euclidean isLoopIntersectingInsideXSegment anotherLoop segmentFirstPoint real segmentSecondPoint real segmentYMirror segmentFirstPoint imag return Truereturn False
def isLoopIntersectingLoop anotherLoop loop for pointIndex in xrange len loop pointFirst loop[pointIndex]pointSecond loop[ pointIndex + 1 % len loop ]segment pointFirst - pointSecond normalizedSegment euclidean getNormalized segment segmentYMirror complex normalizedSegment real - normalizedSegment imag segmentFirstPoint segmentYMirror * pointFirst segmentSecondPoint segmentYMirror * pointSecond if euclidean isLoopIntersectingInsideXSegment anotherLoop segmentFirstPoint real segmentSecondPoint real segmentYMirror segmentFirstPoint imag return Truereturn False
def test_cannot_start_with_multiline lines strings get_stripped_lines INVALID_MULTI_LINE try step Step many_from_lines lines except LettuceSyntaxError returnassert False 'LettuceSyntaxErrornotraised'
def get schema None key None user None **kwargs _gsession _GSettings user user schema schema key key return _gsession _get
def ip_to_cidr ip prefix None net netaddr IPNetwork ip if prefix is not None net netaddr IPNetwork str net ip + '/' + str prefix return str net
def uri_to_path uri return unquote_to_bytes urlsplit uri path
def _compute_subcorr G phi_sig Ug Sg Vg linalg svd G full_matrices False tmp np dot Ug T conjugate phi_sig Uc Sc Vc linalg svd tmp full_matrices False X np dot np dot Vg T np diag 1 0 / Sg Uc return Sc[0] X[ 0] / linalg norm X[ 0]
@cache_permissiondef can_automatic_translation user project return check_permission user project 'trans automatic_translation'
def accept_key pki_dir pub id_ for key_dir in 'minions' 'minions_pre' 'minions_rejected' key_path os path join pki_dir key_dir if not os path exists key_path os makedirs key_path key os path join pki_dir 'minions' id_ with salt utils fopen key 'w+' as fp_ fp_ write pub oldkey os path join pki_dir 'minions_pre' id_ if os path isfile oldkey with salt utils fopen oldkey as fp_ if fp_ read pub os remove oldkey
def write_request_load_scenario reactor cluster request_rate 10 sample_size DEFAULT_SAMPLE_SIZE timeout 45 tolerance_percentage 0 2 return RequestLoadScenario reactor WriteRequest reactor cluster get_control_service reactor request_rate request_rate sample_size sample_size timeout timeout tolerance_percentage tolerance_percentage
def write_request_load_scenario reactor cluster request_rate 10 sample_size DEFAULT_SAMPLE_SIZE timeout 45 tolerance_percentage 0 2 return RequestLoadScenario reactor WriteRequest reactor cluster get_control_service reactor request_rate request_rate sample_size sample_size timeout timeout tolerance_percentage tolerance_percentage
def write_request_load_scenario reactor cluster request_rate 10 sample_size DEFAULT_SAMPLE_SIZE timeout 45 tolerance_percentage 0 2 return RequestLoadScenario reactor WriteRequest reactor cluster get_control_service reactor request_rate request_rate sample_size sample_size timeout timeout tolerance_percentage tolerance_percentage
def cfunc sig locals {} cache False **options sig sigutils normalize_signature sig def wrapper func from ccallback import CFuncres CFunc func sig locals locals options options if cache res enable_caching res compile return resreturn wrapper
def wrap fn if fn is None or fn __class__ is _StackContextWrapper return fndef wrapped *args **kwargs callback contexts args args[0] args[1] args[2 ] if _state contexts new_contexts [NullContext ]else new_contexts []if contexts new_contexts extend cls arg active_cell for cls arg active_cell in contexts if active_cell[0] if len new_contexts > 1 with _nested *new_contexts callback *args **kwargs elif new_contexts with new_contexts[0] callback *args **kwargs else callback *args **kwargs return _StackContextWrapper wrapped fn _state contexts
def wrap fn if fn is None or fn __class__ is _StackContextWrapper return fndef wrapped *args **kwargs callback contexts args args[0] args[1] args[2 ] if _state contexts new_contexts [NullContext ]else new_contexts []if contexts new_contexts extend cls arg active_cell for cls arg active_cell in contexts if active_cell[0] if len new_contexts > 1 with _nested *new_contexts callback *args **kwargs elif new_contexts with new_contexts[0] callback *args **kwargs else callback *args **kwargs return _StackContextWrapper wrapped fn _state contexts
def test_external_js_and_css_resource_embedding class CustomModel1 Model __javascript__ 'external_js_1'__css__ 'external_css_1'class CustomModel2 Model __javascript__ ['external_js_2' 'external_js_3']__css__ ['external_css_2' 'external_css_3']class CustomModel3 Model __javascript__ ['external_js_1' 'external_js_3']__css__ ['external_css_1' 'external_css_2']r resources Resources assert 'external_js_1' in r js_files assert 'external_css_1' in r css_files assert 'external_js_2' in r js_files assert 'external_js_3' in r js_files assert 'external_css_2' in r css_files assert 'external_css_3' in r css_files assert r css_files count 'external_css_1' 1 assert r css_files count 'external_css_2' 1 assert r js_files count 'external_js_3' 1 assert r js_files count 'external_js_1' 1
def test_external_js_and_css_resource_embedding class CustomModel1 Model __javascript__ 'external_js_1'__css__ 'external_css_1'class CustomModel2 Model __javascript__ ['external_js_2' 'external_js_3']__css__ ['external_css_2' 'external_css_3']class CustomModel3 Model __javascript__ ['external_js_1' 'external_js_3']__css__ ['external_css_1' 'external_css_2']r resources Resources assert 'external_js_1' in r js_files assert 'external_css_1' in r css_files assert 'external_js_2' in r js_files assert 'external_js_3' in r js_files assert 'external_css_2' in r css_files assert 'external_css_3' in r css_files assert r css_files count 'external_css_1' 1 assert r css_files count 'external_css_2' 1 assert r js_files count 'external_js_3' 1 assert r js_files count 'external_js_1' 1
def test_external_js_and_css_resource_embedding class CustomModel1 Model __javascript__ 'external_js_1'__css__ 'external_css_1'class CustomModel2 Model __javascript__ ['external_js_2' 'external_js_3']__css__ ['external_css_2' 'external_css_3']class CustomModel3 Model __javascript__ ['external_js_1' 'external_js_3']__css__ ['external_css_1' 'external_css_2']r resources Resources assert 'external_js_1' in r js_files assert 'external_css_1' in r css_files assert 'external_js_2' in r js_files assert 'external_js_3' in r js_files assert 'external_css_2' in r css_files assert 'external_css_3' in r css_files assert r css_files count 'external_css_1' 1 assert r css_files count 'external_css_2' 1 assert r js_files count 'external_js_3' 1 assert r js_files count 'external_js_1' 1
def test_external_js_and_css_resource_embedding class CustomModel1 Model __javascript__ 'external_js_1'__css__ 'external_css_1'class CustomModel2 Model __javascript__ ['external_js_2' 'external_js_3']__css__ ['external_css_2' 'external_css_3']class CustomModel3 Model __javascript__ ['external_js_1' 'external_js_3']__css__ ['external_css_1' 'external_css_2']r resources Resources assert 'external_js_1' in r js_files assert 'external_css_1' in r css_files assert 'external_js_2' in r js_files assert 'external_js_3' in r js_files assert 'external_css_2' in r css_files assert 'external_css_3' in r css_files assert r css_files count 'external_css_1' 1 assert r css_files count 'external_css_2' 1 assert r js_files count 'external_js_3' 1 assert r js_files count 'external_js_1' 1
def _score estimator X_test y_test scorer if y_test is None score scorer estimator X_test else score scorer estimator X_test y_test if hasattr score 'item' try score score item except ValueError passif not isinstance score numbers Number raise ValueError 'scoringmustreturnanumber got%s %s instead ' % str score type score return score
def add_spelling ix fieldnames commit True from whoosh filedb filereading import SegmentReaderwriter ix writer storage writer storageschema writer schemasegments writer segmentsfor segment in segments filename segment dawg_filenamer SegmentReader storage schema segment f storage create_file filename dawg DawgBuilder field_root True for fieldname in fieldnames ft fieldname for word in r lexicon fieldname dawg insert ft + tuple word dawg write f for fieldname in fieldnames schema[fieldname] spelling Trueif commit writer commit merge False
def add_spelling ix fieldnames commit True from whoosh filedb filereading import SegmentReaderwriter ix writer storage writer storageschema writer schemasegments writer segmentsfor segment in segments filename segment dawg_filenamer SegmentReader storage schema segment f storage create_file filename dawg DawgBuilder field_root True for fieldname in fieldnames ft fieldname for word in r lexicon fieldname dawg insert ft + tuple word dawg write f for fieldname in fieldnames schema[fieldname] spelling Trueif commit writer commit merge False
def PmfProbEqual pmf1 pmf2 total 0 0for v1 p1 in pmf1 Items for v2 p2 in pmf2 Items if v1 v2 total + p1 * p2 return total
def _requires_npn func @wraps func def wrapper *args **kwargs if not _lib Cryptography_HAS_NEXTPROTONEG raise NotImplementedError 'NPNnotavailable ' return func *args **kwargs return wrapper
def get_domain_workgroup pythoncom CoInitialize conn wmi WMI for computer in conn Win32_ComputerSystem if computer PartOfDomain return {'Domain' computer Domain}else return {'Workgroup' computer Domain}
def test_deprecated_class_with_super @deprecated u'100 0' class TB object def __init__ self a b super TB self __init__ with catch_warnings AstropyDeprecationWarning as w TB 1 2 assert len w 1 if TB __doc__ is not None assert u'function' not in TB __doc__ assert u'deprecated' in TB __doc__ assert u'function' not in TB __init__ __doc__ assert u'deprecated' in TB __init__ __doc__
def test_deprecated_class_with_super @deprecated u'100 0' class TB object def __init__ self a b super TB self __init__ with catch_warnings AstropyDeprecationWarning as w TB 1 2 assert len w 1 if TB __doc__ is not None assert u'function' not in TB __doc__ assert u'deprecated' in TB __doc__ assert u'function' not in TB __init__ __doc__ assert u'deprecated' in TB __init__ __doc__
def test_deprecated_class_with_super @deprecated u'100 0' class TB object def __init__ self a b super TB self __init__ with catch_warnings AstropyDeprecationWarning as w TB 1 2 assert len w 1 if TB __doc__ is not None assert u'function' not in TB __doc__ assert u'deprecated' in TB __doc__ assert u'function' not in TB __init__ __doc__ assert u'deprecated' in TB __init__ __doc__
def test_deprecated_class_with_super @deprecated u'100 0' class TB object def __init__ self a b super TB self __init__ with catch_warnings AstropyDeprecationWarning as w TB 1 2 assert len w 1 if TB __doc__ is not None assert u'function' not in TB __doc__ assert u'deprecated' in TB __doc__ assert u'function' not in TB __init__ __doc__ assert u'deprecated' in TB __init__ __doc__
def test_sample_ae with open 'gsn_ae_example pkl' as f gsn pickle load f mb_data MNIST which_set 'test' X[105 106 ]history gsn get_samples [ 0 mb_data ] walkback 1000 symbolic False include_first True history list itertools chain *history history np vstack history tiled image tile_raster_images history img_shape [28 28] tile_shape [50 50] tile_spacing 2 2 image save 'gsn_ae_example png' tiled pw ParzenWindows MNIST which_set 'test' X 0 2 print pw get_ll history
def once func lock threading Lock def new_func *args **kwargs if new_func called returnwith lock if new_func called returnrv func *args **kwargs new_func called Truereturn rvnew_func update_wrapper new_func func new_func called Falsereturn new_func
def once func lock threading Lock def new_func *args **kwargs if new_func called returnwith lock if new_func called returnrv func *args **kwargs new_func called Truereturn rvnew_func update_wrapper new_func func new_func called Falsereturn new_func
def cache_file path saltenv 'base' contextkey '{0}_ -{1}_ -{2}' format 'cp cache_file' path saltenv path_is_remote _urlparse path scheme in 'http' 'https' 'ftp' try if path_is_remote and contextkey in __context__ if os path isfile __context__[contextkey] return __context__[contextkey]else __context__ pop contextkey except AttributeError pass path senv salt utils url split_env path if senv saltenv senvresult _client cache_file path saltenv if not result log error "Unabletocachefile'{0}'fromsaltenv'{1}' " format path saltenv if path_is_remote __context__[contextkey] resultreturn result
def cache_file path saltenv 'base' contextkey '{0}_ -{1}_ -{2}' format 'cp cache_file' path saltenv path_is_remote _urlparse path scheme in 'http' 'https' 'ftp' try if path_is_remote and contextkey in __context__ if os path isfile __context__[contextkey] return __context__[contextkey]else __context__ pop contextkey except AttributeError pass path senv salt utils url split_env path if senv saltenv senvresult _client cache_file path saltenv if not result log error "Unabletocachefile'{0}'fromsaltenv'{1}' " format path saltenv if path_is_remote __context__[contextkey] resultreturn result
def fake_bdm_object context bdm_dict return objects BlockDeviceMapping _from_db_object context objects BlockDeviceMapping FakeDbBlockDeviceDict bdm_dict copy
def get_project_build account_project url make_url '/projects/{account_project}' account_project account_project response requests get url headers make_auth_headers return response json
def hessian image scale_range 1 10 scale_step 2 beta1 0 5 beta2 15 filtered lambdas _frangi_hessian_common_filter image scale_range scale_step beta1 beta2 filtered[ lambdas < 0 ] 0out np max filtered axis 0 out[ out < 0 ] 1return out
def _eps_cast dtyp dt dtypif dt np longdouble dt np float64elif dt np clongdouble dt np complex128return np finfo dt eps
def permission_check check def decorator cls cls check_permission staticmethod check return clsreturn decorator
def permission_check check def decorator cls cls check_permission staticmethod check return clsreturn decorator
def CreateInstance clsid reqIID try addnPaths win32api RegQueryValue win32con HKEY_CLASSES_ROOT regAddnPath % clsid split ' ' for newPath in addnPaths if newPath not in sys path sys path insert 0 newPath except win32api error passtry policy win32api RegQueryValue win32con HKEY_CLASSES_ROOT regPolicy % clsid policy resolve_func policy except win32api error policy DefaultPolicytry dispatcher win32api RegQueryValue win32con HKEY_CLASSES_ROOT regDispatcher % clsid if dispatcher dispatcher resolve_func dispatcher except win32api error dispatcher Noneif dispatcher retObj dispatcher policy None else retObj policy None return retObj _CreateInstance_ clsid reqIID
def CreateInstance clsid reqIID try addnPaths win32api RegQueryValue win32con HKEY_CLASSES_ROOT regAddnPath % clsid split ' ' for newPath in addnPaths if newPath not in sys path sys path insert 0 newPath except win32api error passtry policy win32api RegQueryValue win32con HKEY_CLASSES_ROOT regPolicy % clsid policy resolve_func policy except win32api error policy DefaultPolicytry dispatcher win32api RegQueryValue win32con HKEY_CLASSES_ROOT regDispatcher % clsid if dispatcher dispatcher resolve_func dispatcher except win32api error dispatcher Noneif dispatcher retObj dispatcher policy None else retObj policy None return retObj _CreateInstance_ clsid reqIID
def CreateInstance clsid reqIID try addnPaths win32api RegQueryValue win32con HKEY_CLASSES_ROOT regAddnPath % clsid split ' ' for newPath in addnPaths if newPath not in sys path sys path insert 0 newPath except win32api error passtry policy win32api RegQueryValue win32con HKEY_CLASSES_ROOT regPolicy % clsid policy resolve_func policy except win32api error policy DefaultPolicytry dispatcher win32api RegQueryValue win32con HKEY_CLASSES_ROOT regDispatcher % clsid if dispatcher dispatcher resolve_func dispatcher except win32api error dispatcher Noneif dispatcher retObj dispatcher policy None else retObj policy None return retObj _CreateInstance_ clsid reqIID
def romanize string lang 'en' romanizer romanizers get lang 'en' return romanizer romanize string
def p_init_declarator_2 t pass
def p_init_declarator_2 t pass
def comment request template u'generic/comments html' extra_context None response initial_validation request u'comment' if isinstance response HttpResponse return response obj post_data responseform_class import_dotted_path settings COMMENT_FORM_CLASS form form_class request obj post_data if form is_valid url obj get_absolute_url if is_spam request form url return redirect url comment form save request response redirect add_cache_bypass comment get_absolute_url for field in ThreadedCommentForm cookie_fields cookie_name ThreadedCommentForm cookie_prefix + field cookie_value post_data get field u'' set_cookie response cookie_name cookie_value return responseelif request is_ajax and form errors return HttpResponse dumps {u'errors' form errors} context {u'obj' obj u'posted_comment_form' form}context update extra_context or {} return TemplateResponse request template context
def fetch_url url try r requests get url verify False except requests RequestException as exc log debug u'lyricsrequestfailed {0}' format exc returnif r status_code requests codes ok return r textelse log debug u'failedtofetch {0} {1} ' format url r status_code
def memoize function memoized {}@wraps function def wrapper *args try ret memoized[args]except KeyError ret memoized[args] function *args return retreturn wrapper
def test_MultipleLocator_set_params mult mticker MultipleLocator base 0 7 mult set_params base 1 7 assert mult _base 1 7
def get_slave_status **connection_args mod sys _getframe f_code co_namelog debug '{0}<--' format mod conn _connect **connection_args if conn is None return []rtnv __do_query_into_hash conn 'SHOWSLAVESTATUS' conn close if len rtnv 0 rtnv append [] log debug '{0}-->{1}' format mod len rtnv[0] return rtnv[0]
def gaussian_nll x mean ln_var assert isinstance x variable Variable assert isinstance mean variable Variable assert isinstance ln_var variable Variable D x sizex_prec exponential exp - ln_var x_diff x - mean x_power x_diff * x_diff * x_prec * -0 5 return sum sum ln_var + D * math log 2 * math pi / 2 - sum sum x_power
@contextmanagerdef context grpc_context try yield except KeyError as key_error grpc_context code status Code NOT_FOUND grpc_context details 'Unabletofindtheitemkeyedby{}' format key_error
def oo_ami_selector data image_name if not isinstance data list raise errors AnsibleFilterError ' failedexpectsfirstparamisalist' if not data return Noneelif image_name is None or not image_name endswith '_*' ami sorted data key itemgetter 'name' reverse True [0]return ami['ami_id']else ami_info [ ami ami['name'] split '_' [ -1 ] for ami in data]ami sorted ami_info key itemgetter 1 reverse True [0][0]return ami['ami_id']
def oo_ami_selector data image_name if not isinstance data list raise errors AnsibleFilterError ' failedexpectsfirstparamisalist' if not data return Noneelif image_name is None or not image_name endswith '_*' ami sorted data key itemgetter 'name' reverse True [0]return ami['ami_id']else ami_info [ ami ami['name'] split '_' [ -1 ] for ami in data]ami sorted ami_info key itemgetter 1 reverse True [0][0]return ami['ami_id']
def oo_ami_selector data image_name if not isinstance data list raise errors AnsibleFilterError ' failedexpectsfirstparamisalist' if not data return Noneelif image_name is None or not image_name endswith '_*' ami sorted data key itemgetter 'name' reverse True [0]return ami['ami_id']else ami_info [ ami ami['name'] split '_' [ -1 ] for ami in data]ami sorted ami_info key itemgetter 1 reverse True [0][0]return ami['ami_id']
def oo_ami_selector data image_name if not isinstance data list raise errors AnsibleFilterError ' failedexpectsfirstparamisalist' if not data return Noneelif image_name is None or not image_name endswith '_*' ami sorted data key itemgetter 'name' reverse True [0]return ami['ami_id']else ami_info [ ami ami['name'] split '_' [ -1 ] for ami in data]ami sorted ami_info key itemgetter 1 reverse True [0][0]return ami['ami_id']
def oo_ami_selector data image_name if not isinstance data list raise errors AnsibleFilterError ' failedexpectsfirstparamisalist' if not data return Noneelif image_name is None or not image_name endswith '_*' ami sorted data key itemgetter 'name' reverse True [0]return ami['ami_id']else ami_info [ ami ami['name'] split '_' [ -1 ] for ami in data]ami sorted ami_info key itemgetter 1 reverse True [0][0]return ami['ami_id']
def nice_size size include_bytes False niced Falsenice_string '%sbytes' % size try nsize Decimal size for x in ['bytes' 'KB' 'MB' 'GB'] if nsize compare Decimal '1024 0' Decimal '-1' nice_string '%3 1f%s' % nsize x niced Truebreaknsize / Decimal '1024 0' if not niced nice_string '%3 1f%s' % nsize 'TB' niced Trueif include_bytes and x 'bytes' nice_string '%s %sbytes ' % nice_string size except passreturn nice_string
def nice_size size include_bytes False niced Falsenice_string '%sbytes' % size try nsize Decimal size for x in ['bytes' 'KB' 'MB' 'GB'] if nsize compare Decimal '1024 0' Decimal '-1' nice_string '%3 1f%s' % nsize x niced Truebreaknsize / Decimal '1024 0' if not niced nice_string '%3 1f%s' % nsize 'TB' niced Trueif include_bytes and x 'bytes' nice_string '%s %sbytes ' % nice_string size except passreturn nice_string
def error why msg err why msg
def error why msg err why msg
def compute_node_statistics context return IMPL compute_node_statistics context
def common_texification text text re_mathdefault sub repl_mathdefault text parts re_mathsep split text for i s in enumerate parts if not i % 2 s re_escapetext sub repl_escapetext s else s u'\\ \\displaystyle%s\\ ' % s parts[i] sreturn u'' join parts
def stack xs axis 0 xs [expand_dims expand_dims x axis axis for x in xs]return concat concat xs axis axis
def test_max_pool X_sym tensor tensor4 'X' pool_it max_pool X_sym pool_shape 2 2 pool_stride 2 2 image_shape 6 4 f theano function inputs [X_sym] outputs pool_it X np array [[2 1 3 4] [1 1 3 3] [5 5 7 7] [5 6 8 7] [9 10 11 12] [9 10 12 12]] dtype theano config floatX [np newaxis np newaxis ]expected np array [[2 4] [6 8] [10 12]] dtype theano config floatX [np newaxis np newaxis ]actual f X assert np allclose expected actual
def has_open_quotes s if s count '"' % 2 return '"'elif s count "'" % 2 return "'"else return False
def required_estimates_fields columns return metadata_columns union viewvalues columns
def make_avpr_object json_data if hasattr json_data 'get' and callable json_data get name json_data get 'protocol' namespace json_data get 'namespace' types json_data get 'types' messages json_data get 'messages' return Protocol name namespace types messages else raise ProtocolParseException 'NotaJSONobject %s' % json_data
def install_readline hook global readline_hook readline_refreadline_hook hookPyOS_RFP c_int from_address Console GetProcAddress sys dllhandle 'PyOS_ReadlineFunctionPointer' if sys version < '2 3' readline_ref HOOKFUNC22 hook_wrapper else readline_ref HOOKFUNC23 hook_wrapper_23 func_start c_int from_address addressof readline_ref valuePyOS_RFP value func_start
def returner ret _options _get_options ret sid _options get 'sid' None token _options get 'token' None sender _options get 'from' None receiver _options get 'to' None if sid is None or token is None log error 'Twiliosid/authenticationtokenmissing' return Noneif sender is None or receiver is None log error 'Twilioto/fromfieldsaremissing' return Noneclient TwilioRestClient sid token try message client messages create body 'Minion {0}\nCmd {1}\nSuccess {2}\n\nJid {3}' format ret['id'] ret['fun'] ret['success'] ret['jid'] to receiver from_ sender except TwilioRestException as e log error 'Twilio[https //www twilio com/docs/errors/{0}]' format e code return Falsereturn True
def get_all_roles exclude_system False if exclude_system result Role query system False else result Role get_all return result
def volume_get_all_by_group context group_id filters None return IMPL volume_get_all_by_group context group_id filters filters
def create_schema_for_required_keys keys schema {x [not_missing] for x in keys}return schema
def create_schema_for_required_keys keys schema {x [not_missing] for x in keys}return schema
def create_schema_for_required_keys keys schema {x [not_missing] for x in keys}return schema
def create_schema_for_required_keys keys schema {x [not_missing] for x in keys}return schema
def hough_ellipse img threshold 4 accuracy 1 min_size 4 max_size None return _hough_ellipse img threshold accuracy min_size max_size
def setup_platform hass config add_devices discovery_info None import transmissionrpcfrom transmissionrpc error import TransmissionErrorname config get CONF_NAME host config get CONF_HOST username config get CONF_USERNAME password config get CONF_PASSWORD port config get CONF_PORT transmission_api transmissionrpc Client host port port user username password password try transmission_api session_stats except TransmissionError _LOGGING error 'ConnectiontoTransmissionAPIfailed' return Falseadd_devices [TransmissionSwitch transmission_api name ]
@pytest mark cmd@pytest mark parametrize 'command app' [ command app for command app in get_commands iteritems if app startswith 'pootle_' or app in CORE_APPS_WITH_COMMANDS ] def test_initdb_help capfd command app print 'Command %s App %s' % command app with pytest raises SystemExit call_command command '--help' out err capfd readouterr assert '--help' in out
@pytest fixturedef admin_group db return Group objects create name 'Admins' rules '* *'
def get_customizationspec_ref si customization_spec_name customization_spec_name si content customizationSpecManager GetCustomizationSpec name customization_spec_name return customization_spec_name
def restarted service if is_running service if using_systemd systemd restart service else restart service elif using_systemd systemd start service else start service
def get_user_hash request ip request META get 'REMOTE_ADDR' '' ua request META get 'User-Agent' '' session_key request session session_key or '' return hashlib sha1 '-' join map str ip ua session_key hexdigest
def getattr obj name *default if len default > 1 raise TypeError 'getattrexpectedatmost3arguments got%d' % 2 + len default if orig_isinstance obj NetProxy try return obj __getattr__ name except AttributeError if not default raisereturn default[0]else return orig_getattr obj name *default
def create_media_urls nav path_list final_urls []for path in path_list parsed urlparse path if parsed netloc final_urls append path continueurl path_to_url path relative_url u'%s/%s' % nav url_context make_relative u'/' url final_urls append relative_url return final_urls
@receiver SignalHandler item_deleted def handle_item_deleted **kwargs usage_key kwargs get 'usage_key' if usage_key usage_key usage_key for_branch None course_key usage_key course_keydeleted_module modulestore get_item usage_key for module in yield_dynamic_descriptor_descendants deleted_module kwargs get 'user_id' gating_api remove_prerequisite module location gating_api set_required_content course_key module location None None
@receiver SignalHandler item_deleted def handle_item_deleted **kwargs usage_key kwargs get 'usage_key' if usage_key usage_key usage_key for_branch None course_key usage_key course_keydeleted_module modulestore get_item usage_key for module in yield_dynamic_descriptor_descendants deleted_module kwargs get 'user_id' gating_api remove_prerequisite module location gating_api set_required_content course_key module location None None
@receiver SignalHandler item_deleted def handle_item_deleted **kwargs usage_key kwargs get 'usage_key' if usage_key usage_key usage_key for_branch None course_key usage_key course_keydeleted_module modulestore get_item usage_key for module in yield_dynamic_descriptor_descendants deleted_module kwargs get 'user_id' gating_api remove_prerequisite module location gating_api set_required_content course_key module location None None
def get_vmdk_adapter_type adapter_type if adapter_type in [constants ADAPTER_TYPE_LSILOGICSAS constants ADAPTER_TYPE_PARAVIRTUAL] vmdk_adapter_type constants DEFAULT_ADAPTER_TYPEelse vmdk_adapter_type adapter_typereturn vmdk_adapter_type
def get_vmdk_adapter_type adapter_type if adapter_type in [constants ADAPTER_TYPE_LSILOGICSAS constants ADAPTER_TYPE_PARAVIRTUAL] vmdk_adapter_type constants DEFAULT_ADAPTER_TYPEelse vmdk_adapter_type adapter_typereturn vmdk_adapter_type
@login_requireddef password_change request template_name 'authopenid/password_change_form html' set_password_form SetPasswordForm change_password_form PasswordChangeForm post_change_redirect None extra_context None if post_change_redirect is None post_change_redirect settings LOGIN_REDIRECT_URLset_password Falseif request user has_usable_password change_form change_password_formelse set_password Truechange_form set_password_formif request POST form change_form request user request POST if form is_valid form save msg urllib quote _ 'Passwordchanged' redirect_to '%s?%s' % post_change_redirect urllib urlencode {'msg' msg} return HttpResponseRedirect redirect_to else form change_form request user return render template_name {'form' form 'set_password' set_password} context_instance _build_context request extra_context extra_context
def do_score_for_object parser token bits token contents split if len bits 4 raise template TemplateSyntaxError "'%s'tagtakesexactlythreearguments" % bits[0] if bits[2] 'as' raise template TemplateSyntaxError "secondargumentto'%s'tagmustbe'as'" % bits[0] return ScoreForObjectNode bits[1] bits[3]
def do_score_for_object parser token bits token contents split if len bits 4 raise template TemplateSyntaxError "'%s'tagtakesexactlythreearguments" % bits[0] if bits[2] 'as' raise template TemplateSyntaxError "secondargumentto'%s'tagmustbe'as'" % bits[0] return ScoreForObjectNode bits[1] bits[3]
def do_score_for_object parser token bits token contents split if len bits 4 raise template TemplateSyntaxError "'%s'tagtakesexactlythreearguments" % bits[0] if bits[2] 'as' raise template TemplateSyntaxError "secondargumentto'%s'tagmustbe'as'" % bits[0] return ScoreForObjectNode bits[1] bits[3]
def do_score_for_object parser token bits token contents split if len bits 4 raise template TemplateSyntaxError "'%s'tagtakesexactlythreearguments" % bits[0] if bits[2] 'as' raise template TemplateSyntaxError "secondargumentto'%s'tagmustbe'as'" % bits[0] return ScoreForObjectNode bits[1] bits[3]
def shell cmd pin pout os pipe proc sp Popen '/bin/bash' stdin sp PIPE for line in cmd split '\n' line line strip if line startswith '#' print '\x1b[33m>' + line + '\x1b[0m' else print '\x1b[32m>' + line + '\x1b[0m' if line startswith 'cd' os chdir line[3 ] proc stdin write line + '\n' encode 'utf-8' proc stdin write 'echo$?1>&%d\n' % pout encode 'utf-8' ret ''while not ret endswith '\n' ret + os read pin 1 ret int ret strip if ret 0 print '\x1b[31mLastcommandreturned%d bailingout \x1b[0m' % ret sys exit -1 proc stdin close proc wait
def shell cmd pin pout os pipe proc sp Popen '/bin/bash' stdin sp PIPE for line in cmd split '\n' line line strip if line startswith '#' print '\x1b[33m>' + line + '\x1b[0m' else print '\x1b[32m>' + line + '\x1b[0m' if line startswith 'cd' os chdir line[3 ] proc stdin write line + '\n' encode 'utf-8' proc stdin write 'echo$?1>&%d\n' % pout encode 'utf-8' ret ''while not ret endswith '\n' ret + os read pin 1 ret int ret strip if ret 0 print '\x1b[31mLastcommandreturned%d bailingout \x1b[0m' % ret sys exit -1 proc stdin close proc wait
def shell cmd pin pout os pipe proc sp Popen '/bin/bash' stdin sp PIPE for line in cmd split '\n' line line strip if line startswith '#' print '\x1b[33m>' + line + '\x1b[0m' else print '\x1b[32m>' + line + '\x1b[0m' if line startswith 'cd' os chdir line[3 ] proc stdin write line + '\n' encode 'utf-8' proc stdin write 'echo$?1>&%d\n' % pout encode 'utf-8' ret ''while not ret endswith '\n' ret + os read pin 1 ret int ret strip if ret 0 print '\x1b[31mLastcommandreturned%d bailingout \x1b[0m' % ret sys exit -1 proc stdin close proc wait
def unregister_pkg name conn None if conn is None conn init conn execute 'DELETEFROMpackagesWHEREpackage ?' name
def assert_element_text_matches output path expression text xml_find_text output path if re match expression text is None errmsg "Expectedelementwithpath'%s'tocontaintextmatching'%s' insteadtext'%s'wasfound " % path expression text raise AssertionError errmsg
def nopackages pkg_list options None pkg_list [pkg for pkg in pkg_list if is_installed pkg ]if pkg_list uninstall pkg_list options
def connect_to_cloud_blockstorage region None return _create_client ep_name 'volume' region region
def train_regressor options embed_map wordvecs worddict d defaultdict lambda 0 for w in embed_map vocab keys d[w] 1shared OrderedDict count 0for w in worddict keys [ options['n_words'] - 2 ] if d[w] > 0 shared[w] countcount + 1w2v numpy zeros len shared 300 dtype 'float32' sg numpy zeros len shared options['dim_word'] dtype 'float32' for w in shared keys w2v[shared[w]] embed_map[w]sg[shared[w]] wordvecs[w]clf LinearRegression clf fit w2v sg return clf
def form margin spacing *widgets layout QtWidgets QFormLayout layout setSpacing spacing layout setFieldGrowthPolicy QtWidgets QFormLayout ExpandingFieldsGrow set_margin layout margin for idx name widget in enumerate widgets if isinstance name str ustr layout addRow name widget else layout setWidget idx QtWidgets QFormLayout LabelRole name layout setWidget idx QtWidgets QFormLayout FieldRole widget return layout
@disable_for_loaddatadef flush_similar_cache_handler sender **kwargs entry kwargs['instance']if entry is_visible EntryPublishedVectorBuilder cache_flush
@disable_for_loaddatadef flush_similar_cache_handler sender **kwargs entry kwargs['instance']if entry is_visible EntryPublishedVectorBuilder cache_flush
def to_scipy_sparse m **options dtype options get 'dtype' 'complex' if isinstance m Matrix Expr return sympy_to_scipy_sparse m dtype dtype elif isinstance m numpy_ndarray if not sparse raise ImportErrorreturn sparse csr_matrix m elif isinstance m scipy_sparse_matrix return mraise TypeError 'Expectedsympy/numpy/scipy sparsematrix got %r' % m
def constraint_present name constraint_id constraint_type constraint_options None cibname None return _item_present name name item 'constraint' item_id constraint_id item_type constraint_type create None extra_args constraint_options cibname cibname
def constraint_present name constraint_id constraint_type constraint_options None cibname None return _item_present name name item 'constraint' item_id constraint_id item_type constraint_type create None extra_args constraint_options cibname cibname
def get_dict_names dict1_path dict2_path dict1_name os path basename dict1_path dict2_name os path basename dict2_path if dict1_name dict2_name dict1_name 'dict1'dict2_name 'dict2'return dict1_name dict2_name
def local_path_as_url filename return 'file //' + urllib pathname2url os path abspath filename
def rl_op left right if len right > 0 rl_gate right[0]rl_gate_is_unitary is_scalar_matrix Dagger rl_gate rl_gate _get_min_qubits rl_gate True if len right > 0 and rl_gate_is_unitary new_right right[1 len right ]new_left Dagger rl_gate + left return new_left new_right return None
def test_ast_good_assert can_compile u' assert1 ' can_compile u' assert1"Assertlabel" ' can_compile u' assert1 +"spam""eggs" ' can_compile u' assert112345 ' can_compile u' assert1None ' can_compile u' assert1 +2"incomingeggsception" '
def epoch_timestamp dt return dt - EPOCH total_seconds
def load_config filename None text None test False commit True debug False replace False fun 'load_merge_candidate'if replace fun 'load_replace_candidate'_loaded __proxy__['napalm call'] fun **{'filename' filename 'config' text} loaded_config Noneif debug if filename loaded_config open filename read else loaded_config textreturn _config_logic _loaded test test commit_config commit loaded_config loaded_config
def setup_join_cache sender **kwargs sender _meta _join_cache {}
def setup_join_cache sender **kwargs sender _meta _join_cache {}
def get_W word_vecs k 300 vocab_size len word_vecs word_idx_map dict W np zeros shape vocab_size + 1 k dtype 'float32' W[0] np zeros k dtype 'float32' i 1for word in word_vecs W[i] word_vecs[word]word_idx_map[word] ii + 1return W word_idx_map
@asyncio coroutinedef mock_async_subprocess async_popen MagicMock @asyncio coroutinedef communicate input None 'Communicatemock 'fixture bytes load_fixture 'alpr_stdout txt' 'utf-8' return fixture None async_popen communicate communicatereturn async_popen
def _adjust_lines lines formatted_lines []for l in lines l l replace '\r\n' '\n' replace '\r' '\n' strip if l lower startswith 'matrix' formatted_lines append l else l l replace '\n' '' if l formatted_lines append l return formatted_lines
def cors_handler *args **kwargs req_head cherrypy request headersresp_head cherrypy response headersac_method req_head get 'Access-Control-Request-Method' None allowed_methods ['GET' 'POST']allowed_headers ['X-Auth-Token' 'Content-Type']if ac_method and ac_method in allowed_methods resp_head['Access-Control-Allow-Methods'] ' ' join allowed_methods resp_head['Access-Control-Allow-Headers'] ' ' join allowed_headers resp_head['Connection'] 'keep-alive'resp_head['Access-Control-Max-Age'] '1400'return {}
def cors_handler *args **kwargs req_head cherrypy request headersresp_head cherrypy response headersac_method req_head get 'Access-Control-Request-Method' None allowed_methods ['GET' 'POST']allowed_headers ['X-Auth-Token' 'Content-Type']if ac_method and ac_method in allowed_methods resp_head['Access-Control-Allow-Methods'] ' ' join allowed_methods resp_head['Access-Control-Allow-Headers'] ' ' join allowed_headers resp_head['Connection'] 'keep-alive'resp_head['Access-Control-Max-Age'] '1400'return {}
def require_admin_context f def wrapper *args **kwargs if not is_admin_context args[0] raise exception AdminRequired return f *args **kwargs return wrapper
def get_default_config return deepcopy _default_dict
def get_block_device cmd 'lsblk-n-ioKNAME-d-e1 7 11-l'devs __salt__['cmd run'] cmd splitlines return devs
def resolve_object request model query permission 'base view_resourcebase' permission_required True permission_msg None obj get_object_or_404 model **query obj_to_check obj get_self_resource if settings RESOURCE_PUBLISHING if not obj_to_check is_published and not request user has_perm 'publish_resourcebase' obj_to_check raise Http404allowed Trueif permission split ' ' [ -1 ] in ['change_layer_data' 'change_layer_style'] if obj __class__ __name__ 'Layer' obj_to_check objif permission if permission_required or request method 'GET' allowed request user has_perm permission obj_to_check if not allowed mesg permission_msg or _ 'PermissionDenied' raise PermissionDenied mesg return obj
def get_config_directory section if section is None return os getcwd if 'project_dir' in section return path section get 'project_dir' config os path abspath section get 'files' '' origin return config if os path isdir config else os path dirname config
def setup_platform hass config add_devices discovery_info None value_template config get CONF_VALUE_TEMPLATE if value_template is not None value_template hass hassadd_devices [MqttCover hass config get CONF_NAME config get CONF_STATE_TOPIC config get CONF_COMMAND_TOPIC config get CONF_QOS config get CONF_RETAIN config get CONF_STATE_OPEN config get CONF_STATE_CLOSED config get CONF_PAYLOAD_OPEN config get CONF_PAYLOAD_CLOSE config get CONF_PAYLOAD_STOP config get CONF_OPTIMISTIC value_template ]
def get_fc_wwnns hbas get_fc_hbas wwnns []if hbas for hba in hbas if hba['port_state'] 'Online' wwnn hba['node_name'] replace '0x' '' wwnns append wwnn return wwnns
def parse_set source info version info flags & _ALL_VERSIONS or DEFAULT_VERSION saved_ignore source ignore_spacesource ignore_space Falsenegate source match '^' try if version VERSION0 item parse_set_imp_union source info else item parse_set_union source info if not source match ']' raise error 'missing]' source string source pos finally source ignore_space saved_ignoreif negate item item with_flags positive not item positive item item with_flags case_flags make_case_flags info return item
def show_delvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theshow_delvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}instance_id kwargs get 'instance_id' None device kwargs get 'device' None volume_id kwargs get 'volume_id' None if instance_id is None instance_id _get_node name ['instanceId']params {'Action' 'DescribeInstances' 'InstanceId 1' instance_id}data aws query params location get_location provider get_provider opts __opts__ sigver '4' blockmap data[0]['instancesSet']['item']['blockDeviceMapping']if not isinstance blockmap['item'] list blockmap['item'] [blockmap['item']]items []for idx item in enumerate blockmap['item'] device_name item['deviceName']if device is not None and device device_name continueif volume_id is not None and volume_id item['ebs']['volumeId'] continueinfo {'device_name' device_name 'volume_id' item['ebs']['volumeId'] 'deleteOnTermination' item['ebs']['deleteOnTermination']}items append info return items
def show_delvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theshow_delvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}instance_id kwargs get 'instance_id' None device kwargs get 'device' None volume_id kwargs get 'volume_id' None if instance_id is None instance_id _get_node name ['instanceId']params {'Action' 'DescribeInstances' 'InstanceId 1' instance_id}data aws query params location get_location provider get_provider opts __opts__ sigver '4' blockmap data[0]['instancesSet']['item']['blockDeviceMapping']if not isinstance blockmap['item'] list blockmap['item'] [blockmap['item']]items []for idx item in enumerate blockmap['item'] device_name item['deviceName']if device is not None and device device_name continueif volume_id is not None and volume_id item['ebs']['volumeId'] continueinfo {'device_name' device_name 'volume_id' item['ebs']['volumeId'] 'deleteOnTermination' item['ebs']['deleteOnTermination']}items append info return items
def show_delvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Theshow_delvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}instance_id kwargs get 'instance_id' None device kwargs get 'device' None volume_id kwargs get 'volume_id' None if instance_id is None instance_id _get_node name ['instanceId']params {'Action' 'DescribeInstances' 'InstanceId 1' instance_id}data aws query params location get_location provider get_provider opts __opts__ sigver '4' blockmap data[0]['instancesSet']['item']['blockDeviceMapping']if not isinstance blockmap['item'] list blockmap['item'] [blockmap['item']]items []for idx item in enumerate blockmap['item'] device_name item['deviceName']if device is not None and device device_name continueif volume_id is not None and volume_id item['ebs']['volumeId'] continueinfo {'device_name' device_name 'volume_id' item['ebs']['volumeId'] 'deleteOnTermination' item['ebs']['deleteOnTermination']}items append info return items
def set shop key value ConfigurationItem objects update_or_create shop shop key key defaults {u'value' value} if shop cache set _get_cache_key shop None else cache bump_version _SHOP_CONF_NAMESPACE
def init_flowgram_file filename None n 0 l 400 prefix '/tmp/' if filename is None fd filename mkstemp dir prefix suffix ' dat' close fd fh open filename 'w' fh write '%d%d\n' % n l return fh filename
def init_flowgram_file filename None n 0 l 400 prefix '/tmp/' if filename is None fd filename mkstemp dir prefix suffix ' dat' close fd fh open filename 'w' fh write '%d%d\n' % n l return fh filename
def psd v return Hint psd True symmetric True v
def get_instance model instance_or_pk timeout None using None primary_key getattr instance_or_pk 'pk' instance_or_pk key instance_key model instance_or_pk data cache get key if data is not None try instance model pk primary_key **data instance _state adding Falseinstance _state db using or DEFAULT_DB_ALIAS return instanceexcept cache delete key instance model _default_manager using using get pk primary_key data {}for field in instance _meta fields if field primary_key continueif field get_internal_type 'FileField' file_value getattr instance field attname data[field attname] file_value nameelse data[field attname] getattr instance field attname if timeout is None timeout app_settings CACHE_TOOLBOX_DEFAULT_TIMEOUTcache set key data timeout return instance
def _validate_node node try if node is not None node nodeprep node if not node raise InvalidJID u'Localpartmustnotbe0bytes' if len node > 1023 raise InvalidJID u'Localpartmustbelessthan1024bytes' return nodeexcept stringprep_profiles StringPrepError raise InvalidJID u'Invalidlocalpart'
def add_rule name localport protocol 'tcp' action 'allow' dir 'in' ret {'name' name 'result' True 'changes' {} 'comment' ''}commit Falsecurrent_rules __salt__['firewall get_rule'] name if not current_rules commit Trueret['changes'] {'newrule' name}if __opts__['test'] ret['result'] not commit or None return retif commit ret['result'] __salt__['firewall add_rule'] name localport protocol action dir if not ret['result'] ret['comment'] 'Couldnotaddrule'else ret['comment'] 'Arulewiththatnamealreadyexists'return ret
def rot32 w nLeft nLeft & 31if nLeft 0 return wRRR w >> 1 & 2147483647 >> 31 - nLeft sLLLLLL - 1 << 31 - nLeft & w 2147483647 >> nLeft & w return RRR sLLLLLL << nLeft
def rot32 w nLeft nLeft & 31if nLeft 0 return wRRR w >> 1 & 2147483647 >> 31 - nLeft sLLLLLL - 1 << 31 - nLeft & w 2147483647 >> nLeft & w return RRR sLLLLLL << nLeft
def GetClientConfig filename config_lib SetPlatformArchContext config_lib ParseConfigCommandLine context list config_lib CONFIG context context append 'ClientContext' deployer build ClientRepacker config_data deployer GetClientConfig context validate True deploy_timestamp False builder build ClientBuilder with open filename 'w' as fd fd write config_data builder WriteBuildYaml fd build_timestamp False
def _BackupFilters _cpplint_state BackupFilters
def _is_pid_running_on_unix pid try os kill pid 0 except OSError return Falseelse return True
def scale_time_units time_seconds_arr unit if unit u'minutes' return list map lambda x x * 1 0 / 60 time_seconds_arr elif unit u'hours' return list map lambda x x * 1 0 / 60 * 60 time_seconds_arr elif unit u'days' return list map lambda x x * 1 0 / 24 * 60 * 60 time_seconds_arr return time_seconds_arr
def md5_shard word data word encode 'utf-8' return 'server%d' % hashlib md5 data digest [ -1 ] % 4
def http_headers s d {}for line in s split '\r\n' try key value [i strip for i in line split ' ' 1 ]d[key] valueexcept ValueError passreturn d
def adjust_timestamp ts offset here utcoffset return ts - offset - here * 3600
def test_difficult_univariate x Normal 'x' 0 1 assert density x ** 3 assert density exp x ** 2 assert density log x
def test_difficult_univariate x Normal 'x' 0 1 assert density x ** 3 assert density exp x ** 2 assert density log x
def test_difficult_univariate x Normal 'x' 0 1 assert density x ** 3 assert density exp x ** 2 assert density log x
def import_setting name value getattr settings name None return import_object value
def has_unaccent cr cr execute "SELECTpronameFROMpg_procWHEREproname 'unaccent'" return len cr fetchall > 0
def calculate_multipart_etag source_path chunk_size DEFAULT_CHUNK_SIZE md5s []with open source_path 'rb' as fp while True data fp read chunk_size if not data breakmd5s append hashlib md5 data if len md5s 1 new_etag '"{}"' format md5s[0] hexdigest else digests '' join m digest for m in md5s new_md5 hashlib md5 digests new_etag '"{}-{}"' format new_md5 hexdigest len md5s return new_etag
def optionsForClientTLS hostname trustRoot None clientCertificate None acceptableProtocols None **kw extraCertificateOptions kw pop 'extraCertificateOptions' None or {} if trustRoot is None trustRoot platformTrust if kw raise TypeError "optionsForClientTLS gotanunexpectedkeywordargument'{arg}'" format arg kw popitem [0] if not isinstance hostname unicode raise TypeError 'optionsForClientTLSrequirestextforhostnames not' + hostname __class__ __name__ if clientCertificate extraCertificateOptions update privateKey clientCertificate privateKey original certificate clientCertificate original certificateOptions OpenSSLCertificateOptions trustRoot trustRoot acceptableProtocols acceptableProtocols **extraCertificateOptions return ClientTLSOptions hostname certificateOptions getContext
def optionsForClientTLS hostname trustRoot None clientCertificate None acceptableProtocols None **kw extraCertificateOptions kw pop 'extraCertificateOptions' None or {} if trustRoot is None trustRoot platformTrust if kw raise TypeError "optionsForClientTLS gotanunexpectedkeywordargument'{arg}'" format arg kw popitem [0] if not isinstance hostname unicode raise TypeError 'optionsForClientTLSrequirestextforhostnames not' + hostname __class__ __name__ if clientCertificate extraCertificateOptions update privateKey clientCertificate privateKey original certificate clientCertificate original certificateOptions OpenSSLCertificateOptions trustRoot trustRoot acceptableProtocols acceptableProtocols **extraCertificateOptions return ClientTLSOptions hostname certificateOptions getContext
def certificate_downloadable_status student course_key current_status certificate_status_for_student student course_key response_data {'is_downloadable' False 'is_generating' True if current_status['status'] in [CertificateStatuses generating CertificateStatuses error] else False 'is_unverified' True if current_status['status'] CertificateStatuses unverified else False 'download_url' None 'uuid' None}if current_status['status'] CertificateStatuses downloadable response_data['is_downloadable'] Trueresponse_data['download_url'] current_status['download_url'] or get_certificate_url student id course_key response_data['uuid'] current_status['uuid']return response_data
def get_version return open VERSION_PATH read strip
def _wait_for_vhd_coalesce session instance sr_ref vdi_ref vdi_uuid_list if len vdi_uuid_list 1 LOG debug 'OldchainissingleVHD coalescenotpossible ' instance instance returnparent_vdi_uuid vdi_uuid_list[1]if _count_children session parent_vdi_uuid sr_ref > 1 LOG debug 'Parenthasotherchildren coalesceisunlikely ' instance instance returnmax_attempts CONF xenserver vhd_coalesce_max_attemptsgood_parent_uuids vdi_uuid_list[1 ]for i in range max_attempts _scan_sr session sr_ref parent_uuid _get_vhd_parent_uuid session vdi_ref if parent_uuid and parent_uuid not in good_parent_uuids LOG debug 'Parent% parent_uuid snotyetinparentlist% good_parent_uuids s waitingforcoalesce ' {'parent_uuid' parent_uuid 'good_parent_uuids' good_parent_uuids} instance instance else LOG debug 'Coalescedetected becauseparentis %s' parent_uuid instance instance returngreenthread sleep CONF xenserver vhd_coalesce_poll_interval msg _ 'VHDcoalesceattemptsexceeded %d givingup ' % max_attempts raise exception NovaException msg
def _wait_for_vhd_coalesce session instance sr_ref vdi_ref vdi_uuid_list if len vdi_uuid_list 1 LOG debug 'OldchainissingleVHD coalescenotpossible ' instance instance returnparent_vdi_uuid vdi_uuid_list[1]if _count_children session parent_vdi_uuid sr_ref > 1 LOG debug 'Parenthasotherchildren coalesceisunlikely ' instance instance returnmax_attempts CONF xenserver vhd_coalesce_max_attemptsgood_parent_uuids vdi_uuid_list[1 ]for i in range max_attempts _scan_sr session sr_ref parent_uuid _get_vhd_parent_uuid session vdi_ref if parent_uuid and parent_uuid not in good_parent_uuids LOG debug 'Parent% parent_uuid snotyetinparentlist% good_parent_uuids s waitingforcoalesce ' {'parent_uuid' parent_uuid 'good_parent_uuids' good_parent_uuids} instance instance else LOG debug 'Coalescedetected becauseparentis %s' parent_uuid instance instance returngreenthread sleep CONF xenserver vhd_coalesce_poll_interval msg _ 'VHDcoalesceattemptsexceeded %d givingup ' % max_attempts raise exception NovaException msg
def save linux_distro path output open path 'w' output write bz2 compress pickle dumps linux_distro output close
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op GpuElemwise assert topo[ -1 ] op host_from_gpu
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op GpuElemwise assert topo[ -1 ] op host_from_gpu
def test_pdbbreakpoint_op b tensor fmatrix condition tensor gt b sum 0 b_monitored PdbBreakpoint name 'TestBreakpoint' condition b output b_monitored ** 2 f theano function [b] output mode mode_with_gpu topo f maker fgraph toposort assert isinstance topo[ -2 ] op GpuElemwise assert topo[ -1 ] op host_from_gpu
def test_score_2 tpot_obj TPOTClassifier tpot_obj _pbar tqdm total 1 disable True known_score 0 986318199045tpot_obj _optimized_pipeline creator Individual from_string 'RandomForestClassifier input_matrix ' tpot_obj _pset tpot_obj _fitted_pipeline tpot_obj _toolbox compile expr tpot_obj _optimized_pipeline tpot_obj _fitted_pipeline fit training_features training_classes score tpot_obj score testing_features testing_classes def isclose a b rel_tol 1e-09 abs_tol 0 0 return abs a - b < max rel_tol * max abs a abs b abs_tol assert isclose known_score score
def LoadPlist filename data Nonetry p subprocess Popen ['/usr/bin/plutil' '-convert' 'xml1' '-o' '-' filename] stdout subprocess PIPE stderr subprocess PIPE out_data err_data p communicate except IOError as e print eif p returncode 0 data plistlib readPlistFromString out_data return data
def getRotatedWiddershinsQuarterAroundZAxis vector3 return Vector3 - vector3 y vector3 x vector3 z
def getPathInFabmetheusFromFileNameHelp fileNameHelp fabmetheusPath archive getFabmetheusPath splitFileNameHelps fileNameHelp split ' ' splitFileNameDirectoryNames splitFileNameHelps[ -1 ]for splitFileNameDirectoryName in splitFileNameDirectoryNames fabmetheusPath os path join fabmetheusPath splitFileNameDirectoryName return fabmetheusPath
def gettext message global _default _activet _active get currentThread None if t is not None return t gettext message if _default is None from django conf import settings_default translation settings LANGUAGE_CODE return _default gettext message
def _item_to_sub_for_client iterator sub_pb topics resource MessageToDict sub_pb return Subscription from_api_repr resource iterator client topics topics
def humanDurationNanosec nsec if nsec < 1000 return u'%unsec' % nsec usec nsec divmod nsec 1000 if usec < 1000 return u'% 2fusec' % usec + float nsec / 1000 msec usec divmod usec 1000 if msec < 1000 return u'% 2fms' % msec + float usec / 1000 return humanDuration msec
def _convert_string_array data encoding itemsize None if encoding is not None and len data data Series data ravel str encode encoding values reshape data shape if itemsize is None itemsize lib max_len_string_array _ensure_object data ravel data np asarray data dtype 'S%d' % itemsize return data
def _normalized_levenshtein_distance s1 s2 acceptable_differences if len s1 > len s2 s1 s2 s2 s1 acceptable_differences set - i for i in acceptable_differences distances range len s1 + 1 for index2 num2 in enumerate s2 new_distances [ index2 + 1 ]for index1 num1 in enumerate s1 if num2 - num1 in acceptable_differences new_distances append distances[index1] else new_distances append 1 + min distances[index1] distances[ index1 + 1 ] new_distances[ -1 ] distances new_distancesreturn distances[ -1 ]
def get_form_target if get_comment_app_name DEFAULT_COMMENTS_APP and hasattr get_comment_app 'get_form_target' return get_comment_app get_form_target else return urlresolvers reverse 'django contrib comments views comments post_comment'
def nonterminals symbols if u' ' in symbols symbol_list symbols split u' ' else symbol_list symbols split return [Nonterminal s strip for s in symbol_list]
def cache_subnet_group_absent name region None key None keyid None profile None **args ret {'name' name 'result' True 'comment' '' 'changes' {}}args dict [ k v for k v in args items if not k startswith '_' ] exists __salt__['boto3_elasticache cache_subnet_group_exists'] name region region key key keyid keyid profile profile if exists if __opts__['test'] ret['comment'] 'Cachesubnetgroup{0}wouldberemoved ' format name ret['result'] Nonereturn retdeleted __salt__['boto3_elasticache delete_cache_subnet_group'] name region region key key keyid keyid profile profile **args if deleted ret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodelete{0}cache_subnetgroup ' format name else ret['comment'] 'Cachesubnetgroup{0}alreadyabsent ' format name return ret
def GetCompilerPath target_list data options build_file _ _ gyp common ParseQualifiedTarget target_list[0] make_global_settings_dict data[build_file] get 'make_global_settings' {} for key value in make_global_settings_dict if key in ['CC' 'CXX'] return os path join options toplevel_dir value for key in ['CC_target' 'CC' 'CXX'] compiler os environ get key if compiler return compilerreturn 'gcc'
def GetCompilerPath target_list data options build_file _ _ gyp common ParseQualifiedTarget target_list[0] make_global_settings_dict data[build_file] get 'make_global_settings' {} for key value in make_global_settings_dict if key in ['CC' 'CXX'] return os path join options toplevel_dir value for key in ['CC_target' 'CC' 'CXX'] compiler os environ get key if compiler return compilerreturn 'gcc'
def headers_cb headers {'Access-Control-Allow-Credentials' 'true' 'Access-Control-Allow-Headers' 'accept accept-charset accept-encoding ' + 'accept-language authorization content-length ' + 'content-type host origin proxy-connection ' + 'referer user-agent x-requested-with' 'Access-Control-Allow-Methods' 'HEAD GET PUT POST PATCH DELETE' 'Access-Control-Allow-Origin' '*' 'Access-Control-Max-Age' '86400'}if add_headers_cb headers update add_headers_cb return headers
def headers_cb headers {'Access-Control-Allow-Credentials' 'true' 'Access-Control-Allow-Headers' 'accept accept-charset accept-encoding ' + 'accept-language authorization content-length ' + 'content-type host origin proxy-connection ' + 'referer user-agent x-requested-with' 'Access-Control-Allow-Methods' 'HEAD GET PUT POST PATCH DELETE' 'Access-Control-Allow-Origin' '*' 'Access-Control-Max-Age' '86400'}if add_headers_cb headers update add_headers_cb return headers
def memoize func cache {}def inner *args **kwargs args tuple args kwargs_set frozenset iter kwargs items if args kwargs_set in cache result cache[ args kwargs_set ]else result func *args **kwargs cache[ args kwargs_set ] resultreturn resultreturn inner
def memoize func cache {}def inner *args **kwargs args tuple args kwargs_set frozenset iter kwargs items if args kwargs_set in cache result cache[ args kwargs_set ]else result func *args **kwargs cache[ args kwargs_set ] resultreturn resultreturn inner
def continued_fraction_reduce cf from sympy core symbol import Dummyfrom sympy solvers import solveperiod []x Dummy 'x' def untillist cf for nxt in cf if isinstance nxt list period extend nxt yield x break yield nxt a Integer 0 for a in continued_fraction_convergents untillist cf passif period y Dummy 'y' solns solve continued_fraction_reduce period + [y] - y y solns sort pure solns[ -1 ]return a subs x pure radsimp else return a
def _prepare_message txt def plain val 'ReturnTruewhenvalisplainASCII'try val decode 'ascii' return Trueexcept return Falsecode 'ISO-8859-1'msg Message payload []body Falseheader Falsefor line in txt encode code 'replace' split '\n' if header and not line body Trueif body payload append line else m RE_HEADER search line if m header Truekeyword m group 1 strip value m group 2 strip if plain value msg add_header keyword value else header Header value code msg[keyword] headermsg set_payload '\n' join payload code if not msg has_key 'Content-Transfer-Encoding' encode_quopri msg return msg as_string
def os_detection_exec exec_method try linux1 exec_method 'echo-nw3af' linux2 exec_method 'head-n1/etc/passwd' except BaseFrameworkException passelse if 'w3af' in linux1 and linux2 count ' ' > 3 om out debug 'IdentifiedremoteOSasLinux returning"linux" ' return 'linux'try win1 exec_method 'type%SYSTEMROOT%\\win ini' win2 exec_method 'echo/?' except BaseFrameworkException passelse if '[fonts]' in win1 and 'ECHO' in win2 om out debug 'IdentifiedremoteOSasWindows returning"windows" ' return 'windows'raise BaseFrameworkException 'Failedtoget/identifytheremoteOS '
def os_detection_exec exec_method try linux1 exec_method 'echo-nw3af' linux2 exec_method 'head-n1/etc/passwd' except BaseFrameworkException passelse if 'w3af' in linux1 and linux2 count ' ' > 3 om out debug 'IdentifiedremoteOSasLinux returning"linux" ' return 'linux'try win1 exec_method 'type%SYSTEMROOT%\\win ini' win2 exec_method 'echo/?' except BaseFrameworkException passelse if '[fonts]' in win1 and 'ECHO' in win2 om out debug 'IdentifiedremoteOSasWindows returning"windows" ' return 'windows'raise BaseFrameworkException 'Failedtoget/identifytheremoteOS '
def wassuccessful_patch result return make_instancemethod TextTestResult wasSuccessful result
def wassuccessful_patch result return make_instancemethod TextTestResult wasSuccessful result
def wassuccessful_patch result return make_instancemethod TextTestResult wasSuccessful result
def setPrivacyList disp list resp disp SendAndWaitForResponse Iq 'set' NS_PRIVACY payload [list] if isResultNode resp return 1
def _log_multivariate_normal_density_tied X means covars cv np tile covars means shape[0] 1 1 return _log_multivariate_normal_density_full X means cv
def dict_keys_startswith dictionary string matched_keys [key for key in dictionary keys if key startswith string ]return dict k dictionary[k] for k in matched_keys
def adjustTimeDelay lastQueryDuration lowerStdLimit candidate 1 + int round lowerStdLimit if candidate kb delayCandidates [candidate] + kb delayCandidates[ -1 ] if all x candidate for x in kb delayCandidates and candidate < conf timeSec conf timeSec candidateinfoMsg 'adjustingtimedelayto'infoMsg + '%dsecond%sduetogoodresponsetimes' % conf timeSec 's' if conf timeSec > 1 else '' logger info infoMsg
def oid_diff git oid filename None args [ oid + u'~' oid]opts common_diff_opts _add_filename args filename status out err git diff *args **opts if status 0 args [ oid + u'^ ' ]_add_filename args filename status out err git show pretty u'format ' *args **opts out out lstrip return out
def repeat sequence N len sequence def f i return sequence[ i % N ]return partial _force sequence _advance f
def find_roots path file_sig '* plug' roots set for root dirnames filenames in os walk path followlinks True for filename in fnmatch filter filenames file_sig dir_to_add os path dirname os path join root filename relative os path relpath os path realpath dir_to_add os path realpath path for subelement in relative split os path sep if subelement in ' ' ' ' continueif subelement startswith ' ' or subelement '__pycache__' log debug 'Ignore%s' % dir_to_add breakelse roots add dir_to_add return roots
def expected_freq observed observed np asarray observed dtype np float64 margsums margins observed d observed ndimexpected reduce np multiply margsums / observed sum ** d - 1 return expected
def _user_can_manage_leaders user group_profile return user has_perm 'groups change_groupprofile'
def runtests from Cython Debugger Tests import test_libpython_in_gdbsuccess_libcython run_unittest_in_module __name__ success_libpython run_unittest_in_module test_libpython_in_gdb __name__ if not success_libcython or not success_libpython sys exit 2
def CountErrors ocr_text truth_text counts collections Counter truth_text counts subtract ocr_text drops sum c for c in counts values if c > 0 adds sum - c for c in counts values if c < 0 return ErrorCounts drops adds len truth_text len ocr_text
def agent_service_setup test test ca_set get_credential_sets [0]test host '192 0 2 5'test port 54123test reactor MemoryCoreReactor test agent_service AgentService reactor test reactor control_service_host test host control_service_port test port node_credential test ca_set node ca_certificate test ca_set root credential certificate backend_description LOOPBACK api_args {}
def create_filter parameters if parameters['filters'] cli_filters parameters['filters']real_filters []for filter_type filter_pattern in cli_filters real_filters append filter_type lstrip '-' filter_pattern source_location parameters['src']if source_location startswith 's3 //' src_rootdir _get_s3_root source_location parameters['dir_op'] else src_rootdir _get_local_root parameters['src'] parameters['dir_op'] destination_location parameters['dest']if destination_location startswith 's3 //' dst_rootdir _get_s3_root parameters['dest'] parameters['dir_op'] else dst_rootdir _get_local_root parameters['dest'] parameters['dir_op'] return Filter real_filters src_rootdir dst_rootdir else return Filter {} None None
def normalize weight_list minval None maxval None if not weight_list return if maxval is None maxval max weight_list if minval is None minval min weight_list maxval float maxval minval float minval if minval maxval return [0] * len weight_list range_ maxval - minval return i - minval / range_ for i in weight_list
def match_coordinates_3d matchcoord catalogcoord nthneighbor 1 storekdtree u'kdtree_3d' if catalogcoord isscalar or len catalogcoord < 1 raise ValueError u'Thecatalogforcoordinatematchingcannotbeascalarorlength-0 ' kdt _get_cartesian_kdtree catalogcoord storekdtree matchcoord matchcoord transform_to catalogcoord catunit catalogcoord cartesian x unitmatchxyz matchcoord cartesian xyz to catunit matchflatxyz matchxyz reshape 3 np prod matchxyz shape // 3 dist idx kdt query matchflatxyz T nthneighbor if nthneighbor > 1 dist dist[ -1 ]idx idx[ -1 ]sep2d catalogcoord[idx] separation matchcoord return idx reshape matchxyz shape[1 ] sep2d dist reshape matchxyz shape[1 ] * catunit
def get_liveaction_by_id liveaction_id liveaction Nonetry liveaction LiveAction get_by_id liveaction_id except ValidationError ValueError as e LOG error 'DatabaselookupforLiveActionwithid "%s"resultedinexception %s' liveaction_id e raise StackStormDBObjectNotFoundError 'UnabletofindLiveActionwithid "%s"' % liveaction_id return liveaction
def unload_all unload *reversed _PLUGINS
def test_denoise_tv_chambolle_1d x 125 + 100 * np sin np linspace 0 8 * np pi 1000 x + 20 * np random rand x size x np clip x 0 255 res restoration denoise_tv_chambolle x astype np uint8 weight 0 1 assert_ res dtype np float assert_ res std * 255 < x std
def parse_html_dict dictionary prefix '' ret MultiValueDict regex re compile '^%s\\ + $' % re escape prefix for field in dictionary match regex match field if not match continuekey match groups [0]value dictionary getlist field ret setlist key value return ret
def run_solvers model true_params alpha get_l1_slsqp_results get_l1_cvxopt_results print_summaries results {}results['results_ML'] model fit method 'newton' start_params results['results_ML'] params ravel order 'F' if get_l1_slsqp_results results['results_l1_slsqp'] model fit_regularized method 'l1' alpha alpha maxiter 1000 start_params start_params retall True if get_l1_cvxopt_results results['results_l1_cvxopt_cp'] model fit_regularized method 'l1_cvxopt_cp' alpha alpha maxiter 50 start_params start_params retall True feastol 1e-05 return results
def run_solvers model true_params alpha get_l1_slsqp_results get_l1_cvxopt_results print_summaries results {}results['results_ML'] model fit method 'newton' start_params results['results_ML'] params ravel order 'F' if get_l1_slsqp_results results['results_l1_slsqp'] model fit_regularized method 'l1' alpha alpha maxiter 1000 start_params start_params retall True if get_l1_cvxopt_results results['results_l1_cvxopt_cp'] model fit_regularized method 'l1_cvxopt_cp' alpha alpha maxiter 50 start_params start_params retall True feastol 1e-05 return results
def run_solvers model true_params alpha get_l1_slsqp_results get_l1_cvxopt_results print_summaries results {}results['results_ML'] model fit method 'newton' start_params results['results_ML'] params ravel order 'F' if get_l1_slsqp_results results['results_l1_slsqp'] model fit_regularized method 'l1' alpha alpha maxiter 1000 start_params start_params retall True if get_l1_cvxopt_results results['results_l1_cvxopt_cp'] model fit_regularized method 'l1_cvxopt_cp' alpha alpha maxiter 50 start_params start_params retall True feastol 1e-05 return results
def run_solvers model true_params alpha get_l1_slsqp_results get_l1_cvxopt_results print_summaries results {}results['results_ML'] model fit method 'newton' start_params results['results_ML'] params ravel order 'F' if get_l1_slsqp_results results['results_l1_slsqp'] model fit_regularized method 'l1' alpha alpha maxiter 1000 start_params start_params retall True if get_l1_cvxopt_results results['results_l1_cvxopt_cp'] model fit_regularized method 'l1_cvxopt_cp' alpha alpha maxiter 50 start_params start_params retall True feastol 1e-05 return results
def main argv if len argv 1 die 'ERROR Mustspecifysubcommand oneof %s' % nice_join x name for x in subcommands all parser argparse ArgumentParser prog argv[0] parser add_argument '-v' '--version' action 'version' version __version__ subs parser add_subparsers help 'Sub-commands' for cls in subcommands all subparser subs add_parser cls name help cls help subcommand cls parser subparser subparser set_defaults invoke subcommand invoke args parser parse_args argv[1 ] try args invoke args except Exception as e die 'ERROR ' + str e
@pytest fixturedef fake_save_manager fake_save_manager unittest mock Mock spec savemanager SaveManager objreg register 'save-manager' fake_save_manager yield fake_save_manager objreg delete 'save-manager'
def agent_members consul_url None **kwargs ret {}query_params {}if not consul_url consul_url _get_config if not consul_url log error 'NoConsulURLfound ' ret['message'] 'NoConsulURLfound 'ret['res'] Falsereturn retif 'wan' in kwargs query_params['wan'] kwargs['wan']function 'agent/members'ret _query consul_url consul_url function function method 'GET' query_params query_params return ret
@contextmanagerdef temporary_file suffix '' tempfile_stream NamedTemporaryFile suffix suffix delete False tempfile tempfile_stream nametempfile_stream close yield tempfile os remove tempfile
@contextmanagerdef temporary_file suffix '' tempfile_stream NamedTemporaryFile suffix suffix delete False tempfile tempfile_stream nametempfile_stream close yield tempfile os remove tempfile
def make_pad_threshold_message threshold1 threshold2 lower_channel_pressure_threshold upper_channel_pressure_threshold args to_7L5M threshold1 + to_7L5M threshold2 + to_7L5M lower_channel_pressure_threshold + to_7L5M upper_channel_pressure_threshold return make_message 27 args
def make_pad_threshold_message threshold1 threshold2 lower_channel_pressure_threshold upper_channel_pressure_threshold args to_7L5M threshold1 + to_7L5M threshold2 + to_7L5M lower_channel_pressure_threshold + to_7L5M upper_channel_pressure_threshold return make_message 27 args
def test_reset_out _ip run_cell "parrot 'dead'" store_history True _ip run_cell 'parrot' store_history True nt assert_true 'dead' in [_ip user_ns[x] for x in '_' '__' '___' ] _ip magic 'reset-fout' nt assert_false 'dead' in [_ip user_ns[x] for x in '_' '__' '___' ] nt assert_equal len _ip user_ns['Out'] 0
def test_reset_out _ip run_cell "parrot 'dead'" store_history True _ip run_cell 'parrot' store_history True nt assert_true 'dead' in [_ip user_ns[x] for x in '_' '__' '___' ] _ip magic 'reset-fout' nt assert_false 'dead' in [_ip user_ns[x] for x in '_' '__' '___' ] nt assert_equal len _ip user_ns['Out'] 0
def run_python_job job log 'Runningpythonjob \n' sys path append os path realpath job expt_dir params {}for param in job param dbl_vals param dbl_val _valuesint_vals param int_val _valuesstr_vals param str_val _valuesif len dbl_vals > 0 params[param name] np array dbl_vals elif len int_vals > 0 params[param name] np array int_vals dtype int elif len str_vals > 0 params[param name] str_valselse raise Exception 'Unknownparametertype ' module __import__ job name result module main job id params log 'Gotresult%f\n' % result job value resultsave_job job
@pytest mark django_dbdef test_theme_selection with override_current_theme_class with override_provides 'xtheme' ['shuup_tests xtheme utils FauxTheme' 'shuup_tests xtheme utils FauxTheme2' 'shuup_tests xtheme utils H2G2Theme'] ThemeSettings objects all delete for theme in get_provide_objects 'xtheme' set_current_theme theme identifier je get_jinja2_engine wrapper noop if theme identifier 'h2g2' else pytest raises TemplateDoesNotExist with wrapper t je get_template '42 jinja' content t render strip assert 'asliceoflemonwrappedaroundalargegoldbrick' in content replace '\n' ''
@pytest mark django_dbdef test_theme_selection with override_current_theme_class with override_provides 'xtheme' ['shuup_tests xtheme utils FauxTheme' 'shuup_tests xtheme utils FauxTheme2' 'shuup_tests xtheme utils H2G2Theme'] ThemeSettings objects all delete for theme in get_provide_objects 'xtheme' set_current_theme theme identifier je get_jinja2_engine wrapper noop if theme identifier 'h2g2' else pytest raises TemplateDoesNotExist with wrapper t je get_template '42 jinja' content t render strip assert 'asliceoflemonwrappedaroundalargegoldbrick' in content replace '\n' ''
@task name 'geonode tasks email send_email' queue 'email' def send_email *args **kwargs send_mail *args **kwargs
def parallel_execute_iter objects func get_deps if get_deps is None get_deps _no_depsresults Queue state State objects while True feed_queue objects func get_deps results state try event results get timeout 0 1 except Empty continueexcept thread error raise ShutdownException if event is STOP break obj _ exception eventif exception is None log debug u'Finishedprocessing {}' format obj state finished add obj else log debug u'Failed {}' format obj state failed add obj yield event
def parallel_execute_iter objects func get_deps if get_deps is None get_deps _no_depsresults Queue state State objects while True feed_queue objects func get_deps results state try event results get timeout 0 1 except Empty continueexcept thread error raise ShutdownException if event is STOP break obj _ exception eventif exception is None log debug u'Finishedprocessing {}' format obj state finished add obj else log debug u'Failed {}' format obj state failed add obj yield event
def parallel_execute_iter objects func get_deps if get_deps is None get_deps _no_depsresults Queue state State objects while True feed_queue objects func get_deps results state try event results get timeout 0 1 except Empty continueexcept thread error raise ShutdownException if event is STOP break obj _ exception eventif exception is None log debug u'Finishedprocessing {}' format obj state finished add obj else log debug u'Failed {}' format obj state failed add obj yield event
def parallel_execute_iter objects func get_deps if get_deps is None get_deps _no_depsresults Queue state State objects while True feed_queue objects func get_deps results state try event results get timeout 0 1 except Empty continueexcept thread error raise ShutdownException if event is STOP break obj _ exception eventif exception is None log debug u'Finishedprocessing {}' format obj state finished add obj else log debug u'Failed {}' format obj state failed add obj yield event
def parallel_execute_iter objects func get_deps if get_deps is None get_deps _no_depsresults Queue state State objects while True feed_queue objects func get_deps results state try event results get timeout 0 1 except Empty continueexcept thread error raise ShutdownException if event is STOP break obj _ exception eventif exception is None log debug u'Finishedprocessing {}' format obj state finished add obj else log debug u'Failed {}' format obj state failed add obj yield event
@app route '/logout' def logout session pop 'user' None return redirect url_for 'index'
def has_environment_marker_support try return pkg_resources parse_version setuptools __version__ > pkg_resources parse_version '0 7 2' except Exception as exc sys stderr write "Couldnottestsetuptool'sversion %s\n" % exc return False
def has_environment_marker_support try return pkg_resources parse_version setuptools __version__ > pkg_resources parse_version '0 7 2' except Exception as exc sys stderr write "Couldnottestsetuptool'sversion %s\n" % exc return False
@print_durationdef asyncio_run urls pass
def test_mpl_preserve_width f create_figure width height f canvas get_width_height s mplhooks figure_to_tight_array f 0 5 * width 0 5 * height True exp width newwidth newheight f canvas get_width_height obs newwidthplt close f assert exp obs
def fingerprint registry xml_parent data fingerprint XML SubElement xml_parent 'hudson plugins createfingerprint CreateFingerprint' fingerprint set 'plugin' 'create-fingerprint' mapping [ 'targets' 'targets' '' ]convert_mapping_to_xml fingerprint data mapping fail_required True
def Kumaraswamy name a b return rv name KumaraswamyDistribution a b
def all_properties decl for item in decl seq p item valueif isinstance p Property yield p
def keepvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Thekeepvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}device kwargs get 'device' None volume_id kwargs get 'volume_id' None return _toggle_delvol name name device device volume_id volume_id value 'false'
def keepvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Thekeepvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}device kwargs get 'device' None volume_id kwargs get 'volume_id' None return _toggle_delvol name name device device volume_id volume_id value 'false'
def keepvol_on_destroy name kwargs None call None if call 'action' raise SaltCloudSystemExit 'Thekeepvol_on_destroyactionmustbecalledwith-aor--action ' if not kwargs kwargs {}device kwargs get 'device' None volume_id kwargs get 'volume_id' None return _toggle_delvol name name device device volume_id volume_id value 'false'
def _CreateIndexOnlyQueryResults results postfix_props new_results []for result in results new_results extend _CreateIndexEntities result postfix_props return new_results
def shard_df_on_index df divisions if isinstance divisions Iterator divisions list divisions if not len divisions yield df else divisions np array divisions df df sort_index index df indexif is_categorical_dtype index index index as_ordered indices index searchsorted divisions yield df iloc[ indices[0]] for i in range len indices - 1 yield df iloc[indices[i] indices[ i + 1 ]] yield df iloc[indices[ -1 ] ]
def decode_cookie value try return unicode value 'us-ascii' except UnicodeError try return unicode value 'utf-8' except UnicodeError return unicode value 'iso8859' 'ignore'
@event u'manager config_updated' @event u'manager daemon started' def register_web_server manager global web_server config_hashif not manager is_daemon returnconfig manager config get u'web_server' if get_config_hash config config_hash log debug u"webserverconfighas'ntchanged" returnconfig_hash get_config_hash config web_server_config prepare_config config stop_server manager if not web_server_config returnlog info u'RunningwebserveratIP%s %s' web_server_config[u'bind'] web_server_config[u'port'] api_app secret_key get_secret log info u'InitiatingAPI' register_app u'/api' api_app if web_server_config get u'web_ui' log info u'RegisteringWebUI' register_web_ui manager web_server setup_server web_server_config
def _to_pascal_case snake_case space_case re sub '_' '' snake_case wordlist []for word in space_case split wordlist append word[0] upper wordlist append word[1 ] return '' join wordlist
def is_link path if sys getwindowsversion major < 6 return Falsetry if not _is_reparse_point path return Falseexcept SaltInvocationError return Falsereparse_data _get_reparse_data path if not reparse_data return Falseheader_parser struct Struct 'L' ReparseTag header_parser unpack reparse_data[ header_parser size] if not ReparseTag & 2684420095 2684354572 return Falseelse return True
def _TranslateError error detail '' if error > taskqueue_service_pb TaskQueueServiceError DATASTORE_ERROR and isinstance error int from google appengine api import datastoredatastore_exception datastore _DatastoreExceptionFromErrorCodeAndDetail error - taskqueue_service_pb TaskQueueServiceError DATASTORE_ERROR detail class JointException datastore_exception __class__ DatastoreError 'Therewasadatastoreerrorwhileaccessingthequeue '__msg u'taskqueue DatastoreErrorcausedby %s%s' % datastore_exception __class__ detail def __str__ self return JointException __msgreturn JointException else exception_class _ERROR_MAPPING get error None if exception_class return exception_class detail else return Error 'Applicationerror%s %s' % error detail
def _FetchLog http_client log_url output_file callback def _OnFetch response if response code 200 with open output_file 'w' as f f write response body logging info 'wrote%dbytesto%s' % len response body output_file else logging error 'failedtofetch%s' % log_url callback http_client fetch log_url callback _OnFetch method 'GET'
def _FetchLog http_client log_url output_file callback def _OnFetch response if response code 200 with open output_file 'w' as f f write response body logging info 'wrote%dbytesto%s' % len response body output_file else logging error 'failedtofetch%s' % log_url callback http_client fetch log_url callback _OnFetch method 'GET'
def index_template_create name body hosts None profile None es _get_instance hosts profile try result es indices put_template name name body body return Trueexcept elasticsearch exceptions NotFoundError return Nonereturn None
def rm_permissions obj_name principal ace_type 'all' obj_type 'file' dacl Dacl obj_name obj_type dacl rm_ace principal ace_type dacl save obj_name return True
def keys_to_string data if isinstance data dict for key in list data keys if isinstance key six string_types value data[key]val keys_to_string value del data[key]data[key encode 'utf8' 'ignore' ] valreturn data
def generate_file fname ns_func dest_dir ' ' with open pjoin root 'buildutils' 'templates' '%s' % fname 'r' as f tpl f read out tpl format **ns_func dest pjoin dest_dir fname info 'generating%sfromtemplate' % dest with open dest 'w' as f f write out
def use_astropy_helpers **kwargs global BOOTSTRAPPERconfig BOOTSTRAPPER configconfig update **kwargs BOOTSTRAPPER _Bootstrapper **config BOOTSTRAPPER run
def compatibility_mode setattr EventsCodes 'ALL_EVENTS' ALL_EVENTS for evname in globals if evname startswith 'IN_' setattr EventsCodes evname globals [evname] global COMPATIBILITY_MODECOMPATIBILITY_MODE True
def _find_tcl_tk_dir tcl_root exec_statement 'from%simportTcl print Tcl eval "infolibrary" ' % modname_tkinter tk_version exec_statement 'from_tkinterimportTK_VERSION print TK_VERSION ' tk_root os path join os path dirname tcl_root 'tk%s' % tk_version return tcl_root tk_root
def test_str_to_utf8 s '\\u01ff\\u02ff'u utils to_utf8 s assert_equal type s type str assert_equal type u type u'\u01ff\u02ff'
def remove_null_handler _DULWICH_LOGGER removeHandler _NULL_HANDLER
def task_and_vm_state_from_status statuses vm_states set task_states set lower_statuses [status lower for status in statuses]for state task_map in _STATE_MAP items for task_state mapped_state in task_map items status_string mapped_stateif status_string lower in lower_statuses vm_states add state task_states add task_state return sorted vm_states sorted task_states
def setup_light device_id name insteonhub hass add_devices_callback if device_id in _CONFIGURING request_id _CONFIGURING pop device_id configurator get_component 'configurator' configurator request_done request_id _LOGGER info 'Deviceconfigurationdone ' conf_lights config_from_file hass config path INSTEON_LOCAL_LIGHTS_CONF if device_id not in conf_lights conf_lights[device_id] nameif not config_from_file hass config path INSTEON_LOCAL_LIGHTS_CONF conf_lights _LOGGER error 'Failedtosaveconfigurationfile' device insteonhub dimmer device_id add_devices_callback [InsteonLocalDimmerDevice device name ]
def update try salt fileserver reap_fileserver_cache_dir os path join __opts__['cachedir'] 'minionfs/hash' find_file except os error pass
def get_remote_catalog_db dbname cache True verbose True return VOSDatabase from_json urllib parse urljoin vo_conf vos_baseurl dbname + u' json' encoding u'utf8' cache cache show_progress verbose
def absent email profile 'splunk' **kwargs user_identity kwargs get 'name' ret {'name' user_identity 'changes' {} 'result' None 'comment' 'User{0}isabsent ' format user_identity }target __salt__['splunk get_user'] email profile profile if not target ret['comment'] 'User{0}doesnotexist' format user_identity ret['result'] Truereturn retif __opts__['test'] ret['comment'] 'User{0}isallsettobedeleted' format user_identity ret['result'] Nonereturn retresult __salt__['splunk delete_user'] email profile profile if result ret['comment'] 'Deleteduser{0}' format user_identity ret['changes'] setdefault 'old' 'User{0}exists' format user_identity ret['changes'] setdefault 'new' 'User{0}deleted' format user_identity ret['result'] Trueelse ret['comment'] 'Failedtodelete{0}' format user_identity ret['result'] Falsereturn ret
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'delete_config' name matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'delete_config' name matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'delete_config' name matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'delete_config' name matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def config_absent name ret {'name' name 'result' False 'changes' {} 'comment' ''}matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Configisalreadyabsent'elif __opts__['test'] is True ret['result'] Noneret['comment'] 'Configwillberemoved'ret['changes']['new'] nameelse __salt__['nxos cmd'] 'delete_config' name matches __salt__['nxos cmd'] 'find' name if not matches ret['result'] Trueret['comment'] 'Successfullydeletedconfig'ret['changes']['new'] nameelse ret['result'] Falseret['comment'] 'Failedtodeleteconfig'return ret
def _WriteSimpleXMLElement outfile name value indent value_str _StrOrUnicode value if isinstance value bool value_str value_str lower safe_value_str _MakeXMLSafe value_str outfile write '%s<%s>%s</%s>\n' % indent name safe_value_str name
def _make_requires flag error def _requires_decorator func if not flag @wraps func def explode *args **kwargs raise NotImplementedError error return explodeelse return funcreturn _requires_decorator
def finalize_backup_info backup_info_pk mapper_params def tx backup_info BackupInformation get backup_info_pk if backup_info backup_info complete_time datetime datetime now if backup_info filesystem files GS_FILESYSTEM gs_bucket mapper_params['gs_bucket_name']BackupInfoWriter gs_bucket write backup_info backup_info put force_writes True logging info 'Backup%scompleted' backup_info name else logging warn 'Backup%scouldnotbefound' backup_info_pk db run_in_transaction tx
def regions return get_regions 'elasticloadbalancing' connection_cls ELBConnection
def new_agent bindings port 8080 spinnaker Front50Agent new_instance_from_bindings 'front50' Front50Status new bindings port return spinnaker
def relative_position pos global absolute_path_lengthif absolute_path_length 0 absolute_path_length len os path abspath os getcwd return pos[0] get_filenametable_entry [ absolute_path_length + 1 ] pos[1]
def assert_has_extension test credential name value expected X509Extension name False value x509 credential certificate originalvalues []for i in range x509 get_extension_count extension x509 get_extension i if extension get_short_name name values append extension get_data test assertIn expected get_data values
def jarque_bera resids axis 0 resids np asarray resids skew stats skew resids axis axis kurtosis 3 + stats kurtosis resids axis axis n resids shape[axis]jb n / 6 0 * skew ** 2 + 1 / 4 0 * kurtosis - 3 ** 2 jb_pv stats chi2 sf jb 2 return jb jb_pv skew kurtosis
def jarque_bera resids axis 0 resids np asarray resids skew stats skew resids axis axis kurtosis 3 + stats kurtosis resids axis axis n resids shape[axis]jb n / 6 0 * skew ** 2 + 1 / 4 0 * kurtosis - 3 ** 2 jb_pv stats chi2 sf jb 2 return jb jb_pv skew kurtosis
def _weighted_percentile array sample_weight percentile 50 sorted_idx np argsort array weight_cdf stable_cumsum sample_weight[sorted_idx] percentile_idx np searchsorted weight_cdf percentile / 100 0 * weight_cdf[ -1 ] return array[sorted_idx[percentile_idx]]
def _weighted_percentile array sample_weight percentile 50 sorted_idx np argsort array weight_cdf stable_cumsum sample_weight[sorted_idx] percentile_idx np searchsorted weight_cdf percentile / 100 0 * weight_cdf[ -1 ] return array[sorted_idx[percentile_idx]]
def test ret {'comment' '' 'success' False}cmd __execute_cmd 'riak-admin' 'test' if cmd['retcode'] 0 ret['comment'] cmd['stdout']else ret['comment'] cmd['stdout']ret['success'] Truereturn ret
def show_state_usage queue False **kwargs conflict _check_queue queue kwargs if conflict is not None return conflictpillar kwargs get 'pillar' pillar_enc kwargs get 'pillar_enc' if pillar_enc is None and pillar is not None and not isinstance pillar dict raise SaltInvocationError 'Pillardatamustbeformattedasadictionary unlesspillar_encisspecified ' st_ salt state HighState __opts__ pillar pillar_enc pillar_enc st_ push_active try ret st_ compile_state_usage finally st_ pop_active _set_retcode ret return ret
def get_access_flags_string value buff ''for i in ACCESS_FLAGS if i[0] & value i[0] buff + i[1] + '' if buff '' return buff[ -1 ]return buff
def samplemat dims aa np zeros dims for i in range min dims aa[ i i ] ireturn aa
def samplemat dims aa np zeros dims for i in range min dims aa[ i i ] ireturn aa
@pytest mark cmd@pytest mark django_dbdef test_revision capfd call_command 'revision' out err capfd readouterr assert out rstrip isnumeric
def _ module mod Nonetry import importlibmod importlib import_module 'salt modules inspectlib {0}' format module except ImportError as err mod getattr __import__ 'salt modules inspectlib' globals locals fromlist [str module ] module mod __grains__ __grains__mod __pillar__ __pillar__mod __salt__ __salt__return mod
def delete_parameter_group name region None key None keyid None profile None try conn _get_conn region region key key keyid keyid profile profile if not conn return {'results' bool conn }r conn delete_db_parameter_group DBParameterGroupName name return {'deleted' bool r 'message' 'DeletedRDSparametergroup{0} ' format name }except ClientError as e return {'error' salt utils boto3 get_error e }
def entropy pk qk None base None pk asarray pk pk 1 0 * pk / np sum pk axis 0 if qk is None vec entr pk else qk asarray qk if len qk len pk raise ValueError 'qkandpkmusthavesamelength ' qk 1 0 * qk / np sum qk axis 0 vec rel_entr pk qk S np sum vec axis 0 if base is not None S / log base return S
def ntohl integer if sys byteorder 'big' return integerif not isinstance integer int long raise TypeError 'expectedint/long %sfound' % _TypeName integer if integer < 0 raise OverflowError "can'tconvertnegativenumbertounsignedlong" if integer > 1 << 32 raise OverflowError 'longintlargerthan32bits' return int integer & 4278190080 >> 24 integer & 16711680 >> 8 integer & 65280 << 8 integer & 255 << 24
def additions_removed name force False ret {'name' name 'changes' {} 'result' False 'comment' ''}current_state __salt__['vbox_guest additions_version'] if not current_state ret['result'] Trueret['comment'] 'Systemalreadyinthecorrectstate'return retif __opts__['test'] ret['comment'] 'ThestateofVirtualBoxGuestAdditionswillbechanged 'ret['changes'] {'old' current_state 'new' True}ret['result'] Nonereturn retnew_state __salt__['vbox_guest additions_remove'] force force ret['comment'] 'ThestateofVirtualBoxGuestAdditionswaschanged 'ret['changes'] {'old' current_state 'new' new_state}ret['result'] bool new_state return ret
def setSettingsPath path global settingsPathsettingsPath path
def get_h5_data_group grp_name parent '/' f get_h5_data_file existed Truetry group f getNode parent + grp_name except existed Falsemsg 'datafor{}tests' format grp_name + ' py' group f create_group parent grp_name msg return existed group
def __virtual__ if not salt utils is_windows return False 'OnlyavailableonWindowsSystems' if not __salt__['cmd shell_info'] 'powershell' ['installed'] return False 'Powershellnotavailable' if not salt utils powershell module_exists 'PKI' return False 'PowerShellPKImodulenotavailable' return __virtualname__
def get_projects projects {}for file_name in listdir json_directory file_path join json_directory file_name if isfile file_path and file_path endswith u' json' print u'Loading' file_pathprojects[file_path] json load open file_path u'r' object_pairs_hook OrderedDict return projects
def serialize_tag tag out '<'if tag tag_type HtmlTagType CLOSE_TAG out + '/'out + tag tagattributes []for key val in tag attributes items aout keyif val is not None aout + ' ' + _quotify val attributes append aout if attributes out + '' + '' join attributes if tag tag_type HtmlTagType UNPAIRED_TAG out + '/'return out + '>'
def status url 'http //localhost 8080/manager' timeout 180 return _wget 'list' {} url timeout timeout ['res']
def _oneD_norm_2 a raise NotImplementedError
def remove_challenge_for_url url if not url raise ValueError 'URLcannotbeempty' url parse urlparse url del _cache[url netloc]
def guess_pygments_highlighter filename try from pygments lexers import get_lexer_for_filename get_lexer_by_namefrom pygments util import ClassNotFoundexcept ImportError return TextSH root ext os path splitext filename if ext in custom_extension_lexer_mapping lexer get_lexer_by_name custom_extension_lexer_mapping[ext] else try lexer get_lexer_for_filename filename except ClassNotFound return TextSHclass GuessedPygmentsSH PygmentsSH _lexer lexerreturn GuessedPygmentsSH
def _prepare_archive_at_path filename try with ZipFile filename 'r' as archive archive close except BadZipfile return Noneif _is_overwritten filename log debug 'ZIPfilecontainsafilewiththesamename originalisgoingtobeoverwrite' new_zip_path filename + _random_extension move filename new_zip_path filename new_zip_pathreturn filename
def _get_footer_size file_obj file_obj seek -8 2 tup struct unpack '<i' file_obj read 4 return tup[0]
def residue_reduce_derivation H DE z i Dummy 'i' return S sum RootSum a[0] as_poly z Lambda i i * derivation a[1] DE as_expr subs z i / a[1] as_expr subs z i for a in H
def _deterministic_vector_sign_flip u max_abs_rows np argmax np abs u axis 1 signs np sign u[ range u shape[0] max_abs_rows ] u * signs[ np newaxis]return u
def _get_vif_name vif if vif get 'devname' None is not None return vif['devname']return 'nic' + vif['id'] [ model NIC_NAME_LEN]
def fxa_identify code config None try with statsd timer 'accounts fxa identify all' token get_fxa_token code config ['access_token']profile get_fxa_profile token config except statsd incr 'accounts fxa identify all fail' raiseelse statsd incr 'accounts fxa identify all success' return profile
def send tag data None data data or {} event salt utils event get_master_event __opts__ __opts__['sock_dir'] listen False return event fire_event data tag
def get_size ytid url preloading False stream [x for x in g streams[ytid]['meta'] if x['url'] url ][0]size stream['size']prefix 'preload ' if preloading else '' if not size -1 util dbg '%s%susingcachedsize %s%s' c g prefix size c w else screen writestatus 'Gettingcontentlength' mute preloading stream['size'] _get_content_length url preloading preloading util dbg '%s%s-content-length %s%s' c y prefix stream['size'] c w return stream['size']
def is_leaf cluster return len cluster 1
def kendall_pval tau n test_stat tau / 2 * 2 * n + 5 / float 9 * n * n - 1 ** 0 5 return normprob test_stat direction 'two-sided'
@profiler tracedef remove_group_role request role group domain None project None manager keystoneclient request admin True rolesreturn manager revoke role role group group project project domain domain
def get_next_double context builder state_ptr a builder lshr get_next_int32 context builder state_ptr const_int 5 b builder lshr get_next_int32 context builder state_ptr const_int 6 a builder uitofp a double b builder uitofp b double return builder fdiv builder fadd b builder fmul a ir Constant double 67108864 0 ir Constant double 9007199254740992 0
def _create_eeg_el ch t None if ch['kind'] FIFF FIFFV_EEG_CH raise RuntimeError '%sisnotanEEGchannel Cannotcreateanelectrodedefinition ' % ch['ch_name'] if t is None t Transform 'head' 'head' if t from_str 'head' raise RuntimeError 'Inappropriatecoordinatetransformation' r0ex _loc_to_eeg_loc ch['loc'] if r0ex shape[1] 1 w np array [1 0] else w np array [1 0 -1 0 ] r0ex apply_trans t['trans'] r0ex T cosmag r0ex copy _normalize_vectors cosmag res dict chname ch['ch_name'] coil_class FIFF FWD_COILC_EEG w w accuracy _accuracy_dict['normal'] type ch['coil_type'] coord_frame t['to'] rmag r0ex cosmag cosmag return res
def get_kvm_arch flags {'kvm_amd' 'svm' 'kvm_intel' 'vmx'}vendor_name utils get_cpu_vendor_name if not vendor_name raise error TestError 'CPUMustbeAMD IntelorPower7' arch_type 'kvm_%s' % vendor_name cpu_flag flags get arch_type None if cpu_flag is None and vendor_name in 'power7' return arch_typeif not utils cpu_has_flags cpu_flag raise error TestError '%sCPUarchitecturemusthave%sflagactiveandmustbeKVMready' % arch_type cpu_flag return arch_type
def get_kvm_arch flags {'kvm_amd' 'svm' 'kvm_intel' 'vmx'}vendor_name utils get_cpu_vendor_name if not vendor_name raise error TestError 'CPUMustbeAMD IntelorPower7' arch_type 'kvm_%s' % vendor_name cpu_flag flags get arch_type None if cpu_flag is None and vendor_name in 'power7' return arch_typeif not utils cpu_has_flags cpu_flag raise error TestError '%sCPUarchitecturemusthave%sflagactiveandmustbeKVMready' % arch_type cpu_flag return arch_type
def list_length queue backend 'sqlite' queue_funcs salt loader queues __opts__ cmd '{0} list_length' format backend if cmd not in queue_funcs raise SaltInvocationError 'Function"{0}"isnotavailable' format cmd ret queue_funcs[cmd] queue queue return ret
def needs_renewal name window None if window is not None and window in 'force' 'Force' True return Truereturn _renew_by name window < datetime datetime today
def needs_renewal name window None if window is not None and window in 'force' 'Force' True return Truereturn _renew_by name window < datetime datetime today
@facebook_requireddef decorator_example request graph if graph return HttpResponse 'authorized' else return HttpResponse 'userdeniedorerror'
def config_get key cwd None user None password None ignore_retcode False **kwargs all_ kwargs pop 'all' False result _config_getter '--get-all' key cwd cwd user user password password ignore_retcode ignore_retcode **kwargs if result['retcode'] 1 return Noneret result['stdout'] splitlines if all_ return retelse try return ret[ -1 ]except IndexError return ''
def touch_empty_backreferences app what name obj options lines examples_path os path join app srcdir app config sphinx_gallery_conf['mod_example_dir'] '%s examples' % name if not os path exists examples_path open examples_path 'w' close
def search_iter db query limit None batch 100 count search_count db query if not count raise StopIterationremain countif limit is not None remain min remain limit offset 1prev_ids []while remain batch min batch remain ids search db query offset batch read strip split assert len ids batch 'Got%i expected%i' % len ids batch if ids prev_ids raise RuntimeError 'Samesearchresultsforpreviousoffset' for identifier in ids if identifier in prev_ids raise RuntimeError 'Result%swasinpreviousbatch' % identifier yield identifier offset + batchremain - batchprev_ids ids
def search_iter db query limit None batch 100 count search_count db query if not count raise StopIterationremain countif limit is not None remain min remain limit offset 1prev_ids []while remain batch min batch remain ids search db query offset batch read strip split assert len ids batch 'Got%i expected%i' % len ids batch if ids prev_ids raise RuntimeError 'Samesearchresultsforpreviousoffset' for identifier in ids if identifier in prev_ids raise RuntimeError 'Result%swasinpreviousbatch' % identifier yield identifier offset + batchremain - batchprev_ids ids
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_fixed_and_bound_constraints m models Gaussian1D amplitude 3 mean 4 stddev 1 bounds {u'mean' 4 5 } fixed {u'amplitude' True} x np linspace 0 10 10 y np exp - x ** 2 / 2 f fitting LevMarLSQFitter fitted_1 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5 assert fitted_1 amplitude 3 0 m amplitude fixed Falsefitted_2 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_fixed_and_bound_constraints m models Gaussian1D amplitude 3 mean 4 stddev 1 bounds {u'mean' 4 5 } fixed {u'amplitude' True} x np linspace 0 10 10 y np exp - x ** 2 / 2 f fitting LevMarLSQFitter fitted_1 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5 assert fitted_1 amplitude 3 0 m amplitude fixed Falsefitted_2 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_fixed_and_bound_constraints m models Gaussian1D amplitude 3 mean 4 stddev 1 bounds {u'mean' 4 5 } fixed {u'amplitude' True} x np linspace 0 10 10 y np exp - x ** 2 / 2 f fitting LevMarLSQFitter fitted_1 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5 assert fitted_1 amplitude 3 0 m amplitude fixed Falsefitted_2 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5
@pytest mark skipif u'notHAS_SCIPY' def test_fit_with_fixed_and_bound_constraints m models Gaussian1D amplitude 3 mean 4 stddev 1 bounds {u'mean' 4 5 } fixed {u'amplitude' True} x np linspace 0 10 10 y np exp - x ** 2 / 2 f fitting LevMarLSQFitter fitted_1 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5 assert fitted_1 amplitude 3 0 m amplitude fixed Falsefitted_2 f m x y assert fitted_1 mean > 4 assert fitted_1 mean < 5
def tokenize content return [token encode 'utf8' for token in utils tokenize content lower True errors 'ignore' if 2 < len token < 15 and not token startswith '_' ]
def bind_ack data if data[2] '\x0c' return Falseif data[36 38] '\x00\x00' return Falsereturn True
def list_states saltenv 'base' return _client list_states saltenv
def list_states saltenv 'base' return _client list_states saltenv
def type_token_ratio string n 100 punctuation PUNCTUATION def window a n 100 if n > 0 for i in xrange max len a - n + 1 1 yield a[i i + n ] s string lower split s [w strip punctuation for w in s]return mean 1 0 * len set x / max len x 1 for x in window s n
def create_security_group_rule security_group remote_group_id None direction 'ingress' protocol None port_range_min None port_range_max None ethertype 'IPv4' profile None conn _auth profile return conn create_security_group_rule security_group remote_group_id direction protocol port_range_min port_range_max ethertype
def test_ast_lambda_lists cant_compile u' fn[&key{"a"b}&key{"foo"bar}][afoo] ' cant_compile u' fn[&optionala&key{"foo"bar}][afoo] ' cant_compile u' fn[&optional[abc]]a ' cant_compile u' fn[&optional[12]] list12 '
def connection_info_for db_or_uri if db_or_uri startswith 'postgresql //' 'postgres //' us urlparse urlsplit db_or_uri if len us path > 1 db_name us path[1 ]elif us username db_name us usernameelse db_name us hostnamereturn db_name {'dsn' db_or_uri} connection_info {'database' db_or_uri}for p in 'host' 'port' 'user' 'password' cfg tools config[ 'db_' + p ]if cfg connection_info[p] cfgreturn db_or_uri connection_info
def connection_info_for db_or_uri if db_or_uri startswith 'postgresql //' 'postgres //' us urlparse urlsplit db_or_uri if len us path > 1 db_name us path[1 ]elif us username db_name us usernameelse db_name us hostnamereturn db_name {'dsn' db_or_uri} connection_info {'database' db_or_uri}for p in 'host' 'port' 'user' 'password' cfg tools config[ 'db_' + p ]if cfg connection_info[p] cfgreturn db_or_uri connection_info
def stl_case_activity_owner_group table row db current dbs3db current s3dbstable s3db org_servicertable stable with_alias 'root_service' left [stable on stable id table service_id rtable on rtable id stable root_service ]query table id row[table _id] row db query select rtable name left left limitby 0 1 first if not row return Noneroot_service_name row nameif not root_service_name return Noneif root_service_name INDIVIDUAL_SUPPORT owner_group_uuid 'CASE_MANAGEMENT'elif root_service_name MENTAL_HEALTH owner_group_uuid 'MENTAL_HEALTH'else owner_group_uuid 'GROUP_ACTIVITIES'gtable current auth settings table_groupquery gtable uuid owner_group_uuid & gtable deleted True group db query select gtable id limitby 0 1 first return group id if group else None
def resolveSchema schema schemaStore result copy deepcopy schema resolver LocalRefResolver base_uri '' referrer schema store schemaStore def resolve obj if isinstance obj list for item in obj resolve item returnif isinstance obj dict if '$ref' in obj with resolver resolving obj[u'$ref'] as resolved resolve resolved obj clear obj update resolved else for value in obj values resolve value resolve result result['$schema'] 'http //json-schema org/draft-04/schema#'return result
def resolveSchema schema schemaStore result copy deepcopy schema resolver LocalRefResolver base_uri '' referrer schema store schemaStore def resolve obj if isinstance obj list for item in obj resolve item returnif isinstance obj dict if '$ref' in obj with resolver resolving obj[u'$ref'] as resolved resolve resolved obj clear obj update resolved else for value in obj values resolve value resolve result result['$schema'] 'http //json-schema org/draft-04/schema#'return result
@dispatch object def scrub_keys o raise NotImplementedError 'scrub_keysnotimplementedfortype%r' % type o __name__
@dispatch object def scrub_keys o raise NotImplementedError 'scrub_keysnotimplementedfortype%r' % type o __name__
def repr_strength strength return {REQUIRED u'Required' STRONG u'Strong' MEDIUM u'Medium' WEAK u'Weak'}[strength]
def requires_auth func @wraps func def wrapper self *args **kwargs if self token is None or self token_expired self login elif self token_needs_refresh self refresh_token return func self *args **kwargs return wrapper
def md5sum filen with open filen 'rb' as fileh md5 hashlib md5 fileh read return md5 hexdigest
def getSimState try status '?'mContext autoclass 'android content Context' pythonActivity autoclass 'org renpy android PythonService' TelephonyManager autoclass 'android telephony TelephonyManager' telephonyManager cast 'android telephony TelephonyManager' pythonActivity mService getSystemService mContext TELEPHONY_SERVICE simState telephonyManager getSimState if simState TelephonyManager SIM_STATE_UNKNOWN status 'unknown'elif simState TelephonyManager SIM_STATE_ABSENT status 'absent'elif simState TelephonyManager SIM_STATE_PIN_REQUIRED status 'pin_required'elif simState TelephonyManager SIM_STATE_PUK_REQUIRED status 'puk_required'elif simState TelephonyManager SIM_STATE_NETWORK_LOCKED status 'network_locked'elif simState TelephonyManager SIM_STATE_READY status 'ready'return statusexcept Exception as e return None
def _get_tab_registry win_id tab_id if tab_id is None raise ValueError 'Gottab_idNone win_id{} ' format win_id if tab_id 'current' and win_id is None app get 'app' window app activeWindow if window is None or not hasattr window 'win_id' raise RegistryUnavailableError 'tab' win_id window win_idelif win_id is not None window window_registry[win_id]else raise TypeError 'windowisNonewithscopetab ' if tab_id 'current' tabbed_browser get 'tabbed-browser' scope 'window' window win_id tab tabbed_browser currentWidget if tab is None raise RegistryUnavailableError 'window' tab_id tab tab_idtab_registry get 'tab-registry' scope 'window' window win_id try return tab_registry[tab_id] registryexcept AttributeError raise RegistryUnavailableError 'tab'
@register tagdef get_media_prefix parser token return PrefixNode handle_token parser token 'MEDIA_URL'
def get_env_for_subprocess_command env os environ copy if 'PYTHONPATH' in env del env['PYTHONPATH']return env
def pause_execution message 'Testexecutionpaused PressOKtocontinue ' MessageDialog message show
def terminal_size file None if file is None file _get_stdout try s struct pack str u'HHHH' 0 0 0 0 x fcntl ioctl file termios TIOCGWINSZ s lines width xpixels ypixels struct unpack str u'HHHH' x if lines > 12 lines - 6if width > 10 width - 1if lines < 0 or width < 0 raise Exception u'unabletogetterminalsize' return lines width except Exception try return int os environ get u'LINES' int os environ get u'COLUMNS' except TypeError lines conf max_lineswidth conf max_widthif lines is None lines 25if width is None width 80return lines width
def _server_maintenance global EVENNIA _MAINTENANCE_COUNT _FLUSH_CACHE _GAMETIME_MODULEif not _FLUSH_CACHE from evennia utils idmapper models import conditional_flush as _FLUSH_CACHEif not _GAMETIME_MODULE from evennia utils import gametime as _GAMETIME_MODULE_MAINTENANCE_COUNT + 1now time time if _MAINTENANCE_COUNT 1 _GAMETIME_MODULE SERVER_START_TIME now_GAMETIME_MODULE SERVER_RUNTIME ServerConfig objects conf 'runtime' default 0 0 else _GAMETIME_MODULE SERVER_RUNTIME + 60 0_GAMETIME_MODULE SERVER_RUNTIME_LAST_UPDATED nowServerConfig objects conf 'runtime' _GAMETIME_MODULE SERVER_RUNTIME if _MAINTENANCE_COUNT % 300 0 _FLUSH_CACHE _IDMAPPER_CACHE_MAXSIZE if _MAINTENANCE_COUNT % 3600 0 evennia ScriptDB objects validate if _MAINTENANCE_COUNT % 3700 0 evennia CHANNEL_HANDLER update
def _FindServerInMapping mapping hashed server_list list mapping servers val _BisectHashList server_list 0 len server_list - 1 hashed indexreturn val
def test_default_conv img theano tensor ftensor4 fil theano tensor ftensor4 c theano tensor nnet conv2d img fil f theano function [img fil] c mode theano_mode if cuda dnn dnn_available assert any [isinstance a op GpuDnnConv for a in f maker fgraph apply_nodes] else assert any [isinstance a op cuda blas GpuCorrMM for a in f maker fgraph apply_nodes]
def escape_script text return SCRIPT_RE sub u'<-\\1/script>' text
def escape_script text return SCRIPT_RE sub u'<-\\1/script>' text
def test_repo_fs client repository None try nodes client snapshot verify_repository repository repository ['nodes']logger debug 'Allnodescanwritetotherepository' logger debug 'Nodeswithverifiedrepositoryaccess {0}' format nodes except Exception as e try if e status_code 404 msg '---Repository"{0}"notfound Error {1} {2}' format repository e status_code e error else msg '---Gota{0}responsefromElasticsearch Errormessage {1}' format e status_code e error except AttributeError msg '---Errormessage {0}' format e raise ActionError 'Failedtoverifyallnodeshaverepositoryaccess {0}' format msg
def _next_regular target if target < 6 return targetif not target & target - 1 return targetmatch float 'inf' p5 1while p5 < target p35 p5while p35 < target quotient - - target // p35 try p2 2 ** quotient - 1 bit_length except AttributeError p2 2 ** _bit_length_26 quotient - 1 N p2 * p35 if N target return Nelif N < match match Np35 * 3if p35 target return p35if p35 < match match p35p5 * 5if p5 target return p5if p5 < match match p5return match
def thetagrids *args **kwargs ax gca if not isinstance ax PolarAxes raise RuntimeError 'rgridsonlydefinedforpolaraxes' if len args 0 lines ax xaxis get_ticklines labels ax xaxis get_ticklabels else lines labels ax set_thetagrids *args **kwargs draw_if_interactive return silent_list 'Line2Dthetagridline' lines silent_list 'Textthetagridlabel' labels
@register filterdef render_inlines value return inlines value
def is_column_based fname sep ' DCTB ' skip 0 is_multi_byte False headers get_headers fname sep is_multi_byte is_multi_byte count 0if not headers return Falsefor hdr in headers[skip ] if hdr and hdr[0] and not hdr[0] startswith '#' if len hdr > 1 count len hdr breakif count < 2 return Falsefor hdr in headers[skip ] if hdr and hdr[0] and not hdr[0] startswith '#' if len hdr count return Falsereturn True
def is_leap_year builder year_val actual_year builder add year_val Constant int DATETIME64 1970 multiple_of_4 cgutils is_null builder builder and_ actual_year Constant int DATETIME64 3 not_multiple_of_100 cgutils is_not_null builder builder srem actual_year Constant int DATETIME64 100 multiple_of_400 cgutils is_null builder builder srem actual_year Constant int DATETIME64 400 return builder and_ multiple_of_4 builder or_ not_multiple_of_100 multiple_of_400
def is_valid_hostname hostname return re match '^[a-zA-Z0-9-]+$' hostname is not None
def resolve_model model_path module_path model_name model_path rsplit ' ' 1 module importlib import_module module_path model getattr module model_name return model
def build_filter_properties scheduler_hints forced_host forced_node instance_type filter_properties dict scheduler_hints scheduler_hints filter_properties['instance_type'] instance_typeif forced_host filter_properties['force_hosts'] [forced_host]if forced_node filter_properties['force_nodes'] [forced_node]return filter_properties
def list_ name add match stamp False prune 0 ret {'name' name 'changes' {} 'comment' '' 'result' True}if not isinstance add list add add split ' ' if name not in __reg__ __reg__[name] {}__reg__[name]['val'] []for event in __events__ try event_data event['data']['data']except KeyError event_data event['data']if salt utils expr_match event['tag'] match item {}for key in add if key in event_data item[key] event_data[key]if stamp is True item['time'] event['data']['_stamp']__reg__[name]['val'] append item if prune > 0 __reg__[name]['val'] __reg__[name]['val'][ prune]return ret
def _get_quote_state token quote_char prev_char Nonefor idx cur_char in enumerate token if idx > 0 prev_char token[ idx - 1 ]if cur_char in '"\'' and prev_char '\\' if quote_char if cur_char quote_char quote_char Noneelse quote_char cur_charreturn quote_char
def _get_quote_state token quote_char prev_char Nonefor idx cur_char in enumerate token if idx > 0 prev_char token[ idx - 1 ]if cur_char in '"\'' and prev_char '\\' if quote_char if cur_char quote_char quote_char Noneelse quote_char cur_charreturn quote_char
def _get_quote_state token quote_char prev_char Nonefor idx cur_char in enumerate token if idx > 0 prev_char token[ idx - 1 ]if cur_char in '"\'' and prev_char '\\' if quote_char if cur_char quote_char quote_char Noneelse quote_char cur_charreturn quote_char
def _gluster_xml cmd if _get_minor_version < 6 result __salt__['cmd run'] 'script-q-c"gluster--xml--mode script"' stdin '{0}\n\x04' format cmd else result __salt__['cmd run'] 'gluster--xml--mode script' stdin '{0}\n' format cmd try root ET fromstring _gluster_output_cleanup result except ET ParseError raise CommandExecutionError '\n' join result splitlines [ -1 ] if _gluster_ok root output root find 'output' if output is not None log info 'Glustercall"{0}"succeeded {1}' format cmd root find 'output' text else log info 'Glustercall"{0}"succeeded' format cmd else log error 'Failedglustercall {0} {1}' format cmd root find 'opErrstr' text return root
def create_service credentials GoogleCredentials get_application_default return discovery build 'storage' 'v1' credentials credentials
@hook 'after_request' def security_headers json_header True response headers['Server'] 'Server'response headers['X-Content-Type-Options'] 'nosniff'response headers['X-Frame-Options'] 'DENY'response headers['X-XSS-Protection'] '1 mode block'response headers['Pragma'] 'no-cache'response headers['Cache-Control'] 'no-cache'response headers['Expires'] '0'if json_header response content_type 'application/json charset UTF-8'
@register filterdef timesince_or_never dt default None if default is None default _ 'Never' if isinstance dt datetime date return timesince dt else return default
@pytest mark parametrize 'reserved_code' RESERVED_PROJECT_CODES @pytest mark django_dbdef test_create_project_reserved_code english reserved_code with pytest raises ValidationError Project code reserved_code fullname 'whatever' source_language english save reserved_code_with_padding '%s' % reserved_code with pytest raises ValidationError Project code reserved_code_with_padding fullname 'whatever' source_language english save
def _privileged original @wraps original def permissionChecker self *args **kwargs if original __name__ not in self permissions raise IOError EPERM 'Operationnotpermitted' return original self *args **kwargs return permissionChecker
def _create_models_for_thread_and_first_message exploration_id state_name original_author_id subject text has_suggestion thread_id feedback_models FeedbackThreadModel generate_new_thread_id exploration_id thread feedback_models FeedbackThreadModel create exploration_id thread_id thread exploration_id exploration_idthread state_name state_namethread original_author_id original_author_idthread status feedback_models STATUS_CHOICES_OPENthread subject subjectthread has_suggestion has_suggestionthread put create_message exploration_id thread_id original_author_id feedback_models STATUS_CHOICES_OPEN subject text return thread_id
def setup_platform hass config add_devices discovery_info None name config get CONF_NAME heater_entity_id config get CONF_HEATER sensor_entity_id config get CONF_SENSOR min_temp config get CONF_MIN_TEMP max_temp config get CONF_MAX_TEMP target_temp config get CONF_TARGET_TEMP ac_mode config get CONF_AC_MODE min_cycle_duration config get CONF_MIN_DUR tolerance config get CONF_TOLERANCE add_devices [GenericThermostat hass name heater_entity_id sensor_entity_id min_temp max_temp target_temp ac_mode min_cycle_duration tolerance ]
def get_eol_chars text for eol_chars _os_name in EOL_CHARS if text find eol_chars > -1 return eol_chars
def worker_disable worker lbn profile 'default' return _worker_ctl worker lbn 'd' profile
def worker_disable worker lbn profile 'default' return _worker_ctl worker lbn 'd' profile
def scan_postfix_smtpd_line date log collector m re match 'NOQUEUE reject RCPTfrom *? *? from < *? >to < *? >' log if m message sender recipient m groups if recipient in collector['real_mail_addresses'] if 'Recipientaddressrejected Greylisted' in message returnm re search 'Clienthost\\[ *? \\]blockedusingzen spamhaus org * ' message if m message 'ipblocked ' + m group 2 m re search 'Senderaddress\\[ *@ * \\]blockedusingdbl spamhaus org * ' message if m message 'domainblocked ' + m group 2 collector['rejected-mail'] setdefault recipient [] append date sender message
def ec2_credentials_delete user_id None name None access_key None profile None **connection_args kstone auth profile **connection_args if name user_id user_get name name profile None **connection_args [name]['id']if not user_id return {'Error' 'CouldnotresolveUserID'}kstone ec2 delete user_id access_key return 'ec2key"{0}"deletedunderuserid"{1}"' format access_key user_id
def combine result prev if isinstance prev tuple list if len prev 3 raise AssertionError u'combine withlength%d' % len prev combined max prev[0] result[0] combine prev[1] result[1] combine prev[2] result[2] elif prev and result combined prev + u'\n\n' + result elif prev combined prevelse combined resultreturn combined
def readHeader file while ord file read 1 26 pass
def create_resource ext_mgr return wsgi Resource AttachmentsController ext_mgr
def compare_files self result_file ref_file self assertEqual result_file src ref_file src self assertEqual result_file dest ref_file dest self assertEqual result_file compare_key ref_file compare_key self assertEqual result_file size ref_file size self assertEqual result_file last_update ref_file last_update self assertEqual result_file src_type ref_file src_type self assertEqual result_file dest_type ref_file dest_type self assertEqual result_file operation_name ref_file operation_name
def compare_files self result_file ref_file self assertEqual result_file src ref_file src self assertEqual result_file dest ref_file dest self assertEqual result_file compare_key ref_file compare_key self assertEqual result_file size ref_file size self assertEqual result_file last_update ref_file last_update self assertEqual result_file src_type ref_file src_type self assertEqual result_file dest_type ref_file dest_type self assertEqual result_file operation_name ref_file operation_name
def get_public_ip_block module driver network_domain block_id False base_ip False if block_id is not False try block driver ex_get_public_ip_block block_id except DimensionDataAPIException e get_exception if e code 'RESOURCE_NOT_FOUND' or e code 'UNEXPECTED_ERROR' module exit_json changed False msg 'PublicIPBlockdoesnotexist' else module fail_json msg 'Unexpectederrorwhileretrievingblock %s' % e code module fail_json msg 'ErrorretrevingPublicIPBlock' + "'%s' %s" % block id e message else blocks list_public_ip_blocks module driver network_domain if blocks is not False block next block for block in blocks if block base_ip base_ip else module exit_json changed False msg "IPblockstartingwith'%s'doesnotexist " % base_ip return block
def create_https_certificates ssl_cert ssl_key if not sabnzbd HAVE_CRYPTOGRAPHY logging error T '%smissing' 'PythonCryptography' return Falsetry from sabnzbd utils certgen import generate_key generate_local_certprivate_key generate_key key_size 2048 output_file ssl_key cert generate_local_cert private_key days_valid 356 * 10 output_file ssl_cert LN u'SABnzbd' ON u'SABnzbd' CN u'SABnzbd' logging info 'Self-signedcertificatesgeneratedsuccessfully' except logging error T 'ErrorcreatingSSLkeyandcertificate' logging info 'Traceback ' exc_info True return Falsereturn True
def libvlc_video_get_size p_mi num f _Cfunctions get 'libvlc_video_get_size' None or _Cfunction 'libvlc_video_get_size' 1 1 2 2 None ctypes c_int MediaPlayer ctypes c_uint ctypes POINTER ctypes c_uint ctypes POINTER ctypes c_uint return f p_mi num
def _serialize_inventory inventory generation None data {field getattr inventory field for field in OUTPUT_INVENTORY_FIELDS}if generation data['resource_provider_generation'] generationreturn data
def getargspec obj if not callable obj raise TypeError '%sisnotcallable' % type obj try if inspect isfunction obj return inspect getargspec obj elif hasattr obj FUNC_OBJ_ATTR spec inspect getargspec getattr obj FUNC_OBJ_ATTR return inspect ArgSpec spec args[ 1] spec varargs spec keywords spec defaults elif inspect isclass obj return getargspec obj __init__ elif isinstance obj object return getargspec obj __call__ except NotImplementedError passraise NotImplementedError 'donotknowhowtogetargumentlistfor%s' % type obj
def test_goto_assignments_keyword Script 'in' goto_assignments
def test_goto_assignments_keyword Script 'in' goto_assignments
def _weight_function G weight if callable weight return weightif G is_multigraph return lambda u v d min attr get weight 1 for attr in d values return lambda u v data data get weight 1
def change_name command_table session **kwargs utils rename_command command_table 'codedeploy' 'deploy'
def change_name command_table session **kwargs utils rename_command command_table 'codedeploy' 'deploy'
def change_name command_table session **kwargs utils rename_command command_table 'codedeploy' 'deploy'
def getRound value return round value
def job_from_request from digits webapp import schedulerjob_id get_request_arg 'job_id' if job_id is None raise werkzeug exceptions BadRequest 'job_idisarequiredfield' job scheduler get_job job_id if job is None raise werkzeug exceptions NotFound 'Jobnotfound' else return job
def safe_version version return version replace ' ' '_'
def dmp_inject f u K front False f h dmp_to_dict f u {} v K ngens - 1 for f_monom g in f items g g to_dict for g_monom c in g items if front h[ g_monom + f_monom ] celse h[ f_monom + g_monom ] cw u + v + 1 return dmp_from_dict h w K dom w
def dmp_inject f u K front False f h dmp_to_dict f u {} v K ngens - 1 for f_monom g in f items g g to_dict for g_monom c in g items if front h[ g_monom + f_monom ] celse h[ f_monom + g_monom ] cw u + v + 1 return dmp_from_dict h w K dom w
def jenkins_build_results inQueue None builds None strats []if inQueue is None inQueue booleans strats append just pmap without_builds fixed_dictionaries dict inQueue inQueue if builds is None or builds is NO_BUILDS strats append without_builds if builds is None builds lists jenkins_builds average_size 1 if builds is not NO_BUILDS with_builds fixed_dictionaries dict inQueue inQueue builds builds property dictionaries text max_size 2 text max_size 2 average_size 1 max_size 2 strats append with_builds return one_of *strats
def jenkins_build_results inQueue None builds None strats []if inQueue is None inQueue booleans strats append just pmap without_builds fixed_dictionaries dict inQueue inQueue if builds is None or builds is NO_BUILDS strats append without_builds if builds is None builds lists jenkins_builds average_size 1 if builds is not NO_BUILDS with_builds fixed_dictionaries dict inQueue inQueue builds builds property dictionaries text max_size 2 text max_size 2 average_size 1 max_size 2 strats append with_builds return one_of *strats
def __virtual__ if not salt utils which 'rpm' return False 'Therpmexecutionmodulefailedtoload rpmbinaryisnotinthepath ' try os_grain __grains__['os'] lower os_family __grains__['os_family'] lower except Exception return False 'Therpmexecutionmodulefailedtoload failedtodetectosoros_familygrains ' enabled 'amazon' 'xcp' 'xenserver' 'VirtuozzoLinux' if os_family in ['redhat' 'suse'] or os_grain in enabled return __virtualname__return False 'Therpmexecutionmodulefailedtoload onlyavailableonredhat/susetypesystemsoramazon xcporxenserver '
def _serialize value if isinstance value float return unicode value upper elif isinstance value bool return unicode value lower return unicode value
@synchronized SAVE_CONFIG_LOCK def read_config path return _read_config path
@synchronized SAVE_CONFIG_LOCK def read_config path return _read_config path
def disconnect receiver signal Any sender Any weak True if signal is None raise errors DispatcherTypeError 'SignalcannotbeNone receiver %rsender %r ' % receiver sender if weak receiver saferef safeRef receiver senderkey id sender try signals connections[senderkey]receivers signals[signal]except KeyError raise errors DispatcherKeyError 'Noreceiversfoundforsignal%rfromsender%r' % signal sender try _removeOldBackRefs senderkey signal receiver receivers except ValueError raise errors DispatcherKeyError 'Noconnectiontoreceiver%sforsignal%sfromsender%s' % receiver signal sender _cleanupConnections senderkey signal
def disconnect receiver signal Any sender Any weak True if signal is None raise errors DispatcherTypeError 'SignalcannotbeNone receiver %rsender %r ' % receiver sender if weak receiver saferef safeRef receiver senderkey id sender try signals connections[senderkey]receivers signals[signal]except KeyError raise errors DispatcherKeyError 'Noreceiversfoundforsignal%rfromsender%r' % signal sender try _removeOldBackRefs senderkey signal receiver receivers except ValueError raise errors DispatcherKeyError 'Noconnectiontoreceiver%sforsignal%sfromsender%s' % receiver signal sender _cleanupConnections senderkey signal
def jsonrpc_error id code message data None return {'jsonrpc' '2 0' 'error' {'code' code 'message' message 'data' data} 'id' id}
def update_viewer dataset pv vis_batch rows cols mapback hasattr dataset 'mapback_for_viewer' display_batch dataset adjust_for_viewer vis_batch if display_batch ndim 2 display_batch dataset get_topological_view display_batch if mapback mapped_batch get_mapped_batch dataset vis_batch for i in xrange rows row_start cols * i for j in xrange cols pv add_patch display_batch[ row_start + j ] rescale False if mapback pv add_patch mapped_batch[ row_start + j ] rescale False
def build_request path body '' http_headers None unused_scheme unused_netloc path query unused_fragment urlparse urlsplit path env {'SERVER_PORT' 42 'REQUEST_METHOD' 'GET' 'SERVER_NAME' 'localhost' 'HTTP_CONTENT_TYPE' 'application/json' 'PATH_INFO' path 'wsgi input' cStringIO StringIO body }if query env['QUERY_STRING'] queryif http_headers for header value in http_headers header 'HTTP_%s' % header upper replace '-' '_' env[header] valuecgi_request api_request ApiRequest env return cgi_request
def __virtual__ if salt utils which 'brew' and __grains__['os'] 'MacOS' return __virtualname__return False 'Thebrewmodulecouldnotbeloaded brewnotfoundorgrainos MacOS'
def set_enabled_all objects enable for obj in objects obj setEnabled enable
def set_enabled_all objects enable for obj in objects obj setEnabled enable
def deprecated function instead if not isinstance function types FunctionType return function@wraps function def wrap *args **kwargs warnings warn 'Deprecated use%sinstead' % instead PyGIDeprecationWarning return function *args **kwargs return wrap
def blackwhite clip RGB [1 1 1] preserve_luminosity True if RGB 'CRT_phosphor' RGB [0 2125 0 7154 0 0721] R G B 1 0 * np array RGB / sum RGB if preserve_luminosity else 1 def fl im im R * im[ 0] + G * im[ 1] + B * im[ 2] return np dstack 3 * [im] astype 'uint8' return clip fl_image fl
def _logging original @wraps original def logger self request **routeArguments logger _get_logger self action REQUEST logger request_path request path method request method incidentIdentifier action serialize_task_id with action context d DeferredContext original self request **routeArguments def failure reason if reason check BadRequest code reason value coderesult reason value resultelse writeFailure reason logger LOG_SYSTEM code INTERNAL_SERVER_ERRORresult incidentIdentifierrequest setResponseCode code request responseHeaders setRawHeaders 'content-type' ['application/json'] return dumps result d addErrback failure d addActionFinish return d resultreturn logger
def _logging original @wraps original def logger self request **routeArguments logger _get_logger self action REQUEST logger request_path request path method request method incidentIdentifier action serialize_task_id with action context d DeferredContext original self request **routeArguments def failure reason if reason check BadRequest code reason value coderesult reason value resultelse writeFailure reason logger LOG_SYSTEM code INTERNAL_SERVER_ERRORresult incidentIdentifierrequest setResponseCode code request responseHeaders setRawHeaders 'content-type' ['application/json'] return dumps result d addErrback failure d addActionFinish return d resultreturn logger
def test_comments feature Feature from_string FEATURE10 assert_equals feature max_length 55
def _configs_from_dir conf_dir for filename in sorted os listdir conf_dir if filename startswith ' ' or not filename endswith ' ini' continueLOG debug 'Loadingconfigurationfrom %s' % filename try conf configobj ConfigObj os path join conf_dir filename except configobj ConfigObjError as ex LOG error "Errorinconfigurationfile'%s' %s" % os path join conf_dir filename ex raiseconf['DEFAULT'] dict desktop_root get_desktop_root build_dir get_build_dir yield conf
def setup_platform hass config add_devices discovery_info None gtfs_dir hass config path DEFAULT_PATH data config get CONF_DATA origin config get CONF_ORIGIN destination config get CONF_DESTINATION name config get CONF_NAME if not os path exists gtfs_dir os makedirs gtfs_dir if not os path exists os path join gtfs_dir data _LOGGER error 'ThegivenGTFSdatafile/folderwasnotfound ' return Falseimport pygtfssplit_file_name os path splitext data sqlite_file '{} sqlite' format split_file_name[0] joined_path os path join gtfs_dir sqlite_file gtfs pygtfs Schedule joined_path if len gtfs feeds < 1 pygtfs append_feed gtfs os path join gtfs_dir data add_devices [GTFSDepartureSensor gtfs name origin destination ]
def update_axes_image image_axes image image_axes set_array image h w image shape[ 2]image_axes set_extent 0 w h 0
def _get_videos course videos list get_videos_for_course course id VideoSortField created SortDirection desc for video in videos video['status'] convert_video_status video return videos
def get_validator segmentation_type return _supported[segmentation_type]
def rewrite_single_shorthand_state_decl data for sid states in six iteritems data if isinstance states six string_types data[sid] {states []}
def __virtual__ if 'zpool create' in __salt__ return Trueelse return False '{0}statemodulecanonlybeloadedonillumos Solaris SmartOS FreeBSD Linux ' format __virtualname__
@taskdef pip packages with virtualenv return run u'pipinstall%s' % packages
@taskdef pip packages with virtualenv return run u'pipinstall%s' % packages
def getbranches tree if isinstance tree tuple name subtree treea [name]for st in subtree a extend getbranches st return areturn []
def persist_uploads params if 'files' in params new_files []for upload_dataset in params['files'] f upload_dataset['file_data']if isinstance f FieldStorage assert not isinstance f file StringIO assert f file name '<fdopen>' local_filename util mkstemp_ln f file name 'upload_file_data_' f file close upload_dataset['file_data'] dict filename f filename local_filename local_filename elif type f dict and 'local_filename' not in f raise Exception 'UploadedfilewasencodedinawaynotunderstoodbyGalaxy ' if upload_dataset['url_paste'] and upload_dataset['url_paste'] strip '' upload_dataset['url_paste'] is_multi_byte datatypes sniff stream_to_file StringIO upload_dataset['url_paste'] prefix 'strio_url_paste_' else upload_dataset['url_paste'] Nonenew_files append upload_dataset params['files'] new_filesreturn params
def test_hashed_install_success script data tmpdir file_url path_to_url data packages / 'simple-1 0 tar gz' abspath with requirements_file 'simple2 1 0--hash sha256 9336af72ca661e6336eb87bc7de3e8844d853e3848c2b9bbd2e8bf01db88c2c7\n{simple}--hash sha256 393043e672415891885c9a2a0929b1af95fb866d6ca016b42d2e6ce53619b653' format simple file_url tmpdir as reqs_file script pip_install_local '-r' reqs_file abspath expect_error False
def getGeometricDifference first second return max first second / min first second
def _IsTestFilename filename if filename endswith '_test cc' or filename endswith '_unittest cc' or filename endswith '_regtest cc' return Trueelse return False
def safe_union a b if not isinstance a list raise TypeError 'Expectedfirstargumenttobealist butgot' + str type a assert isinstance b list c []for x in a + b if x not in c c append x return c
def safe_union a b if not isinstance a list raise TypeError 'Expectedfirstargumenttobealist butgot' + str type a assert isinstance b list c []for x in a + b if x not in c c append x return c
def no_debug_mode fn @functools wraps fn def wrapped *args **kwargs orig_mode config modeif orig_mode in ['DebugMode' 'DEBUG_MODE'] config mode 'FAST_RUN'try return fn *args **kwargs finally config mode orig_modereturn wrapped
def warn_config_absent sections argument log_printer if all argument not in section for section in sections values log_printer warn 'coalawillnotrunanyanalysis Didyouforgettogivethe`--{}`argument?' format argument return Truereturn False
def _unpickleFunction fullyQualifiedName from twisted python reflect import namedAnyreturn namedAny fullyQualifiedName
@non_atomic_requestsdef legacy_fulltheme_redirects request category None url request get_full_path replace '/full-themes' '/complete-themes' return redirect url permanent not settings DEBUG
@non_atomic_requestsdef legacy_fulltheme_redirects request category None url request get_full_path replace '/full-themes' '/complete-themes' return redirect url permanent not settings DEBUG
def getTricomplexTimesOther firstTricomplex otherTricomplex tricomplexTimesOther [getTricomplexTimesColumn firstTricomplex otherTricomplex[0] ]tricomplexTimesOther append getTricomplexTimesColumn firstTricomplex otherTricomplex[1] tricomplexTimesOther append getTricomplexTimesColumn firstTricomplex otherTricomplex[2] + firstTricomplex[2] return tricomplexTimesOther
def access sandbox_name asset_ids result util oauthgetm '%s/%s' % 'sandbox' 'access' {'sandbox' sandbox_name 'id' asset_ids} return result['response']['assets']
def access sandbox_name asset_ids result util oauthgetm '%s/%s' % 'sandbox' 'access' {'sandbox' sandbox_name 'id' asset_ids} return result['response']['assets']
def access sandbox_name asset_ids result util oauthgetm '%s/%s' % 'sandbox' 'access' {'sandbox' sandbox_name 'id' asset_ids} return result['response']['assets']
def identityPumpPolicy queue target while queue bytes queue get if bytes is None breaktarget dataReceived bytes
def identityPumpPolicy queue target while queue bytes queue get if bytes is None breaktarget dataReceived bytes
def test_maybe_update_geometry completionview config_stub qtbot with qtbot assertNotEmitted completionview update_geometry completionview _maybe_update_geometry config_stub data['completion']['shrink'] Truewith qtbot waitSignal completionview update_geometry completionview _maybe_update_geometry
def _getYearCentRE cent 0 3 distance 3 now MyTime now MyTime alternateNow cent lambda year f cent[0] t cent[1] str year [f t] exprset set cent now[0] year + i for i in -1 distance if len now and now[1] exprset set cent now[1] year + i for i in -1 distance return ' ? %s ' % ' ' join exprset if len exprset > 1 else '' join exprset
def CTRL c assert '@' < c < '_' return chr ord c - ord '@'
def _get_thumbnail_path image_path width height if image_path is None return None _ ext os path splitext image_path if ext in [' png' ' jpg' ' jpeg' ' gif'] thumbnail_path image_pathelse fingerprint cache hash_digest '{width}x{height}\n{image_path}' format **locals thumbnail_path os path join temp_path fingerprint + _IMAGE_EXTENSION _validate_thumbnail_currentness image_path thumbnail_path return thumbnail_path
def sinhm A A _asarray_square A return _maybe_real A 0 5 * expm A - expm - A
def _get_binding_info hostheader '' ipaddress '*' port 80 ret '{0} {1} {2}' format ipaddress port hostheader replace '' '' return ret
def _preprocess expr func None hint '_Integral' derivs expr atoms Derivative if not func funcs set union *[d atoms AppliedUndef for d in derivs] if len funcs 1 raise ValueError 'Thefunctioncannotbeautomaticallydetectedfor%s ' % expr func funcs pop fvars set func args if hint is None return expr func reps [ d d doit for d in derivs if not hint endswith '_Integral' or d has func or set d variables & fvars ]eq expr subs reps return eq func
def get_long_description title ROOT os path abspath os path dirname __file__ readme open os path join ROOT u'README rst' u'r' u'utf8' read body_tag u' Omitbadgesfromdocs'readme_body_start readme index body_tag assert readme_body_startreadme_body readme[ readme_body_start + len body_tag ]changelog open os path join ROOT u'changelog rst' u'r' u'utf8' read old_tag u' Omitolderchangesfrompackage'changelog_body_end changelog index old_tag assert changelog_body_endchangelog_body changelog[ changelog_body_end]bars u' ' * len title long_description u'\n% bars s\n% title s\n% bars s\n% readme_body s\n\n% changelog_body s\n\n_ Olderchangescanbefoundinthefulldocumentation _\n' % locals return long_description
def validate_table table_text font_colors font_colors_len_options [1 3 len table_text ]if len font_colors not in font_colors_len_options raise exceptions PlotlyError 'Oops font_colorsshouldbealistoflength1 3orlen text '
def validate_table table_text font_colors font_colors_len_options [1 3 len table_text ]if len font_colors not in font_colors_len_options raise exceptions PlotlyError 'Oops font_colorsshouldbealistoflength1 3orlen text '
def get_taxa_prevalence tax_counts tax_ratios apply_along_axis lambda x x / float sum x 0 tax_counts lineage_sums apply_along_axis lambda x sum x 1 tax_ratios total_count sum lineage_sums prevalence lineage_sums / float total_count prevalence prevalence - min prevalence / max prevalence - min prevalence return prevalence
def get_taxa_prevalence tax_counts tax_ratios apply_along_axis lambda x x / float sum x 0 tax_counts lineage_sums apply_along_axis lambda x sum x 1 tax_ratios total_count sum lineage_sums prevalence lineage_sums / float total_count prevalence prevalence - min prevalence / max prevalence - min prevalence return prevalence
@pytest mark parametrize 'parallel' [True False] def test_empty_quotes parallel read_basic table read_basic 'ab\n1""\n2""' parallel parallel expected Table [[1 2] [0 0]] names 'a' 'b' assert_table_equal table expected
@pytest mark parametrize 'parallel' [True False] def test_empty_quotes parallel read_basic table read_basic 'ab\n1""\n2""' parallel parallel expected Table [[1 2] [0 0]] names 'a' 'b' assert_table_equal table expected
def generate_binary_structure rank connectivity if connectivity < 1 connectivity 1if rank < 1 if connectivity < 1 return numpy array 0 dtype bool else return numpy array 1 dtype bool output numpy fabs numpy indices [3] * rank - 1 output numpy add reduce output 0 return numpy asarray output < connectivity dtype bool
def clear_dag_task_instances session settings Session TI TaskInstancetis session query TI filter TI dag_id in_ DAG_IDS all for ti in tis logging info 'DeletingTaskInstance {}' format ti session delete ti session commit
@box IndexType def box_index typ val c index make_index c context c builder typ value val classobj c pyapi unserialize c pyapi serialize_object typ pyclass arrayobj c box typ as_array index data indexobj c pyapi call_function_objargs classobj arrayobj return indexobj
def _endpoint_from_view_func view_func assert view_func is not None 'expectedviewfuncifendpointisnotprovided 'return view_func __name__
def resource_list name def make_responder list_all def responder return app response_class json_generator list_all root name expand is_expand mimetype 'application/json' responder __name__ 'all_{0}' format name return responderreturn make_responder
def load_macros module_name def _import module module_name module_name '__import__amodule avoidingrecursions'if module module_name __import__ module for module in CORE_MACROS _import module if module_name startswith 'hy core' returnfor module in EXTRA_MACROS _import module
def survey_getQuestionFromCode code series_id None s3db current s3dbsertable s3db survey_seriesq_ltable s3db survey_question_listqsntable s3db survey_questionif series_id None query sertable id series_id & q_ltable template_id sertable template_id & q_ltable question_id qsntable id & qsntable code code else query q_ltable template_id sertable template_id & q_ltable question_id qsntable id & qsntable code code record current db query select qsntable id qsntable code qsntable name qsntable type q_ltable posn limitby 0 1 first question {}if record None question_row record survey_questionquestion['qstn_id'] question_row idquestion['code'] question_row codequestion['name'] question_row namequestion['type'] question_row typequestion['posn'] record survey_question_list posnreturn question
def sm_flavor_get context sm_flavor return IMPL sm_flavor_get context sm_flavor
def _lltrace selector def traced cls *args **kwargs ret selector cls *args **kwargs if TRACED_OIDS is not None _trace_selector cls selector args ret return rettraced __name__ selector __name__traced __doc__ selector __doc__return traced
def move_file source dest import shutilshutil copy source dest remove_file source
def rootname filename if os path sep not in filename return ''else file_root _ filename split os path sep 1 return file_root
def slice_shape lst slices if atomp lst return []return [len lst[slices[0]] ] + slice_shape lst[0] slices[1 ]
def slice_shape lst slices if atomp lst return []return [len lst[slices[0]] ] + slice_shape lst[0] slices[1 ]
def connect_discussion_signals post_save connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PS_COUNT_DISCUSSIONS pre_delete connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PD_COUNT_DISCUSSIONS comment_was_flagged connect count_discussions_handler sender comment_model dispatch_uid COMMENT_WF_COUNT_DISCUSSIONS comment_was_posted connect count_comments_handler sender comment_model dispatch_uid COMMENT_WP_COUNT_COMMENTS pingback_was_posted connect count_pingbacks_handler sender comment_model dispatch_uid PINGBACK_WF_COUNT_PINGBACKS trackback_was_posted connect count_trackbacks_handler sender comment_model dispatch_uid TRACKBACK_WF_COUNT_TRACKBACKS
def connect_discussion_signals post_save connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PS_COUNT_DISCUSSIONS pre_delete connect count_discussions_handler sender comment_model dispatch_uid COMMENT_PD_COUNT_DISCUSSIONS comment_was_flagged connect count_discussions_handler sender comment_model dispatch_uid COMMENT_WF_COUNT_DISCUSSIONS comment_was_posted connect count_comments_handler sender comment_model dispatch_uid COMMENT_WP_COUNT_COMMENTS pingback_was_posted connect count_pingbacks_handler sender comment_model dispatch_uid PINGBACK_WF_COUNT_PINGBACKS trackback_was_posted connect count_trackbacks_handler sender comment_model dispatch_uid TRACKBACK_WF_COUNT_TRACKBACKS
def get_collection_summary_from_model collection_summary_model return collection_domain CollectionSummary collection_summary_model id collection_summary_model title collection_summary_model category collection_summary_model objective collection_summary_model language_code collection_summary_model tags collection_summary_model status collection_summary_model community_owned collection_summary_model owner_ids collection_summary_model editor_ids collection_summary_model viewer_ids collection_summary_model contributor_ids collection_summary_model contributors_summary collection_summary_model version collection_summary_model node_count collection_summary_model collection_model_created_on collection_summary_model collection_model_last_updated
def rowadd matlist index1 index2 k K result []for i in range len matlist[index1] matlist[index1][i] matlist[index1][i] + k * matlist[index2][i] return matlist
def rowadd matlist index1 index2 k K result []for i in range len matlist[index1] matlist[index1][i] matlist[index1][i] + k * matlist[index2][i] return matlist
@pytest mark networkdef test_install_package_which_contains_dev_in_name script result script pip 'install' 'django-devserver 0 0 4' devserver_folder script site_packages / 'devserver' egg_info_folder script site_packages / 'django_devserver-0 0 4-py%s egg-info' % pyversion assert devserver_folder in result files_created str result stdout assert egg_info_folder in result files_created str result
@commands u'wt' u'define' u'dict' @example u' wtbailiwick' def wiktionary bot trigger word trigger group 2 if word is None bot reply u'Youmusttellmewhattolookup ' return _etymology definitions wikt word if not definitions bot say u"Couldn'tgetanydefinitionsfor%s " % word returnresult format word definitions if len result < 150 result format word definitions 3 if len result < 150 result format word definitions 5 if len result > 300 result result[ 295] + u'[ ]' bot say result
@login_requireddef follow request username template_name 'relationships/relationship_add_confirm html' success_template_name 'relationships/relationship_add_success html' content_type 'text/html' to_user get_object_or_404 User username username from_user request usernext request GET get 'next' None if request method 'POST' relationship created Relationship objects get_or_create from_user from_user to_user to_user if request is_ajax response {'success' 'Success' 'to_user' {'username' to_user username 'user_id' to_user pk} 'from_user' {'username' from_user username 'user_id' from_user pk}}return HttpResponse json dumps response content_type 'application/json' if next return HttpResponseRedirect next template_name success_template_namecontext {'to_user' to_user 'next' next}return render_to_response template_name context context_instance RequestContext request content_type content_type
def get_sync_num KEY datetime date today cache add KEY 1 return cache get KEY
def hsv_value image_filter image *args **kwargs hsv color rgb2hsv image[ 3] value hsv[ 2] copy value image_filter value *args **kwargs hsv[ 2] convert value hsv dtype return color hsv2rgb hsv
@requires_application 'pyqt4' has ['uic'] def test_qt_designer from PyQt4 import QtGui uicapp QtGui QApplication instance if app is None app QtGui QApplication [] fname op join op dirname __file__ 'qt-designer ui' with warnings catch_warnings record True WindowTemplate TemplateBaseClass uic loadUiType fname class MainWindow TemplateBaseClass def __init__ self TemplateBaseClass __init__ self self ui WindowTemplate self ui setupUi self win MainWindow try canvas win ui canvascanvas central_widget add_view win show app processEvents finally win close return win
@requires_application 'pyqt4' has ['uic'] def test_qt_designer from PyQt4 import QtGui uicapp QtGui QApplication instance if app is None app QtGui QApplication [] fname op join op dirname __file__ 'qt-designer ui' with warnings catch_warnings record True WindowTemplate TemplateBaseClass uic loadUiType fname class MainWindow TemplateBaseClass def __init__ self TemplateBaseClass __init__ self self ui WindowTemplate self ui setupUi self win MainWindow try canvas win ui canvascanvas central_widget add_view win show app processEvents finally win close return win
@project_signals privacy_set_public connectdef queue_first_public_project_email user node meeting_creation if not meeting_creation sent_mail mails QueuedMail find Q 'user' 'eq' user & Q 'sent_at' 'ne' None & Q 'email_type' 'eq' mails NEW_PUBLIC_PROJECT_TYPE if not sent_mail count mails queue_mail to_addr user username mail mails NEW_PUBLIC_PROJECT send_at timezone now + settings NEW_PUBLIC_PROJECT_WAIT_TIME user user nid node _id fullname user fullname project_title node title
@project_signals privacy_set_public connectdef queue_first_public_project_email user node meeting_creation if not meeting_creation sent_mail mails QueuedMail find Q 'user' 'eq' user & Q 'sent_at' 'ne' None & Q 'email_type' 'eq' mails NEW_PUBLIC_PROJECT_TYPE if not sent_mail count mails queue_mail to_addr user username mail mails NEW_PUBLIC_PROJECT send_at timezone now + settings NEW_PUBLIC_PROJECT_WAIT_TIME user user nid node _id fullname user fullname project_title node title
def bitarray_to_bool data length results []for byte in data if six PY2 byte ord byte for bit_no in range 7 -1 -1 bit byte & 1 << bit_no bit bit 0 results append bit if len results length breakif len results length breakreturn np array results dtype u'b1'
def bitarray_to_bool data length results []for byte in data if six PY2 byte ord byte for bit_no in range 7 -1 -1 bit byte & 1 << bit_no bit bit 0 results append bit if len results length breakif len results length breakreturn np array results dtype u'b1'
@click command u'make-app' @click argument u'destination' @click argument u'app_name' def make_app destination app_name from frappe utils boilerplate import make_boilerplatemake_boilerplate destination app_name
@register filterdef bootstrap_setting value return get_bootstrap_setting value
@register filterdef bootstrap_setting value return get_bootstrap_setting value
@register filterdef bootstrap_setting value return get_bootstrap_setting value
def make_runner_scenarios pidlockfile_scenarios make_pidlockfile_scenarios scenarios {'simple' {'pidlockfile_scenario_name' 'simple'} 'pidfile-locked' {'pidlockfile_scenario_name' 'exist-other-pid-locked'}}for scenario in scenarios values if 'pidlockfile_scenario_name' in scenario pidlockfile_scenario pidlockfile_scenarios pop scenario['pidlockfile_scenario_name'] scenario['pid'] pidlockfile_scenario['pid']scenario['pidfile_path'] pidlockfile_scenario['path']scenario['pidfile_timeout'] 23scenario['pidlockfile_scenario'] pidlockfile_scenarioreturn scenarios
@require_authorized_admindef add_facility_teacher request title _ 'Addanewcoach' return _facility_user request new_user True is_teacher True title title
def get_controller_args_for_types func arg_types args kwargs result_args []result_kwargs {}argspec inspect getargspec func names argspec args[1 ]for index name in enumerate names if name in kwargs try value kwargs[name]value_type arg_types[index]value cast_argument_value value_type value_type value value result_kwargs[name] valueexcept IndexError LOG warning "Typedefinitionfor'%s'argumentof'%s'ismissing " name func __name__ continuetry value args pop 0 value_type arg_types[index]value cast_argument_value value_type value_type value value result_args append value except IndexError LOG warning "Typedefinitionfor'%s'argumentof'%s'ismissing " name func __name__ return result_args result_kwargs
def DuplicateFlags flagnames None flag_values gflags FlagValues for name in flagnames gflags DEFINE_boolean name False 'Flagnamed%s' % name flag_values flag_values return flag_values
@cython ccall@cython returns cython double def c_call x return x
def _loadExamples path examplesRaw safe_load path getContent examplesMap dict example['id'] example for example in examplesRaw if len examplesRaw len examplesMap identifiers [example['id'] for example in examplesRaw]duplicates list identifier for index identifier in enumerate identifiers if identifiers index identifier index raise Exception 'Duplicateidentifiersinexamplefile %r' % duplicates return examplesMap
def close_review_request review_request review_request_id description if review_request status ReviewRequest SUBMITTED logging warning u'Reviewrequest#%sisalreadysubmitted ' review_request_id returnif not review_request public review_request publish review_request submitter review_request close ReviewRequest SUBMITTED description description logging debug u'Reviewrequest#%sissetto%s ' review_request_id review_request status
def matchDLLArch filename if not is_win return Truefrom lib import pefileglobal _exe_machine_typeif _exe_machine_type is None exe_pe pefile PE sys executable fast_load True _exe_machine_type exe_pe FILE_HEADER Machineexe_pe close pe pefile PE filename fast_load True match_arch pe FILE_HEADER Machine _exe_machine_type pe close return match_arch
def matchDLLArch filename if not is_win return Truefrom lib import pefileglobal _exe_machine_typeif _exe_machine_type is None exe_pe pefile PE sys executable fast_load True _exe_machine_type exe_pe FILE_HEADER Machineexe_pe close pe pefile PE filename fast_load True match_arch pe FILE_HEADER Machine _exe_machine_type pe close return match_arch
def ip_for_event event eth dpid_to_str event dpid True split ' ' [0] replace '-' ' ' return EthAddr eth
def parse_linters linters result list for name in split_csp_str linters linter LINTERS get name if linter result append name linter else logging warn 'Linter`%s`notfound ' name return result
def main if len sys argv > 1 writeOutput '' join sys argv[1 ] else settings startMainLoopFromConstructor getNewRepository
def ownership_required function None def decorator request *args **kwargs group get_object_or_404 Group slug kwargs['slug'] if request user is_anonymous return HttpResponseRedirect reverse 'django contrib auth views login' if GroupMember objects is_owner group request user return function request *args **kwargs else raise Http404return decorator
def user_can_edit_setting_type user model return user has_perm u'{} change_{}' format model _meta app_label model _meta model_name
def user_can_edit_setting_type user model return user has_perm u'{} change_{}' format model _meta app_label model _meta model_name
def get_profile_model model Noneprofile_string getattr settings 'AUTH_PROFILE_MODULE' None if profile_string app_label model_label profile_string split ' ' model apps get_model app_label model_label return model
def get_profile_model model Noneprofile_string getattr settings 'AUTH_PROFILE_MODULE' None if profile_string app_label model_label profile_string split ' ' model apps get_model app_label model_label return model
def encryptAES_http_request s http_key m md5 new m update http_key http_key m hexdigest http_key str http_key cipher AES new http_key encrypted EncodeAES cipher s return encrypted http_key
def getLengthMinusOneMinimumOne elementList return max 1 len elementList - 1
def history_add paths state _open_state if HISTORY_KEY not in state state[HISTORY_KEY] set state[HISTORY_KEY] add tuple paths _save_state state
def history_add paths state _open_state if HISTORY_KEY not in state state[HISTORY_KEY] set state[HISTORY_KEY] add tuple paths _save_state state
def history_add paths state _open_state if HISTORY_KEY not in state state[HISTORY_KEY] set state[HISTORY_KEY] add tuple paths _save_state state
def webserver_for_test test url_path response_content app Klein @app route url_path def _respond request return response_contentfactory Site app resource endpoint serverFromString reactor 'tcp 0' listening endpoint listen factory def stop_port port test addCleanup port stopListening return portlistening addCallback stop_port return listening
def webserver_for_test test url_path response_content app Klein @app route url_path def _respond request return response_contentfactory Site app resource endpoint serverFromString reactor 'tcp 0' listening endpoint listen factory def stop_port port test addCleanup port stopListening return portlistening addCallback stop_port return listening
@register simple_tag takes_context True def review_request_actions context content []for top_level_action in get_top_level_actions try content append top_level_action render context except Exception logging exception u'Errorrenderingtop-levelaction%s' top_level_action action_id return u'' join content
def _is_ignorable_404 uri if getattr settings 'IGNORABLE_404_STARTS' import warningswarnings warn 'TheIGNORABLE_404_STARTSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for start in settings IGNORABLE_404_STARTS if uri startswith start return Trueif getattr settings 'IGNORABLE_404_ENDS' import warningswarnings warn 'TheIGNORABLE_404_ENDSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for end in settings IGNORABLE_404_ENDS if uri endswith end return Truereturn any pattern search uri for pattern in settings IGNORABLE_404_URLS
def _is_ignorable_404 uri if getattr settings 'IGNORABLE_404_STARTS' import warningswarnings warn 'TheIGNORABLE_404_STARTSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for start in settings IGNORABLE_404_STARTS if uri startswith start return Trueif getattr settings 'IGNORABLE_404_ENDS' import warningswarnings warn 'TheIGNORABLE_404_ENDSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for end in settings IGNORABLE_404_ENDS if uri endswith end return Truereturn any pattern search uri for pattern in settings IGNORABLE_404_URLS
def _is_ignorable_404 uri if getattr settings 'IGNORABLE_404_STARTS' import warningswarnings warn 'TheIGNORABLE_404_STARTSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for start in settings IGNORABLE_404_STARTS if uri startswith start return Trueif getattr settings 'IGNORABLE_404_ENDS' import warningswarnings warn 'TheIGNORABLE_404_ENDSsettinghasbeendeprecatedinfavorofIGNORABLE_404_URLS ' DeprecationWarning for end in settings IGNORABLE_404_ENDS if uri endswith end return Truereturn any pattern search uri for pattern in settings IGNORABLE_404_URLS
def allpairs x return [ s f for i f in enumerate x for s in x[ i + 1 ]]
def HandleRequestDirectly request client_address BaseHTTPServer HTTPServer process_request HttpServer request client_address
def get_logger name handlers l logbook Logger name for h in handlers if isinstance h list l handlers + helse l handlers append h return l
def get_edge_attributes G name if G is_multigraph edges G edges keys True data True else edges G edges data True return {x[ -1 ] x[ -1 ][name] for x in edges if name in x[ -1 ] }
def setlocal name value global_dict local_dict get_twill_glocals local_dict[name] value
@click group @click option '--repo-home' envvar 'REPO_HOME' default ' repo' metavar 'PATH' help 'Changestherepositoryfolderlocation ' @click option '--config' nargs 2 multiple True metavar 'KEYVALUE' help 'Overridesaconfigkey/valuepair ' @click option '--verbose' '-v' is_flag True help 'Enablesverbosemode ' @click version_option '1 0' @click pass_contextdef cli ctx repo_home config verbose ctx obj Repo os path abspath repo_home ctx obj verbose verbosefor key value in config ctx obj set_config key value
@click group @click option '--repo-home' envvar 'REPO_HOME' default ' repo' metavar 'PATH' help 'Changestherepositoryfolderlocation ' @click option '--config' nargs 2 multiple True metavar 'KEYVALUE' help 'Overridesaconfigkey/valuepair ' @click option '--verbose' '-v' is_flag True help 'Enablesverbosemode ' @click version_option '1 0' @click pass_contextdef cli ctx repo_home config verbose ctx obj Repo os path abspath repo_home ctx obj verbose verbosefor key value in config ctx obj set_config key value
def update_plex host port token library_name section_key get_music_section host port token library_name api_endpoint 'library/sections/{0}/refresh' format section_key api_endpoint append_token api_endpoint token url urljoin 'http //{0} {1}' format host port api_endpoint r requests get url return r
def update_plex host port token library_name section_key get_music_section host port token library_name api_endpoint 'library/sections/{0}/refresh' format section_key api_endpoint append_token api_endpoint token url urljoin 'http //{0} {1}' format host port api_endpoint r requests get url return r
def asset_type asset_type_choices 95 'asset' 100 'video' d100 random randint 0 100 for choice in asset_type_choices if d100 < choice[0] return choice[1]return asset_type_choices[ -1 ][1]
def lookahead n iterable for value in islice copy copy iterable n None return valueraise IndexError n
def lookahead n iterable for value in islice copy copy iterable n None return valueraise IndexError n
def lookahead n iterable for value in islice copy copy iterable n None return valueraise IndexError n
def generateVersionFileData version if version prerelease is not None prerelease ' prerelease %r' % version prerelease else prerelease ''data '#Thisisanauto-generatedfile Donoteditit \nfromtwisted pythonimportversions\nversion versions Version %r %s %s %s%s \n' % version package version major version minor version micro prerelease return data
def get_edit_filetypes pygments_exts _get_pygments_extensions favorite_exts [' py' ' R' ' jl' ' ipynb' ' md' ' pyw' ' pyx' ' C' ' CPP']other_exts [ext for ext in pygments_exts if ext not in favorite_exts ]all_exts tuple favorite_exts + other_exts text_filetypes _ 'Supportedtextfiles' all_exts return [text_filetypes] + EDIT_FILETYPES
@library global_functiondef nonprefixed_url viewname *args **kwargs return django_reverse viewname *args **kwargs
@library global_functiondef nonprefixed_url viewname *args **kwargs return django_reverse viewname *args **kwargs
@library global_functiondef nonprefixed_url viewname *args **kwargs return django_reverse viewname *args **kwargs
def setup_platform hass config add_devices discovery_info None if discovery_info is None or zwave NETWORK is None returnnode zwave NETWORK nodes[discovery_info[zwave const ATTR_NODE_ID]]value node values[discovery_info[zwave const ATTR_VALUE_ID]]value set_change_verified False if value node manufacturer_id strip and value node product_id strip specific_sensor_key int value node manufacturer_id 16 int value node product_id 16 value index if specific_sensor_key in DEVICE_MAPPINGS if DEVICE_MAPPINGS[specific_sensor_key] WORKAROUND_NO_OFF_EVENT re_arm_multiplier zwave get_config_value value node 9 or 4 add_devices [ZWaveTriggerSensor value 'motion' hass re_arm_multiplier * 8 ] returnif value command_class zwave const COMMAND_CLASS_SENSOR_BINARY add_devices [ZWaveBinarySensor value None ]
def get_freq_code freqstr if isinstance freqstr DateOffset freqstr freqstr rule_code freqstr n if isinstance freqstr tuple if is_integer freqstr[0] and is_integer freqstr[1] return freqstrelse try code _period_str_to_code freqstr[0] stride freqstr[1]except if is_integer freqstr[1] raisecode _period_str_to_code freqstr[1] stride freqstr[0]return code stride if is_integer freqstr return freqstr 1 base stride _base_and_stride freqstr code _period_str_to_code base return code stride
def get_freq_code freqstr if isinstance freqstr DateOffset freqstr freqstr rule_code freqstr n if isinstance freqstr tuple if is_integer freqstr[0] and is_integer freqstr[1] return freqstrelse try code _period_str_to_code freqstr[0] stride freqstr[1]except if is_integer freqstr[1] raisecode _period_str_to_code freqstr[1] stride freqstr[0]return code stride if is_integer freqstr return freqstr 1 base stride _base_and_stride freqstr code _period_str_to_code base return code stride
def _get_kernel_context return _kernel_context
def get_nipype_gitversion import osimport subprocesstry import nipypegitpath os path realpath os path join os path dirname nipype __file__ os path pardir except gitpath os getcwd gitpathgit os path join gitpath u' git' if not os path exists gitpathgit return Nonever Nonetry o _ subprocess Popen u'gitdescribe' shell True cwd gitpath stdout subprocess PIPE communicate except Exception passelse ver o decode strip split u'-' [ -1 ]return ver
def unmanagedDLL twain Environment GetEnvironmentVariable 'SystemRoot' + '\\twain dll' File Copy twain DLLS_DIR + '\\twain dll'
def unmanagedDLL twain Environment GetEnvironmentVariable 'SystemRoot' + '\\twain dll' File Copy twain DLLS_DIR + '\\twain dll'
def _find_dumb_path challbs preferences path []for i challb in enumerate challbs supported next True for pref_c in preferences if isinstance challb chall pref_c False if supported path append i else _report_no_chall_path return path
def _get_top_docs count top_qs WikiDocumentVisits objects select_related 'document' filter period LAST_90_DAYS order_by '-visits' [ count]return [v document for v in top_qs]
def _get_top_docs count top_qs WikiDocumentVisits objects select_related 'document' filter period LAST_90_DAYS order_by '-visits' [ count]return [v document for v in top_qs]
def test_takes_args assert not hug introspect takes_args function_with_kwargs assert hug introspect takes_args function_with_args assert not hug introspect takes_args function_with_neither assert hug introspect takes_args function_with_both
def some_function input input np asarray input output fortran_module some_function input ravel return output reshape input shape
@require_POST@csrf_protectdef hardlink request if not test_user_authenticated request return login request next '/cobbler_web/hardlink' expired True remote background_hardlink {} request session['token'] return HttpResponseRedirect '/cobbler_web/task_created'
def _get_block_summary_totals course_data block_summary_counts {}unique_course_counts {}for course in course_data block_counts course get BLOCK_COUNTS_KEY for count_label value in block_counts items unique 0if value > 0 unique 1if count_label in block_summary_counts block_summary_counts[count_label] + valueunique_course_counts[count_label] + uniqueelse block_summary_counts[count_label] valueunique_course_counts[count_label] uniquereturn block_summary_counts unique_course_counts
def _get_block_summary_totals course_data block_summary_counts {}unique_course_counts {}for course in course_data block_counts course get BLOCK_COUNTS_KEY for count_label value in block_counts items unique 0if value > 0 unique 1if count_label in block_summary_counts block_summary_counts[count_label] + valueunique_course_counts[count_label] + uniqueelse block_summary_counts[count_label] valueunique_course_counts[count_label] uniquereturn block_summary_counts unique_course_counts
def insertGridPointPair gridPoint gridPointInsetX gridPoints isJunctionWide paths pixelTable yIntersectionPath width linePath getNonIntersectingGridPointLine gridPointInsetX isJunctionWide paths pixelTable yIntersectionPath width insertGridPointPairWithLinePath gridPoint gridPointInsetX gridPoints isJunctionWide linePath paths pixelTable yIntersectionPath width
def fetch url body None headers None fetcher getDefaultFetcher return fetcher fetch url body headers
def main reactor jid secret return Client reactor JID jid secret finished
def cache tex_root name generate return cache_local tex_root name generate
def do_SpnCreate po if g_createdSCP is None _option_error po 'ScpCreatemusthavebeenspecifiedbeforeSpnCreate' spns win32security DsGetSpn dscon DS_SPN_SERVICE _get_option po 'service_class' g_createdSCP distinguishedName _get_option po 'port' 0 None None spn spns[0]log 2 'CreatedSPN %s' spn global g_createdSPNLastg_createdSPNLast spng_createdSPNs append spn return spn
def emptyNet net Mininet controller Controller info '***Addingcontroller\n' net addController 'c0' info '***Addinghosts\n' h1 net addHost 'h1' ip '10 0 0 1' h2 net addHost 'h2' ip '10 0 0 2' info '***Addingswitch\n' s3 net addSwitch 's3' info '***Creatinglinks\n' net addLink h1 s3 net addLink h2 s3 info '***Startingnetwork\n' net start info '***RunningCLI\n' CLI net info '***Stoppingnetwork' net stop
def commands *command_list def add_attribute function if not hasattr function u'commands' function commands []function commands extend command_list return functionreturn add_attribute
def commands *command_list def add_attribute function if not hasattr function u'commands' function commands []function commands extend command_list return functionreturn add_attribute
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def delete_build_requests_with_no_instance_uuid context count orphaned_build_requests _get_build_requests_with_no_instance_uuid context count done 0for orphan_buildreq in orphaned_build_requests result _destroy_in_db context orphan_buildreq id if result done + 1return len orphaned_build_requests done
def getTransferredNestedRings insides loop transferredSurroundings []for insideIndex in xrange len insides - 1 -1 -1 insideSurrounding insides[insideIndex]if isPathInsideLoop loop insideSurrounding boundary transferredSurroundings append insideSurrounding del insides[insideIndex]return transferredSurroundings
def change_value global _GROWL_REG_GROWL_REG False
def imresize im sz pil_im Image fromarray uint8 im return array pil_im resize sz
def imresize im sz pil_im Image fromarray uint8 im return array pil_im resize sz
def _extract_argmax_and_embed embedding output_projection None update_embedding True def loop_function prev _ 'functionthatfeedpreviousmodeloutputratherthangroundtruth 'if output_projection is not None prev tf nn xw_plus_b prev output_projection[0] output_projection[1] prev_symbol tf argmax prev 1 emb_prev tf nn embedding_lookup embedding prev_symbol if not update_embedding emb_prev tf stop_gradient emb_prev return emb_prevreturn loop_function
def _extract_argmax_and_embed embedding output_projection None update_embedding True def loop_function prev _ 'functionthatfeedpreviousmodeloutputratherthangroundtruth 'if output_projection is not None prev tf nn xw_plus_b prev output_projection[0] output_projection[1] prev_symbol tf argmax prev 1 emb_prev tf nn embedding_lookup embedding prev_symbol if not update_embedding emb_prev tf stop_gradient emb_prev return emb_prevreturn loop_function
def get_args parser argparse ArgumentParser epilog 'ToimportbookmarksfromChromium FirefoxorIE exportthemtoHTMLinyourbrowsersbookmarkmanager Bydefault thisscriptwilloutputinaquickmarksformat ' parser add_argument 'browser' help 'Whichbrowser? chromium firefox ' choices ['chromium' 'firefox' 'ie'] metavar 'browser' parser add_argument '-b' help 'Outputinbookmarkformat ' dest 'bookmark_format' action 'store_true' default False required False parser add_argument 'bookmarks' help 'Bookmarksfile htmlformat ' args parser parse_args return args
def _construct_target_list targets target_entries []for entry in targets if not isinstance entry Gtk TargetEntry entry Gtk TargetEntry new *entry target_entries append entry return target_entries
def _construct_target_list targets target_entries []for entry in targets if not isinstance entry Gtk TargetEntry entry Gtk TargetEntry new *entry target_entries append entry return target_entries
def _construct_target_list targets target_entries []for entry in targets if not isinstance entry Gtk TargetEntry entry Gtk TargetEntry new *entry target_entries append entry return target_entries
def _find_permutation a b t np argsort a u np argsort b u_ _inverse_permutation u return t[u_]
@memoize 'media fetch_size' time 3600 def _fetch_image_size url referer request _initialize_request url referer if not request return Noneparser ImageFile Parser response Nonetry response urllib2 urlopen request while True chunk response read 1024 if not chunk breakparser feed chunk if parser image return parser image sizeexcept urllib2 URLError return Nonefinally if response response close
@memoize 'media fetch_size' time 3600 def _fetch_image_size url referer request _initialize_request url referer if not request return Noneparser ImageFile Parser response Nonetry response urllib2 urlopen request while True chunk response read 1024 if not chunk breakparser feed chunk if parser image return parser image sizeexcept urllib2 URLError return Nonefinally if response response close
def chunkize_serial iterable chunksize as_numpy False it iter iterable while True if as_numpy wrapped_chunk [[np array doc for doc in itertools islice it int chunksize ]]else wrapped_chunk [list itertools islice it int chunksize ]if not wrapped_chunk[0] break yield wrapped_chunk pop
def chunkize_serial iterable chunksize as_numpy False it iter iterable while True if as_numpy wrapped_chunk [[np array doc for doc in itertools islice it int chunksize ]]else wrapped_chunk [list itertools islice it int chunksize ]if not wrapped_chunk[0] break yield wrapped_chunk pop
def restart container timeout 10 client _get_client status base_status copy try dcontainer _get_container_infos container ['Id']client restart dcontainer timeout timeout if is_running dcontainer _valid status comment 'Container{0}wasrestarted' format container id_ container else _invalid status except Exception _invalid status id_ container out traceback format_exc comment 'Anexceptionoccurredwhilerestartingyourcontainer{0}' format container __salt__['mine send'] 'dockerng ps' verbose True all True host True return status
def restart container timeout 10 client _get_client status base_status copy try dcontainer _get_container_infos container ['Id']client restart dcontainer timeout timeout if is_running dcontainer _valid status comment 'Container{0}wasrestarted' format container id_ container else _invalid status except Exception _invalid status id_ container out traceback format_exc comment 'Anexceptionoccurredwhilerestartingyourcontainer{0}' format container __salt__['mine send'] 'dockerng ps' verbose True all True host True return status
def get_format format None if isinstance format type and issubclass format Base return formatelif not isinstance format string_types or format is None raise TypeError u'Formattermustasubclassorinstanceofasubclassof{0 r}orastringgivingthenameoftheformatter Validformatternamesare [{1}]' format Base u' ' join Base registry if format is None format u'generic'format_lower format lower if format_lower in Base registry return Base registry[format_lower]raise ValueError u'Unknownformat{0 r} Validformatternamesare [{1}]' format format u' ' join Base registry
def install_plugin site plugin_name output_dir None show_install_notes False LOGGER notice u"Installingplugin'{0}'" format plugin_name plugin_installer_info site plugin_manager getPluginByName u'plugin' u'Command' if plugin_installer_info is None LOGGER error u'Internalerror cannotfindthe"plugin"pluginwhichissupposedtocomewithNikola ' return Falseif not plugin_installer_info is_activated site plugin_manager activatePluginByName plugin_installer_info name plugin_installer_info plugin_object set_site site plugin_installer plugin_installer_info plugin_objectoptions {}for option in plugin_installer cmd_options options[option[u'name']] option[u'default']options[u'install'] plugin_nameoptions[u'output_dir'] output_diroptions[u'show_install_notes'] show_install_notesif plugin_installer execute options options > 0 return Falsesite plugin_manager collectPlugins site compiler_extensions site _activate_plugins_of_category u'CompilerExtension' return True
def connectableEndpoint debug False reactor MemoryReactorClock clientEndpoint TCP4ClientEndpoint reactor '0 0 0 0' 4321 serverEndpoint TCP4ServerEndpoint reactor 4321 serverEndpoint listen Factory forProtocol Protocol return clientEndpoint ConnectionCompleter reactor
def is_valid_git_sha1 hash if len hash 40 return Falsetry value int hash 16 except ValueError return Falsereturn True
def convert_to_grayscale imlist for imname in imlist im Image open imname convert 'L' im save imname
def test_ast_good_yield can_compile u' yield1 '
def absent name region None key None keyid None profile None ret {'name' name 'result' True 'comment' '' 'changes' {}}exists __salt__['boto_dynamodb exists'] name region key keyid profile if not exists ret['comment'] 'DynamoDBtable{0}doesnotexist' format name return retif __opts__['test'] ret['comment'] 'DynamoDBtable{0}issettobedeleted' format name ret['result'] Nonereturn retis_deleted __salt__['boto_dynamodb delete'] name region key keyid profile if is_deleted ret['comment'] 'DeletedDynamoDBtable{0}' format name ret['changes'] setdefault 'old' 'Table{0}exists' format name ret['changes'] setdefault 'new' 'Table{0}deleted' format name else ret['comment'] 'FailedtodeleteDynamoDBtable{0}' format name ret['result'] Falsereturn ret
def returns rtype def check_returns f def new_f *args **kwds result f *args **kwds assert isinstance result rtype 'returnvalue%rdoesnotmatch%s' % result rtype return resultnew_f __name__ f __name__return new_freturn check_returns
def absent name user None password None host None port None authdb None ret {'name' name 'changes' {} 'result' True 'comment' ''}if __salt__['mongodb db_exists'] name user password host port authdb authdb if __opts__['test'] ret['result'] Noneret['comment'] 'Database{0}ispresentandneedstoberemoved' format name return retif __salt__['mongodb db_remove'] name user password host port authdb authdb ret['comment'] 'Database{0}hasbeenremoved' format name ret['changes'][name] 'Absent'return retret['comment'] 'User{0}isnotpresent soitcannotberemoved' format name return ret
def absent name user None password None host None port None authdb None ret {'name' name 'changes' {} 'result' True 'comment' ''}if __salt__['mongodb db_exists'] name user password host port authdb authdb if __opts__['test'] ret['result'] Noneret['comment'] 'Database{0}ispresentandneedstoberemoved' format name return retif __salt__['mongodb db_remove'] name user password host port authdb authdb ret['comment'] 'Database{0}hasbeenremoved' format name ret['changes'][name] 'Absent'return retret['comment'] 'User{0}isnotpresent soitcannotberemoved' format name return ret
def absent name user None password None host None port None authdb None ret {'name' name 'changes' {} 'result' True 'comment' ''}if __salt__['mongodb db_exists'] name user password host port authdb authdb if __opts__['test'] ret['result'] Noneret['comment'] 'Database{0}ispresentandneedstoberemoved' format name return retif __salt__['mongodb db_remove'] name user password host port authdb authdb ret['comment'] 'Database{0}hasbeenremoved' format name ret['changes'][name] 'Absent'return retret['comment'] 'User{0}isnotpresent soitcannotberemoved' format name return ret
def absent name user None password None host None port None authdb None ret {'name' name 'changes' {} 'result' True 'comment' ''}if __salt__['mongodb db_exists'] name user password host port authdb authdb if __opts__['test'] ret['result'] Noneret['comment'] 'Database{0}ispresentandneedstoberemoved' format name return retif __salt__['mongodb db_remove'] name user password host port authdb authdb ret['comment'] 'Database{0}hasbeenremoved' format name ret['changes'][name] 'Absent'return retret['comment'] 'User{0}isnotpresent soitcannotberemoved' format name return ret
def absent name user None password None host None port None authdb None ret {'name' name 'changes' {} 'result' True 'comment' ''}if __salt__['mongodb db_exists'] name user password host port authdb authdb if __opts__['test'] ret['result'] Noneret['comment'] 'Database{0}ispresentandneedstoberemoved' format name return retif __salt__['mongodb db_remove'] name user password host port authdb authdb ret['comment'] 'Database{0}hasbeenremoved' format name ret['changes'][name] 'Absent'return retret['comment'] 'User{0}isnotpresent soitcannotberemoved' format name return ret
def execute_java_async classpath main jvm_options None args None executor None workunit_factory None workunit_name None workunit_labels None cwd None workunit_log_config None distribution None create_synthetic_jar True synthetic_jar_dir None runner _get_runner classpath main jvm_options args executor cwd distribution create_synthetic_jar synthetic_jar_dir workunit_name workunit_name or main return execute_runner_async runner workunit_factory workunit_factory workunit_name workunit_name workunit_labels workunit_labels workunit_log_config workunit_log_config
def colors pass
def append_random_bottlecap_phrase message bottlecap Nonetry wp WikiPage get Frontpage g wiki_page_gold_bottlecaps split_list re split '^[*-]' wp content flags re MULTILINE choices [item strip for item in split_list if item strip ]if len choices bottlecap choice choices except NotFound passif bottlecap message + '\n\n>' + bottlecap return message
def _elements_to_dict data position obj_end opts result opts document_class pos positionfor key value pos in _iterate_elements data position obj_end opts result[key] valueif pos obj_end raise InvalidBSON 'badobjectorelementlength' return result
def get_useragent with open settings USERAGENTS 'r' as f agents f readlines selection random randint 0 len agents - 1 agent agents[selection]return agent strip
def get_useragent with open settings USERAGENTS 'r' as f agents f readlines selection random randint 0 len agents - 1 agent agents[selection]return agent strip
def get_useragent with open settings USERAGENTS 'r' as f agents f readlines selection random randint 0 len agents - 1 agent agents[selection]return agent strip
def calculate_results sim_params env data_portal splits None txns None commissions None txns txns or [] splits splits or {} commissions commissions or {} perf_tracker perf PerformanceTracker sim_params get_calendar 'NYSE' env results []for date in sim_params sessions for txn in filter lambda txn txn dt date txns perf_tracker process_transaction txn try commissions_for_date commissions[date]for comm in commissions_for_date perf_tracker process_commission comm except KeyError passtry splits_for_date splits[date]perf_tracker handle_splits splits_for_date except KeyError passmsg perf_tracker handle_market_close date data_portal perf_tracker position_tracker sync_last_sale_prices date False data_portal msg['account'] perf_tracker get_account True results append copy deepcopy msg return results
def calculate_results sim_params env data_portal splits None txns None commissions None txns txns or [] splits splits or {} commissions commissions or {} perf_tracker perf PerformanceTracker sim_params get_calendar 'NYSE' env results []for date in sim_params sessions for txn in filter lambda txn txn dt date txns perf_tracker process_transaction txn try commissions_for_date commissions[date]for comm in commissions_for_date perf_tracker process_commission comm except KeyError passtry splits_for_date splits[date]perf_tracker handle_splits splits_for_date except KeyError passmsg perf_tracker handle_market_close date data_portal perf_tracker position_tracker sync_last_sale_prices date False data_portal msg['account'] perf_tracker get_account True results append copy deepcopy msg return results
def remove_master_course_staff_from_ccx master_course ccx_key display_name send_email True list_staff list_with_level master_course 'staff' list_instructor list_with_level master_course 'instructor' with ccx_course ccx_key as course_ccx list_staff_ccx list_with_level course_ccx 'staff' list_instructor_ccx list_with_level course_ccx 'instructor' email_params get_email_params course_ccx auto_enroll True course_key ccx_key display_name display_name for staff in list_staff if staff in list_staff_ccx revoke_access course_ccx staff 'staff' unenroll_email course_id ccx_key student_email staff email email_students send_email email_params email_params for instructor in list_instructor if instructor in list_instructor_ccx revoke_access course_ccx instructor 'instructor' unenroll_email course_id ccx_key student_email instructor email email_students send_email email_params email_params
def _get_regex data position dummy0 opts dummy1 pattern position _get_c_string data position opts bson_flags position _get_c_string data position opts bson_re Regex pattern bson_flags return bson_re position
def create use_app call_reuse False return default_app create
def get_patterns_for_title path title app apphook_pool get_apphook title page application_urls url_patterns []for pattern_list in get_app_urls app get_urls title page title language if path and not path endswith '/' path + '/'page_id title page idurl_patterns + recurse_patterns path pattern_list page_id return url_patterns
def add_certificate_exception course_key student certificate_exception if len CertificateWhitelist get_certificate_white_list course_key student > 0 raise ValueError _ 'Student username/email {user} alreadyincertificateexceptionlist ' format user student username certificate_white_list __ CertificateWhitelist objects get_or_create user student course_id course_key defaults {'whitelist' True 'notes' certificate_exception get 'notes' '' } generated_certificate GeneratedCertificate eligible_certificates filter user student course_id course_key status CertificateStatuses downloadable first exception dict {'id' certificate_white_list id 'user_email' student email 'user_name' student username 'user_id' student id 'certificate_generated' generated_certificate and generated_certificate created_date strftime '%B%d %Y' 'created' certificate_white_list created strftime '%A %B%d %Y' } return exception
def computeObjectKey id generationNum encryptionKey keyLengthBytes algorithm 'RC4' key encryptionKey + struct pack '<i' id [ 3] + struct pack '<i' generationNum [ 2] if algorithm 'AES' key + 'sAlT'key hashlib md5 key digest if keyLengthBytes + 5 < 16 key key[ keyLengthBytes + 5 ]else key key[ 16]return key
def echo data '' return data
def prioritize while True hp_qs Message objects high_priority using u'default' mp_qs Message objects medium_priority using u'default' lp_qs Message objects low_priority using u'default' while hp_qs count or mp_qs count while hp_qs count for message in hp_qs order_by u'when_added' yield message while hp_qs count 0 and mp_qs count yield mp_qs order_by u'when_added' [0] while hp_qs count 0 and mp_qs count 0 and lp_qs count yield lp_qs order_by u'when_added' [0] if Message objects non_deferred using u'default' count 0 break
def reservation_create context uuid usage project_id resource delta expire return IMPL reservation_create context uuid usage project_id resource delta expire
def _shouldRelocateCommand cmd return cmd in _RELOCATABLE
def build_inverse_barcode_map seqs inverse_map {}map_count defaultdict int for label seq in seqs map_id seq_id label split [ 2]map_id map_id split '_' [0]inverse_map[seq_id] map_idmap_count[map_id] + 1return inverse_map map_count
@_ensure_existsdef state name contextkey 'docker state {0}' format name if contextkey in __context__ return __context__[contextkey]c_info inspect_container name if c_info get 'State' {} get 'Paused' False __context__[contextkey] 'paused'elif c_info get 'State' {} get 'Running' False __context__[contextkey] 'running'else __context__[contextkey] 'stopped'return __context__[contextkey]
def string_at ptr size -1 return _string_at ptr size
def test_zero_precision_recall try old_error_settings np seterr all 'raise' y_real np array [['a' 'b' 'c']] y_pred np array [[]] assert_array_almost_equal precision_score y_real y_pred 0 0 2 assert_array_almost_equal recall_score y_real y_pred 0 0 2 assert_array_almost_equal f1_score y_real y_pred 0 0 2 finally np seterr **old_error_settings
def test_zero_precision_recall try old_error_settings np seterr all 'raise' y_real np array [['a' 'b' 'c']] y_pred np array [[]] assert_array_almost_equal precision_score y_real y_pred 0 0 2 assert_array_almost_equal recall_score y_real y_pred 0 0 2 assert_array_almost_equal f1_score y_real y_pred 0 0 2 finally np seterr **old_error_settings
def test_zero_precision_recall try old_error_settings np seterr all 'raise' y_real np array [['a' 'b' 'c']] y_pred np array [[]] assert_array_almost_equal precision_score y_real y_pred 0 0 2 assert_array_almost_equal recall_score y_real y_pred 0 0 2 assert_array_almost_equal f1_score y_real y_pred 0 0 2 finally np seterr **old_error_settings
def ValidateXsrfToken token action user_str _MakeUserStr token_obj memcache get token namespace MEMCACHE_NAMESPACE if not token_obj return False token_str token_action token_objif user_str token_str or action token_action return Falsereturn True
def check_journaled con warning critical perf_data warning warning or 20 critical critical or 40 try data get_server_status con journaled data['dur']['journaledMB']message 'Journaled % 2fMB' % journaled message + performance_data perf_data [ '% 2f' % journaled 'journaled' warning critical ] return check_levels journaled warning critical message except Exception as e return exit_with_general_critical e
def test_from_float method prec exprange restricted_range itr stat for rounding in RoundModes context rounding roundingfor i in range 1000 f randfloat op f if method startswith 'context ' else 'sNaN' f t TestSet method op try if not convert t continuecallfuncs t verify t stat except VerifyError as err log err
def list_minus l minus return [o for o in l if o not in minus ]
def _has_eeg_average_ref_proj projs check_active False for proj in projs if proj['desc'] 'AverageEEGreference' or proj['kind'] FIFF FIFFV_MNE_PROJ_ITEM_EEG_AVREF if not check_active or proj['active'] return Truereturn False
def _has_eeg_average_ref_proj projs check_active False for proj in projs if proj['desc'] 'AverageEEGreference' or proj['kind'] FIFF FIFFV_MNE_PROJ_ITEM_EEG_AVREF if not check_active or proj['active'] return Truereturn False
def enable_module module if not is_module_enabled module run_as_root 'a2enmod%s' % module
def copy_to_master registry xml_parent data cm XML SubElement xml_parent 'com michelin cio hudson plugins copytoslave CopyToMasterNotifier' cm set 'plugin' 'copy-to-slave' XML SubElement cm 'includes' text ' ' join data get 'includes' [''] XML SubElement cm 'excludes' text ' ' join data get 'excludes' [''] mappings [ 'run-after-result' 'runAfterResultFinalised' True 'destination' 'destinationFolder' '' ]helpers convert_mapping_to_xml cm data mappings fail_required True if data get 'destination' '' XML SubElement cm 'overrideDestinationFolder' text 'true'
def get_cluster_host req params cluster_version None if cluster_version is not False and req api_version_request matches cluster_version cluster_name params get 'cluster' msg _ 'Oneandonlyoneofclusterandhostmustbeset ' else cluster_name Nonemsg _ 'Hostfieldismissing ' host params get 'host' if bool cluster_name bool host raise exception InvalidInput reason msg return cluster_name host
def role role def wrapper handler_method def check_login self *args **kwargs user users get_current_user if not user if self request method 'GET' logging debug 'Notuser-aborting' self error 403 else logging debug 'Usernotloggedin--forcelogin' self redirect users create_login_url self request uri elif role 'user' or role 'admin' and users is_current_user_admin logging debug 'Roleis%ssowillallowhandler' role handler_method self *args **kwargs elif self request method 'GET' logging debug 'Unknownrole %s onGET' role self redirect '/403 html' else logging debug 'Unknownrole %s' role self error 403 return check_loginreturn wrapper
def _add_var var value makeconf _get_makeconf layman 'source/var/lib/layman/make conf'fullvar '{0} "{1}"' format var value if __salt__['file contains'] makeconf layman cmd ['sed' '-i' '/{0}/i\\{1}' format layman replace '/' '\\/' fullvar makeconf]__salt__['cmd run'] cmd else __salt__['file append'] makeconf fullvar
def parse file return Parser file parse
def parse file return Parser file parse
def writewav24 filename rate data a32 _np asarray data dtype _np int32 if a32 ndim 1 a32 shape a32 shape + 1 a8 a32 reshape a32 shape + 1 >> _np array [0 8 16] & 255 wavdata a8 astype _np uint8 tostring w _wave open filename 'wb' w setnchannels a32 shape[1] w setsampwidth 3 w setframerate rate w writeframes wavdata w close
def saveimage filename im if len im shape 3 cv2 imwrite filename 255 * im[ -1 ] else cv2 imwrite filename 255 * im
def boxplot_runtimes runtimes pred_type configuration fig ax1 plt subplots figsize 10 6 bp plt boxplot runtimes cls_infos [ '%s\n %d%s ' % estimator_conf['name'] estimator_conf['complexity_computer'] estimator_conf['instance'] estimator_conf['complexity_label'] for estimator_conf in configuration['estimators']]plt setp ax1 xticklabels cls_infos plt setp bp['boxes'] color 'black' plt setp bp['whiskers'] color 'black' plt setp bp['fliers'] color 'red' marker '+' ax1 yaxis grid True linestyle '-' which 'major' color 'lightgrey' alpha 0 5 ax1 set_axisbelow True ax1 set_title 'PredictionTimeperInstance-%s %dfeats ' % pred_type capitalize configuration['n_features'] ax1 set_ylabel 'PredictionTime us ' plt show
def make_csrf_token req session_id ts None ts '%x' % ts if ts is not None else time time payload [req server secret session_id ts]return '%s-%s' % ts b64w sha512b64 '-' join payload
def make_csrf_token req session_id ts None ts '%x' % ts if ts is not None else time time payload [req server secret session_id ts]return '%s-%s' % ts b64w sha512b64 '-' join payload
@skip_unless_environ 'GALAXY_TEST_INCLUDE_SLOW' def test_conda_resolution_failure base_path mkdtemp prefix 'x' * 80 try job_dir os path join base_path '000' dependency_manager DependencyManager base_path resolver CondaDependencyResolver dependency_manager auto_init True auto_install True use_path_exec False conda_context resolver conda_contextassert len list conda_util installed_conda_targets conda_context 0 dependency resolver resolve name 'samtools' version None type 'package' job_directory job_dir assert dependency shell_commands None is None installed_targets list conda_util installed_conda_targets conda_context assert len installed_targets 0 finally shutil rmtree base_path
@skip_unless_environ 'GALAXY_TEST_INCLUDE_SLOW' def test_conda_resolution_failure base_path mkdtemp prefix 'x' * 80 try job_dir os path join base_path '000' dependency_manager DependencyManager base_path resolver CondaDependencyResolver dependency_manager auto_init True auto_install True use_path_exec False conda_context resolver conda_contextassert len list conda_util installed_conda_targets conda_context 0 dependency resolver resolve name 'samtools' version None type 'package' job_directory job_dir assert dependency shell_commands None is None installed_targets list conda_util installed_conda_targets conda_context assert len installed_targets 0 finally shutil rmtree base_path
def aggregate_file_tree_metadata addon_short_name fileobj_metadata user disk_usage fileobj_metadata get 'size' if fileobj_metadata['kind'] 'file' result StatResult target_name fileobj_metadata['name'] target_id fileobj_metadata['path'] lstrip '/' disk_usage disk_usage or 0 return resultelse return AggregateStatResult target_id fileobj_metadata['path'] lstrip '/' target_name fileobj_metadata['name'] targets [aggregate_file_tree_metadata addon_short_name child user for child in fileobj_metadata get 'children' [] ]
def read_version variables {}with open VERSION_FILE as f exec compile f read 'version py' 'exec' in variablesreturn variables['VERSION']
def DetectExecutablePaths source_values vars_map None detector CreateWindowsRegistryExecutablePathsDetector vars_map vars_map for source_value in source_values for result in detector Detect source_value yield result
def _fa items s if atomp items return itemsif len s 0 return items[0]lst [0] * s[0] stride s[0]for i in range s[0] lst[i] _fa items[i stride] s[1 ] return lst
def test_setitem_as_column_name t Table t['a'] ['x' 'y']t['b'] 'b'assert np all t['a'] ['x' 'y'] assert np all t['b'] ['b' 'b']
def test_setitem_as_column_name t Table t['a'] ['x' 'y']t['b'] 'b'assert np all t['a'] ['x' 'y'] assert np all t['b'] ['b' 'b']
def load_class name setting try module attr name rsplit ' ' 1 except ValueError as error raise ImproperlyConfigured 'Errorimportingclass%sin%s "%s"' % name setting error try mod import_module module except ImportError as error raise ImproperlyConfigured 'Errorimportingmodule%sin%s "%s"' % module setting error try cls getattr mod attr except AttributeError raise ImproperlyConfigured 'Module"%s"doesnotdefinea"%s"classin%s' % module attr setting return cls
def hmac_sha512 k m key OpenSSL malloc k len k d OpenSSL malloc m len m md OpenSSL malloc 0 64 i OpenSSL pointer OpenSSL c_int 0 OpenSSL HMAC OpenSSL EVP_sha512 key len k d len m md i return md raw
def create_user options sess token data {'user[name]' options username 'user[username]' options username 'user[password1]' options password 'user[password2]' options password 'user[email1]' options email 'user[email2]' options email 'user[groups][]' '7' 'user[activation]' '0' 'user[block]' '0' 'form[name]' options username 'form[username]' options username 'form[password1]' options password 'form[password2]' options password 'form[email1]' options email 'form[email2]' options email 'form[option]' 'com_users' 'form[task]' 'user register' token '1'}return sess post options url + '/index php/component/users/?task user register' data data allow_redirects False verify False
def create_user options sess token data {'user[name]' options username 'user[username]' options username 'user[password1]' options password 'user[password2]' options password 'user[email1]' options email 'user[email2]' options email 'user[groups][]' '7' 'user[activation]' '0' 'user[block]' '0' 'form[name]' options username 'form[username]' options username 'form[password1]' options password 'form[password2]' options password 'form[email1]' options email 'form[email2]' options email 'form[option]' 'com_users' 'form[task]' 'user register' token '1'}return sess post options url + '/index php/component/users/?task user register' data data allow_redirects False verify False
def create_user options sess token data {'user[name]' options username 'user[username]' options username 'user[password1]' options password 'user[password2]' options password 'user[email1]' options email 'user[email2]' options email 'user[groups][]' '7' 'user[activation]' '0' 'user[block]' '0' 'form[name]' options username 'form[username]' options username 'form[password1]' options password 'form[password2]' options password 'form[email1]' options email 'form[email2]' options email 'form[option]' 'com_users' 'form[task]' 'user register' token '1'}return sess post options url + '/index php/component/users/?task user register' data data allow_redirects False verify False
def error_response_app error_code message debug_message None __warn True if __warn warnings warn 'wsgilib error_response_appisdeprecated usethewsgi_applicationmethodonanHTTPExceptionobjectinstead' DeprecationWarning 2 def application environ start_response status headers body error_response environ error_code message debug_message debug_message __warn False start_response status headers return [body]return application
@register inclusion_tag u'admin/includes/recent_actions html' takes_context True def recent_actions context return context
@register inclusion_tag u'admin/includes/recent_actions html' takes_context True def recent_actions context return context
def detect_fakeroot return os getenv 'FAKEROOTKEY' None
def libvlc_video_set_marquee_string p_mi option psz_text f _Cfunctions get 'libvlc_video_set_marquee_string' None or _Cfunction 'libvlc_video_set_marquee_string' 1 1 1 None None MediaPlayer ctypes c_uint ctypes c_char_p return f p_mi option psz_text
def make_simp z def simp expr 'Efficientlysimplifytherationalfunction``expr`` ' numer denom expr as_numer_denom c numer denom poly numer z cancel poly denom z return c * numer as_expr / denom as_expr return simp
def make_simp z def simp expr 'Efficientlysimplifytherationalfunction``expr`` ' numer denom expr as_numer_denom c numer denom poly numer z cancel poly denom z return c * numer as_expr / denom as_expr return simp
def vn_delete call None kwargs None if call 'function' raise SaltCloudSystemExit 'Thevn_deletefunctionmustbecalledwith-for--function ' if kwargs is None kwargs {}name kwargs get 'name' None vn_id kwargs get 'vn_id' None if vn_id if name log warning "Boththe'vn_id'and'name'argumentswereprovided 'vn_id'willtakeprecedence " elif name vn_id get_vn_id kwargs {'name' name} else raise SaltCloudSystemExit "Thevn_deletefunctionrequiresa'name'ora'vn_id'tobeprovided " server user password _get_xml_rpc auth ' ' join [user password] response server one vn delete auth int vn_id data {'action' 'vn delete' 'deleted' response[0] 'vn_id' response[1] 'error_code' response[2]}return data
def patch_dns from gevent import socketpatch_module 'socket' items socket __dns__
def registered_tasks request return JsonResponse {'regular' tasks regular keys 'periodic' tasks periodic keys }
@_get_clientdef image_location_delete client image_id location_id status session None client image_location_delete image_id image_id location_id location_id status status
def getLeftPointIndex points if len points < 1 return NoneleftPointIndex 0for pointIndex in xrange len points if points[pointIndex] real < points[leftPointIndex] real leftPointIndex pointIndexreturn leftPointIndex
def shared_like variable name None **kwargs variable tensor as_tensor_variable variable if name is None name 'shared_{}' format variable name return theano shared numpy zeros 0 * variable ndim dtype variable dtype name name **kwargs
def shared_like variable name None **kwargs variable tensor as_tensor_variable variable if name is None name 'shared_{}' format variable name return theano shared numpy zeros 0 * variable ndim dtype variable dtype name name **kwargs
def mac address '' interface '' vlan 0 proxy_output __proxy__['napalm call'] 'get_mac_address_table' **{} if not proxy_output get 'result' return proxy_outputmac_address_table proxy_output get 'out' if vlan and isinstance vlan int mac_address_table _filter_list mac_address_table 'vlan' vlan if address mac_address_table _filter_list mac_address_table 'mac' address if interface mac_address_table _filter_list mac_address_table 'interface' interface proxy_output update {'out' mac_address_table} return proxy_output
@access_log_level logging DEBUG def status_bar request resp ''for view in _status_bar_views try r view request if r status_code 200 resp + r contentelse LOG warning 'Failedtoexecutestatus_barview%s' % view except LOG exception 'Failedtoexecutestatus_barview%s' % view return HttpResponse resp
def squared_error a b a b align_targets a b return theano tensor square a - b
def _pty_size from fabric state import win32if not win32 import fcntlimport termiosimport struct default_rows default_cols 24 80 rows cols default_rows default_cols if not win32 and isatty sys stdout fmt 'HH'buffer struct pack fmt 0 0 try result fcntl ioctl sys stdout fileno termios TIOCGWINSZ buffer rows cols struct unpack fmt result if rows 0 rows default_rowsif cols 0 cols default_colsexcept AttributeError passreturn rows cols
def _pty_size from fabric state import win32if not win32 import fcntlimport termiosimport struct default_rows default_cols 24 80 rows cols default_rows default_cols if not win32 and isatty sys stdout fmt 'HH'buffer struct pack fmt 0 0 try result fcntl ioctl sys stdout fileno termios TIOCGWINSZ buffer rows cols struct unpack fmt result if rows 0 rows default_rowsif cols 0 cols default_colsexcept AttributeError passreturn rows cols
def sign params signed_fields_key 'orderPage_signedFields' full_sig_key 'orderPage_signaturePublic' merchant_id get_processor_config get 'MERCHANT_ID' '' order_page_version get_processor_config get 'ORDERPAGE_VERSION' '7' serial_number get_processor_config get 'SERIAL_NUMBER' '' params['merchantID'] merchant_idparams['orderPage_timestamp'] int time time * 1000 params['orderPage_version'] order_page_versionparams['orderPage_serialNumber'] serial_numberfields u' ' join params keys values u' ' join [u'{0} {1}' format i params[i] for i in params keys ] fields_sig processor_hash fields values + u' signedFieldsPublicSignature ' + fields_sig params[full_sig_key] processor_hash values params[signed_fields_key] fieldsreturn params
def Benini name alpha beta sigma return rv name BeniniDistribution alpha beta sigma
@ajax_requireddef preview_content request if 'text' not in request POST return JsonResponseBadRequest {'msg' _ 'Textismissing' } return JsonResponse {'rendered' apply_markup_filter request POST['text'] }
def _item_to_topic iterator resource return Topic from_api_repr {'name' resource name} iterator client
def list_config_modules etcdir if not os path isdir etcdir return iter return name for name in os listdir etcdir if name endswith ' py' and os path isfile os path join etcdir name
def configure_errorhandlers app @app errorhandler 403 def forbidden_page error return render_template 'errors/forbidden_page html' 403 @app errorhandler 404 def page_not_found error return render_template 'errors/page_not_found html' 404 @app errorhandler 500 def server_error_page error return render_template 'errors/server_error html' 500
def str_split arr pat None n None if pat is None if n is None or n 0 n -1 f lambda x x split pat n elif len pat 1 if n is None or n 0 n -1 f lambda x x split pat n else if n is None or n -1 n 0regex re compile pat f lambda x regex split x maxsplit n res _na_map f arr return res
def get_model_location session service_definition service_name None service_model ServiceModel service_definition if service_name is None endpoint_prefix service_model endpoint_prefixservice_name _get_service_name session endpoint_prefix api_version service_model api_versiondata_path session get_component 'data_loader' CUSTOMER_DATA_PATHservice_model_name 'service-%d json' % int float service_definition get 'version' '2 0' return os path join data_path service_name api_version service_model_name
@condition etag_func lambda r ETAG strip '"' def etag_view_unquoted request return HttpResponse FULL_RESPONSE
def s_bit_field value width endian '<' format 'binary' signed False full_range False fuzzable True name None bit_field primitives bit_field value width None endian format signed full_range fuzzable name blocks CURRENT push bit_field
def clean destination recursive if destination[ 5] 's3 //' rm_args ['aws' 's3' 'rm' '--quiet' destination]if recursive rm_args append '--recursive' subprocess check_call rm_args elif recursive shutil rmtree destination else os remove destination
def reap_children if hasattr os 'waitpid' any_process -1 while True try pid status os waitpid any_process os WNOHANG if pid 0 breakexcept break
def template_funcs funcs {}for plugin in find_plugins if plugin template_funcs funcs update plugin template_funcs return funcs
def write_callback option _opt_str _value parser *_args **_kwargs if not hasattr parser values 'write' option dest 'write'option action 'store_false'parser values write Falsefor _ in range 3 testphrase 'Yes Iwanttoenablewritesupport'response raw_input 'Writesupportrequested Pleasetype"' + testphrase + '"belowprecisely case-sensitive \n' if response testphrase option action 'store_true'parser values write Truereturnprint 'Writesupportdisabled '
def write_callback option _opt_str _value parser *_args **_kwargs if not hasattr parser values 'write' option dest 'write'option action 'store_false'parser values write Falsefor _ in range 3 testphrase 'Yes Iwanttoenablewritesupport'response raw_input 'Writesupportrequested Pleasetype"' + testphrase + '"belowprecisely case-sensitive \n' if response testphrase option action 'store_true'parser values write Truereturnprint 'Writesupportdisabled '
def write_callback option _opt_str _value parser *_args **_kwargs if not hasattr parser values 'write' option dest 'write'option action 'store_false'parser values write Falsefor _ in range 3 testphrase 'Yes Iwanttoenablewritesupport'response raw_input 'Writesupportrequested Pleasetype"' + testphrase + '"belowprecisely case-sensitive \n' if response testphrase option action 'store_true'parser values write Truereturnprint 'Writesupportdisabled '
def arrays_to_list_of_tuples arrays colnames first_array arrays[colnames[0]]return [tuple arrays[colname][i] for colname in colnames for i in range len first_array ]
@library global_functiondef tags_to_text tags return ' ' join [t slug for t in tags]
@library global_functiondef tags_to_text tags return ' ' join [t slug for t in tags]
def _do_extra_actions api_content cc_content request_fields actions_form context request for field form_value in actions_form cleaned_data items if field in request_fields and form_value api_content[field] api_content[field] form_valueif field 'following' _handle_following_field form_value context['cc_requester'] cc_content elif field 'abuse_flagged' _handle_abuse_flagged_field form_value context['cc_requester'] cc_content elif field 'voted' _handle_voted_field form_value cc_content api_content request context elif field 'read' _handle_read_field api_content form_value context['cc_requester'] cc_content else raise ValidationError {field ['InvalidKey']}
def _do_extra_actions api_content cc_content request_fields actions_form context request for field form_value in actions_form cleaned_data items if field in request_fields and form_value api_content[field] api_content[field] form_valueif field 'following' _handle_following_field form_value context['cc_requester'] cc_content elif field 'abuse_flagged' _handle_abuse_flagged_field form_value context['cc_requester'] cc_content elif field 'voted' _handle_voted_field form_value cc_content api_content request context elif field 'read' _handle_read_field api_content form_value context['cc_requester'] cc_content else raise ValidationError {field ['InvalidKey']}
def _do_extra_actions api_content cc_content request_fields actions_form context request for field form_value in actions_form cleaned_data items if field in request_fields and form_value api_content[field] api_content[field] form_valueif field 'following' _handle_following_field form_value context['cc_requester'] cc_content elif field 'abuse_flagged' _handle_abuse_flagged_field form_value context['cc_requester'] cc_content elif field 'voted' _handle_voted_field form_value cc_content api_content request context elif field 'read' _handle_read_field api_content form_value context['cc_requester'] cc_content else raise ValidationError {field ['InvalidKey']}
def parse_rows_with reader parsers for row in reader yield parse_row row parsers
def suite testSuite unittest TestSuite testSuite addTest SampleTests 'testGoodStuff' return testSuite
def suite testSuite unittest TestSuite testSuite addTest SampleTests 'testGoodStuff' return testSuite
def image_snapshot_flatten call None kwargs None if call 'function' raise SaltCloudSystemExit 'Theimage_snapshot_flattenfunctionmustbecalledwith-for--function ' if kwargs is None kwargs {}image_id kwargs get 'image_id' None image_name kwargs get 'image_name' None snapshot_id kwargs get 'snapshot_id' None if snapshot_id is None raise SaltCloudSystemExit "Theimage_stanpshot_flattenfunctionrequiresa'snapshot_id'tobeprovided " if image_id if image_name log warning "Boththe'image_id'and'image_name'argumentswereprovided 'image_id'willtakeprecedence " elif image_name image_id get_image_id kwargs {'name' image_name} else raise SaltCloudSystemExit "Theimage_snapshot_flattenfunctionrequireseitheran'image_id'oran'image_name'tobeprovided " server user password _get_xml_rpc auth ' ' join [user password] response server one image snapshotflatten auth int image_id int snapshot_id data {'action' 'image snapshotflatten' 'flattened' response[0] 'snapshot_id' response[1] 'error_code' response[2]}return data
def libvlc_audio_equalizer_set_preamp p_equalizer f_preamp f _Cfunctions get 'libvlc_audio_equalizer_set_preamp' None or _Cfunction 'libvlc_audio_equalizer_set_preamp' 1 1 None ctypes c_int ctypes c_void_p ctypes c_float return f p_equalizer f_preamp
def _build_editable_options req regexp re compile '[\\?#&] ?P<name>[^& ]+ ?P<value>[^& ]+ ' matched regexp findall req if matched ret dict for option in matched name value optionif name in ret raise Exception '%soptionalreadydefined' % name ret[name] valuereturn retreturn None
def keyring_save **kwargs return ceph_cfg keyring_save **kwargs
def get_distribution_id vm_ distributions _query 'avail' 'distributions' ['DATA']vm_image_name config get_cloud_config_value 'image' vm_ __opts__ distro_id ''for distro in distributions if vm_image_name distro['LABEL'] distro_id distro['DISTRIBUTIONID']return distro_idif not distro_id raise SaltCloudNotFound "TheDistributionIDforthe'{0}'profilecouldnotbefound \nThe'{1}'instancecouldnotbeprovisioned Thefollowingdistributionsareavailable \n{2}" format vm_image_name vm_['name'] pprint pprint sorted [distro['LABEL'] encode __salt_system_encoding__ for distro in distributions]
def ec2_instance_create context instance_uuid id None return IMPL ec2_instance_create context instance_uuid id
def getDivisionFailure *args **kwargs try 1 / 0 except f failure Failure *args **kwargs return f
def is_valid_xml_char_ordinal i return 32 < i < 55295 or i in 9 10 13 or 57344 < i < 65533 or 65536 < i < 1114111
def is_valid_xml_char_ordinal i return 32 < i < 55295 or i in 9 10 13 or 57344 < i < 65533 or 65536 < i < 1114111
def thread_test method @functools wraps method def Wrapper self thread TestThread partial method self partial self io_loop add_callback self stop thread start self wait thread MaybeRaise return Wrapper
def get_demo_driver provider_name 'RACKSPACE' *args **kwargs provider_name provider_name upper DriverClass get_driver getattr Provider provider_name if not args args getattr secrets provider_name + '_PARAMS' if not kwargs kwargs getattr secrets provider_name + '_KEYWORD_PARAMS' {} try return DriverClass *args **kwargs except InvalidCredsError raise InvalidCredsError 'validvaluesshouldbeputinsecrets py'
def feed_data func new_name *args **kwargs @wraps func def wrapper self return func self *args **kwargs wrapper __name__ new_nameif func __doc__ try wrapper __doc__ func __doc__ format *args **kwargs except IndexError KeyError passreturn wrapper
def feed_data func new_name *args **kwargs @wraps func def wrapper self return func self *args **kwargs wrapper __name__ new_nameif func __doc__ try wrapper __doc__ func __doc__ format *args **kwargs except IndexError KeyError passreturn wrapper
def percentOutputsStableOverNTimeSteps vectors numSamples None totalSamples len vectors windowSize numSamplesnumWindows 0pctStable 0for wStart in range 0 totalSamples - windowSize + 1 data vectors[wStart wStart + windowSize ]outputSums data sum axis 0 stableOutputs outputSums windowSize sum samplePctStable float stableOutputs / data[0] sum print samplePctStablepctStable + samplePctStablenumWindows + 1return float pctStable / numWindows
def json_view f @wraps f def _wrapped req *a **kw try ret f req *a **kw blob json dumps ret return http HttpResponse blob content_type JSON except http Http404 as e blob json dumps {'success' False 'error' 404 'message' str e } return http HttpResponseNotFound blob content_type JSON except PermissionDenied as e blob json dumps {'success' False 'error' 403 'message' str e } return http HttpResponseForbidden blob content_type JSON except Exception as e blob json dumps {'success' False 'error' 500 'message' str e } return http HttpResponseServerError blob content_type JSON return _wrapped
def dir_setup test_dir pkg temp_dir tempfile mkdtemp 'temp' config_dir tempfile mkdtemp 'config' work_dir tempfile mkdtemp 'work' os chmod temp_dir constants CONFIG_DIRS_MODE os chmod config_dir constants CONFIG_DIRS_MODE os chmod work_dir constants CONFIG_DIRS_MODE test_configs pkg_resources resource_filename pkg os path join 'testdata' test_dir shutil copytree test_configs os path join temp_dir test_dir symlinks True return temp_dir config_dir work_dir
def AddFileToFileStore pathspec None client_id None token None if pathspec is None raise ValueError "pathspeccan'tbeNone" if client_id is None raise ValueError "client_idcan'tbeNone" urn aff4_grr VFSGRRClient PathspecToURN pathspec client_id client_mock action_mocks GetFileClientMock for _ in test_lib TestFlowHelper transfer GetFile __name__ client_mock token token client_id client_id pathspec pathspec passauth_state rdf_flows GrrMessage AuthorizationState AUTHENTICATEDevents Events PublishEvent 'FileStore AddFileToStore' rdf_flows GrrMessage payload urn auth_state auth_state token token worker test_lib MockWorker token token worker Simulate return urn
def parse_enum key value enumeration return parse_enum_csv key value enumeration 1 [0]
def update_status msg **redis_kwargs pid getpid red StrictRedis **redis_kwargs key 'pid-%d-statuses' % pid msg '% 6f%s' % time msg red lpush key msg red expire key 60 * 60 red ltrim key 0 _keep
def update_status msg **redis_kwargs pid getpid red StrictRedis **redis_kwargs key 'pid-%d-statuses' % pid msg '% 6f%s' % time msg red lpush key msg red expire key 60 * 60 red ltrim key 0 _keep
def attach_priorities queryset as_field 'priorities_attr' model queryset modelsql '\nSELECTjson_agg \nrow_to_json projects_priority \nORDERBYprojects_priority order\n \nFROMprojects_priority\nWHEREprojects_priority project_id {tbl} id\n'sql sql format tbl model _meta db_table queryset queryset extra select {as_field sql} return queryset
def test_GPU_nstreams_limit if not cuda_available raise SkipTest 'Optionalpackagecudanotavailable' seed 12345R MRG_RandomStreams seed seed use_cuda True def eval_uniform size nstreams if theano config mode 'FAST_COMPILE' mode 'FAST_RUN'else mode copy copy theano compile get_default_mode mode check_py_code Falseout R uniform size size nstreams nstreams dtype 'float32' f theano function [] out mode mode return f eval_uniform 10 2 ** 20 assert_raises ValueError eval_uniform 10 2 ** 20 + 1
def volume_absent name driver None ret {'name' name 'changes' {} 'result' False 'comment' ''}volume _find_volume name if not volume ret['result'] Trueret['comment'] "Volume'{0}'alreadyabsent" format name return rettry ret['changes']['removed'] __salt__['dockerng remove_volume'] name ret['result'] Trueexcept Exception as exc ret['comment'] "Failedtoremovevolume'{0}' {1}" format name exc return ret
def patch_user_model def get_absolute_url self return reverse 'users profile' args [self pk] User get_absolute_url get_absolute_url
def store_multiple option opt value parser *args **kwargs for attribute in args setattr parser values attribute None for key value in kwargs items setattr parser values key value
def _nsort roots separated False if not all r is_number for r in roots raise NotImplementedErrorkey [[i n 2 as_real_imag [0] for i in r as_real_imag ] for r in roots]if any i _prec 1 for k in key for i in k raise NotImplementedError 'couldnotcomputerootwithprecision' key [ 1 if i else 0 r i for r i in key]key sorted zip key roots if separated r []i []for im _ _ v in key if im i append v else r append v return r i _ roots zip *key return list roots
def _nsort roots separated False if not all r is_number for r in roots raise NotImplementedErrorkey [[i n 2 as_real_imag [0] for i in r as_real_imag ] for r in roots]if any i _prec 1 for k in key for i in k raise NotImplementedError 'couldnotcomputerootwithprecision' key [ 1 if i else 0 r i for r i in key]key sorted zip key roots if separated r []i []for im _ _ v in key if im i append v else r append v return r i _ roots zip *key return list roots
def test_multitype_conv_invalid_type param inspect Parameter 'foo' inspect Parameter POSITIONAL_ONLY with pytest raises ValueError as excinfo argparser multitype_conv param [None] '' assert str excinfo value 'foo UnknowntypeNone '
def _item_to_metric iterator resource return Metric from_api_repr resource iterator client
def resizeWindow win w h timeout 2 0 QtGui QApplication processEvents QtTest QTest qWaitForWindowShown win win resize w h start time time while True w1 h1 win width win height if w h w1 h1 returnQtTest QTest qWait 10 if time time - start > timeout raise TimeoutError 'Windowresizefailed requested%dx%d got%dx%d ' % w h w1 h1
def resizeWindow win w h timeout 2 0 QtGui QApplication processEvents QtTest QTest qWaitForWindowShown win win resize w h start time time while True w1 h1 win width win height if w h w1 h1 returnQtTest QTest qWait 10 if time time - start > timeout raise TimeoutError 'Windowresizefailed requested%dx%d got%dx%d ' % w h w1 h1
def amp_server_context_factory ca_certificate control_credential return _ControlServiceContextFactory ca_certificate control_credential 'node-'
def amp_server_context_factory ca_certificate control_credential return _ControlServiceContextFactory ca_certificate control_credential 'node-'
def get_info_from_core path full_exe_path Noneoutput commands getoutput 'gdb-c%sbatch' % path path_pattern re compile "Corewasgeneratedby` [^\x00]+ '" re IGNORECASE match re findall path_pattern output for m in match m m split '' [0]if os path isfile m full_exe_path mbreakif full_exe_path is None syslog syslog 'Couldnotdeterminefromwhichapplicationcorefile%sisfrom' % path return {'full_exe_path' full_exe_path}
def get_info_from_core path full_exe_path Noneoutput commands getoutput 'gdb-c%sbatch' % path path_pattern re compile "Corewasgeneratedby` [^\x00]+ '" re IGNORECASE match re findall path_pattern output for m in match m m split '' [0]if os path isfile m full_exe_path mbreakif full_exe_path is None syslog syslog 'Couldnotdeterminefromwhichapplicationcorefile%sisfrom' % path return {'full_exe_path' full_exe_path}
def takes_args function return bool function __code__ co_flags & 4
def takes_args function return bool function __code__ co_flags & 4
def flatten results for row in results yield c value for c in row
def _ExtractProxyConfig product_yaml_key proxy_config_data cafile proxy_config_data get 'cafile' None disable_certificate_validation proxy_config_data get 'disable_certificate_validation' False http_proxy _ExtractProxy _HTTP_PROXY_YAML_KEY proxy_config_data https_proxy _ExtractProxy _HTTPS_PROXY_YAML_KEY proxy_config_data proxy_config ProxyConfig http_proxy http_proxy https_proxy https_proxy cafile cafile disable_certificate_validation disable_certificate_validation return proxy_config
def apply_gmail_label_rules db_session message added_categories removed_categories add {}discard {}categories {c name c for c in message categories if c name}for cat in added_categories if cat name 'all' discard {'trash' 'spam'}elif cat name 'trash' discard {'all' 'spam' 'inbox'}elif cat name 'spam' discard {'all' 'trash' 'inbox'}elif cat name 'inbox' add {'all'}discard {'trash' 'spam'}for name in add if name not in categories category db_session query Category filter Category namespace_id message namespace_id Category name name one message categories add category for name in discard if name in categories message categories discard categories[name]
def bbox_to_array arr label 0 max_bboxes 64 bbox_width 16 arr pad_bbox arr max_bboxes bbox_width return arr[np newaxis ]
def bbox_to_array arr label 0 max_bboxes 64 bbox_width 16 arr pad_bbox arr max_bboxes bbox_width return arr[np newaxis ]
def fill_in_subscriptions apps schema_editor Project apps get_model u'trans' u'Project' Group apps get_model u'auth' u'Group' Profile apps get_model u'accounts' u'Profile' for project in Project objects all for owner in project owners all try owner profile subscriptions add project except Profile DoesNotExist passif project enable_acl try group Group objects get name project name for user in group user_set all try user profile subscriptions add project except Profile DoesNotExist passexcept Group DoesNotExist pass
def fill_in_subscriptions apps schema_editor Project apps get_model u'trans' u'Project' Group apps get_model u'auth' u'Group' Profile apps get_model u'accounts' u'Profile' for project in Project objects all for owner in project owners all try owner profile subscriptions add project except Profile DoesNotExist passif project enable_acl try group Group objects get name project name for user in group user_set all try user profile subscriptions add project except Profile DoesNotExist passexcept Group DoesNotExist pass
@utils arg 'os' metavar '<os>' help _ 'TypeofOS ' @utils arg 'architecture' metavar '<architecture>' help _ 'Typeofarchitecture ' @utils arg 'version' metavar '<version>' help _ 'Version ' @utils arg 'url' metavar '<url>' help _ 'URL ' @utils arg 'md5hash' metavar '<md5hash>' help _ 'MD5hash ' @utils arg 'hypervisor' metavar '<hypervisor>' default 'xen' help _ 'Typeofhypervisor ' def do_agent_create cs args result cs agents create args os args architecture args version args url args md5hash args hypervisor utils print_dict result to_dict
def _get_flat_core_sizes cores core_sizes_lists []for core in cores flat_output_size nest flatten core output_size core_sizes_lists append [tensor_shape as_shape size as_list for size in flat_output_size] return core_sizes_lists
@celery taskdef send_reset_token user token make_token user user operation 'reset_password' send_email subject _ 'PasswordRecoveryConfirmation' recipients [user email] text_body render_template 'email/reset_password txt' user user token token html_body render_template 'email/reset_password html' user user token token
def _wrap_result name data sparse_index fill_value dtype None if name in 'eq' 'ne' 'lt' 'gt' 'le' 'ge' dtype np boolif is_bool_dtype dtype fill_value bool fill_value return SparseArray data sparse_index sparse_index fill_value fill_value dtype dtype
@utils arg 'host' metavar '<hostname>' help _ 'Nameofhost ' def do_host_describe cs args result cs hosts get args host columns ['HOST' 'PROJECT' 'cpu' 'memory_mb' 'disk_gb']utils print_list result columns
def getKeyA row column prefix '' return '%sa%s%s' % prefix row column
def authorize permits True authz_class None if authz_class is None authz_class 'tests core support AllowAuthorizationPolicy'def wrapper f @functools wraps f def wrapped *args **kwargs with mock patch '%s permits' % authz_class return_value permits return f *args **kwargs return wrappedreturn wrapper
def authorize permits True authz_class None if authz_class is None authz_class 'tests core support AllowAuthorizationPolicy'def wrapper f @functools wraps f def wrapped *args **kwargs with mock patch '%s permits' % authz_class return_value permits return f *args **kwargs return wrappedreturn wrapper
def get_valid_domains domains valid_domains []for domain in domains try valid_domains append util enforce_domain_sanity domain except errors ConfigurationError continuereturn valid_domains
def _complex_expand_series context builder ty initial x coefs assert ty in types complex_domain binary_sig typing signature * [ty] * 3 accum context make_complex builder ty value initial ONE context get_constant ty underlying_float 1 0 for coef in reversed coefs constant context get_constant ty underlying_float coef value numbers complex_mul_impl context builder binary_sig [x accum _getvalue ] accum _setvalue value accum real builder fadd ONE builder fmul accum real constant accum imag builder fmul accum imag constant return accum _getvalue
def _complex_expand_series context builder ty initial x coefs assert ty in types complex_domain binary_sig typing signature * [ty] * 3 accum context make_complex builder ty value initial ONE context get_constant ty underlying_float 1 0 for coef in reversed coefs constant context get_constant ty underlying_float coef value numbers complex_mul_impl context builder binary_sig [x accum _getvalue ] accum _setvalue value accum real builder fadd ONE builder fmul accum real constant accum imag builder fmul accum imag constant return accum _getvalue
def _complex_expand_series context builder ty initial x coefs assert ty in types complex_domain binary_sig typing signature * [ty] * 3 accum context make_complex builder ty value initial ONE context get_constant ty underlying_float 1 0 for coef in reversed coefs constant context get_constant ty underlying_float coef value numbers complex_mul_impl context builder binary_sig [x accum _getvalue ] accum _setvalue value accum real builder fadd ONE builder fmul accum real constant accum imag builder fmul accum imag constant return accum _getvalue
def _complex_expand_series context builder ty initial x coefs assert ty in types complex_domain binary_sig typing signature * [ty] * 3 accum context make_complex builder ty value initial ONE context get_constant ty underlying_float 1 0 for coef in reversed coefs constant context get_constant ty underlying_float coef value numbers complex_mul_impl context builder binary_sig [x accum _getvalue ] accum _setvalue value accum real builder fadd ONE builder fmul accum real constant accum imag builder fmul accum imag constant return accum _getvalue
def _complex_expand_series context builder ty initial x coefs assert ty in types complex_domain binary_sig typing signature * [ty] * 3 accum context make_complex builder ty value initial ONE context get_constant ty underlying_float 1 0 for coef in reversed coefs constant context get_constant ty underlying_float coef value numbers complex_mul_impl context builder binary_sig [x accum _getvalue ] accum _setvalue value accum real builder fadd ONE builder fmul accum real constant accum imag builder fmul accum imag constant return accum _getvalue
def require name version None def decorator obj @functools wraps obj def func_wrapped *args **kwargs if is_installed name version return obj *args **kwargs else msg '"%s"in"%s"requires"%s'msg msg % obj obj __module__ name if not version is None msg + '%s' % version raise ImportError msg + '"' return func_wrappedreturn decorator
def require name version None def decorator obj @functools wraps obj def func_wrapped *args **kwargs if is_installed name version return obj *args **kwargs else msg '"%s"in"%s"requires"%s'msg msg % obj obj __module__ name if not version is None msg + '%s' % version raise ImportError msg + '"' return func_wrappedreturn decorator
def run_benchmark with tf Graph as_default image_size 224images tf Variable tf random_normal [FLAGS batch_size image_size image_size 3] dtype tf float32 stddev 0 1 pool5 parameters inference images init tf global_variables_initializer config tf ConfigProto config gpu_options allocator_type 'BFC'sess tf Session config config sess run init time_tensorflow_run sess pool5 'Forward' objective tf nn l2_loss pool5 grad tf gradients objective parameters time_tensorflow_run sess grad 'Forward-backward'
def create_service_check check_name status tags None timestamp None hostname None check_run_id None message None if check_run_id is None check_run_id get_next_id 'service_check' return {'id' check_run_id 'check' check_name 'status' status 'host_name' hostname 'tags' tags 'timestamp' float timestamp or time time 'message' message}
def _watch_callback obj_weakref method_name *args **kwargs obj obj_weakref if obj is None returngetattr obj method_name *args **kwargs
def _watch_callback obj_weakref method_name *args **kwargs obj obj_weakref if obj is None returngetattr obj method_name *args **kwargs
def _asa d1 l d2 xy Line 0 0 slope _slope d1 intersection Line l 0 slope _slope 180 - d2 [0]return Triangle 0 0 l 0 xy
@ensure_csrf_cookiedef jump_to _request course_id location try course_key CourseKey from_string course_id usage_key UsageKey from_string location replace course_key course_key except InvalidKeyError raise Http404 u'Invalidcourse_keyorusage_key' try redirect_url get_redirect_url course_key usage_key user _request useruser_is_global_staff GlobalStaff has_user user user_is_enrolled CourseEnrollment is_enrolled user course_key if user_is_global_staff and not user_is_enrolled redirect_url get_redirect_url_for_global_staff course_key _next redirect_url except ItemNotFoundError raise Http404 u'Nodataatthislocation {0}' format usage_key except NoPathToItem raise Http404 u'Thislocationisnotinanyclass {0}' format usage_key return redirect redirect_url
@ensure_csrf_cookiedef jump_to _request course_id location try course_key CourseKey from_string course_id usage_key UsageKey from_string location replace course_key course_key except InvalidKeyError raise Http404 u'Invalidcourse_keyorusage_key' try redirect_url get_redirect_url course_key usage_key user _request useruser_is_global_staff GlobalStaff has_user user user_is_enrolled CourseEnrollment is_enrolled user course_key if user_is_global_staff and not user_is_enrolled redirect_url get_redirect_url_for_global_staff course_key _next redirect_url except ItemNotFoundError raise Http404 u'Nodataatthislocation {0}' format usage_key except NoPathToItem raise Http404 u'Thislocationisnotinanyclass {0}' format usage_key return redirect redirect_url
def netstat name sanitize_name str name netstat_infos __salt__['cmd run'] 'netstat-nap' found_infos []ret []for info in netstat_infos splitlines if info find sanitize_name -1 found_infos append info ret extend [sanitize_name found_infos] return ret
def _footer_logo_img is_secure logo_name configuration_helpers get_value 'FOOTER_ORGANIZATION_IMAGE' settings FOOTER_ORGANIZATION_IMAGE try return _absolute_url_staticfile is_secure logo_name except ValueError default_logo 'images/logo png'log info "Failedtofindfooterlogoat'%s' using'%s'instead" logo_name default_logo return staticfiles_storage url default_logo
def check_csrf_token request token 'csrf_token' header 'X-CSRF-Token' raises True supplied_token ''if token is not None supplied_token request POST get token '' if supplied_token '' and header is not None supplied_token request headers get header '' expected_token request session get_csrf_token if strings_differ bytes_ expected_token bytes_ supplied_token if raises raise BadCSRFToken 'check_csrf_token Invalidtoken' return Falsereturn True
def _use_appnope return sys platform 'darwin' and V platform mac_ver [0] > V '10 9'
def get_python_library_path dlls getImports sys executable for filename in dlls for name in PYDYLIB_NAMES if os path basename filename name if is_win and not os path isabs filename filename getfullnameof filename return filenameif is_unix for name in PYDYLIB_NAMES python_libname findLibrary name if python_libname return python_libnameelif is_darwin prefixes [compat base_prefix os path join compat base_prefix 'lib' ]for prefix in prefixes for name in PYDYLIB_NAMES full_path os path join prefix name if os path exists full_path return full_pathreturn None
def getBusFreq if importCtypesFailed return Falsemib ctypes c_int * 2 CTL_HW HW_BUS_FREQ val ctypes c_int intSize ctypes c_int ctypes sizeof val cocoa sysctl ctypes byref mib 2 ctypes byref val ctypes byref intSize 0 0 return val value
def _graph_connected_component graph node_id n_node graph shape[0]if sparse issparse graph graph graph tocsr connected_nodes np zeros n_node dtype np bool nodes_to_explore np zeros n_node dtype np bool nodes_to_explore[node_id] Truefor _ in range n_node last_num_component connected_nodes sum np logical_or connected_nodes nodes_to_explore out connected_nodes if last_num_component > connected_nodes sum breakindices np where nodes_to_explore [0]nodes_to_explore fill False for i in indices if sparse issparse graph neighbors graph[i] toarray ravel else neighbors graph[i]np logical_or nodes_to_explore neighbors out nodes_to_explore return connected_nodes
def _graph_connected_component graph node_id n_node graph shape[0]if sparse issparse graph graph graph tocsr connected_nodes np zeros n_node dtype np bool nodes_to_explore np zeros n_node dtype np bool nodes_to_explore[node_id] Truefor _ in range n_node last_num_component connected_nodes sum np logical_or connected_nodes nodes_to_explore out connected_nodes if last_num_component > connected_nodes sum breakindices np where nodes_to_explore [0]nodes_to_explore fill False for i in indices if sparse issparse graph neighbors graph[i] toarray ravel else neighbors graph[i]np logical_or nodes_to_explore neighbors out nodes_to_explore return connected_nodes
def _graph_connected_component graph node_id n_node graph shape[0]if sparse issparse graph graph graph tocsr connected_nodes np zeros n_node dtype np bool nodes_to_explore np zeros n_node dtype np bool nodes_to_explore[node_id] Truefor _ in range n_node last_num_component connected_nodes sum np logical_or connected_nodes nodes_to_explore out connected_nodes if last_num_component > connected_nodes sum breakindices np where nodes_to_explore [0]nodes_to_explore fill False for i in indices if sparse issparse graph neighbors graph[i] toarray ravel else neighbors graph[i]np logical_or nodes_to_explore neighbors out nodes_to_explore return connected_nodes
def make_color_table in_class for name value in color_templates setattr in_class name in_class _base % value
def deleteMenuItems menu try lastMenuIndex menu index Tkinter END if lastMenuIndex None menu delete 0 lastMenuIndex except print 'thisshouldneverhappen thelastMenuIndexindeleteMenuItemsinsettingscouldnotbedetermined '
def _parse_number stream rv ''while stream peek and stream peek in string digits rv + next stream return int rv
def get_deprecated_tense removal_version future_tense u'willbe' past_tense u'was' return future_tense if Version removal_version > PANTS_SEMVER else past_tense
def broken_send *args **kwargs raise SMTPException 'Failuremockedbylettuce'
def match pattern data vars None if vars is None vars {}if type pattern is ListType vars[pattern[0]] datareturn 1 vars if type pattern is not TupleType return pattern data vars if len data len pattern return 0 vars for pattern data in map None pattern data same vars match pattern data vars if not same breakreturn same vars
def create_l2_gw_service cluster tenant_id display_name devices tags [{'tag' tenant_id 'scope' 'os_tid'}]gateways [{'transport_node_uuid' device['id'] 'device_id' device['interface_name'] 'type' 'L2Gateway'} for device in devices]gwservice_obj {'display_name' _check_and_truncate_name display_name 'tags' tags 'gateways' gateways 'type' 'L2GatewayServiceConfig'}try return json loads do_single_request 'POST' _build_uri_path GWSERVICE_RESOURCE json dumps gwservice_obj cluster cluster except NvpApiClient NvpApiException LOG exception _ 'AnexceptionoccuredwhilecommunicatingwiththeNVPcontrollerforcluster %s' cluster name raise
def setup_platform hass config add_devices discovery_info None add_devices [DemoLock 'FrontDoor' STATE_LOCKED DemoLock 'KitchenDoor' STATE_UNLOCKED ]
def Web_Template key defweb wdir if wdir is None try wdir fix_webname key except wdir ''if not wdir wdir defwebif key key set wdir if not wdir return ''full_dir real_path sabnzbd DIR_INTERFACES wdir full_main real_path full_dir DEF_MAIN_TMPL logging info 'Webdiris%s' full_dir if not os path exists full_main if defweb DEF_STDCONFIG return ''logging warning T 'Cannotfindwebtemplate %s tryingstandardtemplate' full_main full_dir real_path sabnzbd DIR_INTERFACES DEF_STDINTF full_main real_path full_dir DEF_MAIN_TMPL if not os path exists full_main logging exception 'Cannotfindstandardtemplate %s' full_dir panic_tmpl full_dir exit_sab 1 return real_path full_dir 'templates'
def list_security_groups profile None conn _auth profile return conn list_security_groups
def stats ret {}out __salt__['cmd run'] 'quotastats' splitlines for line in out if not line continuecomps line split ' ' ret[comps[0]] comps[1]return ret
@pytest mark cmd@pytest mark django_dbdef test_update_tmserver_nosetting capfd po_directory tp0 with pytest raises CommandError as e call_command 'update_tmserver' assert 'POOTLE_TM_SERVERsettingismissing ' in str e
@cached_classmethoddef get_edit_handler cls if hasattr cls u'edit_handler' return cls edit_handler bind_to_model cls tabs []if cls content_panels tabs append ObjectList cls content_panels heading ugettext_lazy u'Content' if cls promote_panels tabs append ObjectList cls promote_panels heading ugettext_lazy u'Promote' if cls settings_panels tabs append ObjectList cls settings_panels heading ugettext_lazy u'Settings' classname u'settings' EditHandler TabbedInterface tabs base_form_class cls base_form_class return EditHandler bind_to_model cls
@cached_classmethoddef get_edit_handler cls if hasattr cls u'edit_handler' return cls edit_handler bind_to_model cls tabs []if cls content_panels tabs append ObjectList cls content_panels heading ugettext_lazy u'Content' if cls promote_panels tabs append ObjectList cls promote_panels heading ugettext_lazy u'Promote' if cls settings_panels tabs append ObjectList cls settings_panels heading ugettext_lazy u'Settings' classname u'settings' EditHandler TabbedInterface tabs base_form_class cls base_form_class return EditHandler bind_to_model cls
def _get_entities_custom_fields entities custom_fields set for entity in entities fields dir entity for field in fields if not field startswith '_' custom_fields add field for skip_field in ['PartitionKey' 'RowKey' 'Timestamp' 'etag'] custom_fields discard skip_field return custom_fields
def parseLines chunk items {}for lineno line in chunk header data line split ' ' 1 header header lower items[header] lineno data strip return items
def make_action app_factory hostname 'localhost' port 5000 threaded False processes 1 stream None sort_by 'time' 'calls' restrictions def action hostname 'h' hostname port 'p' port threaded threaded processes processes 'Startanewdevelopmentserver 'from werkzeug serving import run_simpleapp ProfilerMiddleware app_factory stream sort_by restrictions run_simple hostname port app False None threaded processes return action
def init macro_recorder MacroRecorder objreg register 'macro-recorder' macro_recorder
def get_vcenter_version kwargs None call None if call 'function' raise SaltCloudSystemExit 'Theget_vcenter_versionfunctionmustbecalledwith-for--function ' inv salt utils vmware get_inventory _get_si return inv about fullName
def escalate_prerelease_permissions app validation version app_permissions validation get 'permissions' or [] if any perm in PRERELEASE_PERMISSIONS for perm in app_permissions nobody UserProfile objects get email settings NOBODY_EMAIL_ADDRESS escalate_app app version nobody 'Appusesprereleasepermissions' mkt LOG ESCALATION_PRERELEASE_APP
def get_date_time format '%Y-%m-%d%H %M %S' UTC_OFFSET 3 local_datetime datetime now now local_datetime - timedelta hours UTC_OFFSET if format 'datetimeProperty' now now strftime format return now
def getPythonFileNamesExceptInit fileInDirectory '' pythonFileNamesExceptInit getFilesWithFileTypeWithoutWords 'py' ['__init__ py'] fileInDirectory pythonFileNamesExceptInit sort return pythonFileNamesExceptInit
@verbosedef tfr_morlet inst freqs n_cycles use_fft False return_itc True decim 1 n_jobs 1 picks None zero_mean True average True verbose None tfr_params dict n_cycles n_cycles n_jobs n_jobs use_fft use_fft zero_mean zero_mean return _tfr_aux 'morlet' inst freqs decim return_itc picks average **tfr_params
@commands u'cur' u'currency' u'exchange' @example u' cur20EURinUSD' def exchange bot trigger if not trigger group 2 return bot reply u'Nosearchterm Anexample cur20EURinUSD' match regex match trigger group 2 if not match bot reply u"Sorry Ididn'tunderstandtheinput " return NOLIMIT amount of to match groups try amount float amount except bot reply u"Sorry Ididn'tunderstandtheinput " display bot amount of to
@pytest mark networkdef test_upgrade_vcs_req_with_no_dists_found script tmpdir req '%s#egg pip-test-package' % local_checkout 'git+http //github com/pypa/pip-test-package git' tmpdir join 'cache' script pip 'install' req result script pip 'install' '-U' req assert not result returncode
@pytest mark networkdef test_upgrade_vcs_req_with_no_dists_found script tmpdir req '%s#egg pip-test-package' % local_checkout 'git+http //github com/pypa/pip-test-package git' tmpdir join 'cache' script pip 'install' req result script pip 'install' '-U' req assert not result returncode
def flatpages_link_list request from django contrib flatpages models import FlatPagelink_list [ page title page url for page in FlatPage objects all ]return render_to_link_list link_list
def default_completers return collections OrderedDict [ 'python_mode' complete_python_mode 'base' complete_base 'completer' complete_completer 'skip' complete_skipper 'pip' complete_pip 'cd' complete_cd 'rmdir' complete_rmdir 'xonfig' complete_xonfig 'xontrib' complete_xontrib 'bash' complete_from_bash 'man' complete_from_man 'import' complete_import 'python' complete_python 'path' complete_path ]
def install __builtins__['_'] gettext
def install __builtins__['_'] gettext
def install __builtins__['_'] gettext
def fuzzy_url urlstr cwd None relative False do_search True force_search False urlstr urlstr strip path get_path_if_valid urlstr cwd cwd relative relative check_exists True if not force_search and path is not None url QUrl fromLocalFile path elif force_search or do_search and not is_url urlstr log url debug 'URLisafuzzysearchterm' try url _get_search_url urlstr except ValueError url qurl_from_user_input urlstr else log url debug 'URLisafuzzyaddress' url qurl_from_user_input urlstr log url debug 'Convertingfuzzyterm{ r}toURL->{}' format urlstr url toDisplayString if do_search and config get 'general' 'auto-search' and urlstr qtutils ensure_valid url elif not url isValid raise InvalidUrlError url return url
@conf commands registerdef srbt1 peer pkts *args **kargs a b srbt peer pkts *args **kargs if len a > 0 return a[0][1]
@conf commands registerdef srbt1 peer pkts *args **kargs a b srbt peer pkts *args **kargs if len a > 0 return a[0][1]
def test_encounter_slots session version_group_a aliased tables VersionGroup version_group_b aliased tables VersionGroup sanity_q session query tables Encounter join tables EncounterSlot tables Encounter slot join version_group_a tables EncounterSlot version_group join tables Version tables Encounter version join version_group_b tables Version version_group filter version_group_a id version_group_b id assert sanity_q count 0
def name_from_basename basename return u'icons ' + basename
def name_from_basename basename return u'icons ' + basename
def linux_standby if not HAVE_DBUS return proxy interface _get_sessionproxy if proxy if proxy CanSuspend proxy Suspend dbus_interface interface else proxy interface pinterface _get_systemproxy 'UPower' if not proxy proxy interface pinterface _get_systemproxy 'DeviceKit' if proxy if proxy Get interface 'can-suspend' dbus_interface pinterface try proxy Suspend dbus_interface interface except dbus exceptions DBusException as msg logging info 'ReceivedaDBusexception%s' msg else logging info 'DBusdoesnotsupportSuspend standby ' time sleep 10
def has_configuration_override name configuration get_current_site_configuration if configuration and name in configuration values return Truereturn False
def _get_values profile None profile profile or {} serializers salt loader serializers __opts__ ret {}for fname in profile get 'files' [] try with salt utils flopen fname as f contents serializers yaml deserialize f ret salt utils dictupdate merge ret contents **profile get 'merge' {} except IOError log error "Filenotfound'{0}'" format fname except TypeError log error "Errordeserializingsdbfile'{0}'" format fname return ret
def start_scan_helper target_urls scan_profile scan_info_setup scan_info ScanInfo SCANS[get_new_scan_id ] scan_infoscan_info w3af_core w3af_core w3afCore scan_info target_urls target_urlsscan_info output RESTAPIOutput scan_info_setup set scan_profile_file_name profile_path create_temp_profile scan_profile om manager set_output_plugins [] try w3af_core profiles use_profile scan_profile_file_name workdir profile_path target_options w3af_core target get_options target_option target_options['target']target_option set_value [URL u for u in target_urls] w3af_core target set_options target_options w3af_core plugins init_plugins om manager set_output_plugin_inst scan_info output w3af_core verify_environment w3af_core start except Exception as e scan_info exception etry w3af_core stop except AttributeError passfinally scan_info finished Truetry os unlink os path join profile_path scan_profile_file_name except AttributeError IOError as _ pass
def _replace_conditional match string conditional_match _CONDITIONAL search string while conditional_match start conditional_match start end _find_closing_brace string start + 4 args _split_conditional string[ start + 4 end - 1 ] rv ''if match group int conditional_match group 1 rv unescape _replace_conditional match args[0] elif len args > 1 rv unescape _replace_conditional match args[1] string string[ start] + rv + string[end ] conditional_match _CONDITIONAL search string return string
def _replace_conditional match string conditional_match _CONDITIONAL search string while conditional_match start conditional_match start end _find_closing_brace string start + 4 args _split_conditional string[ start + 4 end - 1 ] rv ''if match group int conditional_match group 1 rv unescape _replace_conditional match args[0] elif len args > 1 rv unescape _replace_conditional match args[1] string string[ start] + rv + string[end ] conditional_match _CONDITIONAL search string return string
def apply_template template_dir output_dir context _mergetreejinja template_dir output_dir context
def apply_template template_dir output_dir context _mergetreejinja template_dir output_dir context
def _get_portage return reload portage
def _get_portage return reload portage
def test_on_content_type formatter hug output_format on_content_type {'application/json' hug output_format json 'text/plain' hug output_format text} class FakeRequest object content_type 'application/json'request FakeRequest response FakeRequest converted hug input_format json formatter BytesIO hug output_format json {'name' 'name'} request response assert converted {'name' 'name'} request content_type 'text/plain'assert formatter 'hi' request response 'hi' with pytest raises hug HTTPNotAcceptable request content_type 'undefined always'formatter 'hi' request response
def test_on_content_type formatter hug output_format on_content_type {'application/json' hug output_format json 'text/plain' hug output_format text} class FakeRequest object content_type 'application/json'request FakeRequest response FakeRequest converted hug input_format json formatter BytesIO hug output_format json {'name' 'name'} request response assert converted {'name' 'name'} request content_type 'text/plain'assert formatter 'hi' request response 'hi' with pytest raises hug HTTPNotAcceptable request content_type 'undefined always'formatter 'hi' request response
def read_config_file option opt value parser try new_settings parser get_config_file_settings value except ValueError as error parser error error parser values update new_settings parser
def create_return_url base query **kwargs part urlsplit base if part fragment raise ValueError "BaseURLcontainedpartsitshouldn't" for key values in parse_qs query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] valuesif part query for key values in parse_qs part query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] values_pre base split '?' [0]else _pre baselogger debug 'kwargs %s' % kwargs return '%s?%s' % _pre url_encode_params kwargs
def create_return_url base query **kwargs part urlsplit base if part fragment raise ValueError "BaseURLcontainedpartsitshouldn't" for key values in parse_qs query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] valuesif part query for key values in parse_qs part query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] values_pre base split '?' [0]else _pre baselogger debug 'kwargs %s' % kwargs return '%s?%s' % _pre url_encode_params kwargs
def create_return_url base query **kwargs part urlsplit base if part fragment raise ValueError "BaseURLcontainedpartsitshouldn't" for key values in parse_qs query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] valuesif part query for key values in parse_qs part query items if key in kwargs if isinstance kwargs[key] basestring kwargs[key] [kwargs[key]]kwargs[key] extend values else kwargs[key] values_pre base split '?' [0]else _pre baselogger debug 'kwargs %s' % kwargs return '%s?%s' % _pre url_encode_params kwargs
def clear_entries options with Session as session query session query PendingEntry filter PendingEntry approved False if options task_name query query filter PendingEntry task_name options task_name deleted query delete console u'Successfullydeleted%ipendingentries' % deleted
def update_user_attributes user profile attributes_dict save False profile_fields []if profile profile_fields [f name for f in profile _meta fields]user_fields [f name for f in user _meta fields]is_profile_field lambda f f in profile_fields and hasattr profile f is_user_field lambda f f in user_fields and hasattr user f for f value in attributes_dict items if is_profile_field f setattr profile f value profile _fb_is_dirty Trueelif is_user_field f setattr user f value user _fb_is_dirty Trueelse logger info 'skippingupdateoffield%s' f if save if getattr user '_fb_is_dirty' False user save if profile and getattr profile '_fb_is_dirty' False profile save
def setup_platform hass config add_devices discovery_info None from pysabnzbd import SabnzbdApi SabnzbdApiExceptionhost config get CONF_HOST port config get CONF_PORT name config get CONF_NAME api_key config get CONF_API_KEY monitored_types config get CONF_MONITORED_VARIABLES use_ssl config get CONF_SSL if use_ssl uri_scheme 'https //'else uri_scheme 'http //'base_url '{}{} {}/' format uri_scheme host port sab_api SabnzbdApi base_url api_key try sab_api check_available except SabnzbdApiException _LOGGER error 'ConnectiontoSABnzbdAPIfailed' return Falseglobal _THROTTLED_REFRESH_THROTTLED_REFRESH Throttle MIN_TIME_BETWEEN_UPDATES sab_api refresh_queue devices []for variable in monitored_types devices append SabnzbdSensor variable sab_api name add_devices devices
def widgets_sorter widget return WIDGETS[widget] order
def validate_index index_vals from numbers import Numberif isinstance index_vals[0] Number if not all isinstance item Number for item in index_vals raise exceptions PlotlyError 'Errorinindexingcolumn Makesureallentriesofeachcolumnareallnumbersorallstrings ' elif isinstance index_vals[0] str if not all isinstance item str for item in index_vals raise exceptions PlotlyError 'Errorinindexingcolumn Makesureallentriesofeachcolumnareallnumbersorallstrings '
def getPointPlusSegmentWithLength length point segment return segment * length / abs segment + point
def __getMasterPassword global MasterPassword pw ok QInputDialog getText None QCoreApplication translate u'Crypto' u'MasterPassword' QCoreApplication translate u'Crypto' u'Enterthemasterpassword ' QLineEdit Password if ok from py3PBKDF2 import verifyPasswordmasterPassword Preferences getUser u'MasterPassword' try if masterPassword if verifyPassword pw masterPassword MasterPassword pwEncode pw else E5MessageBox warning None QCoreApplication translate u'Crypto' u'MasterPassword' QCoreApplication translate u'Crypto' u'Thegivenpasswordisincorrect ' else E5MessageBox critical None QCoreApplication translate u'Crypto' u'MasterPassword' QCoreApplication translate u'Crypto' u'Thereisnomasterpasswordregistered ' except ValueError as why E5MessageBox warning None QCoreApplication translate u'Crypto' u'MasterPassword' QCoreApplication translate u'Crypto' u'<p>Thegivenpasswordcannotbeverified </p><p>Reason {0}' format str why
@require_POST@login_requireddef update_coupon request course_id coupon_id request POST get 'coupon_id' None if not coupon_id return JsonResponse {'message' _ 'couponidnotfound' } status 400 try coupon Coupon objects get pk coupon_id except ObjectDoesNotExist return JsonResponse {'message' _ 'couponwiththecouponid {coupon_id} DoesNotExist' format coupon_id coupon_id } status 400 description request POST get 'description' coupon description descriptioncoupon save return JsonResponse {'message' _ 'couponwiththecouponid {coupon_id} updatedSuccessfully' format coupon_id coupon_id }
def absent name region None key None keyid None profile None ret {'name' name 'result' True 'comment' '' 'changes' {}}is_present __salt__['boto_cloudwatch get_alarm'] name region key keyid profile if is_present if __opts__['test'] ret['comment'] 'alarm{0}issettoberemoved ' format name ret['result'] Nonereturn retdeleted __salt__['boto_cloudwatch delete_alarm'] name region key keyid profile if deleted ret['changes']['old'] nameret['changes']['new'] Noneelse ret['result'] Falseret['comment'] 'Failedtodelete{0}alarm ' format name else ret['comment'] '{0}doesnotexistin{1} ' format name region return ret
def paging pause 0 marker_property 'marker' def wrapper f def page *args **kwargs results []marker Nonewhile True try new f marker marker *args **kwargs marker getattr new marker_property results extend new if not marker breakelif pause sleep pause except TypeError results f *args **kwargs breakreturn resultsreturn pagereturn wrapper
def paging pause 0 marker_property 'marker' def wrapper f def page *args **kwargs results []marker Nonewhile True try new f marker marker *args **kwargs marker getattr new marker_property results extend new if not marker breakelif pause sleep pause except TypeError results f *args **kwargs breakreturn resultsreturn pagereturn wrapper
def paging pause 0 marker_property 'marker' def wrapper f def page *args **kwargs results []marker Nonewhile True try new f marker marker *args **kwargs marker getattr new marker_property results extend new if not marker breakelif pause sleep pause except TypeError results f *args **kwargs breakreturn resultsreturn pagereturn wrapper
def paging pause 0 marker_property 'marker' def wrapper f def page *args **kwargs results []marker Nonewhile True try new f marker marker *args **kwargs marker getattr new marker_property results extend new if not marker breakelif pause sleep pause except TypeError results f *args **kwargs breakreturn resultsreturn pagereturn wrapper
def _feed_cli_with_input text editing_mode EditingMode EMACS clipboard None history None multiline False check_line_ending True pre_run_callback None if check_line_ending assert text endswith u'\n' loop PosixEventLoop try inp PipeInput inp send_text text cli CommandLineInterface application Application buffer Buffer accept_action AcceptAction RETURN_DOCUMENT history history is_multiline multiline editing_mode editing_mode clipboard clipboard or InMemoryClipboard key_bindings_registry KeyBindingManager for_prompt registry eventloop loop input inp output DummyOutput if pre_run_callback pre_run_callback cli result cli run return result cli finally loop close inp close
def gcd a b while b a b b a % b return a
def applyRedirects manifest redirects for binding in redirects for dep in manifest dependentAssemblies if match_binding_redirect dep binding logger info 'Redirecting%sversion%s->%s' binding name dep version binding newVersion dep version binding newVersion
def bulk_update_nodes serialize nodes index None index index or INDEX actions []for node in nodes serialized serialize node if serialized actions append {'_op_type' 'update' '_index' index '_id' node _id '_type' get_doctype_from_node node 'doc' serialized 'doc_as_upsert' True} if actions return helpers bulk client actions
def test_now now datetime datetime utcnow t Time now assert t format 'datetime' assert t scale 'utc' dt t datetime - now if sys version_info[ 2] < 2 7 total_secs lambda td td microseconds + td seconds + td days * 24 * 3600 * 10 ** 6 / 10 ** 6 0 else total_secs lambda td td total_seconds assert total_secs dt < 0 1
def test_now now datetime datetime utcnow t Time now assert t format 'datetime' assert t scale 'utc' dt t datetime - now if sys version_info[ 2] < 2 7 total_secs lambda td td microseconds + td seconds + td days * 24 * 3600 * 10 ** 6 / 10 ** 6 0 else total_secs lambda td td total_seconds assert total_secs dt < 0 1
def check_key_expired key node url if key in node private_link_keys_deleted url furl url add {'status' 'expired'} urlreturn url
@pytest fixture scope 'session' def stubs return stubsmod
def test_neg_clrtype_wrong_case global calledcalled Falseclass MyType type def __clrType__ self global calledcalled Truereturn super MyType self __clrtype__ class X object __metaclass__ MyTypeAreEqual called False
def test_neg_clrtype_wrong_case global calledcalled Falseclass MyType type def __clrType__ self global calledcalled Truereturn super MyType self __clrtype__ class X object __metaclass__ MyTypeAreEqual called False
def cmd_watch args if len args 0 mpstate status watch Nonereturnmpstate status watch args[0]print 'Watching%s' % mpstate status watch
@utils expects_func_args 'self' 'spec_obj' def set_update_time_on_success function @functools wraps function def decorated_function self spec_obj return_value Nonetry return_value function self spec_obj except Exception as e LOG warning _LW 'Selectedhost % host sfailedtoconsumefrominstance Error % error s' {'host' self host 'error' e} else now timeutils utcnow self updated now replace tzinfo iso8601 iso8601 Utc return return_valuereturn decorated_function
@utils expects_func_args 'self' 'spec_obj' def set_update_time_on_success function @functools wraps function def decorated_function self spec_obj return_value Nonetry return_value function self spec_obj except Exception as e LOG warning _LW 'Selectedhost % host sfailedtoconsumefrominstance Error % error s' {'host' self host 'error' e} else now timeutils utcnow self updated now replace tzinfo iso8601 iso8601 Utc return return_valuereturn decorated_function
def nopackage pkg_name orphan True if is_installed pkg_name uninstall pkg_name orphan
def _generate_indices f values False axes f axesif values axes [lrange len a for a in axes]return itertools product *axes
def listOfFeatures2Matrix features X numpy array [] Y numpy array [] for i f in enumerate features if i 0 X fY i * numpy ones len f 1 else X numpy vstack X f Y numpy append Y i * numpy ones len f 1 return X Y
def listOfFeatures2Matrix features X numpy array [] Y numpy array [] for i f in enumerate features if i 0 X fY i * numpy ones len f 1 else X numpy vstack X f Y numpy append Y i * numpy ones len f 1 return X Y
@instrumented_task name 'sentry tasks options sync_options' queue 'options' def sync_options cutoff ONE_HOUR cutoff_dt timezone now - timedelta seconds cutoff for option in Option objects filter last_updated__gte cutoff_dt iterator try opt default_manager lookup_key option key default_manager store set_cache opt option value except UnknownOption as e logger exception six text_type e
@instrumented_task name 'sentry tasks options sync_options' queue 'options' def sync_options cutoff ONE_HOUR cutoff_dt timezone now - timedelta seconds cutoff for option in Option objects filter last_updated__gte cutoff_dt iterator try opt default_manager lookup_key option key default_manager store set_cache opt option value except UnknownOption as e logger exception six text_type e
@instrumented_task name 'sentry tasks options sync_options' queue 'options' def sync_options cutoff ONE_HOUR cutoff_dt timezone now - timedelta seconds cutoff for option in Option objects filter last_updated__gte cutoff_dt iterator try opt default_manager lookup_key option key default_manager store set_cache opt option value except UnknownOption as e logger exception six text_type e
@instrumented_task name 'sentry tasks options sync_options' queue 'options' def sync_options cutoff ONE_HOUR cutoff_dt timezone now - timedelta seconds cutoff for option in Option objects filter last_updated__gte cutoff_dt iterator try opt default_manager lookup_key option key default_manager store set_cache opt option value except UnknownOption as e logger exception six text_type e
def task_ready request remove_request requests pop discard_active_request active_requests discard discard_reserved_request reserved_requests discard remove_request request id None discard_active_request request discard_reserved_request request
@celery taskdef send_activation_token user token make_token user user operation 'activate_account' send_email subject _ 'AccountActivation' recipients [user email] text_body render_template 'email/activate_account txt' user user token token html_body render_template 'email/activate_account html' user user token token
def addCube elementNode faces inradius vertexes square [complex - inradius x - inradius y complex inradius x - inradius y complex inradius x inradius y complex - inradius x inradius y ]bottomTopSquare triangle_mesh getAddIndexedLoops square vertexes [ - inradius z inradius z] triangle_mesh addPillarByLoops faces bottomTopSquare
@register function@jinja2 contextfunctiondef sort_link context pretty_name sort_field request context['request'] sort order clean_sort_param request get_params [ k v for k v in urlparse parse_qsl smart_str request META['QUERY_STRING'] if k not in 'sort' 'order' ]return create_sort_link pretty_name sort_field get_params sort order
def migrate_osx_xdg_data config assert is_osx 'ThisfunctionshouldonlyberunonOSX 'xdg_data_home os path join os path expanduser '~' ' local' 'share' xdg_aj_home os path join xdg_data_home 'autojump' data_path os path join xdg_aj_home 'autojump txt' backup_path os path join xdg_aj_home 'autojump txt bak' if os path exists data_path move_file data_path config['data_path'] if os path exists backup_path move_file backup_path config['backup_path'] shutil rmtree xdg_aj_home if len os listdir xdg_data_home 0 shutil rmtree xdg_data_home
def migrate_osx_xdg_data config assert is_osx 'ThisfunctionshouldonlyberunonOSX 'xdg_data_home os path join os path expanduser '~' ' local' 'share' xdg_aj_home os path join xdg_data_home 'autojump' data_path os path join xdg_aj_home 'autojump txt' backup_path os path join xdg_aj_home 'autojump txt bak' if os path exists data_path move_file data_path config['data_path'] if os path exists backup_path move_file backup_path config['backup_path'] shutil rmtree xdg_aj_home if len os listdir xdg_data_home 0 shutil rmtree xdg_data_home
def get_price_infos context products quantity 1 mod ctx _get_module_and_context context prices mod get_price_infos ctx products quantity for module in get_discount_modules prices module discount_prices ctx products prices return prices
def strategy_largest_first G colors return sorted G key G degree reverse True
def new_agent bindings port 8084 spinnaker GateAgent new_instance_from_bindings 'gate' GateTaskStatus new bindings port return spinnaker
def make_testdata_filename mission_type filename return os path join os path dirname __file__ ' ' mission_type 'testdata' filename
@contextmanagerdef swap_stdin_and_argv stdin_data '' argv_data tuple real_stdin sys stdinif PY3 sys stdin StringIO stdin_data sys stdin buffer BytesIO to_bytes stdin_data else sys stdin BytesIO to_bytes stdin_data real_argv sys argvsys argv argv_data yield sys stdin real_stdinsys argv real_argv
@contextmanagerdef swap_stdin_and_argv stdin_data '' argv_data tuple real_stdin sys stdinif PY3 sys stdin StringIO stdin_data sys stdin buffer BytesIO to_bytes stdin_data else sys stdin BytesIO to_bytes stdin_data real_argv sys argvsys argv argv_data yield sys stdin real_stdinsys argv real_argv
def getEmptyZLoops archivableObjects importRadius shouldPrintWarning z zoneArrangement emptyZ zoneArrangement getEmptyZ z visibleObjects evaluate getVisibleObjects archivableObjects visibleObjectLoopsList boolean_solid getVisibleObjectLoopsList importRadius visibleObjects emptyZ loops euclidean getConcatenatedList visibleObjectLoopsList if euclidean isLoopListIntersecting loops loops boolean_solid getLoopsUnion importRadius visibleObjectLoopsList if shouldPrintWarning print 'Warning thetrianglemeshsliceintersectsitselfingetExtruderPathsinboolean_geometry 'print 'Somethingwillstillbeprinted butthereisnoguaranteethatitwillbethecorrectshape 'print 'Oncethegcodeissaved youshouldcheckoverthelayerwithazof 'print zreturn loops
def add_threading_args parser parser add_argument u'--threads' u'-T' default DEFAULT_N_THREADS type int help u'Numberofsimultaneousthreadstoexecute'
def demo print '---------------------------------------'print 'Processing%dsequencesfrom%dsamples' % len DEMO_SEQUENCES len DEMO_SAMPLE_MAPPING print '---------------------------------------'for ix cur_seq in enumerate DEMO_SEQUENCES barcode cur_seq[ 8]seq_read cur_seq[8 ]print '--->processingdemosequence' ixprint 'readbarcode ' barcodetry corrected_barcode decode_barcode_8 barcode orig_sample_id DEMO_SAMPLE_MAPPING[corrected_barcode]if corrected_barcode barcode print '*correctedbarcode ' corrected_barcodeelse print '-noerrorbarcode ' corrected_barcodeprint 'originalsampleid ' orig_sample_idprint 'sequenceread ' seq_readexcept ValueError as e print ' ' str e 'skipping 'continue
def demo print '---------------------------------------'print 'Processing%dsequencesfrom%dsamples' % len DEMO_SEQUENCES len DEMO_SAMPLE_MAPPING print '---------------------------------------'for ix cur_seq in enumerate DEMO_SEQUENCES barcode cur_seq[ 8]seq_read cur_seq[8 ]print '--->processingdemosequence' ixprint 'readbarcode ' barcodetry corrected_barcode decode_barcode_8 barcode orig_sample_id DEMO_SAMPLE_MAPPING[corrected_barcode]if corrected_barcode barcode print '*correctedbarcode ' corrected_barcodeelse print '-noerrorbarcode ' corrected_barcodeprint 'originalsampleid ' orig_sample_idprint 'sequenceread ' seq_readexcept ValueError as e print ' ' str e 'skipping 'continue
def findElementsWithId node elems None if elems is None elems {}id node getAttribute 'id' if id '' elems[id] nodeif node hasChildNodes for child in node childNodes if child nodeType 1 findElementsWithId child elems return elems
def get_user_settings_from_username username user_model user_models UserSettingsModel get_by_normalized_username UserSettings normalize_username username if user_model is None return Noneelse return get_user_settings user_model id
def migrate_hosted_facts facts if 'master' in facts if 'router_selector' in facts['master'] if 'hosted' not in facts facts['hosted'] {}if 'router' not in facts['hosted'] facts['hosted']['router'] {}facts['hosted']['router']['selector'] facts['master'] pop 'router_selector' if 'registry_selector' in facts['master'] if 'hosted' not in facts facts['hosted'] {}if 'registry' not in facts['hosted'] facts['hosted']['registry'] {}facts['hosted']['registry']['selector'] facts['master'] pop 'registry_selector' return facts
def get_markup_filter_display_name name get_markup_filter_name return {'textile' u'Textile' 'markdown' u'Markdown' 'restructuredtext' u'reStructuredText'} get name u'HTML'
def get_markup_filter_display_name name get_markup_filter_name return {'textile' u'Textile' 'markdown' u'Markdown' 'restructuredtext' u'reStructuredText'} get name u'HTML'
def json_dump data filename with open filename u'w' as fh json dump data fh cls JSONEncoder indent 2
def get_available_ctid current_ctids list_ctids if current_ctids return max current_ctids + 1 else return 1000
def get_default_compiler osname None platform None if osname is None osname os nameif platform is None platform sys platformfor pattern compiler in _default_compilers if re match pattern platform is not None or re match pattern osname is not None return compilerreturn 'unix'
def sort key new new def sort_rl expr return new expr __class__ *sorted expr args key key return sort_rl
def GetFeedItemIdsForCampaign campaign_feed feed_item_ids set try lhs_operand campaign_feed['matchingFunction']['lhsOperand']except KeyError lhs_operand Noneif lhs_operand and lhs_operand[0]['FunctionArgumentOperand Type'] 'RequestContextOperand' request_context_operand lhs_operand[0]if request_context_operand['contextType'] 'FEED_ITEM_ID' and campaign_feed['matchingFunction']['operator'] 'IN' for argument in campaign_feed['matchingFunction']['rhsOperand'] if argument['xsi_type'] 'ConstantOperand' feed_item_ids add argument['longValue'] return feed_item_ids
def GetFeedItemIdsForCampaign campaign_feed feed_item_ids set try lhs_operand campaign_feed['matchingFunction']['lhsOperand']except KeyError lhs_operand Noneif lhs_operand and lhs_operand[0]['FunctionArgumentOperand Type'] 'RequestContextOperand' request_context_operand lhs_operand[0]if request_context_operand['contextType'] 'FEED_ITEM_ID' and campaign_feed['matchingFunction']['operator'] 'IN' for argument in campaign_feed['matchingFunction']['rhsOperand'] if argument['xsi_type'] 'ConstantOperand' feed_item_ids add argument['longValue'] return feed_item_ids
def tp_read fd n return get_hub threadpool apply _read fd n
def normalize_dotted_fields document if isinstance document list prev documentfor i in prev normalize_dotted_fields i elif isinstance document dict for field in list document if ' ' in field parts field split ' ' prev documentfor part in parts[ -1 ] if part not in prev prev[part] {}prev prev[part]if isinstance document[field] dict list normalize_dotted_fields document[field] prev[parts[ -1 ]] document[field]document pop field elif isinstance document[field] dict list normalize_dotted_fields document[field]
def version_compare value version operator 'eq' strict False op_map {' ' 'eq' ' ' 'eq' 'eq' 'eq' '<' 'lt' 'lt' 'lt' '< ' 'le' 'le' 'le' '>' 'gt' 'gt' 'gt' '> ' 'ge' 'ge' 'ge' ' ' 'ne' '<>' 'ne' 'ne' 'ne'}if strict Version StrictVersionelse Version LooseVersionif operator in op_map operator op_map[operator]else raise errors AnsibleFilterError 'Invalidoperatortype' try method getattr py_operator operator return method Version str value Version str version except Exception as e raise errors AnsibleFilterError 'Versioncomparison %s' % e
def fsencoding s encoding sys getfilesystemencoding if isinstance s unicode s s encode encoding return s
def getUniqueQuoteIndex uniqueQuoteIndex word uniqueQuoteIndex + 1while getTokenByNumber uniqueQuoteIndex in word uniqueQuoteIndex + 1return uniqueQuoteIndex
def get_original mod_name item_name if isinstance item_name string_types return _get_original mod_name [item_name] [0]else return _get_original mod_name item_name
def read_file filename mode 'rb' fh open filename mode try return fh read finally fh close
def main logging_manager configure_logging BuildExternalsLoggingConfig verbose True os umask 18 top_of_tree external_packages find_top_of_autotest_tree package_dir os path join top_of_tree PACKAGE_DIR install_dir os path join top_of_tree INSTALL_DIR if install_dir not in sys path sys path insert 0 install_dir env_python_path_varname 'PYTHONPATH'env_python_path os environ get env_python_path_varname '' if install_dir + ' ' not in env_python_path os environ[env_python_path_varname] ' ' join [install_dir env_python_path] fetched_packages fetch_errors fetch_necessary_packages package_dir install_dir install_errors build_and_install_packages fetched_packages install_dir logging info 'compiling pyfilesin%sto pyc' install_dir compileall compile_dir install_dir quiet True external_packages system "chmod-Ra+rX'%s'" % install_dir errors fetch_errors + install_errors for error_msg in errors logging error error_msg return len errors
def main logging_manager configure_logging BuildExternalsLoggingConfig verbose True os umask 18 top_of_tree external_packages find_top_of_autotest_tree package_dir os path join top_of_tree PACKAGE_DIR install_dir os path join top_of_tree INSTALL_DIR if install_dir not in sys path sys path insert 0 install_dir env_python_path_varname 'PYTHONPATH'env_python_path os environ get env_python_path_varname '' if install_dir + ' ' not in env_python_path os environ[env_python_path_varname] ' ' join [install_dir env_python_path] fetched_packages fetch_errors fetch_necessary_packages package_dir install_dir install_errors build_and_install_packages fetched_packages install_dir logging info 'compiling pyfilesin%sto pyc' install_dir compileall compile_dir install_dir quiet True external_packages system "chmod-Ra+rX'%s'" % install_dir errors fetch_errors + install_errors for error_msg in errors logging error error_msg return len errors
def main logging_manager configure_logging BuildExternalsLoggingConfig verbose True os umask 18 top_of_tree external_packages find_top_of_autotest_tree package_dir os path join top_of_tree PACKAGE_DIR install_dir os path join top_of_tree INSTALL_DIR if install_dir not in sys path sys path insert 0 install_dir env_python_path_varname 'PYTHONPATH'env_python_path os environ get env_python_path_varname '' if install_dir + ' ' not in env_python_path os environ[env_python_path_varname] ' ' join [install_dir env_python_path] fetched_packages fetch_errors fetch_necessary_packages package_dir install_dir install_errors build_and_install_packages fetched_packages install_dir logging info 'compiling pyfilesin%sto pyc' install_dir compileall compile_dir install_dir quiet True external_packages system "chmod-Ra+rX'%s'" % install_dir errors fetch_errors + install_errors for error_msg in errors logging error error_msg return len errors
def isotime at if at is None return Nonereturn at strftime '%Y-%m-%dT%H %M %SZ'
def remove_masquerade zone None permanent True if zone cmd '--zone {0}--remove-masquerade' format zone else cmd '--remove-masquerade'if permanent cmd + '--permanent'return __firewall_cmd cmd
def get_http_status status_code default_reason 'Unknown' try code float status_code code int code if code < 100 raise ValueErrorexcept ValueError raise ValueError 'get_http_statusfailed "%s"isnotavalidstatuscode' status_code try return getattr status_codes 'HTTP_' + str code except AttributeError return str code + '' + default_reason
def get_http_status status_code default_reason 'Unknown' try code float status_code code int code if code < 100 raise ValueErrorexcept ValueError raise ValueError 'get_http_statusfailed "%s"isnotavalidstatuscode' status_code try return getattr status_codes 'HTTP_' + str code except AttributeError return str code + '' + default_reason
def get_http_status status_code default_reason 'Unknown' try code float status_code code int code if code < 100 raise ValueErrorexcept ValueError raise ValueError 'get_http_statusfailed "%s"isnotavalidstatuscode' status_code try return getattr status_codes 'HTTP_' + str code except AttributeError return str code + '' + default_reason
def _generate_site_navigation pages_config url_context use_dir_urls True nav_items []pages []previous Nonefor config_line in pages_config for page_or_header in _follow config_line url_context use_dir_urls if isinstance page_or_header Header if page_or_header is_top_level nav_items append page_or_header elif isinstance page_or_header Page if page_or_header is_top_level nav_items append page_or_header pages append page_or_header if previous page_or_header previous_page previousprevious next_page page_or_headerprevious page_or_headerif len pages 0 raise exceptions ConfigurationError u'Nopagesfoundinthepagesconfig Removeitentirelytoenableautomaticpagediscovery ' return nav_items pages
def _generate_site_navigation pages_config url_context use_dir_urls True nav_items []pages []previous Nonefor config_line in pages_config for page_or_header in _follow config_line url_context use_dir_urls if isinstance page_or_header Header if page_or_header is_top_level nav_items append page_or_header elif isinstance page_or_header Page if page_or_header is_top_level nav_items append page_or_header pages append page_or_header if previous page_or_header previous_page previousprevious next_page page_or_headerprevious page_or_headerif len pages 0 raise exceptions ConfigurationError u'Nopagesfoundinthepagesconfig Removeitentirelytoenableautomaticpagediscovery ' return nav_items pages
@pytest mark parametrize 'fast_writer' [True False] def test_write_no_data_ipac fast_writer table ascii get_reader Reader ascii Ipac data table read 't/no_data_ipac dat' for test_def in test_defs_no_data check_write_table test_def data fast_writer check_write_table_via_table test_def data fast_writer
@contextlib contextmanagerdef HandleServerException display True truncate False try try yield except UnknownExtraConf as e if vimsupport Confirm str e _LoadExtraConfFile e extra_conf_file else _IgnoreExtraConfFile e extra_conf_file except Exception as e _logger exception u'Errorwhilehandlingserverresponse' if display DisplayServerException e truncate
@contextlib contextmanagerdef HandleServerException display True truncate False try try yield except UnknownExtraConf as e if vimsupport Confirm str e _LoadExtraConfFile e extra_conf_file else _IgnoreExtraConfFile e extra_conf_file except Exception as e _logger exception u'Errorwhilehandlingserverresponse' if display DisplayServerException e truncate
def subgraph G nbunch return G subgraph nbunch
def _flat_palette color n_colors 6 reverse False as_cmap False input 'rgb' color _color_to_rgb color input flat desaturate color 0 colors [color flat] if reverse else [flat color] return blend_palette colors n_colors as_cmap
def _compute_residual proj_op B_orig fwd_orig Q return np dot proj_op B_orig - np dot np dot Q fwd_orig proj_op T
def psave fname d f file fname 'w' pickle dump d f f close
def reverse_version version if version try return reverse 'version-detail' kwargs {'pk' version pk} except AttributeError return versionreturn
def reverse_version version if version try return reverse 'version-detail' kwargs {'pk' version pk} except AttributeError return versionreturn
def reverse_version version if version try return reverse 'version-detail' kwargs {'pk' version pk} except AttributeError return versionreturn
def filter_re_search val pattern if not isinstance val basestring return valresult re search pattern val if result return result group 0 return u''
def median_absolute_deviation a axis None if isinstance a np ma MaskedArray func np ma medianelse func np mediana np asanyarray a a_median func a axis axis if axis is not None a_median np expand_dims a_median axis axis return func np abs a - a_median axis axis
def xml_format a if isinstance a basestring return '"%s"' % encode_entities a if isinstance a bool return '"%s"' % 'no' 'yes' [int a ] if isinstance a int long return '"%s"' % a if isinstance a float return '"%s"' % round a 5 if isinstance a type None return '""'if isinstance a Date return '"%s"' % str a if isinstance a datetime datetime return '"%s"' % str date mktime a timetuple
def makeKVPost request_message server_url resp fetchers fetch server_url body request_message toURLEncoded return _httpResponseToMessage resp server_url
def libvlc_video_get_track_count p_mi f _Cfunctions get 'libvlc_video_get_track_count' None or _Cfunction 'libvlc_video_get_track_count' 1 None ctypes c_int MediaPlayer return f p_mi
def notify_owner f @functools wraps f def wrapper *args **kwargs '\nifrequest args get \'confirmed\' "true" \ndag_id request args get \'dag_id\' \ntask_id request args get \'task_id\' \ndagbag models DagBag \nos path expanduser configuration get \'core\' \'DAGS_FOLDER\' \n\ndag dagbag get_dag dag_id \ntask dag get_task task_id \n\nifcurrent_userandhasattr current_user \'username\' \nuser current_user username\nelse \nuser \'anonymous\'\n\niftask owner user \nsubject \n\'ActionstakenonDAG{0}by{1}\' format \ndag_id user \nitems request args items \ncontent Template \'\'\'\naction <i>{{f __name__}}</i><br>\n<br>\n<b>Parameters</b> <br>\n<table>\n{%fork vinitems%}\n{%ifk \'origin\'%}\n<tr>\n<td>{{k}}</td>\n<td>{{v}}</td>\n</tr>\n{%endif%}\n{%endfor%}\n</table>\n\'\'\' render **locals \niftask email \nsend_email task email subject content \n'return f *args **kwargs return wrapper
def notify_owner f @functools wraps f def wrapper *args **kwargs '\nifrequest args get \'confirmed\' "true" \ndag_id request args get \'dag_id\' \ntask_id request args get \'task_id\' \ndagbag models DagBag \nos path expanduser configuration get \'core\' \'DAGS_FOLDER\' \n\ndag dagbag get_dag dag_id \ntask dag get_task task_id \n\nifcurrent_userandhasattr current_user \'username\' \nuser current_user username\nelse \nuser \'anonymous\'\n\niftask owner user \nsubject \n\'ActionstakenonDAG{0}by{1}\' format \ndag_id user \nitems request args items \ncontent Template \'\'\'\naction <i>{{f __name__}}</i><br>\n<br>\n<b>Parameters</b> <br>\n<table>\n{%fork vinitems%}\n{%ifk \'origin\'%}\n<tr>\n<td>{{k}}</td>\n<td>{{v}}</td>\n</tr>\n{%endif%}\n{%endfor%}\n</table>\n\'\'\' render **locals \niftask email \nsend_email task email subject content \n'return f *args **kwargs return wrapper
def notify_owner f @functools wraps f def wrapper *args **kwargs '\nifrequest args get \'confirmed\' "true" \ndag_id request args get \'dag_id\' \ntask_id request args get \'task_id\' \ndagbag models DagBag \nos path expanduser configuration get \'core\' \'DAGS_FOLDER\' \n\ndag dagbag get_dag dag_id \ntask dag get_task task_id \n\nifcurrent_userandhasattr current_user \'username\' \nuser current_user username\nelse \nuser \'anonymous\'\n\niftask owner user \nsubject \n\'ActionstakenonDAG{0}by{1}\' format \ndag_id user \nitems request args items \ncontent Template \'\'\'\naction <i>{{f __name__}}</i><br>\n<br>\n<b>Parameters</b> <br>\n<table>\n{%fork vinitems%}\n{%ifk \'origin\'%}\n<tr>\n<td>{{k}}</td>\n<td>{{v}}</td>\n</tr>\n{%endif%}\n{%endfor%}\n</table>\n\'\'\' render **locals \niftask email \nsend_email task email subject content \n'return f *args **kwargs return wrapper
def login_rate_limit_message current_limit getattr g 'view_rate_limit' None if current_limit is not None window_stats limiter limiter get_window_stats *current_limit reset_time datetime utcfromtimestamp window_stats[0] timeout reset_time - datetime utcnow return '{timeout}' format timeout format_timedelta timeout
def _GenerateMSBuildFiltersFile filters_path source_files rule_dependencies extension_to_rule_name filter_group []source_group []_AppendFiltersForMSBuild '' source_files rule_dependencies extension_to_rule_name filter_group source_group if filter_group content ['Project' {'ToolsVersion' '4 0' 'xmlns' 'http //schemas microsoft com/developer/msbuild/2003'} ['ItemGroup'] + filter_group ['ItemGroup'] + source_group ]easy_xml WriteXmlIfChanged content filters_path pretty True win32 True elif os path exists filters_path os unlink filters_path
def domains_configured f @functools wraps f def wrapper self *args **kwargs if not self domain_configs configured and CONF identity domain_specific_drivers_enabled with self domain_configs lock if not self domain_configs configured self domain_configs setup_domain_drivers self driver self resource_api return f self *args **kwargs return wrapper
def build_control_amp_service test_case reactor None if reactor is None reactor Clock cluster_state ClusterStateService reactor cluster_state startService test_case addCleanup cluster_state stopService persistence_service ConfigurationPersistenceService reactor test_case make_temporary_directory persistence_service startService test_case addCleanup persistence_service stopService return ControlAMPService reactor cluster_state persistence_service TCP4ServerEndpoint MemoryReactor 1234 ClientContextFactory
def filter_factory global_conf **local_conf conf global_conf copy conf update local_conf enabled not config_true_value conf get 'disable_encryption' 'false' register_swift_info 'encryption' admin True enabled enabled def encryption_filter app return Decrypter Encrypter app conf conf return encryption_filter
def is_hash_deleted context builder h deleted ir Constant h type DELETED return builder icmp_unsigned ' ' h deleted
def system_groovy registry xml_parent data root_tag 'hudson plugins groovy SystemGroovy'sysgroovy XML SubElement xml_parent root_tag sysgroovy append _groovy_common_scriptSource data XML SubElement sysgroovy 'bindings' text str data get 'bindings' '' XML SubElement sysgroovy 'classpath' text str data get 'class-path' ''
def segment_range_to_fragment_range segment_start segment_end segment_size fragment_size fragment_start segment_start / segment_size * fragment_size if segment_start is not None else None fragment_end None if segment_end is None else segment_end + 1 / segment_size * fragment_size if segment_start is None else segment_end + 1 / segment_size * fragment_size - 1 return fragment_start fragment_end
def segment_range_to_fragment_range segment_start segment_end segment_size fragment_size fragment_start segment_start / segment_size * fragment_size if segment_start is not None else None fragment_end None if segment_end is None else segment_end + 1 / segment_size * fragment_size if segment_start is None else segment_end + 1 / segment_size * fragment_size - 1 return fragment_start fragment_end
def buildDMG outdir os path join WORKDIR 'diskimage' if os path exists outdir shutil rmtree outdir imagepath os path join outdir 'python-%s-macosx' % getFullVersion if INCLUDE_TIMESTAMP imagepath imagepath + '%04d-%02d-%02d' % time localtime [ 3] imagepath imagepath + ' dmg' os mkdir outdir runCommand "hdiutilcreate-volname'UniversalMacPython%s'-srcfolder%s%s" % getFullVersion shellQuote os path join WORKDIR 'installer' shellQuote imagepath return imagepath
def buildDMG outdir os path join WORKDIR 'diskimage' if os path exists outdir shutil rmtree outdir imagepath os path join outdir 'python-%s-macosx' % getFullVersion if INCLUDE_TIMESTAMP imagepath imagepath + '%04d-%02d-%02d' % time localtime [ 3] imagepath imagepath + ' dmg' os mkdir outdir runCommand "hdiutilcreate-volname'UniversalMacPython%s'-srcfolder%s%s" % getFullVersion shellQuote os path join WORKDIR 'installer' shellQuote imagepath return imagepath
def decimal_relative_time d other None ndigits 0 cardinalize True if other is None other datetime utcnow diff other - d diff_seconds total_seconds diff abs_diff abs diff b_idx bisect bisect _BOUND_DELTAS abs_diff - 1 bbound bunit bname _BOUNDS[b_idx]f_diff diff_seconds / total_seconds bunit rounded_diff round f_diff ndigits if cardinalize return rounded_diff _cardinalize_time_unit bname abs rounded_diff return rounded_diff bname
def decimal_relative_time d other None ndigits 0 cardinalize True if other is None other datetime utcnow diff other - d diff_seconds total_seconds diff abs_diff abs diff b_idx bisect bisect _BOUND_DELTAS abs_diff - 1 bbound bunit bname _BOUNDS[b_idx]f_diff diff_seconds / total_seconds bunit rounded_diff round f_diff ndigits if cardinalize return rounded_diff _cardinalize_time_unit bname abs rounded_diff return rounded_diff bname
def _host_url_property def getter self if 'HTTP_HOST' in self environ host self environ['HTTP_HOST']else host '%s %s' % self environ['SERVER_NAME'] self environ['SERVER_PORT'] scheme self environ get 'wsgi url_scheme' 'http' if scheme 'http' and host endswith ' 80' host port host rsplit ' ' 1 elif scheme 'https' and host endswith ' 443' host port host rsplit ' ' 1 return '%s //%s' % scheme host return property getter doc 'Geturlforrequest/responseuptopath'
def _build_html_slider slices_range slides_klass slider_id start_value None if start_value is None start_value slices_range[ len slices_range // 2 ]return slider_template substitute slider_id slider_id klass slides_klass step slices_range[1] - slices_range[0] minvalue slices_range[0] maxvalue slices_range[ -1 ] startvalue start_value
def write_urls_index app exc inventory os path join app builder outdir 'objects inv' objects sphinx ext intersphinx fetch_inventory app DOCS_URL inventory with open os path join app builder outdir 'shorturls json' 'w' as f json dump objects f
def obtain_model show_ver match re search 'Cisco +? +bytesofmemory' show_ver if match return match group 1 else return None
def test_marked_class_run_twice testdir request py_file testdir makepyfile "\nimportpytest\n@pytest mark parametrize 'abc' [1 2 3] \nclassTest1 object \ndeftest_1 self abc \nassertabcin[1 2 3]\n" file_name os path basename py_file strpath rec testdir inline_run file_name file_name rec assertoutcome passed 6
def add_to_recent_scan name md5 url try db_obj RecentScansDB objects filter MD5 md5 if not db_obj exists new_db_obj RecentScansDB NAME name MD5 md5 URL url TS timezone now new_db_obj save except PrintException '[ERROR]AddingScanURLtoDatabase'
def add_to_recent_scan name md5 url try db_obj RecentScansDB objects filter MD5 md5 if not db_obj exists new_db_obj RecentScansDB NAME name MD5 md5 URL url TS timezone now new_db_obj save except PrintException '[ERROR]AddingScanURLtoDatabase'
def post_form_view request return post_form_response
@skip 'multiple_execute' @skip 'netstandard' def test_addreferencetofileandpath_conflict code1 '\nusingSystem \n\npublicclassCollisionTest{\npublicstaticstringResult {\nreturn"Test1" \n}\n}\n'code2 '\nusingSystem \n\npublicclassCollisionTest{\npublicstaticstringResult {\nreturn"Test2" \n}\n}\n'tmp testpath temporary_dir test1_cs test1_dll path_combine tmp 'test1 cs' path_combine tmp 'CollisionTest dll' test2_cs test2_dll path_combine tmp 'test2 cs' path_combine sys prefix 'CollisionTest dll' write_to_file test1_cs code1 write_to_file test2_cs code2 AreEqual run_csc '/nologo/target library/out ' + test2_dll + '' + test2_cs 0 AreEqual run_csc '/nologo/target library/out ' + test1_dll + '' + test1_cs 0 clr AddReferenceToFileAndPath test1_dll import CollisionTestAreEqual CollisionTest Result 'Test1'
def fit_constrained_wrap model constraints start_params None **fit_kwds self modelfrom patsy import DesignInfolc DesignInfo self exog_names linear_constraint constraints R q lc coefs lc constants params cov res_constr fit_constrained self R q start_params start_params fit_kwds fit_kwds res self fit start_params params maxiter 0 warn_convergence False res _results params paramsres _results normalized_cov_params covk_constr len q res _results df_resid + k_constrres _results df_model - k_constrres _results constraints lcres _results k_constr k_constrres _results results_constrained res_constrreturn res
def get_promo country_code programming_language gold_project False gold_user False promo_queryset SupporterPromo objects filter live True display_type 'doc' filtered_promos []for obj in promo_queryset if obj programming_language and not show_to_programming_language obj programming_language continueif country_code and not show_to_geo obj country_code continuefiltered_promos append obj promo_obj choose_promo filtered_promos if not promo_obj house_promo SupporterPromo objects filter live True name 'house' order_by '?' if house_promo exists promo_obj house_promo first if gold_user gold_promo SupporterPromo objects filter live True name 'gold-user' if gold_promo exists promo_obj gold_promo first if gold_project gold_promo SupporterPromo objects filter live True name 'gold-project' if gold_promo exists promo_obj gold_promo first return promo_obj
def test_property_always_set_descriptor class C object x property lambda self self _x def __init__ self self _x 42c C c __dict__['x'] 43AreEqual c x 42 class MyDescriptor object def __get__ self *args return 42class C object x MyDescriptor c C c __dict__['x'] 43AreEqual c x 43 class MyDescriptor object def __get__ self *args return 42def __set__ self *args passclass C object x MyDescriptor c C c __dict__['x'] 43AreEqual c x 42
def test_property_always_set_descriptor class C object x property lambda self self _x def __init__ self self _x 42c C c __dict__['x'] 43AreEqual c x 42 class MyDescriptor object def __get__ self *args return 42class C object x MyDescriptor c C c __dict__['x'] 43AreEqual c x 43 class MyDescriptor object def __get__ self *args return 42def __set__ self *args passclass C object x MyDescriptor c C c __dict__['x'] 43AreEqual c x 42
def migrate_admission_plugin_facts facts if 'master' in facts if 'kube_admission_plugin_config' in facts['master'] if 'admission_plugin_config' not in facts['master'] facts['master']['admission_plugin_config'] dict facts['master']['admission_plugin_config'] merge_facts facts['master']['admission_plugin_config'] facts['master']['kube_admission_plugin_config'] additive_facts_to_overwrite [] protected_facts_to_overwrite [] facts['master'] pop 'kube_admission_plugin_config' None return facts
def to_address num if num < 0 return to_hex num if num > 4294967295 return '0x%016x' % num else return '0x%08x' % num
def xml_add_meta data xml ''meta []if data get config META ordered_meta OrderedDict sorted data[config META] items for name value in ordered_meta items meta append '<%s>%d</%s>' % name value name if meta xml '<%s>%s</%s>' % config META '' join meta config META return xml
def group_snapshot_get context group_snapshot_id return IMPL group_snapshot_get context group_snapshot_id
def auto_complete request queryset fields None object_list []limit request GET get 'limit' 10 query request GET get 'term' '' if fields q_object Q for field in fields q_object Q **{field query} queryset queryset filter q_object for obj in queryset[ limit] object_list append {'text' obj __unicode__ 'id' obj pk} return HttpResponse json dumps object_list mimetype 'application/json'
def find_system_symbol img instruction_addr sdk_info None return DSymSymbol objects lookup_symbol instruction_addr instruction_addr image_addr img['image_addr'] image_vmaddr img['image_vmaddr'] uuid img['uuid'] cpu_name get_cpu_name img['cpu_type'] img['cpu_subtype'] object_path img['name'] sdk_info sdk_info
def _primitive f p ring f ringdom ring domaink ring ngenscoeffs {}for monom coeff in f iterterms if monom[ -1 ] not in coeffs coeffs[monom[ -1 ]] {}coeffs[monom[ -1 ]][monom[ -1 ]] coeffcont []for coeff in iter coeffs values cont gf_gcd cont gf_from_dict coeff p dom p dom yring ring clone symbols ring symbols[ k - 1 ] contf yring from_dense cont trunc_ground p return contf f quo contf set_ring ring
def getSubfolderWithBasename basename directory archive makeDirectory directory directoryListing os listdir directory for fileName in directoryListing joinedFileName os path join directory fileName if os path isdir joinedFileName if basename fileName return joinedFileNamereturn None
def groups many_to_one one_to_many defaultdict set for v k in many_to_one items one_to_many[k] add v return dict one_to_many
def get_tu source lang 'c' all_warnings False flags [] args list flags name 't c'if lang 'cpp' name 't cpp'args append '-std c++11' elif lang 'objc' name 't m'elif lang 'c' raise Exception 'Unknownlanguage %s' % lang if all_warnings args + ['-Wall' '-Wextra']return TranslationUnit from_source name args unsaved_files [ name source ]
def get_template_source name dirs None loaders []for loader in Engine get_default template_loaders if hasattr loader 'loaders' loaders extend loader loaders else loaders append loader for loader in loaders try return loader load_template_source name template_dirs dirs except TemplateDoesNotExist passraise TemplateDoesNotExist name
def get_page_class page_id warn u'get_page_classisdeprecatedinReviewBoard3 0andwillberemoved useAccountPage registry getinstead ' DeprecationWarning return AccountPage registry get u'page_id' page_id
@verbosedef data_path path None force_update False update_path True download True verbose None return _data_path path path force_update force_update update_path update_path name 'visual_92_categories' download download
def set_rollback rollback using None return get_connection using set_rollback rollback
def arg_string func return inspect formatargspec *inspect getargspec func
@receiver got_request_exception def record_request_exception sender **kwargs logging exception 'Uncaughtexceptionfrom{sender}' format sender sender
@receiver got_request_exception def record_request_exception sender **kwargs logging exception 'Uncaughtexceptionfrom{sender}' format sender sender
def instructor_task_status request output {}task_id request GET get 'task_id' or request POST get 'task_id' tasks request GET get 'task_ids[]' or request POST get 'task_ids[]' if task_id output _get_instructor_task_status task_id elif tasks for task_id in tasks task_output _get_instructor_task_status task_id if task_output is not None output[task_id] task_outputreturn HttpResponse json dumps output indent 4
def make_img_name file_ext ' png' fn []for i in range 0 30 fn append choice ALPHABET return '' join fn + file_ext
def default_route family None if family 'inet' and family 'inet6' and family is not None raise CommandExecutionError 'Invalidaddressfamily{0}' format family _routes routes default_route {}if __grains__['kernel'] 'Linux' default_route['inet'] ['0 0 0 0' 'default']default_route['inet6'] [' /0' 'default']elif __grains__['os'] in ['FreeBSD' 'NetBSD' 'OpenBSD' 'MacOS' 'Darwin'] or __grains__['kernel'] 'SunOS' default_route['inet'] ['default']default_route['inet6'] ['default']else raise CommandExecutionError 'Notyetsupportedonthisplatform' ret []for route in _routes if family if route['destination'] in default_route[family] if __grains__['kernel'] 'SunOS' and route['addr_family'] family continueret append route elif route['destination'] in default_route['inet'] or route['destination'] in default_route['inet6'] ret append route return ret
def get_dev_count_for_disk_bus disk_bus if disk_bus 'ide' return 4else return 26
def initialize api bootstrap context 'cli' api finalize try api Backend rpcclient connect except AttributeError api Backend xmlclient connect return api
def _check_ip_available ip_addr for vm_name vm_details in six iteritems get_resources_vms includeConfig True vm_config vm_details['config']if ip_addr in vm_config['ip_address'] or vm_config['ip_address'] ip_addr log debug 'IP"{0}"isalreadydefined' format ip_addr return Falselog debug "IP'{0}'isavailabletobedefined" format ip_addr return True
def _check_ip_available ip_addr for vm_name vm_details in six iteritems get_resources_vms includeConfig True vm_config vm_details['config']if ip_addr in vm_config['ip_address'] or vm_config['ip_address'] ip_addr log debug 'IP"{0}"isalreadydefined' format ip_addr return Falselog debug "IP'{0}'isavailabletobedefined" format ip_addr return True
def _UpdateUserHistory user t auth ts _history get user [] [ -30 ]ts append t auth _history[user] tsreturn ts
def getappterminology fullname verbose None if not MacOS WMAvailable raise RuntimeError 'CannotsendAppleEvents noaccesstowindowmanager'import Carbon EvtCarbon Evt WaitNextEvent 0 0 if os path isdir fullname pkginfo os path join fullname 'Contents' 'PkgInfo' if not os path exists pkginfo raise RuntimeError 'NoPkgInfofilefound'tp_cr open pkginfo 'rb' read cr tp_cr[4 8]else cr tp MacOS GetCreatorAndType fullname talker aetools TalkTo cr try talker _start except MacOS Error aetools Error as arg if verbose print >>verbose 'Warning start failed continuinganyway ' argreply talker send 'ascr' 'gdte' return reply[1]['----'] cr
def getappterminology fullname verbose None if not MacOS WMAvailable raise RuntimeError 'CannotsendAppleEvents noaccesstowindowmanager'import Carbon EvtCarbon Evt WaitNextEvent 0 0 if os path isdir fullname pkginfo os path join fullname 'Contents' 'PkgInfo' if not os path exists pkginfo raise RuntimeError 'NoPkgInfofilefound'tp_cr open pkginfo 'rb' read cr tp_cr[4 8]else cr tp MacOS GetCreatorAndType fullname talker aetools TalkTo cr try talker _start except MacOS Error aetools Error as arg if verbose print >>verbose 'Warning start failed continuinganyway ' argreply talker send 'ascr' 'gdte' return reply[1]['----'] cr
def windowSequenceEval DS winsz result si_old 0idx 0x []y []seq_res []for i si in enumerate DS['sequence_index'][1 ] astype int tar DS['target'][ si - 1 ]curr_x si_oldcorrect 0 0wrong 0 0while curr_x < si x append curr_x if result[idx] tar correct + 1 0y + [1 0 1 0]else wrong + 1 0y + [0 0 0 0]idx + 1curr_x + winszx append curr_x seq_res append 100 0 * correct / correct + wrong print 'sequence%dcorrect %g12 2%%' % i seq_res[ -1 ] seq_res array seq_res print 'totalfractionofcorrectsequences ' 100 0 * float seq_res > 0 5 sum / seq_res size
def windowSequenceEval DS winsz result si_old 0idx 0x []y []seq_res []for i si in enumerate DS['sequence_index'][1 ] astype int tar DS['target'][ si - 1 ]curr_x si_oldcorrect 0 0wrong 0 0while curr_x < si x append curr_x if result[idx] tar correct + 1 0y + [1 0 1 0]else wrong + 1 0y + [0 0 0 0]idx + 1curr_x + winszx append curr_x seq_res append 100 0 * correct / correct + wrong print 'sequence%dcorrect %g12 2%%' % i seq_res[ -1 ] seq_res array seq_res print 'totalfractionofcorrectsequences ' 100 0 * float seq_res > 0 5 sum / seq_res size
def _generate_init class_ class_manager original__init__ class_ __init__assert original__init__func_body 'def__init__ % apply_pos s \nnew_state class_manager _new_state_if_none % self_arg s \nifnew_state \nreturnnew_state _initialize_instance % apply_kw s \nelse \nreturnoriginal__init__ % apply_kw s \n'func_vars util format_argspec_init original__init__ grouped False func_text func_body % func_vars if util py2k func getattr original__init__ 'im_func' original__init__ func_defaults getattr func 'func_defaults' None else func_defaults getattr original__init__ '__defaults__' None func_kw_defaults getattr original__init__ '__kwdefaults__' None env locals copy exec func_text in env__init__ env['__init__']__init__ __doc__ original__init__ __doc__if func_defaults __init__ __defaults__ func_defaultsif not util py2k and func_kw_defaults __init__ __kwdefaults__ func_kw_defaultsreturn __init__
def _generate_init class_ class_manager original__init__ class_ __init__assert original__init__func_body 'def__init__ % apply_pos s \nnew_state class_manager _new_state_if_none % self_arg s \nifnew_state \nreturnnew_state _initialize_instance % apply_kw s \nelse \nreturnoriginal__init__ % apply_kw s \n'func_vars util format_argspec_init original__init__ grouped False func_text func_body % func_vars if util py2k func getattr original__init__ 'im_func' original__init__ func_defaults getattr func 'func_defaults' None else func_defaults getattr original__init__ '__defaults__' None func_kw_defaults getattr original__init__ '__kwdefaults__' None env locals copy exec func_text in env__init__ env['__init__']__init__ __doc__ original__init__ __doc__if func_defaults __init__ __defaults__ func_defaultsif not util py2k and func_kw_defaults __init__ __kwdefaults__ func_kw_defaultsreturn __init__
def _generate_init class_ class_manager original__init__ class_ __init__assert original__init__func_body 'def__init__ % apply_pos s \nnew_state class_manager _new_state_if_none % self_arg s \nifnew_state \nreturnnew_state _initialize_instance % apply_kw s \nelse \nreturnoriginal__init__ % apply_kw s \n'func_vars util format_argspec_init original__init__ grouped False func_text func_body % func_vars if util py2k func getattr original__init__ 'im_func' original__init__ func_defaults getattr func 'func_defaults' None else func_defaults getattr original__init__ '__defaults__' None func_kw_defaults getattr original__init__ '__kwdefaults__' None env locals copy exec func_text in env__init__ env['__init__']__init__ __doc__ original__init__ __doc__if func_defaults __init__ __defaults__ func_defaultsif not util py2k and func_kw_defaults __init__ __kwdefaults__ func_kw_defaultsreturn __init__
def get_client_class version warnings warn _LW "'get_client_class'isdeprecated Pleaseuse`novaclient client Client`instead " _api_version client_class _get_client_class_and_version version return client_class
def gen_auth_resp chall_list return [ '%s%s' % chall __class__ __name__ chall domain for chall in chall_list]
def test_elemwise4 shape 3 4 a tcn shared_constructor theano _asarray numpy random rand *shape dtype 'float32' 'a' b tensor fvector c tensor fvector f pfunc [b c] [] updates [ a a + b dimshuffle 'x' 0 * c dimshuffle 0 'x' ] mode mode_with_gpu has_elemwise Falsefor i node in enumerate f maker fgraph toposort has_elemwise has_elemwise or isinstance node op tensor Elemwise assert not has_elemwise f theano _asarray numpy random rand 4 dtype 'float32' theano _asarray numpy random rand 3 dtype 'float32'
def app from nltk grammar import Nonterminal Production CFGnonterminals 'SVPNPPPPNNameVDet' S VP NP PP P N Name V Det [Nonterminal s for s in nonterminals split ]productions Production S [NP VP] Production NP [Det N] Production NP [NP PP] Production VP [VP PP] Production VP [V NP PP] Production VP [V NP] Production PP [P NP] Production NP ['I'] Production Det ['the'] Production Det ['a'] Production N ['man'] Production V ['saw'] Production P ['in'] Production P ['with'] Production N ['park'] Production N ['dog'] Production N ['statue'] Production Det ['my'] grammar CFG S productions sent 'mydogsawamanintheparkwithastatue' split ShiftReduceApp grammar sent mainloop
def get_tests_info input_dir msg_dir prefix suffix result []for fname in glob join input_dir prefix + '*' + suffix infile basename fname fbase splitext infile [0]pyrestr fbase rsplit '_py' 1 [ -1 ]if pyrestr isdigit if SYS_VERS_STR < pyrestr continueif pyrestr startswith '_' and pyrestr[1 ] isdigit if SYS_VERS_STR > pyrestr[1 ] continuemessages glob join msg_dir fbase + '* txt' if messages for outfile in sorted messages reverse True py_rest outfile rsplit '_py' 1 [ -1 ][ -4 ]if py_rest isdigit and SYS_VERS_STR > py_rest breakelse outfile join msg_dir fbase + ' txt' result append infile outfile return result
def get_tests_info input_dir msg_dir prefix suffix result []for fname in glob join input_dir prefix + '*' + suffix infile basename fname fbase splitext infile [0]pyrestr fbase rsplit '_py' 1 [ -1 ]if pyrestr isdigit if SYS_VERS_STR < pyrestr continueif pyrestr startswith '_' and pyrestr[1 ] isdigit if SYS_VERS_STR > pyrestr[1 ] continuemessages glob join msg_dir fbase + '* txt' if messages for outfile in sorted messages reverse True py_rest outfile rsplit '_py' 1 [ -1 ][ -4 ]if py_rest isdigit and SYS_VERS_STR > py_rest breakelse outfile join msg_dir fbase + ' txt' result append infile outfile return result
def printer string quiet False debug False **kwargs if debug and not DEBUG returnif debug out '\x1b[1 30mDEBUG %s\x1b[0m' % string else out stringif not quiet print_ out **kwargs
@register tagdef more_like_this parser token bits token split_contents if not len bits in 4 6 8 raise template TemplateSyntaxError u"'%s'tagrequireseither3 5or7arguments " % bits[0] model bits[1]if bits[2] u'as' raise template TemplateSyntaxError u"'%s'tag'ssecondargumentshouldbe'as' " % bits[0] varname bits[3]limit Nonefor_types Noneif len bits 6 if bits[4] u'limit' and bits[4] u'for' raise template TemplateSyntaxError u"'%s'tag'sfourthargumentshouldbeeither'limit'or'for' " % bits[0] if bits[4] u'limit' limit bits[5]else for_types bits[5]if len bits 8 if bits[4] u'for' raise template TemplateSyntaxError u"'%s'tag'sfourthargumentshouldbe'for' " % bits[0] for_types bits[5]if bits[6] u'limit' raise template TemplateSyntaxError u"'%s'tag'ssixthargumentshouldbe'limit' " % bits[0] limit bits[7]return MoreLikeThisNode model varname for_types limit
def combine_images im1 im2 alpha return 1 - alpha * im1 + alpha * im2
@app before_requestdef require_json if request method in {'GET' 'HEAD' 'DELETE'} returnif request mimetype 'application/json' abort 400 NO_HEADER json_data request get_json silent True if json_data is None abort 400 INVALID_JSON
@app before_requestdef require_json if request method in {'GET' 'HEAD' 'DELETE'} returnif request mimetype 'application/json' abort 400 NO_HEADER json_data request get_json silent True if json_data is None abort 400 INVALID_JSON
def histogram input min max bins labels None index None _bins numpy linspace min max bins + 1 def _hist vals return numpy histogram vals _bins [0]return labeled_comprehension input labels index _hist object None pass_positions False
def get_disk_bus_for_device_type virt_type image_meta None device_type 'disk' if image_meta key 'hw_' + device_type + '_bus' disk_bus image_meta get 'properties' {} get key if disk_bus is not None if not is_disk_bus_valid_for_virt virt_type disk_bus raise exception UnsupportedHardware model disk_bus virt virt_type return disk_busif virt_type 'uml' if device_type 'disk' return 'uml'elif virt_type 'lxc' return 'lxc'elif virt_type 'xen' if device_type 'cdrom' return 'ide'elif device_type 'disk' return 'xen'elif virt_type in 'qemu' 'kvm' if device_type 'cdrom' return 'ide'elif device_type 'disk' return 'virtio'return None
def _GetFieldByName message_descriptor field_name try return message_descriptor fields_by_name[field_name]except KeyError raise ValueError 'Protocolmessagehasno"%s"field ' % field_name
def get_about_info vim return vim service_content about
def psaux name sanitize_name str name pattern re compile sanitize_name salt_exception_pattern re compile 'salt +ps psaux +' ps_aux __salt__['cmd run'] 'psaux' found_infos []ret []nb_lines 0for info in ps_aux splitlines found pattern search info if found is not None if not salt_exception_pattern search info nb_lines + 1found_infos append info pid_count str nb_lines + 'occurence s ' ret []ret extend [sanitize_name found_infos pid_count] return ret
def qos_specs_associations_get context qos_specs_id return IMPL qos_specs_associations_get context qos_specs_id
def service_get_all_volume_sorted context return IMPL service_get_all_volume_sorted context
def convertPermanences sourceSP destSP numColumns sourceSP getNumColumns numInputs sourceSP getNumInputs for i in xrange numColumns potential numpy zeros numInputs astype uintType sourceSP getPotential i potential destSP setPotential i potential perm numpy zeros numInputs astype realType sourceSP getPermanence i perm destSP setPermanence i perm
def convertPermanences sourceSP destSP numColumns sourceSP getNumColumns numInputs sourceSP getNumInputs for i in xrange numColumns potential numpy zeros numInputs astype uintType sourceSP getPotential i potential destSP setPotential i potential perm numpy zeros numInputs astype realType sourceSP getPermanence i perm destSP setPermanence i perm
def get_network_with_the_name session network_name 'vmnet0' cluster None vm_networks session _call_method vim_util 'get_object_properties' None cluster 'ClusterComputeResource' ['network'] while vm_networks if vm_networks objects network_obj _get_network_obj session vm_networks objects network_name if network_obj session _call_method vutil 'cancel_retrieval' vm_networks return network_objvm_networks session _call_method vutil 'continue_retrieval' vm_networks LOG debug 'Network%snotfoundoncluster ' network_name
def get_terminal_size fallback 80 24 try columns int os environ['COLUMNS'] except KeyError ValueError columns 0try lines int os environ['LINES'] except KeyError ValueError lines 0if columns < 0 or lines < 0 try columns lines _get_terminal_size sys __stdout__ fileno except NameError OSError passif columns < 0 and lines < 0 columns lines fallbackreturn terminal_size columns lines
def prepend_path newpath oldpath if oldpath return newpath + ' ' + oldpath else return newpath
@must_be_contributor_or_publicdef grid_data auth node **kwargs data request args to_dict return {'data' rubeus to_hgrid node auth **data }
def get_lexer_for_filename _fn code None **options matches []fn basename _fn for modname name _ filenames _ in LEXERS itervalues for filename in filenames if fnmatch fnmatch fn filename if name not in _lexer_cache _load_lexers modname matches append _lexer_cache[name] for cls in find_plugin_lexers for filename in cls filenames if fnmatch fnmatch fn filename matches append cls if sys version_info > 3 and isinstance code bytes code code decode 'latin1' def get_rating cls d cls analyse_text code return dif code matches sort key get_rating if matches return matches[ -1 ] **options raise ClassNotFound 'nolexerforfilename%rfound' % _fn
def _add_kernel_to_bootloader bootloader base_args tag args image initrd bootloader remove_kernel tag if base_args if args args '%s%s' % base_args args else args base_argsbootloader add_kernel path image title tag initrd initrd args args
def _add_kernel_to_bootloader bootloader base_args tag args image initrd bootloader remove_kernel tag if base_args if args args '%s%s' % base_args args else args base_argsbootloader add_kernel path image title tag initrd initrd args args
def set_gui_mode global gui_modegui_mode True
def set_gui_mode global gui_modegui_mode True
def ishow for manager in Gcf get_all_fig_managers manager show if show _needmain thread start_new_thread Fltk_run_interactive show _needmain False
def ishow for manager in Gcf get_all_fig_managers manager show if show _needmain thread start_new_thread Fltk_run_interactive show _needmain False
def ishow for manager in Gcf get_all_fig_managers manager show if show _needmain thread start_new_thread Fltk_run_interactive show _needmain False
def ishow for manager in Gcf get_all_fig_managers manager show if show _needmain thread start_new_thread Fltk_run_interactive show _needmain False
def task *args **kwargs if len args 1 and callable args[0] new_task invoke task args[0] ns add_task new_task return new_taskdef decorator f new_task invoke task f *args **kwargs ns add_task new_task return new_taskreturn decorator
@conf commands registerdef promiscping net timeout 2 fake_bcast 'ff ff ff ff ff fe' **kargs ans unans srp Ether dst fake_bcast / ARP pdst net filter 'arpandarp[7] 2' timeout timeout iface_hint net **kargs ans ARPingResult ans res name 'PROMISCPing' ans display return ans unans
@conf commands registerdef promiscping net timeout 2 fake_bcast 'ff ff ff ff ff fe' **kargs ans unans srp Ether dst fake_bcast / ARP pdst net filter 'arpandarp[7] 2' timeout timeout iface_hint net **kargs ans ARPingResult ans res name 'PROMISCPing' ans display return ans unans
def _instantiate_proxy_tuple proxy bindings None if proxy in bindings return bindings[proxy]else if proxy callable do_not_recurse obj proxy keywords['value']else if len proxy positionals > 0 raise NotImplementedError 'positionalargumentsnotyetsupportedinproxyinstantiation' kwargs dict k _instantiate v bindings for k v in six iteritems proxy keywords obj checked_call proxy callable kwargs try obj yaml_src proxy yaml_srcexcept AttributeError passbindings[proxy] objreturn bindings[proxy]
def get_mcp_version driver location location driver ex_get_location_by_id location if 'MCP2 0' in location name return '2 0'return '1 0'
def SetupCore searchPaths import sysfor path in searchPaths sys path append path import string osimport regutil win32api win32con installPath corePaths LocatePythonCore searchPaths print corePathsregutil RegisterNamedPath None string join corePaths ' ' hKey win32api RegCreateKey regutil GetRootKey regutil BuildDefaultPythonKey try win32api RegSetValue hKey 'InstallPath' win32con REG_SZ installPath finally win32api RegCloseKey hKey win32paths os path abspath os path split win32api __file__ [0] + ' ' + os path abspath os path split LocateFileName 'win32con py win32con pyc' sys path [0] check os path join sys prefix 'PCBuild' if os path isdir check regutil RegisterNamedPath 'PCBuild' check
def address_book_to_list address_book ab ABAddressBook sharedAddressBook people address_book people return [ab_person_to_dict person for person in people]
def _has_explicit_scheme url return url isValid and url scheme and url host or url path and '' not in url path and not url path startswith ' '
def at addr for o in gc get_objects if id o addr return oreturn None
@log_calldef metadef_property_get_all context namespace_name namespace metadef_namespace_get context namespace_name properties []_check_namespace_visibility context namespace namespace_name for property in DATA['metadef_properties'] if property['namespace_id'] namespace['id'] properties append property return properties
def handle_extends tail line_index if tail return 'extends' [p strip for p in tail split ' ' ] else return 'error' "'extends'withoutfiletypes" line_index
def saturate color percent return adjust color 1 percent
def _extract_doc_comment_simple content line column markers align_column column - len markers[0] pos content[line] find markers[2] column if pos -1 return line pos + len markers[2] content[line][column pos] doc_comment content[line][column ]line + 1while line < len content pos content[line] find markers[2] if pos -1 doc_comment + '\n' if content[line][align_column ] '' else content[line][align_column ] else doc_comment + content[line][align_column pos]return line pos + len markers[2] doc_comment line + 1return None
def _extract_doc_comment_simple content line column markers align_column column - len markers[0] pos content[line] find markers[2] column if pos -1 return line pos + len markers[2] content[line][column pos] doc_comment content[line][column ]line + 1while line < len content pos content[line] find markers[2] if pos -1 doc_comment + '\n' if content[line][align_column ] '' else content[line][align_column ] else doc_comment + content[line][align_column pos]return line pos + len markers[2] doc_comment line + 1return None
def _wrap_results result dtype if is_datetime64_dtype dtype if not isinstance result np ndarray result lib Timestamp result else result result view dtype elif is_timedelta64_dtype dtype if not isinstance result np ndarray if np fabs result > _int64_max raise ValueError 'overflowintimedeltaoperation' result lib Timedelta result unit 'ns' else result result astype 'i8' view dtype return result
def format_call func args kwargs object_name 'Memory' path signature format_signature func *args **kwargs msg '%s\n[%s]Calling%s \n%s' % 80 * '_' object_name path signature return msg
def format_call func args kwargs object_name 'Memory' path signature format_signature func *args **kwargs msg '%s\n[%s]Calling%s \n%s' % 80 * '_' object_name path signature return msg
def test_special_bindings keyhint key_config_stub key_config_stub set_bindings_for 'normal' OrderedDict [ '<a' 'cmd-<a' '<b' 'cmd-<b' '<ctrl-a>' 'cmd-ctrla' ] keyhint update_keyhint 'normal' '<' assert keyhint text expected_text '&lt ' 'yellow' 'a' 'cmd-&lt a' '&lt ' 'yellow' 'b' 'cmd-&lt b'
def test_special_bindings keyhint key_config_stub key_config_stub set_bindings_for 'normal' OrderedDict [ '<a' 'cmd-<a' '<b' 'cmd-<b' '<ctrl-a>' 'cmd-ctrla' ] keyhint update_keyhint 'normal' '<' assert keyhint text expected_text '&lt ' 'yellow' 'a' 'cmd-&lt a' '&lt ' 'yellow' 'b' 'cmd-&lt b'
def resource_type_from_id context resource_id known_types {'i' 'instance' 'r' 'reservation' 'vol' 'volume' 'snap' 'snapshot' 'ami' 'image' 'aki' 'image' 'ari' 'image'}type_marker resource_id split '-' [0]return known_types get type_marker
def deep_format obj paramdict allow_empty False if hasattr obj 'format' try ret CustomFormatter allow_empty format obj **paramdict except KeyError as exc missing_key exc args[0]desc '%sparametermissingtoformat%s\nGiven \n%s' % missing_key obj pformat paramdict raise JenkinsJobsException desc elif isinstance obj list ret type obj for item in obj ret append deep_format item paramdict allow_empty elif isinstance obj dict ret type obj for item in obj try ret[CustomFormatter allow_empty format item **paramdict ] deep_format obj[item] paramdict allow_empty except KeyError as exc missing_key exc args[0]desc '%sparametermissingtoformat%s\nGiven \n%s' % missing_key obj pformat paramdict raise JenkinsJobsException desc else ret objreturn ret
def deep_format obj paramdict allow_empty False if hasattr obj 'format' try ret CustomFormatter allow_empty format obj **paramdict except KeyError as exc missing_key exc args[0]desc '%sparametermissingtoformat%s\nGiven \n%s' % missing_key obj pformat paramdict raise JenkinsJobsException desc elif isinstance obj list ret type obj for item in obj ret append deep_format item paramdict allow_empty elif isinstance obj dict ret type obj for item in obj try ret[CustomFormatter allow_empty format item **paramdict ] deep_format obj[item] paramdict allow_empty except KeyError as exc missing_key exc args[0]desc '%sparametermissingtoformat%s\nGiven \n%s' % missing_key obj pformat paramdict raise JenkinsJobsException desc else ret objreturn ret
def getXNormalizedVector3Path path if len path < 1 return pathminimumX path[0] xfor point in path[1 ] minimumX min minimumX point x for point in path point x - minimumXmaximumX path[0] xfor point in path[1 ] maximumX max maximumX point x for point in path point x / maximumXreturn path
def merge_events events ids new_id replace_events True events np asarray events events_out events copy idx_touched []for col in [1 2] for i in ids mask events[ col] i events_out[ mask col ] new_ididx_touched append np where mask [0] if not replace_events idx_touched np unique np concatenate idx_touched events_out np concatenate events_out events[idx_touched] axis 0 events_out events_out[np lexsort events_out T[ -1 ] ]return events_out
def get_attrs_flag attrs attrs_flag 0if u'bold' in attrs attrs_flag ATTR_BOLDif u'italic' in attrs attrs_flag ATTR_ITALICif u'underline' in attrs attrs_flag ATTR_UNDERLINEreturn attrs_flag
def run_command cmd stdin None stdout subprocess PIPE stderr subprocess PIPE shell False cwd None env None assert isinstance cmd list tuple + six string_types if not env env os environ copy process subprocess Popen cmd stdin stdin stdout stdout stderr stderr env env cwd cwd shell shell stdout stderr process communicate exit_code process returncodereturn exit_code stdout stderr
def job_id conf return hashlib sha1 json dumps conf sort_keys True encode u'utf-8' hexdigest
def find_all_stacktraces data rv []exc_container data get 'sentry interfaces Exception' if exc_container for exc in exc_container['values'] stacktrace exc get 'stacktrace' if stacktrace rv append stacktrace exc stacktrace data get 'sentry interfaces Stacktrace' if stacktrace rv append stacktrace None threads data get 'threads' if threads for thread in threads['values'] stacktrace thread get 'stacktrace' if stacktrace rv append stacktrace thread return rv
def matrix_to_vector matrix system outvec Vector zerovects system base_vectors for i x in enumerate matrix outvec + x * vects[i] return outvec
def matrix_to_vector matrix system outvec Vector zerovects system base_vectors for i x in enumerate matrix outvec + x * vects[i] return outvec
def Triangular name a b c return rv name TriangularDistribution a b c
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def _check_partial_fit_first_call clf classes None if getattr clf 'classes_' None is None and classes is None raise ValueError 'classesmustbepassedonthefirstcalltopartial_fit ' elif classes is not None if getattr clf 'classes_' None is not None if not array_equal clf classes_ unique_labels classes raise ValueError '`classes %r`isnotthesameasonlastcalltopartial_fit was %r' % classes clf classes_ else clf classes_ unique_labels classes return Truereturn False
def db_get name **connection_args dbc _connect **connection_args if dbc is None return []cur dbc cursor qry 'SELECTDEFAULT_CHARACTER_SET_NAME DEFAULT_COLLATION_NAMEFROMINFORMATION_SCHEMA SCHEMATAWHERESCHEMA_NAME % dbname s 'args {'dbname' name}_execute cur qry args if cur rowcount rows cur fetchall return {'character_set' rows[0][0] 'collate' rows[0][1]}return {}
@_call_asidedef _initialize g globals manager ResourceManager g['_manager'] managerfor name in dir manager if not name startswith '_' g[name] getattr manager name
def generate_token length 20 chars UNICODE_ASCII_CHARACTER_SET return u'' join choice chars for x in range length
def _wait_for_volume_state_change operation volume update _get_ebs_volume_state timeout VOLUME_STATE_CHANGE_TIMEOUT time sleep 5 0 start_time time time poll_until lambda _reached_end_state operation volume update time time - start_time timeout itertools repeat 1
def exit setConfigOptions exitCleanup False atexit _run_exitfuncs if sys platform 'darwin' for fd in range 3 4096 if fd not in [7] os close fd else os closerange 3 4096 os _exit 0
def exit setConfigOptions exitCleanup False atexit _run_exitfuncs if sys platform 'darwin' for fd in range 3 4096 if fd not in [7] os close fd else os closerange 3 4096 os _exit 0
def save_minions jid minions syndic_id None cb_ _get_connection try jid_doc cb_ get str jid except couchbase exceptions NotFoundError log warning 'Couldnotwritejobcachefileforjid {0}' format jid return Falseif 'minions' in jid_doc value jid_doc value['minions'] sorted set jid_doc value['minions'] + minions else jid_doc value['minions'] minionscb_ replace str jid jid_doc value cas jid_doc cas ttl _get_ttl
def cleanup call ['sudo' 'pkill' '-9' 'qemu-nbd']
def get_filename_from_path path dirpath filename ntpath split path return filename if filename else ntpath basename dirpath
def typed_list conversion_func return lambda setting [conversion_func StringConverter elem for elem in setting]
def typed_list conversion_func return lambda setting [conversion_func StringConverter elem for elem in setting]
def check_package_data package_data print 'checkingpackagedata'for pkg data in package_data items pkg_root pjoin *pkg split ' ' for d in data path pjoin pkg_root d if '*' in path assert len glob path > 0 'Nofilesmatchpattern%s' % path else assert os path exists path 'Missingpackagedata %s' % path
def getStartingAddress packet return ord packet[8] << 8 + ord packet[9]
def assert_manual_typechecking bad_grammar test_obj for attr value in bad_grammar with nt assert_raises ValueError as err setattr test_obj attr value nt assert_equal err expected ValueError
def assert_manual_typechecking bad_grammar test_obj for attr value in bad_grammar with nt assert_raises ValueError as err setattr test_obj attr value nt assert_equal err expected ValueError
def test_obstime b1950 Time u'B1950' scale u'utc' j1975 Time u'J1975' scale u'utc' fk4_50 FK4 ra 1 * u deg dec 2 * u deg obstime b1950 fk4_75 FK4 ra 1 * u deg dec 2 * u deg obstime j1975 icrs_50 fk4_50 transform_to ICRS icrs_75 fk4_75 transform_to ICRS assert icrs_50 ra degree icrs_75 ra degree assert icrs_50 dec degree icrs_75 dec degree
def test_range assert hug types in_range 1 10 '1' 1 assert hug types in_range 1 10 1 1 assert '1' in hug types in_range 1 10 __doc__ with pytest raises ValueError hug types in_range 1 10 'bacon' with pytest raises ValueError hug types in_range 1 10 '15' with pytest raises ValueError hug types in_range 1 10 -34
def test_range assert hug types in_range 1 10 '1' 1 assert hug types in_range 1 10 1 1 assert '1' in hug types in_range 1 10 __doc__ with pytest raises ValueError hug types in_range 1 10 'bacon' with pytest raises ValueError hug types in_range 1 10 '15' with pytest raises ValueError hug types in_range 1 10 -34
def norm s s re sub '\\s+' '' str s strip return re sub '>\\s+<' '><' s
def norm s s re sub '\\s+' '' str s strip return re sub '>\\s+<' '><' s
def _to_gapic_feature feature return image_annotator_pb2 Feature type getattr image_annotator_pb2 Feature feature feature_type max_results feature max_results
def _get_variables_to_train if FLAGS trainable_scopes is None return tf trainable_variables else scopes [scope strip for scope in FLAGS trainable_scopes split ' ' ]variables_to_train []for scope in scopes variables tf get_collection tf GraphKeys TRAINABLE_VARIABLES scope variables_to_train extend variables return variables_to_train
def test_feature_first_scenario_tags_extraction feature Feature from_string FEATURE23 assert that feature scenarios[0] tags deep_equals ['onetag' 'another' '$%^&even-weird_chars']
def datetime_aligned ds1 ds2 maxLen None aligned1 dataseries SequenceDataSeries maxLen aligned2 dataseries SequenceDataSeries maxLen Syncer ds1 ds2 aligned1 aligned2 return aligned1 aligned2
def datetime_aligned ds1 ds2 maxLen None aligned1 dataseries SequenceDataSeries maxLen aligned2 dataseries SequenceDataSeries maxLen Syncer ds1 ds2 aligned1 aligned2 return aligned1 aligned2
def minimum input labels None index None return _select input labels index find_min True [0]
def _revoked_to_list revs list_ []for rev in revs for rev_name props in six iteritems rev dict_ {}for prop in props for propname val in six iteritems prop if isinstance val datetime datetime val val strftime '%Y-%m-%d%H %M %S' dict_[propname] vallist_ append dict_ return list_
def _revoked_to_list revs list_ []for rev in revs for rev_name props in six iteritems rev dict_ {}for prop in props for propname val in six iteritems prop if isinstance val datetime datetime val val strftime '%Y-%m-%d%H %M %S' dict_[propname] vallist_ append dict_ return list_
def _show_receipt_json order order_info {'orderNum' order id 'currency' order currency 'status' order status 'purchase_datetime' get_default_time_display order purchase_time if order purchase_time else None 'billed_to' {'first_name' order bill_to_first 'last_name' order bill_to_last 'street1' order bill_to_street1 'street2' order bill_to_street2 'city' order bill_to_city 'state' order bill_to_state 'postal_code' order bill_to_postalcode 'country' order bill_to_country} 'total_cost' order total_cost 'items' [{'quantity' item qty 'unit_cost' item unit_cost 'line_cost' item line_cost 'line_desc' item line_desc 'course_key' unicode item course_id } for item in OrderItem objects filter order order select_subclasses ]}return JsonResponse order_info
def transfer_destroy context transfer_id return IMPL transfer_destroy context transfer_id
def GetBlobStorage return apiproxy_stub_map apiproxy GetStub 'blobstore' storage
def ensure_not_within_tag_definition cursor forward True block offset cursor block cursor positionInBlock b boundary next_tag_boundary block offset forward False if b is None return Falseif boundary is_start if forward block boundary next_tag_boundary block offset if block is not None cursor setPosition block position + boundary offset + 1 return Trueelse cursor setPosition b position + boundary offset return Truereturn False
def get_vlanid_and_vswitch_for_portgroup session pg_name cluster None host_mor vm_util get_host_ref session cluster port_grps_on_host_ret session _call_method vutil 'get_object_property' host_mor 'config network portgroup' if not port_grps_on_host_ret msg _ 'ESXSOAPserverreturnedanemptyportgroupforthehostsysteminitsresponse' LOG error msg raise exception NovaException msg port_grps_on_host port_grps_on_host_ret HostPortGroupfor p_gp in port_grps_on_host if p_gp spec name pg_name p_grp_vswitch_name p_gp spec vswitchNamereturn p_gp spec vlanId p_grp_vswitch_name return None None
def lookup_scopes service_name if service_name in CLIENT_LOGIN_SCOPES return CLIENT_LOGIN_SCOPES[service_name]return None
@lower 'print_item' types Any def print_item_impl context builder sig args ty sig args val argspyapi context get_python_api builder if context enable_nrt context nrt incref builder ty val obj pyapi from_native_value ty val with builder if_else cgutils is_not_null builder obj likely True as if_ok if_error with if_ok pyapi print_object obj pyapi decref obj with if_error cstr context insert_const_string builder module 'theprint function' strobj pyapi string_from_string cstr pyapi err_write_unraisable strobj pyapi decref strobj res context get_dummy_value return impl_ret_untracked context builder sig return_type res
@expect_downsample_frequency@templated_docstring frequency PIPELINE_DOWNSAMPLING_FREQUENCY_DOC def select_sampling_indices dates frequency return changed_locations _dt_to_period[frequency] dates include_first True
def item keys default '' ret {}key_list []if isinstance keys six string_types key_list append keys elif isinstance keys list key_list keyselse log debug "{0} 'keys'argumentisnotastringorlisttype '{1}'" format __name__ keys for key in key_list ret[key] os environ get key default return ret
def hosts *host_list return _list_annotating_decorator 'hosts' *host_list
def hosts *host_list return _list_annotating_decorator 'hosts' *host_list
def hosts *host_list return _list_annotating_decorator 'hosts' *host_list
def get_search_location try return file_io read constants SEARCH_FILE_LOC rstrip except IOError logging warning 'Searchroleisnotconfigured ' return ''
def tidy_stacktrace stack trace []for frame path line_no func_name text in f[ 5] for f in stack if omit_path os path realpath path continuetext u'' join force_text t for t in text strip if text else u'' trace append path line_no func_name text return trace
def _get_channel channel __salt__['config get'] 'mattermost channel' or __salt__['config get'] 'mattermost channel' return channel
def longest_id ids seqs lengths map len [seqs get id_ '' for id_ in ids] return ids[argmax lengths ]
def model_fields model only None exclude None field_args None converter None converter converter or ModelConverter field_args field_args or {} model_fields f attname f for f in model _meta fields if only model_fields x for x in model_fields if x[0] in only elif exclude model_fields x for x in model_fields if x[0] not in exclude field_dict {}for name model_field in model_fields field converter convert model model_field field_args get name if field is not None field_dict[name] fieldreturn field_dict
def __virtual__ if not _proxy return Falsedef _mkf cmd_name doc '\nNestedfunctiontohelpmoveproxyfunctionsintosys modules\n'def _cmd *args **kw '\nCallcommandsinproxy\n'proxyfn 'philips_hue ' + cmd_name return __proxy__[proxyfn] *args **kw return _cmdimport salt proxy philips_hue as huefor method in dir hue if method startswith 'call_' setattr sys modules[__name__] method[5 ] _mkf method getattr hue method __doc__ del huereturn _proxy and __virtualname__ or False
def batch_inv a return BatchInv a
def dealias dsk keys None dependencies None keys keys or set if not isinstance keys set keys set keys if not dependencies dependencies {k get_dependencies dsk k for k in dsk}aliases set k for k task in dsk items if ishashable task and task in dsk dsk2 inline dsk aliases inline_constants False for k in aliases difference keys del dsk2[k]return dsk2
def _RunningAvgLoss loss running_avg_loss summary_writer step decay 0 999 if running_avg_loss 0 running_avg_loss losselse running_avg_loss running_avg_loss * decay + 1 - decay * loss running_avg_loss min running_avg_loss 12 loss_sum tf Summary loss_sum value add tag 'running_avg_loss' simple_value running_avg_loss summary_writer add_summary loss_sum step sys stdout write 'running_avg_loss %f\n' % running_avg_loss return running_avg_loss
def validate_plural_forms plural_forms_str tokens tokenize generate_tokens StringIO plural_forms_str readline try danger [x for x in tokens if x[0] token NAME and x[1] 'n' ]except tokenize TokenError raise ValueError 'pluralformsexpressionerror maybeunbalancedparenthesis'else if danger raise ValueError 'pluralformsexpressioncouldbedangerous'
def _convert_to_line_delimits s if not s[0] '[' and s[ -1 ] ']' return ss s[1 -1 ]from pandas lib import convert_json_to_linesreturn convert_json_to_lines s
def _convert_to_line_delimits s if not s[0] '[' and s[ -1 ] ']' return ss s[1 -1 ]from pandas lib import convert_json_to_linesreturn convert_json_to_lines s
def can_resize_image image size LOG debug 'Checkingifwecanresizeimage% image s size % size s' {'image' image 'size' size} virt_size get_disk_size image if virt_size > size LOG debug 'Cannotresizeimage%stoasmallersize ' image return Falsereturn True
def load_plugin_names settings seen set def generate_name path maxsplit 0 splits None if splits is None splits len path split ' ' - 1 name ' ' join path split ' ' splits - maxsplit [ -1 ] rsplit ' ' maxsplit if name not in seen or maxsplit > splits seen add name return namereturn generate_name path maxsplit + 1 splits if settings['PLUGINS'] return [generate_name path for path in settings['PLUGINS']]else return ['Annotations']
def _get_window_registry window if window is None raise TypeError 'windowisNonewithscopewindow ' try if window 'current' app get 'app' win app activeWindow elif window 'last-focused' win last_focused_window else win window_registry[window]except KeyError NoWindow win Nonetry return win registryexcept AttributeError raise RegistryUnavailableError 'window'
def search s sub n m len s len sub hsub_digest md5 sub encode 'utf-8' digest offsets []if m > n return offsetsfor i in range n - m + 1 if md5 s[i i + m ] encode 'utf-8' digest hsub_digest if s[i i + m ] sub offsets append i return offsets
def search s sub n m len s len sub hsub_digest md5 sub encode 'utf-8' digest offsets []if m > n return offsetsfor i in range n - m + 1 if md5 s[i i + m ] encode 'utf-8' digest hsub_digest if s[i i + m ] sub offsets append i return offsets
def search s sub n m len s len sub hsub_digest md5 sub encode 'utf-8' digest offsets []if m > n return offsetsfor i in range n - m + 1 if md5 s[i i + m ] encode 'utf-8' digest hsub_digest if s[i i + m ] sub offsets append i return offsets
def test_show_message_twice_after_first_disappears qtbot view with qtbot waitSignal view _clear_timer timeout view show_message usertypes MessageLevel info 'test' assert not view _messages view show_message usertypes MessageLevel info 'test' assert len view _messages 1
def extension_elements_to_elements extension_elements schemas res []if isinstance schemas list passelif isinstance schemas dict schemas schemas values else return resfor extension_element in extension_elements for schema in schemas inst extension_element_to_element extension_element schema ELEMENT_FROM_STRING schema NAMESPACE if inst res append inst breakreturn res
def extension_elements_to_elements extension_elements schemas res []if isinstance schemas list passelif isinstance schemas dict schemas schemas values else return resfor extension_element in extension_elements for schema in schemas inst extension_element_to_element extension_element schema ELEMENT_FROM_STRING schema NAMESPACE if inst res append inst breakreturn res
def extension_elements_to_elements extension_elements schemas res []if isinstance schemas list passelif isinstance schemas dict schemas schemas values else return resfor extension_element in extension_elements for schema in schemas inst extension_element_to_element extension_element schema ELEMENT_FROM_STRING schema NAMESPACE if inst res append inst breakreturn res
def lookup path parent None user None exists None url build_url RESOURCE route 'lookup' params make_params path path parent parent user user exists exists return request 'get' url params params
def packages pkg_list update False options None pkg_list [pkg for pkg in pkg_list if not is_installed pkg ]if pkg_list install pkg_list update update options options
def setup_platform hass config add_devices discovery_info None host config get CONF_HOST port config get CONF_PORT name config get CONF_NAME url 'http //{} {}/api/LiveData xml' format host port gateway Ted5000Gateway url gateway update dev []for mtu in gateway data dev append Ted5000Sensor gateway name mtu 'W' dev append Ted5000Sensor gateway name mtu 'V' add_devices dev return True
def external_script script p1 p2 p3 None p4 None command [script p1 p2 p3 p4]try stup need_shell command creationflags build_command command env fix_env logging info 'Runninguserscript%s %s %s ' script p1 p2 p subprocess Popen command shell need_shell stdin subprocess PIPE stdout subprocess PIPE stderr subprocess STDOUT startupinfo stup env env creationflags creationflags except logging debug 'Failedscript%s Traceback ' script exc_info True return 'Cannotrunscript%s\r\n' % script -1 output p stdout read ret p wait return output ret
def get_token_for_user user scope data { 'user_%s_id' % scope user id}return signing dumps data
def get_token_for_user user scope data { 'user_%s_id' % scope user id}return signing dumps data
def get_token_for_user user scope data { 'user_%s_id' % scope user id}return signing dumps data
def find_font_face_rules sheet oeb ans []try rules sheet data cssRulesexcept AttributeError rules sheet cssRulesfor i rule in enumerate rules if rule type rule FONT_FACE_RULE continueprops get_font_properties rule default u'normal' if not props[u'font-family'] or not props[u'src'] continuetry path sheet abshref props[u'src'] except AttributeError path props[u'src']ff oeb manifest hrefs get urlnormalize path None if not ff continueprops[u'item'] ffif props[u'font-weight'] in {u'bolder' u'lighter'} props[u'font-weight'] u'400'props[u'weight'] int props[u'font-weight'] props[u'rule'] ruleprops[u'chars'] set ans append props return ans
def find_font_face_rules sheet oeb ans []try rules sheet data cssRulesexcept AttributeError rules sheet cssRulesfor i rule in enumerate rules if rule type rule FONT_FACE_RULE continueprops get_font_properties rule default u'normal' if not props[u'font-family'] or not props[u'src'] continuetry path sheet abshref props[u'src'] except AttributeError path props[u'src']ff oeb manifest hrefs get urlnormalize path None if not ff continueprops[u'item'] ffif props[u'font-weight'] in {u'bolder' u'lighter'} props[u'font-weight'] u'400'props[u'weight'] int props[u'font-weight'] props[u'rule'] ruleprops[u'chars'] set ans append props return ans
def find_font_face_rules sheet oeb ans []try rules sheet data cssRulesexcept AttributeError rules sheet cssRulesfor i rule in enumerate rules if rule type rule FONT_FACE_RULE continueprops get_font_properties rule default u'normal' if not props[u'font-family'] or not props[u'src'] continuetry path sheet abshref props[u'src'] except AttributeError path props[u'src']ff oeb manifest hrefs get urlnormalize path None if not ff continueprops[u'item'] ffif props[u'font-weight'] in {u'bolder' u'lighter'} props[u'font-weight'] u'400'props[u'weight'] int props[u'font-weight'] props[u'rule'] ruleprops[u'chars'] set ans append props return ans
def is_bind_mounted module linux_mounts dest src None fstype None is_mounted Falseif get_platform 'Linux' and linux_mounts is not None if src is None if dest in linux_mounts is_mounted Trueelif dest in linux_mounts and linux_mounts[dest]['src'] src is_mounted Trueelse bin_path module get_bin_path 'mount' required True cmd '%s-l' % bin_path rc out err module run_command cmd mounts []if len out mounts to_native out strip split '\n' for mnt in mounts arguments mnt split if arguments[0] src or src is None and arguments[2] dest and arguments[4] fstype or fstype is None is_mounted Trueif is_mounted breakreturn is_mounted
@pytest yield_fixture scope u'module' autouse True def ctx builtins __xonsh_shell__ Shell {u'PATH' []} yield del builtins __xonsh_shell__
@pytest mark django_dbdef test_getorig project0_nongnu store0 store0 sync for i db_unit in enumerate store0 units iterator store_unit store0 file store units[ i + 1 ]assert db_unit getid store_unit getid
def _iqr_nanpercentile x q axis None interpolation 'linear' keepdims False contains_nan False if hasattr np 'nanpercentile' result np nanpercentile x q axis axis interpolation interpolation keepdims keepdims if result ndim > 1 and NumpyVersion np __version__ < '1 11 0a' axis np asarray axis if axis size 1 if axis ndim 0 axis axis[None]result np rollaxis result axis[0] else result np rollaxis result -1 else msg "Keywordnan_policy 'omit'notcorrectlysupportedfornumpyversions<1 9 x Thedefaultbehaviorofnumpy percentilewillbeused "warnings warn msg RuntimeWarning result _iqr_percentile x q axis axis return result
@cronjobs registerdef update_visitors_metric if settings STAGE returnlatest_metric _get_latest_metric VISITORS_METRIC_CODE if latest_metric is not None latest_metric_date latest_metric startelse latest_metric_date date 2011 1 1 start latest_metric_date + timedelta days 1 end date today - timedelta days 1 visitors googleanalytics visitors start end metric_kind MetricKind objects get code VISITORS_METRIC_CODE for date_str visits in visitors items day datetime strptime date_str '%Y-%m-%d' date Metric objects create kind metric_kind start day end day + timedelta days 1 value visits
def wrappertask task @six wraps task def wrapper *args **kwargs parent task *args **kwargs try subtask next parent except StopIteration returnwhile True try if isinstance subtask types GeneratorType subtask_running Truetry step next subtask except StopIteration subtask_running Falsewhile subtask_running try yield step except GeneratorExit subtask close raiseexcept try step subtask throw *sys exc_info except StopIteration subtask_running Falseelse try step next subtask except StopIteration subtask_running Falseelse yield subtask except GeneratorExit parent close raiseexcept try subtask parent throw *sys exc_info except StopIteration returnelse try subtask next parent except StopIteration returnreturn wrapper
def wrappertask task @six wraps task def wrapper *args **kwargs parent task *args **kwargs try subtask next parent except StopIteration returnwhile True try if isinstance subtask types GeneratorType subtask_running Truetry step next subtask except StopIteration subtask_running Falsewhile subtask_running try yield step except GeneratorExit subtask close raiseexcept try step subtask throw *sys exc_info except StopIteration subtask_running Falseelse try step next subtask except StopIteration subtask_running Falseelse yield subtask except GeneratorExit parent close raiseexcept try subtask parent throw *sys exc_info except StopIteration returnelse try subtask next parent except StopIteration returnreturn wrapper
def set_locale_info domain localedir global _DOMAIN _LOCALEDIR_DOMAIN domain_LOCALEDIR localedir
def MakeBadSignatureResponse return '{"status" 21003}'
def makeRst prefix section app exampleByIdentifier schema_store for route in sorted getRoutes app if route attributes get 'private_api' False continuedata _introspectRoute route exampleByIdentifier schema_store if data['section'] section continuefor method in route methods if data['header'] is not None yield data['header'] yield '-' * len data['header'] yield '' body _formatRouteBody data schema_store for line in http_directive method prefix + route path body yield line
def all_builtins return p for p in plugin plugins values if p builtin
def _windows_long_path_name short_path if not isinstance short_path six text_type short_path short_path decode _fsencoding import ctypesbuf ctypes create_unicode_buffer 260 get_long_path_name_w ctypes windll kernel32 GetLongPathNameWreturn_value get_long_path_name_w short_path buf 260 if return_value 0 or return_value > 260 return short_pathelse long_path buf valueif len long_path > 1 and long_path[1] ' ' long_path long_path[0] upper + long_path[1 ] return long_path
def _windows_long_path_name short_path if not isinstance short_path six text_type short_path short_path decode _fsencoding import ctypesbuf ctypes create_unicode_buffer 260 get_long_path_name_w ctypes windll kernel32 GetLongPathNameWreturn_value get_long_path_name_w short_path buf 260 if return_value 0 or return_value > 260 return short_pathelse long_path buf valueif len long_path > 1 and long_path[1] ' ' long_path long_path[0] upper + long_path[1 ] return long_path
def _windows_long_path_name short_path if not isinstance short_path six text_type short_path short_path decode _fsencoding import ctypesbuf ctypes create_unicode_buffer 260 get_long_path_name_w ctypes windll kernel32 GetLongPathNameWreturn_value get_long_path_name_w short_path buf 260 if return_value 0 or return_value > 260 return short_pathelse long_path buf valueif len long_path > 1 and long_path[1] ' ' long_path long_path[0] upper + long_path[1 ] return long_path
def SignComponentContent component_filename output_filename component rdf_client ClientComponent FromSerializedString open component_filename 'rb' read EPrint 'Openedcomponent%s ' % component summary name if component build_system system 'Windows' _SignWindowsComponent component output_filename returnraise RuntimeError 'ComponentsigningisnotimplementedforOS%s ' % component build_system system
def SignComponentContent component_filename output_filename component rdf_client ClientComponent FromSerializedString open component_filename 'rb' read EPrint 'Openedcomponent%s ' % component summary name if component build_system system 'Windows' _SignWindowsComponent component output_filename returnraise RuntimeError 'ComponentsigningisnotimplementedforOS%s ' % component build_system system
def nonthreadsafe fn @wraps fn def core *args **kwargs with _cuda_compiler_lock return fn *args **kwargs return core
def nonthreadsafe fn @wraps fn def core *args **kwargs with _cuda_compiler_lock return fn *args **kwargs return core
def nonthreadsafe fn @wraps fn def core *args **kwargs with _cuda_compiler_lock return fn *args **kwargs return core
def get_logger_name_for_module module module_file module __file__base_dir os path dirname os path abspath module_file module_name os path basename module_file module_name module_name replace ' pyc' '' replace ' py' '' split base_dir split os path sep split [component for component in split if component]start_index 0for index component in enumerate reversed split if component startswith 'st2' start_index len split - 1 - index breaksplit split[start_index ]name ' ' join split + ' ' + module_name return name
def build_url resource id '' route '' base config get_config ['plotly_api_domain']formatter {'base' base 'resource' resource 'id' id 'route' route}if id if route url '{base}/v2/{resource}/{id}/{route}' format **formatter else url '{base}/v2/{resource}/{id}' format **formatter elif route url '{base}/v2/{resource}/{route}' format **formatter else url '{base}/v2/{resource}' format **formatter return url
def get_default_location complete_id db current dbs3db current s3dbctable s3db survey_completeqtable s3db survey_questionatable s3db survey_answerquery atable question_id qtable id & atable complete_id ctable id code_list ['STD-L4' 'STD-L3' 'STD-L2' 'STD-L1' 'STD-L0']for location_code in code_list record db query & qtable code location_code select qtable id limitby 0 1 first if record widget_obj survey_getWidgetFromQuestion record id breakif record widget_obj loadAnswer complete_id record id return widget_objelse return None
def get_default_location complete_id db current dbs3db current s3dbctable s3db survey_completeqtable s3db survey_questionatable s3db survey_answerquery atable question_id qtable id & atable complete_id ctable id code_list ['STD-L4' 'STD-L3' 'STD-L2' 'STD-L1' 'STD-L0']for location_code in code_list record db query & qtable code location_code select qtable id limitby 0 1 first if record widget_obj survey_getWidgetFromQuestion record id breakif record widget_obj loadAnswer complete_id record id return widget_objelse return None
def read_int32 fid return _unpack_simple fid '>i4' np int32
def getKeys repository repositoryClass repository __class__if repositoryClass list or repositoryClass tuple return range len repository if repositoryClass dict return repository keys return None
@contextlib contextmanagerdef batch_normalization *bricks from blocks bricks import BatchNormalizationbn find_bricks bricks lambda b isinstance b BatchNormalization try for brick in bn brick __enter__ yield finally for brick in bn[ -1 ] brick __exit__
@contextlib contextmanagerdef batch_normalization *bricks from blocks bricks import BatchNormalizationbn find_bricks bricks lambda b isinstance b BatchNormalization try for brick in bn brick __enter__ yield finally for brick in bn[ -1 ] brick __exit__
def add_tagids source return _modify_tagids source
@check_login_required@valid_prefs_requireddef root request local_site_name None if request user is_authenticated url_name u'dashboard'else url_name u'all-review-requests'return HttpResponseRedirect local_site_reverse url_name local_site_name local_site_name
@taskdef upload distutils_check GitHub_release pypi_register pypi_upload test_pypi 2 test_pypi 3
def setsebools pairs persist False if not isinstance pairs dict return {}if persist cmd 'setsebool-P'else cmd 'setsebool'for boolean value in six iteritems pairs cmd '{0}{1} {2}' format cmd boolean value return not __salt__['cmd retcode'] cmd python_shell False
def binary_crossentropy output target return - target * tensor log output + 1 0 - target * tensor log 1 0 - output
def required_module_list docstring None if not docstring return []ret []modules parse_docstring docstring get 'deps' [] for mod in modules try imp find_module mod except ImportError ret append mod return ret
def required_module_list docstring None if not docstring return []ret []modules parse_docstring docstring get 'deps' [] for mod in modules try imp find_module mod except ImportError ret append mod return ret
def HTTPInfoFromException value if isinstance value web HTTPError return value status_code value log_message elif isinstance value InvalidRequestError return 400 value args[0] elif isinstance value HttpForbiddenError return 403 value args[0] elif isinstance value NotFoundError return 404 value args[0] elif isinstance value ServiceUnavailableError return 503 value args[0] else return 500 str value
def _get_current_site request crum get_current_request if not request returnreturn {'id' request site id 'domain' request site domain 'name' request site name}
def ebAuthentication failure proto username password failure trap imap4 NoSupportedAuthentication return proto prompt 'Nosecureauthenticationavailable Logininsecurely? y/N ' addCallback cbInsecureLogin proto username password
def _contains_ch_type info ch_type if not isinstance ch_type string_types raise ValueError '`ch_type`isofclass{actual_class} Itmustbe`str`' format actual_class type ch_type meg_extras ['mag' 'grad' 'planar1' 'planar2']fnirs_extras ['hbo' 'hbr']valid_channel_types sorted [key for key in _PICK_TYPES_KEYS if key 'meg' ] + meg_extras + fnirs_extras if ch_type not in valid_channel_types raise ValueError 'ch_typemustbeoneof%s not"%s"' % valid_channel_types ch_type if info is None raise ValueError 'Cannotcheckforchannelsoftype"%s"becauseinfoisNone' % ch_type return ch_type in [channel_type info ii for ii in range info['nchan'] ]
def load_demo collection_id delete_demo collection_id if not collection_domain Collection is_demo_collection_id collection_id raise Exception 'Invaliddemocollectionid%s' % collection_id demo_filepath os path join feconf SAMPLE_COLLECTIONS_DIR feconf DEMO_COLLECTIONS[collection_id] if demo_filepath endswith 'yaml' yaml_content utils get_file_contents demo_filepath else raise Exception 'Unrecognizedfilepath %s' % demo_filepath collection save_new_collection_from_yaml feconf SYSTEM_COMMITTER_ID yaml_content collection_id publish_collection_and_update_user_profiles feconf SYSTEM_COMMITTER_ID collection_id index_collections_given_ids [collection_id] for collection_node in collection nodes exp_id collection_node exploration_idif exp_services get_exploration_by_id exp_id strict False is None exp_services load_demo exp_id logging info 'Collectionwithid%swasloaded ' % collection_id
@library global_functiondef mozillians_form element template get_template 'includes/form html' context {'form' element}return mark_safe template render context
def get_test_classes_from_testsuite suite if not isinstance suite unittest TestSuite raise TypeError 'notaTestSuite' suite results set for test in suite _tests if isinstance test unittest TestCase results add test __class__ else classes get_test_classes_from_testsuite test results update classes return results
def get_test_classes_from_testsuite suite if not isinstance suite unittest TestSuite raise TypeError 'notaTestSuite' suite results set for test in suite _tests if isinstance test unittest TestCase results add test __class__ else classes get_test_classes_from_testsuite test results update classes return results
def resolve_action bundle default_debug None allow_debug True if not settings DEBUG or not allow_debug return True True if default_debug is None default_debug settings ASSETS_DEBUGdebug bundle debug if bundle debug is not None else default_debug if debug 'merge' return True False elif debug is True return False False elif debug is False return True True else raise ValueError 'Invaliddebugvalue %s' % debug
def resolve_action bundle default_debug None allow_debug True if not settings DEBUG or not allow_debug return True True if default_debug is None default_debug settings ASSETS_DEBUGdebug bundle debug if bundle debug is not None else default_debug if debug 'merge' return True False elif debug is True return False False elif debug is False return True True else raise ValueError 'Invaliddebugvalue %s' % debug
def get_shared_secret_key provider_id secret getattr settings 'CREDIT_PROVIDER_SECRET_KEYS' {} get provider_id if isinstance secret unicode try secret str secret except UnicodeEncodeError secret Nonelog error u'Sharedsecretkeyforcreditprovider"%s"containsnon-ASCIIunicode ' provider_id return secret
def dup_sturm f K if not K has_Field raise DomainError "can'tcomputeSturmsequenceover%s" % K f dup_sqf_part f K sturm [f dup_diff f 1 K ]while sturm[ -1 ] s dup_rem sturm[ -2 ] sturm[ -1 ] K sturm append dup_neg s K return sturm[ -1 ]
def demo_legacy_grammar from nltk grammar import FeatureGrammarg FeatureGrammar fromstring u"\n%startS\nS[sem <hello>]->'hello'\n" print u'Readinggrammar %s' % g print u'*' * 20 for reading in interpret_sents [u'hello'] g semkey u'sem' syn sem reading[0]print print u'output ' sem
def demo_legacy_grammar from nltk grammar import FeatureGrammarg FeatureGrammar fromstring u"\n%startS\nS[sem <hello>]->'hello'\n" print u'Readinggrammar %s' % g print u'*' * 20 for reading in interpret_sents [u'hello'] g semkey u'sem' syn sem reading[0]print print u'output ' sem
def asdict sobject return dict items sobject
def row2feature row id_field geometry_field feature {'type' 'Feature' 'properties' _copy row }geometry feature['properties'] pop geometry_field feature['geometry'] _loadshape _unhexlify geometry feature['id'] feature['properties'] pop id_field return feature
def get_index usage_key children children [unicode child for child in children]return children index usage_key
def bytes_to_elementtree bytes_or_file if isinstance bytes_or_file compat basestring s bytes_or_fileelse s bytes_or_file read if compat is_py3 s _unicode s 'utf-8' f compat StringIO s tree ET ElementTree file f return tree
def double_complex_from_npy_cdouble var res '_complexstuff double_complex_from_npy_cdouble {} ' format var return res
def getAcceptable accept_header have_types accepted parseAcceptHeader accept_header preferred matchTypes accepted have_types return [mtype for mtype _ in preferred]
def _build_element_wise_ufunc_wrapper cres signature ctx cres target_contextlibrary cres libraryfname cres fndesc llvm_func_nameenv Noneif cres objectmode env cres environmentassert env is not None ll_intp cres target_context get_value_type types intp ll_pyobj cres target_context get_value_type types pyobject envptr lc Constant int ll_intp id env inttoptr ll_pyobj else envptr Noneptr build_ufunc_wrapper library ctx fname signature cres objectmode envptr env dtypenums [as_dtype a num for a in signature args]dtypenums append as_dtype signature return_type num return dtypenums ptr env
def tokenizeJsonEntry json_dict return set find_words findall '' join word lower for word in json_dict values
def tokenizeJsonEntry json_dict return set find_words findall '' join word lower for word in json_dict values
def line_2d_to_3d line zs 0 zdir u'z' line __class__ Line3Dline set_3d_properties zs zdir
def _save_password_in_keyring credential_id username password try import keyringreturn keyring set_password credential_id username password except ImportError log error 'Triedtostorepasswordinkeyring butnokeyringmoduleisinstalled' return False
def _save_password_in_keyring credential_id username password try import keyringreturn keyring set_password credential_id username password except ImportError log error 'Triedtostorepasswordinkeyring butnokeyringmoduleisinstalled' return False
def GenApiConfig service_class_names generator None hostname None service_map {}generator generator or api_config ApiConfigGenerator for service_class_name in service_class_names module_name base_service_class_name service_class_name rsplit ' ' 1 module __import__ module_name fromlist base_service_class_name service getattr module base_service_class_name if not isinstance service type and issubclass service remote Service raise TypeError '%sisnotaProtoRPCservice' % service_class_name hostname service api_info hostname or hostname service_map[service_class_name] generator pretty_print_config_to_json service hostname hostname return service_map
def save_list_setting settings filename name new_value old_value None new_value list set new_value new_value sorted new_value key lambda s s lower if old_value is not None if old_value new_value returnsettings set name new_value sublime save_settings filename
def get_comments_file worksheet_path archive valid_files sheet_codename os path split worksheet_path [ -1 ]rels_file PACKAGE_WORKSHEET_RELS + '/' + sheet_codename + ' rels' if rels_file not in valid_files return Nonerels_source archive read rels_file root fromstring rels_source for i in root if i attrib['Type'] COMMENTS_NS comments_file os path split i attrib['Target'] [ -1 ]comments_file PACKAGE_XL + '/' + comments_file if comments_file in valid_files return comments_filereturn None
def get_comments_file worksheet_path archive valid_files sheet_codename os path split worksheet_path [ -1 ]rels_file PACKAGE_WORKSHEET_RELS + '/' + sheet_codename + ' rels' if rels_file not in valid_files return Nonerels_source archive read rels_file root fromstring rels_source for i in root if i attrib['Type'] COMMENTS_NS comments_file os path split i attrib['Target'] [ -1 ]comments_file PACKAGE_XL + '/' + comments_file if comments_file in valid_files return comments_filereturn None
def check_args options for path in [options aws_credentials options master_yml] if path and not os path exists path sys stderr write 'ERROR {path}notfound \n' format path path sys exit -1
def check_args options for path in [options aws_credentials options master_yml] if path and not os path exists path sys stderr write 'ERROR {path}notfound \n' format path path sys exit -1
def dot u v w a b u_1 u_2 u v_1 v_2 vreturn w * u_1 + b * u_2 * w * v_1 + b * v_2 + abs a * u_1 * v_1
@register simple_tag takes_context True def simple_tag_without_context_parameter arg return 'Expectedresult'
def _ensure_datetime_tzinfo datetime tzinfo None if datetime tzinfo is None datetime datetime replace tzinfo UTC if tzinfo is not None datetime datetime astimezone get_timezone tzinfo if hasattr tzinfo 'normalize' datetime tzinfo normalize datetime return datetime
def _ensure_datetime_tzinfo datetime tzinfo None if datetime tzinfo is None datetime datetime replace tzinfo UTC if tzinfo is not None datetime datetime astimezone get_timezone tzinfo if hasattr tzinfo 'normalize' datetime tzinfo normalize datetime return datetime
def with_ioloop method expect_success True def test_method self r method self loop self io_loopif expect_success self pullstream on_recv self on_message_succeed else self pullstream on_recv self on_message_fail loop call_later 1 self attempt_connection loop call_later 1 2 self send_msg if expect_success loop call_later 2 self on_test_timeout_fail else loop call_later 2 self on_test_timeout_succeed loop start if self fail_msg self fail self fail_msg return rreturn test_method
def disable_inheritance path objectType copy True dc daclConstants objectType dc getObjectTypeBit objectType path dc processPath path objectType return _set_dacl_inheritance path objectType False copy None
def clean_config config patterns comment_out_list []for line in config if line strip startswith '#' continueif '#' in line pure_line line[ line index '#' ]else pure_line lineif pure_line strip endswith ' ' comment_out_list append line continueif any [re search pat pure_line for pat in patterns] comment_out_list append line new_config [ line if line not in comment_out_list else '#' + line for line in config]return new_config
def clean_config config patterns comment_out_list []for line in config if line strip startswith '#' continueif '#' in line pure_line line[ line index '#' ]else pure_line lineif pure_line strip endswith ' ' comment_out_list append line continueif any [re search pat pure_line for pat in patterns] comment_out_list append line new_config [ line if line not in comment_out_list else '#' + line for line in config]return new_config
def _get_ax_freq ax ax_freq getattr ax 'freq' None if ax_freq is None if hasattr ax 'left_ax' ax_freq getattr ax left_ax 'freq' None elif hasattr ax 'right_ax' ax_freq getattr ax right_ax 'freq' None if ax_freq is None shared_axes ax get_shared_x_axes get_siblings ax if len shared_axes > 1 for shared_ax in shared_axes ax_freq getattr shared_ax 'freq' None if ax_freq is not None breakreturn ax_freq
def getTreeWalker treeType implementation None **kwargs treeType treeType lower if treeType not in treeWalkerCache if treeType u'dom' from import domtreeWalkerCache[treeType] dom TreeWalkerelif treeType u'genshi' from import genshitreeWalkerCache[treeType] genshi TreeWalkerelif treeType u'lxml' from import etree_lxmltreeWalkerCache[treeType] etree_lxml TreeWalkerelif treeType u'etree' from import etreeif implementation is None implementation default_etreereturn etree getETreeModule implementation **kwargs TreeWalkerreturn treeWalkerCache get treeType
def first_every_last iterable first every last did_first Falsefor item in iterable if not did_first did_first Truefirst item every item if did_first last item
def remove_comments code pattern ' \\" *?\\" \\\' *?\\\' /\\* *?\\*/ //[^\\r\\n]*\\n 'regex re compile pattern re MULTILINE re DOTALL def do_replace match if match group 2 is not None return ''else return match group 1 return regex sub do_replace code
def from_bundle_ingest_dirname cs return pd Timestamp cs replace ' ' ' '
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def get_function_object obj attr getattr obj '__numba__' None if attr return getattr obj attr return obj
def _split_commits_and_tags obj_store lst ignore_unknown False commits set tags set others set for e in lst try o obj_store[e]except KeyError if not ignore_unknown raiseelse if isinstance o Commit commits add e elif isinstance o Tag tags add e tagged o object[1] c t o _split_commits_and_tags obj_store [tagged] ignore_unknown ignore_unknown commits ctags tothers oelse others add e return commits tags others
def eval_expr expr return eval_node ast parse expr body[0] value
def _auto_create_specific_service_result_parser run utils run result_parser _result_parsers[get_name_of_init run ]command_list [c for c in COMMANDS if c not in ['list' 'set_target'] ]return _ServiceResultParser result_parser command_list
def _auto_create_specific_service_result_parser run utils run result_parser _result_parsers[get_name_of_init run ]command_list [c for c in COMMANDS if c not in ['list' 'set_target'] ]return _ServiceResultParser result_parser command_list
def _auto_create_specific_service_result_parser run utils run result_parser _result_parsers[get_name_of_init run ]command_list [c for c in COMMANDS if c not in ['list' 'set_target'] ]return _ServiceResultParser result_parser command_list
def configure_cloud_init cloudcfg open '/etc/cloud/cloud cfg' 'w' cloudcfg write CLOUD_INIT_CFG cloudcfg close
def get_partial_date_formats from django conf import settingsyear_month_format _ 'YEAR_MONTH_FORMAT' month_day_format _ 'MONTH_DAY_FORMAT' if year_month_format 'YEAR_MONTH_FORMAT' year_month_format settings YEAR_MONTH_FORMATif month_day_format 'MONTH_DAY_FORMAT' month_day_format settings MONTH_DAY_FORMATreturn year_month_format month_day_format
def get_partial_date_formats from django conf import settingsyear_month_format _ 'YEAR_MONTH_FORMAT' month_day_format _ 'MONTH_DAY_FORMAT' if year_month_format 'YEAR_MONTH_FORMAT' year_month_format settings YEAR_MONTH_FORMATif month_day_format 'MONTH_DAY_FORMAT' month_day_format settings MONTH_DAY_FORMATreturn year_month_format month_day_format
def get_partial_date_formats from django conf import settingsyear_month_format _ 'YEAR_MONTH_FORMAT' month_day_format _ 'MONTH_DAY_FORMAT' if year_month_format 'YEAR_MONTH_FORMAT' year_month_format settings YEAR_MONTH_FORMATif month_day_format 'MONTH_DAY_FORMAT' month_day_format settings MONTH_DAY_FORMATreturn year_month_format month_day_format
def running_service_owners exclude '/dev' '/home' '/media' '/proc' '/run' '/sys/' '/tmp' '/var' error {}if 'pkg owner' not in __salt__ error['UnsupportedPackageManager'] 'Themoduleforthepackagemanageronthissystemdoesnotsupportlookingupwhichpackage s ownswhichfile s 'if 'file open_files' not in __salt__ error['UnsupportedFileModule'] 'Thefilemoduleonthissystemdoesnotsupportlookingupopenfilesonthesystem'if error return {'Error' error}ret {}open_files __salt__['file open_files'] execs __salt__['service execs'] for path in open_files ignore Falsefor bad_dir in exclude if path startswith bad_dir ignore Trueif ignore continueif not os access path os X_OK continuefor service in execs if path execs[service] pkg __salt__['pkg owner'] path ret[service] next six itervalues pkg return ret
def _clean_missing resource_id items user key '#' + unicode resource_id + ' ' contacts Object filter_permitted user Contact objects filter nuvius_resource__contains key if not len contacts len items candidates []for contact in contacts found Falsefor item in items itemkey key + unicode item id raw if itemkey in contact nuvius_resource found Trueif not found candidates append contact for victim in candidates victim subscribers clear victim delete
@receiver post_save sender User def create_profile_callback sender instance created False **kwargs if created for auto in AutoGroup objects all if re match auto match instance email instance groups add auto group Token objects create user instance Profile objects get_or_create user instance
def def_physical_type unit name r unit _get_physical_type_id if r in _physical_unit_mapping raise ValueError u'{0 r} {1 r} alreadydefinedas{2 r}' format r name _physical_unit_mapping[r] _physical_unit_mapping[r] name
def gating_enabled default None def wrap f def function_wrapper course *args if not course enable_subsection_gating return defaultreturn f course *args return function_wrapperreturn wrap
def _plot results metrics formats title x_ticks x_label format_markers 'x' ' ' 'o' '+' metric_colors 'c' 'm' 'y' 'k' 'g' 'r' 'b' fig plt figure 'scikit-learnmultilabelmetricsbenchmarks' plt title title ax fig add_subplot 111 for i metric in enumerate metrics for j format in enumerate formats ax plot x_ticks results[ i j ] flat label '{} {}' format metric format marker format_markers[j] color metric_colors[ i % len metric_colors ] ax set_xlabel x_label ax set_ylabel 'Time s ' ax legend plt show
def endpoint_absent name profile None **connection_args ret {'name' name 'changes' {} 'result' True 'comment' 'Endpointforservice"{0}"isalreadyabsent' format name }endpoint __salt__['keystone endpoint_get'] name profile profile **connection_args if not endpoint return retelse if __opts__ get 'test' ret['result'] Noneret['comment'] 'Endpointforservice"{0}"willbedeleted' format name return ret__salt__['keystone endpoint_delete'] name profile profile **connection_args ret['comment'] 'Endpointforservice"{0}"hasbeendeleted' format name ret['changes']['endpoint'] 'Deleted'return ret
def endpoint_absent name profile None **connection_args ret {'name' name 'changes' {} 'result' True 'comment' 'Endpointforservice"{0}"isalreadyabsent' format name }endpoint __salt__['keystone endpoint_get'] name profile profile **connection_args if not endpoint return retelse if __opts__ get 'test' ret['result'] Noneret['comment'] 'Endpointforservice"{0}"willbedeleted' format name return ret__salt__['keystone endpoint_delete'] name profile profile **connection_args ret['comment'] 'Endpointforservice"{0}"hasbeendeleted' format name ret['changes']['endpoint'] 'Deleted'return ret
def endpoint_absent name profile None **connection_args ret {'name' name 'changes' {} 'result' True 'comment' 'Endpointforservice"{0}"isalreadyabsent' format name }endpoint __salt__['keystone endpoint_get'] name profile profile **connection_args if not endpoint return retelse if __opts__ get 'test' ret['result'] Noneret['comment'] 'Endpointforservice"{0}"willbedeleted' format name return ret__salt__['keystone endpoint_delete'] name profile profile **connection_args ret['comment'] 'Endpointforservice"{0}"hasbeendeleted' format name ret['changes']['endpoint'] 'Deleted'return ret
def libvlc_media_library_retain p_mlib f _Cfunctions get 'libvlc_media_library_retain' None or _Cfunction 'libvlc_media_library_retain' 1 None None MediaLibrary return f p_mlib
def _get_default_unit_format config return u'cds'
def _get_default_unit_format config return u'cds'
def delete_pool hostname username password name ret {'name' name 'changes' {} 'result' False 'comment' ''}if __opts__['test'] return _test_output ret 'delete' params {'hostname' hostname 'username' username 'password' password 'name' name} existing __salt__['bigip list_pool'] hostname username password name if existing['code'] 200 deleted __salt__['bigip delete_pool'] hostname username password name if deleted['code'] 200 ret['result'] Trueret['comment'] 'Poolwassuccessfullydeleted 'ret['changes']['old'] existing['content']ret['changes']['new'] {}else ret _load_result deleted ret elif existing['code'] 404 ret['result'] Trueret['comment'] 'Thispoolalreadydoesnotexist Nochangesmade 'ret['changes']['old'] {}ret['changes']['new'] {}else ret _load_result existing ret return ret
def spatial_inter_hemi_connectivity src dist verbose None from scipy spatial distance import cdistsrc _ensure_src src kind 'surf' conn cdist src[0]['rr'][src[0]['vertno']] src[1]['rr'][src[1]['vertno']] conn sparse csr_matrix conn < dist dtype int empties [sparse csr_matrix nv nv dtype int for nv in conn shape]conn sparse vstack [sparse hstack [empties[0] conn] sparse hstack [conn T empties[1]] ] return conn
def spatial_inter_hemi_connectivity src dist verbose None from scipy spatial distance import cdistsrc _ensure_src src kind 'surf' conn cdist src[0]['rr'][src[0]['vertno']] src[1]['rr'][src[1]['vertno']] conn sparse csr_matrix conn < dist dtype int empties [sparse csr_matrix nv nv dtype int for nv in conn shape]conn sparse vstack [sparse hstack [empties[0] conn] sparse hstack [conn T empties[1]] ] return conn
def is_page_candidate urlLink urlTitle title artist title slugify title lower artist slugify artist lower sitename re search u'// [^/]+ / *' slugify urlLink lower group 1 urlTitle slugify urlTitle lower if urlTitle find title -1 return Truetokens [ by + '_' + artist for by in BY_TRANS] + [artist sitename sitename replace 'www ' '' ] + LYRICS_TRANS songTitle re sub u' %s ' % u' ' join tokens u'' urlTitle songTitle songTitle strip '_ ' typoRatio 0 9return difflib SequenceMatcher None songTitle title ratio > typoRatio
def is_page_candidate urlLink urlTitle title artist title slugify title lower artist slugify artist lower sitename re search u'// [^/]+ / *' slugify urlLink lower group 1 urlTitle slugify urlTitle lower if urlTitle find title -1 return Truetokens [ by + '_' + artist for by in BY_TRANS] + [artist sitename sitename replace 'www ' '' ] + LYRICS_TRANS songTitle re sub u' %s ' % u' ' join tokens u'' urlTitle songTitle songTitle strip '_ ' typoRatio 0 9return difflib SequenceMatcher None songTitle title ratio > typoRatio
def is_page_candidate urlLink urlTitle title artist title slugify title lower artist slugify artist lower sitename re search u'// [^/]+ / *' slugify urlLink lower group 1 urlTitle slugify urlTitle lower if urlTitle find title -1 return Truetokens [ by + '_' + artist for by in BY_TRANS] + [artist sitename sitename replace 'www ' '' ] + LYRICS_TRANS songTitle re sub u' %s ' % u' ' join tokens u'' urlTitle songTitle songTitle strip '_ ' typoRatio 0 9return difflib SequenceMatcher None songTitle title ratio > typoRatio
@pytest mark cmd@pytest mark django_dbdef test_find_duplicate_emails_noemails capfd member member2 call_command 'find_duplicate_emails' out err capfd readouterr assert 'Thefollowingusershavenoemailset' in out assert 'member' in out assert 'member2' in out
def multiple_file_nmds input_dir output_dir dimensions 2 if not os path exists output_dir os makedirs output_dir file_names os listdir input_dir file_names [fname for fname in file_names if not fname startswith ' ' ]for fname in file_names base_fname ext os path splitext fname infile os path join input_dir fname lines open infile 'U' nmds_res_string nmds lines dimensions outfile os path join output_dir 'nmds_' + base_fname + ' txt' outfile open outfile 'w' outfile write nmds_res_string outfile close
def multiple_file_nmds input_dir output_dir dimensions 2 if not os path exists output_dir os makedirs output_dir file_names os listdir input_dir file_names [fname for fname in file_names if not fname startswith ' ' ]for fname in file_names base_fname ext os path splitext fname infile os path join input_dir fname lines open infile 'U' nmds_res_string nmds lines dimensions outfile os path join output_dir 'nmds_' + base_fname + ' txt' outfile open outfile 'w' outfile write nmds_res_string outfile close
def get_results_dir_list pid core_dir_basename pid_dir_dict {}for debugdir_file in glob glob '/tmp/autotest_results_dir *' a_pid os path splitext debugdir_file [1]results_dir open debugdir_file read strip pid_dir_dict[a_pid] os path join results_dir core_dir_basename results_dir_list []if pid is not None while pid > 1 if pid in pid_dir_dict results_dir_list append pid_dir_dict[pid] pid get_parent_pid pid else results_dir_list pid_dir_dict values return results_dir_list or pid_dir_dict values or [os path join '/tmp' core_dir_basename ]
def intfOptions net Mininet autoStaticArp True net addController 'c0' h1 net addHost 'h1' h2 net addHost 'h2' s1 net addSwitch 's1' link1 net addLink h1 s1 cls TCLink net addLink h2 s1 net start net pingAll info '\n***Configuringoneintfwithbandwidthof5Mb\n' link1 intf1 config bw 5 info '\n***Runningiperftotest\n' net iperf info '\n***Configuringoneintfwithlossof50%\n' link1 intf1 config loss 50 info '\n' net iperf h1 h2 l4Type 'UDP' info '\n***Configuringoneintfwithdelayof15ms\n' link1 intf1 config delay '15ms' info '\n***Runapingtoconfirmdelay\n' net pingPairFull info '\n***Donetesting\n' net stop
def apply_overwrites_to_context context overwrite_context for variable overwrite in overwrite_context items if variable not in context continuecontext_value context[variable]if isinstance context_value list if overwrite in context_value context_value remove overwrite context_value insert 0 overwrite else context[variable] overwrite
def apply_overwrites_to_context context overwrite_context for variable overwrite in overwrite_context items if variable not in context continuecontext_value context[variable]if isinstance context_value list if overwrite in context_value context_value remove overwrite context_value insert 0 overwrite else context[variable] overwrite
def nearest_roads client points params {'points' convert location_list points }return client _get '/v1/nearestRoads' params base_url _ROADS_BASE_URL accepts_clientid False extract_body _roads_extract get 'snappedPoints' []
def _loc_to_eeg_loc loc if loc[3 6] any return np array [loc[0 3] loc[3 6]] Telse return loc[0 3][ np newaxis] copy
def function_call_count variance 0 05 def decorate fn def wrap *args **kw with count_functions variance variance return fn *args **kw return update_wrapper wrap fn return decorate
@skipif not has_qt def test_line_profile_rgb plugin setup_line_profile data chelsea limits None for i in range 6 plugin line_tool _thicken_scan_line line_image scan_data plugin output assert_equal line_image[ line_image 128 ] size 750 assert_equal line_image[ line_image 255 ] size 151 assert_equal line_image shape 300 451 assert_equal scan_data shape 151 3 assert_allclose scan_data max 0 772 rtol 0 001 assert_allclose scan_data mean 0 4359 rtol 0 001
def clean_course_key course_key padding_char return 'course_{}' format b32encode unicode course_key replace ' ' padding_char
def get_non_shed_tool_panel_configs app config_filenames []for config_filename in app config tool_configs tree error_message xml_util parse_xml config_filename if tree is None continueroot tree getroot tool_path root get 'tool_path' None if tool_path is None config_filenames append config_filename return config_filenames
def _canonical_type name if name 'int' return 'int256'if name 'uint' return 'uint256'if name 'fixed' return 'fixed128x128'if name 'ufixed' return 'ufixed128x128'if name startswith 'int[' return 'int256' + name[3 ] if name startswith 'uint[' return 'uint256' + name[4 ] if name startswith 'fixed[' return 'fixed128x128' + name[5 ] if name startswith 'ufixed[' return 'ufixed128x128' + name[6 ] return name
def _canonical_type name if name 'int' return 'int256'if name 'uint' return 'uint256'if name 'fixed' return 'fixed128x128'if name 'ufixed' return 'ufixed128x128'if name startswith 'int[' return 'int256' + name[3 ] if name startswith 'uint[' return 'uint256' + name[4 ] if name startswith 'fixed[' return 'fixed128x128' + name[5 ] if name startswith 'ufixed[' return 'ufixed128x128' + name[6 ] return name
def query *args **kwargs query _ 'query' try return query Query kwargs get 'scope' cachedir __opts__['cachedir'] *args **kwargs except InspectorQueryException as ex raise CommandExecutionError ex except Exception as ex log error _get_error_message ex raise Exception ex
def _maybe_partial_time_string index indexer kind assert isinstance index pd Index if not isinstance index pd DatetimeIndex pd PeriodIndex return indexerif isinstance indexer slice if isinstance indexer start pd compat string_types start index _maybe_cast_slice_bound indexer start 'left' kind else start indexer startif isinstance indexer stop pd compat string_types stop index _maybe_cast_slice_bound indexer stop 'right' kind else stop indexer stopreturn slice start stop elif isinstance indexer pd compat string_types start index _maybe_cast_slice_bound indexer 'left' 'loc' stop index _maybe_cast_slice_bound indexer 'right' 'loc' return slice min start stop max start stop return indexer
def notify_retweet t source t['user']created_at t['created_at']source_user cycle_color source['name'] + color_func c['NOTIFICATION']['source_nick'] '@' + source['screen_name'] notify color_func c['NOTIFICATION']['notify'] 'retweetedyourtweet' date parser parse created_at clock fallback_humanize date clock color_func c['NOTIFICATION']['clock'] clock meta c['NOTIFY_FORMAT']meta source_user join meta split '#source_user' meta notify join meta split '#notify' meta clock join meta split '#clock' meta emojize meta printNicely '' printNicely meta draw t t['retweeted_status'] noti True
def version with settings hide 'running' 'warnings' warn_only True res local 'vagrant--version' capture True if res failed return Noneline res splitlines [ -1 ]version re match 'Vagrant ? v ? ersion ? ? * ' line group 1 return tuple _to_int part for part in version split ' '
def GetRegisteredServerOption clsid optionName keyNameRoot 'CLSID\\%s\\%s' % str clsid str optionName return _get_string keyNameRoot
def test_list_add a HyList [1 2 3] b HyList [3 4 5] c a + b assert c [1 2 3 3 4 5] assert c __class__ HyList
def insort col element get lambda x x if not col col insert 0 element return col lo hi 0 len col while lo < hi mid int hi + lo / 2 if get col[mid] > get element hi midelse lo mid + 1 col insert lo element return col
def timestamp return '%s%s' % date today isoformat datetime now strftime '%I %M%p'
def zk_service_name ip_address keyname key_file '{}/{} key' format KEY_DIRECTORY keyname ssh_cmd ['ssh' '-i' key_file ip_address 'ls{}' format SERVICES_DIR ]response subprocess check_output ssh_cmd init_files response split for init_file in init_files if 'zookeeper' in init_file return init_fileraise OSError 'UnabletofindZooKeeperon{}' format ip_address
def make_dictValidator keyvalidator valuevalidator def v d newd util OrderedDict for key value in d iteritems newd[keyvalidator key ] valuevalidator value return newdv keyvalidator keyvalidatorv valuevalidator valuevalidatorreturn v
def delete_vpnservice vpnservice profile None conn _auth profile return conn delete_vpnservice vpnservice
def crosstalk width height connections d { 'x' 0 i i for i in range width }for j in range 1 height d update { 'x' j i noop [ 'x' j - 1 randint 0 width for _ in range connections ] for i in range width } return d [ 'x' height - 1 i for i in range width ]
def get_state_ptr context builder name assert name in 'py' 'np' func_name 'numba_get_%s_random_state' % name fnty ir FunctionType rnd_state_ptr_t fn builder module get_or_insert_function fnty func_name fn attributes add 'readnone' fn attributes add 'nounwind' return builder call fn
def _get_unicode data force False if isinstance data binary_type return data decode u'utf-8' elif data is None return u''elif force if PY2 return unicode data else return str data else return data
def gaussian_kl_divergence mean ln_var assert isinstance mean variable Variable assert isinstance ln_var variable Variable J mean sizevar exponential exp ln_var return sum sum mean * mean + sum sum var - sum sum ln_var - J * 0 5
def nodesplit name parts name split NODENAME_SEP 1 if len parts 1 return None parts[0] return parts
def xpath elem path return elem xpath path namespaces NS
def xpath elem path return elem xpath path namespaces NS
def volume_type_access_remove context type_id project_id return IMPL volume_type_access_remove context type_id project_id
def list_nat_rules module driver network_domain try return driver ex_list_nat_rules network_domain except DimensionDataAPIException e get_exception module fail_json msg 'FailedtolistNATrules %s' % e message
def await_results program timeout_seconds 2 countdown timeout_seconds * 10 while program poll is None and countdown > 0 time sleep 0 1 countdown - 1if countdown 0 program kill raise TimeoutFailure '<programtimedout>'
def await_results program timeout_seconds 2 countdown timeout_seconds * 10 while program poll is None and countdown > 0 time sleep 0 1 countdown - 1if countdown 0 program kill raise TimeoutFailure '<programtimedout>'
def await_results program timeout_seconds 2 countdown timeout_seconds * 10 while program poll is None and countdown > 0 time sleep 0 1 countdown - 1if countdown 0 program kill raise TimeoutFailure '<programtimedout>'
def _reloader_observer server app interval fd lockfile tempfile mkstemp prefix 'bottle-reloader ' suffix ' lock' os close fd try while os path exists lockfile args [sys executable] + sys argv environ os environ copy environ['BOTTLE_CHILD'] 'true'environ['BOTTLE_LOCKFILE'] lockfilep subprocess Popen args env environ while p poll is None os utime lockfile None time sleep interval if p poll 3 if os path exists lockfile os unlink lockfile sys exit p poll elif not server quiet print 'Reloadingserver 'except KeyboardInterrupt passif os path exists lockfile os unlink lockfile
def _reloader_observer server app interval fd lockfile tempfile mkstemp prefix 'bottle-reloader ' suffix ' lock' os close fd try while os path exists lockfile args [sys executable] + sys argv environ os environ copy environ['BOTTLE_CHILD'] 'true'environ['BOTTLE_LOCKFILE'] lockfilep subprocess Popen args env environ while p poll is None os utime lockfile None time sleep interval if p poll 3 if os path exists lockfile os unlink lockfile sys exit p poll elif not server quiet print 'Reloadingserver 'except KeyboardInterrupt passif os path exists lockfile os unlink lockfile
def http_auth_required realm def decorator fn @wraps fn def wrapper *args **kwargs if _check_http_auth return fn *args **kwargs if _security _unauthorized_callback return _security _unauthorized_callback else r _security default_http_auth_realm if callable realm else realm h {'WWW-Authenticate' 'Basicrealm "%s"' % r }return _get_unauthorized_response headers h return wrapperif callable realm return decorator realm return decorator
def get_all_groups inventory containers {}for container_name in inventory['_meta']['hostvars'] keys if '_' not in container_name continuegroups get_groups_for_container inventory container_name containers[container_name] groupsreturn containers
def cache_disk seconds 86400 * 5 cache_folder '/tmp' def do_cache function def inner_function *args **kwargs 'Calculateacachekeybasedonthedecoratedmethodsignature\nargs[1]indicatesthedomainoftheinputs wehashondomain \n'key sha1 str args[1] + str kwargs encode 'utf-8' hexdigest filepath os path join cache_folder key if os path exists filepath modified os path getmtime filepath age_seconds time time - modified if age_seconds < seconds return pickle load open filepath 'rb' result function *args **kwargs pickle dump result open filepath 'wb' return resultreturn inner_functionreturn do_cache
def cache_disk seconds 86400 * 5 cache_folder '/tmp' def do_cache function def inner_function *args **kwargs 'Calculateacachekeybasedonthedecoratedmethodsignature\nargs[1]indicatesthedomainoftheinputs wehashondomain \n'key sha1 str args[1] + str kwargs encode 'utf-8' hexdigest filepath os path join cache_folder key if os path exists filepath modified os path getmtime filepath age_seconds time time - modified if age_seconds < seconds return pickle load open filepath 'rb' result function *args **kwargs pickle dump result open filepath 'wb' return resultreturn inner_functionreturn do_cache
def cache_disk seconds 86400 * 5 cache_folder '/tmp' def do_cache function def inner_function *args **kwargs 'Calculateacachekeybasedonthedecoratedmethodsignature\nargs[1]indicatesthedomainoftheinputs wehashondomain \n'key sha1 str args[1] + str kwargs encode 'utf-8' hexdigest filepath os path join cache_folder key if os path exists filepath modified os path getmtime filepath age_seconds time time - modified if age_seconds < seconds return pickle load open filepath 'rb' result function *args **kwargs pickle dump result open filepath 'wb' return resultreturn inner_functionreturn do_cache
def get_master_uri required True env None argv None if env is None env os environif argv is None argv sys argvtry for arg in argv if arg startswith '__master ' val Nonetry _ val arg split ' ' except passif not val raise ROSEnvException "__masterremappingargument'%s'improperlyspecified" % arg return valreturn env[ROS_MASTER_URI]except KeyError as e if required raise ROSEnvException '%shasnotbeenconfigured' % ROS_MASTER_URI
@require_context@require_volume_existsdef volume_glance_metadata_bulk_create context volume_id metadata session get_session with session begin for key value in metadata items rows session query models VolumeGlanceMetadata filter_by volume_id volume_id filter_by key key filter_by deleted False all if len rows > 0 raise exception GlanceMetadataExists key key volume_id volume_id vol_glance_metadata models VolumeGlanceMetadata vol_glance_metadata volume_id volume_idvol_glance_metadata key keyvol_glance_metadata value six text_type value session add vol_glance_metadata
def test_iba_error_y_score_prob y_true y_pred _ make_prediction binary True aps make_index_balanced_accuracy alpha 0 5 squared True average_precision_score assert_raises AttributeError aps y_true y_pred brier make_index_balanced_accuracy alpha 0 5 squared True brier_score_loss assert_raises AttributeError brier y_true y_pred kappa make_index_balanced_accuracy alpha 0 5 squared True cohen_kappa_score assert_raises AttributeError kappa y_true y_pred ras make_index_balanced_accuracy alpha 0 5 squared True roc_auc_score assert_raises AttributeError ras y_true y_pred
def test_iba_error_y_score_prob y_true y_pred _ make_prediction binary True aps make_index_balanced_accuracy alpha 0 5 squared True average_precision_score assert_raises AttributeError aps y_true y_pred brier make_index_balanced_accuracy alpha 0 5 squared True brier_score_loss assert_raises AttributeError brier y_true y_pred kappa make_index_balanced_accuracy alpha 0 5 squared True cohen_kappa_score assert_raises AttributeError kappa y_true y_pred ras make_index_balanced_accuracy alpha 0 5 squared True roc_auc_score assert_raises AttributeError ras y_true y_pred
def delete name **kwargs ret {'comment' 'Failedtodeletebeacon{0} ' format name 'result' False}if 'test' in kwargs and kwargs['test'] ret['result'] Trueret['comment'] 'Beacon {0}wouldbedeleted ' format name else try eventer salt utils event get_event 'minion' opts __opts__ res __salt__['event fire'] {'name' name 'func' 'delete'} 'manage_beacons' if res event_ret eventer get_event tag '/salt/minion/minion_beacon_delete_complete' wait 30 if event_ret and event_ret['complete'] beacons event_ret['beacons']if name not in beacons ret['result'] Trueret['comment'] 'Deletedbeacon {0} ' format name return retexcept KeyError ret['comment'] 'Eventmodulenotavailable Beaconaddfailed 'return ret
def walk_metadata metadata_url headers None expect_json False metadata dict for line in query_metadata metadata_url headers expect_json if line endswith '/' and not line 'public-keys/' key line[ -1 ]metadata[key] walk_metadata metadata_url + line headers expect_json else results query_metadata metadata_url + line headers expect_json if len results 1 metadata[line] results pop else metadata[line] resultsreturn metadata
def shellQuote value return "'%s'" % value replace "'" '\'"\'"\''
def _postprocess_for_cut fac bins retbins x_is_series series_index name if x_is_series fac Series fac index series_index name name if not retbins return facreturn fac bins
def _postprocess_for_cut fac bins retbins x_is_series series_index name if x_is_series fac Series fac index series_index name name if not retbins return facreturn fac bins
def MatchScorerAmbigs match mismatch matches None matches matches or {'A' {'A' None} 'G' {'G' None} 'C' {'C' None} 'T' {'T' None} '-' {'-' None}} for ambig chars in DNASequence iupac_degeneracies iteritems try matches[ambig] update {} fromkeys chars except KeyError matches[ambig] {} fromkeys chars for char in chars try matches[char] update {ambig None} except KeyError matches[char] {ambig None}def scorer x y if x not in matches or y not in matches raise ValueError 'Unknowncharacter %sor%s' % x y if y in matches[x] return matchelse return mismatchreturn scorer
def MatchScorerAmbigs match mismatch matches None matches matches or {'A' {'A' None} 'G' {'G' None} 'C' {'C' None} 'T' {'T' None} '-' {'-' None}} for ambig chars in DNASequence iupac_degeneracies iteritems try matches[ambig] update {} fromkeys chars except KeyError matches[ambig] {} fromkeys chars for char in chars try matches[char] update {ambig None} except KeyError matches[char] {ambig None}def scorer x y if x not in matches or y not in matches raise ValueError 'Unknowncharacter %sor%s' % x y if y in matches[x] return matchelse return mismatchreturn scorer
def write_embedding_tensor_to_disk vocab_path output_path sess embedding embeddings sess run embedding with open output_path 'w' as out_f with open vocab_path as vocab_f for index word in enumerate vocab_f word word strip embedding embeddings[index]out_f write word + ' DCTB ' + ' DCTB ' join [str x for x in embedding] + '\n'
def write_embedding_tensor_to_disk vocab_path output_path sess embedding embeddings sess run embedding with open output_path 'w' as out_f with open vocab_path as vocab_f for index word in enumerate vocab_f word word strip embedding embeddings[index]out_f write word + ' DCTB ' + ' DCTB ' join [str x for x in embedding] + '\n'
def updateInstance self try self __class__ latestClass self __class__ except TypeError if hasattr self __class__ '__slots__' raise RebuildError "Can'trebuildclasswith__slots__onPython<2 6" else raise
def _normalize_basedir basedir None if isinstance basedir six string_types basedir [x strip for x in basedir split ' ' ]if basedir is None basedir []if not basedir basedir _get_yum_config_value 'reposdir' if not isinstance basedir list or not basedir raise SaltInvocationError 'Couldnotdetermineanyrepodirectories' return basedir
def change_cwd cwd os getcwd if os path split cwd [1] 'scripts' os chdir os path join cwd os pardir
@_np deprecate message 'scipy constants K2Cisdeprecatedinscipy0 18 0 Usescipy constants convert_temperatureinstead Notethatthenewfunctionhasadifferentsignature ' def K2C K return _np asanyarray K - zero_Celsius
def disable_monitor try adapt get_monitor_adapter if not adapt is None tmp getoutput 'airmon-ngstop%s' % adapt debug 'killedmonitoradapter%s' % adapt except Exception as j Error 'errorkillingmonitoradapter %s' % j
def absent name ret {'name' name 'changes' {} 'result' False 'comment' ''}if not __salt__['chronos has_job'] name ret['result'] Trueret['comment'] 'Job{0}alreadyabsent' format name return retif __opts__['test'] ret['result'] Noneret['comment'] 'Job{0}issettoberemoved' format name return retif __salt__['chronos rm_job'] name ret['changes'] {'job' name}ret['result'] Trueret['comment'] 'Removedjob{0}' format name return retelse ret['result'] Falseret['comment'] 'Failedtoremovejob{0}' format name return ret
def delete_queue name region opts None user None queues list_queues region opts user url_map _parse_queue_list queues logger logging getLogger __name__ logger debug 'map' + six text_type url_map if name in url_map delete {'queue-url' url_map[name]}rtn _run_aws 'delete-queue' region region opts opts user user **delete success Trueerr ''out '{0}deleted' format name else out ''err 'Deletefailed'success Falseret {'retcode' 0 if success else 1 'stdout' out 'stderr' err}return ret
def ec2_credentials_create user_id None name None tenant_id None tenant None profile None **connection_args kstone auth profile **connection_args if name user_id user_get name name profile profile **connection_args [name]['id']if not user_id return {'Error' 'CouldnotresolveUserID'}if tenant tenant_id tenant_get name tenant profile profile **connection_args [tenant]['id']if not tenant_id return {'Error' 'CouldnotresolveTenantID'}newec2 kstone ec2 create user_id tenant_id return {'access' newec2 access 'secret' newec2 secret 'tenant_id' newec2 tenant_id 'user_id' newec2 user_id}
def send_verification_mail request user verification_type verify_url reverse verification_type kwargs {u'uidb36' int_to_base36 user id u'token' default_token_generator make_token user } + u'?next ' + next_url request or u'/' context {u'request' request u'user' user u'verify_url' verify_url}subject_template_name u'email/%s_subject txt' % verification_type subject subject_template subject_template_name context send_mail_template subject u'email/%s' % verification_type settings DEFAULT_FROM_EMAIL user email context context
def send_verification_mail request user verification_type verify_url reverse verification_type kwargs {u'uidb36' int_to_base36 user id u'token' default_token_generator make_token user } + u'?next ' + next_url request or u'/' context {u'request' request u'user' user u'verify_url' verify_url}subject_template_name u'email/%s_subject txt' % verification_type subject subject_template subject_template_name context send_mail_template subject u'email/%s' % verification_type settings DEFAULT_FROM_EMAIL user email context context
def start_project_transfer project user reason signer signing TimestampSigner token signer sign user id project transfer_token tokenproject save template mail_builder transfer_startcontext {'project' project 'receiver' user 'token' token 'reason' reason}email template user context email send
def show_image kwargs call None if call 'function' raise SaltCloudSystemExit 'Theshow_imagefunctionmustbecalledwith-for--function ' items query action 'template' command kwargs['image'] if 'error' in items return items['error']ret {}for item in items ret update {item attrib['name'] item attrib} return ret
def CombinePlaces places time_resolution sorted_places sorted [{'locality' GetPlace p['placemark'] 'timestamp' p['timestamp'] 'opacity' 1 0 'num_combined' 1 'total_count' p['total_count']} for p in places] key itemgetter 'timestamp' place_list []def _GetAvgTimestamp p return p['timestamp'] / p['num_combined'] def _MaybeCombinePlace p if place_list last_place place_list[ -1 ]if p['locality'] last_place['locality'] and abs p['timestamp'] - _GetAvgTimestamp last_place < time_resolution for attr in ['timestamp' 'total_count' 'num_combined'] last_place[attr] + p[attr]returnplace_list append p for p in sorted_places _MaybeCombinePlace p for p in place_list p['timestamp'] _GetAvgTimestamp p return place_list
def CombinePlaces places time_resolution sorted_places sorted [{'locality' GetPlace p['placemark'] 'timestamp' p['timestamp'] 'opacity' 1 0 'num_combined' 1 'total_count' p['total_count']} for p in places] key itemgetter 'timestamp' place_list []def _GetAvgTimestamp p return p['timestamp'] / p['num_combined'] def _MaybeCombinePlace p if place_list last_place place_list[ -1 ]if p['locality'] last_place['locality'] and abs p['timestamp'] - _GetAvgTimestamp last_place < time_resolution for attr in ['timestamp' 'total_count' 'num_combined'] last_place[attr] + p[attr]returnplace_list append p for p in sorted_places _MaybeCombinePlace p for p in place_list p['timestamp'] _GetAvgTimestamp p return place_list
def CombinePlaces places time_resolution sorted_places sorted [{'locality' GetPlace p['placemark'] 'timestamp' p['timestamp'] 'opacity' 1 0 'num_combined' 1 'total_count' p['total_count']} for p in places] key itemgetter 'timestamp' place_list []def _GetAvgTimestamp p return p['timestamp'] / p['num_combined'] def _MaybeCombinePlace p if place_list last_place place_list[ -1 ]if p['locality'] last_place['locality'] and abs p['timestamp'] - _GetAvgTimestamp last_place < time_resolution for attr in ['timestamp' 'total_count' 'num_combined'] last_place[attr] + p[attr]returnplace_list append p for p in sorted_places _MaybeCombinePlace p for p in place_list p['timestamp'] _GetAvgTimestamp p return place_list
def f5_reduce f B order Polyn f ring orderdomain Polyn f ring domainif not Polyn f return fwhile True g ffor h in B if Polyn h if monomial_divides Polyn h LM Polyn f LM t term_div Polyn f LT Polyn h LT domain if sig_cmp sig_mult Sign h t[0] Sign f order < 0 hp lbp_mul_term h t f lbp_sub f hp breakif g f or not Polyn f return f
def inv_item_total_volume row try inv_item getattr row 'inv_inv_item' except AttributeError inv_item rowtry quantity inv_item quantityexcept AttributeError return 0 0try supply_item getattr row 'supply_item' volume supply_item volumeexcept AttributeError itable current s3db inv_inv_itemstable current s3db supply_itemquery itable id inv_item id & itable item_id stable id supply_item current db query select stable volume limitby 0 1 first if not supply_item returnelse volume supply_item volumeif volume is None return current messages['NONE']else return quantity * volume
def markup_join seq buf []iterator imap soft_unicode seq for arg in iterator buf append arg if hasattr arg '__html__' return Markup u'' join chain buf iterator return concat buf
def create_clip_in_selected_slot creator song clip_length None selected_slot song view highlighted_clip_slotif creator and selected_slot and not selected_slot has_clip creator create selected_slot clip_length song view detail_clip selected_slot clipreturn selected_slot clip
def _check_estimator estimator get_params True valid_methods 'predict' 'transform' 'predict_proba' 'decision_function' if not hasattr estimator 'fit' or not any hasattr estimator method for method in valid_methods raise ValueError 'estimatormustbeascikit-learntransformeroranestimatorwiththefitandapredict-like e g predict_proba oratransformmethod ' if get_params and not hasattr estimator 'get_params' raise ValueError 'estimatormustbeascikit-learntransformeroranestimatorwiththeget_paramsmethodthatallowscloning '
def bokeh_installer env_name install_string if os name 'nt' command_string 'activate%s&%s' % env_name install_string else command_string 'sourceactivate%s %s' % env_name install_string result subprocess call command_string shell True executable '/bin/bash' return result 0
def bokeh_installer env_name install_string if os name 'nt' command_string 'activate%s&%s' % env_name install_string else command_string 'sourceactivate%s %s' % env_name install_string result subprocess call command_string shell True executable '/bin/bash' return result 0
def bokeh_installer env_name install_string if os name 'nt' command_string 'activate%s&%s' % env_name install_string else command_string 'sourceactivate%s %s' % env_name install_string result subprocess call command_string shell True executable '/bin/bash' return result 0
def get_permalink_url self return '/' join self settings['SITEURL'] self get_permalink_path
def ck_delete try filename request args[0]except raise HTTP 401 'Requiredargumentfilenamemissing ' table s3db doc_ckeditordb table upload filename delete filepath os path join request folder 'uploads' filename os unlink filepath
def binop x op y lineno None col None lineno x lineno if lineno is None else lineno col x col_offset if col is None else col return ast BinOp left x op op right y lineno lineno col_offset col
def _fastq_generic in_handle out_handle mapping from Bio SeqIO QualityIO import FastqGeneralIteratorcount 0null chr 0 for title seq old_qual in FastqGeneralIterator in_handle count + 1qual old_qual translate mapping if null in qual raise ValueError 'Invalidcharacterinqualitystring' out_handle write '@%s\n%s\n+\n%s\n' % title seq qual return count
def _fastq_generic in_handle out_handle mapping from Bio SeqIO QualityIO import FastqGeneralIteratorcount 0null chr 0 for title seq old_qual in FastqGeneralIterator in_handle count + 1qual old_qual translate mapping if null in qual raise ValueError 'Invalidcharacterinqualitystring' out_handle write '@%s\n%s\n+\n%s\n' % title seq qual return count
def _gitInit path runCommand ['git' 'init' path path] _gitConfig path
def convert_date_input date_to_convert if date_to_convert try converted_date datetime datetime strptime date_to_convert '%m/%d/%Y' except raise InvalidDateFormat return converted_dateelse return date_to_convert
def convert_date_input date_to_convert if date_to_convert try converted_date datetime datetime strptime date_to_convert '%m/%d/%Y' except raise InvalidDateFormat return converted_dateelse return date_to_convert
def build_ws_upgrade_request web_socket_url extra_headers None web_socket_version DEFAULT_PROTOCOL_VERSION origin None request_headers Headers request_headers['Sec-WebSocket-Key'] gen_ws_sec_key for key value in WEBSOCKET_UPGRADE_HEADERS items request_headers[key] valueif extra_headers is not None for key value in extra_headers request_headers[key] valuerequest_headers['Sec-WebSocket-Version'] str web_socket_version if origin is not None request_headers['Origin'] originelse scheme 'https //' if 'wss //' in web_socket_url else 'http //' args scheme web_socket_url get_domain request_headers['Origin'] '%s%s' % args forged_url web_socket_url url_string replace 'wss //' 'https //' 1 forged_url forged_url replace 'ws //' 'http //' 1 forged_url URL forged_url upgrade_request FuzzableRequest forged_url 'GET' headers request_headers return upgrade_request
def show destination protocol None return __proxy__['napalm call'] 'get_route_to' **{'destination' destination 'protocol' protocol}
def _ConcatenateErrorMessages prefix status if status error_detail return prefix + ' ' + status error_detail return prefix
def validate_instantiation **kwargs if kwargs and kwargs get 'netapp_mode' 'proxy' returnLOG warning _LW 'ItisnottherecommendedwaytousedriversbyNetApp PleaseuseNetAppDrivertoachievethefunctionality '
def _get_return_dict success True data None errors None warnings None data {} if data is None else data errors [] if errors is None else errors warnings [] if warnings is None else warnings ret {'success' success 'data' data 'errors' errors 'warnings' warnings}return ret
def update_collection_summary collection_id contributor_id_to_add create_collection_summary collection_id contributor_id_to_add
def set_boot_arch arch 'default' if arch not in ['i386' 'x86_64' 'default'] msg 'Invalidvaluepassedforarch \nMustbei386 x86_64 ordefault \nPassed {0}' format arch raise SaltInvocationError msg cmd 'systemsetup-setkernelbootarchitecture{0}' format arch salt utils mac_utils execute_return_success cmd return salt utils mac_utils confirm_updated arch get_boot_arch
def user_agent _implementation platform python_implementation if _implementation 'CPython' _implementation_version platform python_version elif _implementation 'PyPy' _implementation_version '%s %s %s' % sys pypy_version_info major sys pypy_version_info minor sys pypy_version_info micro if sys pypy_version_info releaselevel 'final' _implementation_version '' join [_implementation_version sys pypy_version_info releaselevel] elif _implementation 'Jython' _implementation_version platform python_version elif _implementation 'IronPython' _implementation_version platform python_version else _implementation_version 'Unknown'try p_system platform system p_release platform release except IOError p_system 'Unknown'p_release 'Unknown'return '' join [ 'pip/%s' % pip __version__ '%s/%s' % _implementation _implementation_version '%s/%s' % p_system p_release ]
def import_demo_csv_part2 job_id request post_vars jobif not job_id return "ErrorNoJobID'sprovided"request controller 'stats'output s3_rest_controller 'stats' 'demographic_data' csv_stylesheet 'demographic_data xsl' totalRecords output[0]totalErrors output[1]totalIgnored output[2]from gluon serializers import json as jsonsresponse headers['Content-Type'] 'application/json'return jsons {'totalRecords' totalRecords 'totalErrors' totalErrors 'totalIgnored' totalIgnored}
def create_app config None app_name None if app_name is None app_name DefaultConfig PROJECTapp Flask app_name instance_path INSTANCE_FOLDER_PATH instance_relative_config True configure_app app config configure_hook app configure_blueprints app configure_extensions app configure_logging app configure_template_filters app configure_error_handlers app configure_cli app return app
def _assert_n_free raw_sss lower upper None upper lower if upper is None else upper n_free raw_sss info['proc_history'][0]['max_info']['sss_info']['nfree']assert_true lower < n_free < upper 'nfreefail %s< %s< %s' % lower n_free upper
def __get_location conn vm_ location config get_cloud_config_value 'location' vm_ __opts__ return conn ex_get_zone location
def update_ports_tree ports_tree _check_config_exists if ports_tree cmd 'poudriereports-u-p{0}' format ports_tree else cmd 'poudriereports-u'ret __salt__['cmd run'] cmd return ret
def _get_dev_port_var backend instance None port_var 'BACKEND_PORT %s' % str backend lower if instance is not None port_var '%s %d' % port_var instance return port_var
def assign perm user_or_group obj None warnings warn u"Shortcutfunction'assign'isbeingrenamedto'assign_perm' Updateyourcodeaccordinglyasoldnamewillbedepreciatedin2 0version " DeprecationWarning return assign_perm perm user_or_group obj
def get_hosts_mapped_with_segments context segment_host_mapping network SegmentHostMapping get_objects context return {row host for row in segment_host_mapping}
def get_hosts_mapped_with_segments context segment_host_mapping network SegmentHostMapping get_objects context return {row host for row in segment_host_mapping}
def split_function payload return payload[ - append_size ] payload
def split_function payload return payload[ - append_size ] payload
def safe_str o return _safeFormat str o
def safe_str o return _safeFormat str o
def rand_base length bad chars cset set chars - set list bad if len cset 0 return ''chars [list cset [random randrange len cset ] for i in xrange length ]chars map str chars return '' join chars
def get_args parser build_arg_parser args parser parse_args return prompt_for_password args
def get_args parser build_arg_parser args parser parse_args return prompt_for_password args
def xl_cell_to_rowcol_abs cell_str if not cell_str return 0 0 False False match range_parts match cell_str col_abs match group 1 col_str match group 2 row_abs match group 3 row_str match group 4 if col_abs col_abs Trueelse col_abs Falseif row_abs row_abs Trueelse row_abs Falseexpn 0col 0for char in reversed col_str col + ord char - ord 'A' + 1 * 26 ** expn expn + 1row int row_str - 1 col - 1return row col row_abs col_abs
def save_registration_code user course_id mode_slug invoice None order None invoice_item None code random_code_generator matching_coupons Coupon objects filter code code is_active True if matching_coupons return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item course_registration CourseRegistrationCode code code course_id unicode course_id created_by user invoice invoice order order mode_slug mode_slug invoice_item invoice_item try with transaction atomic course_registration save return course_registrationexcept IntegrityError return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item
def save_registration_code user course_id mode_slug invoice None order None invoice_item None code random_code_generator matching_coupons Coupon objects filter code code is_active True if matching_coupons return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item course_registration CourseRegistrationCode code code course_id unicode course_id created_by user invoice invoice order order mode_slug mode_slug invoice_item invoice_item try with transaction atomic course_registration save return course_registrationexcept IntegrityError return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item
def save_registration_code user course_id mode_slug invoice None order None invoice_item None code random_code_generator matching_coupons Coupon objects filter code code is_active True if matching_coupons return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item course_registration CourseRegistrationCode code code course_id unicode course_id created_by user invoice invoice order order mode_slug mode_slug invoice_item invoice_item try with transaction atomic course_registration save return course_registrationexcept IntegrityError return save_registration_code user course_id mode_slug invoice invoice order order invoice_item invoice_item
def skipIfPy3 message from unittest import skipIffrom platform import is_py3return skipIf is_py3 message
def region_invalidate namespace region *args if callable namespace if not region region namespace _arg_regionnamespace namespace _arg_namespaceif not region raise BeakerException 'Regionorcallablefunctionnamespaceisrequired' else region cache_regions[region]cache Cache _get_cache namespace region cache_key '' join str x for x in args cache remove_value cache_key
def region_invalidate namespace region *args if callable namespace if not region region namespace _arg_regionnamespace namespace _arg_namespaceif not region raise BeakerException 'Regionorcallablefunctionnamespaceisrequired' else region cache_regions[region]cache Cache _get_cache namespace region cache_key '' join str x for x in args cache remove_value cache_key
def region_invalidate namespace region *args if callable namespace if not region region namespace _arg_regionnamespace namespace _arg_namespaceif not region raise BeakerException 'Regionorcallablefunctionnamespaceisrequired' else region cache_regions[region]cache Cache _get_cache namespace region cache_key '' join str x for x in args cache remove_value cache_key
def usergroup_exists name None node None nodeids None **connection_args conn_args _login **connection_args zabbix_version apiinfo_version **connection_args try if conn_args if LooseVersion zabbix_version > LooseVersion '2 5' if not name name ''ret usergroup_get name None **connection_args return bool ret else method 'usergroup exists'params {}if not name and not node and not nodeids return {'result' False 'comment' 'Pleasesubmitname nodeornodeidsparametertocheckifatleastoneusergroupexists '}if name params['name'] nameif LooseVersion zabbix_version < LooseVersion '2 4' if node params['node'] nodeif nodeids params['nodeids'] nodeidsret _query method params conn_args['url'] conn_args['auth'] return ret['result']else raise KeyErrorexcept KeyError return False
def test_lambda_list_keywords_mixed can_compile u' fn x&restxs&kwargskw listxxskw ' cant_compile u' fn x&restxs&fasfkey{bar"baz"} ' if PY3 can_compile u' fn[x&restxs&kwargskwxs&kwonlykwoxs] listxxskwxskwoxs '
def select_best_encoding outstream None outstream outstream or sys stdout encoding getattr outstream 'encoding' None or sys getdefaultencoding if is_ascii_encoding encoding return 'utf-8'return encoding
def dump filename options out sys stdout with open filename u'rb' as file_obj return _dump file_obj options options out out
def _count_leading line ch i n 0 len line while i < n and line[i] ch i + 1return i
def _count_leading line ch i n 0 len line while i < n and line[i] ch i + 1return i
def read_channel model channel_name monitor_name 'monitor' return getattr model monitor_name channels[channel_name] val_record[ -1 ]
def read_channel model channel_name monitor_name 'monitor' return getattr model monitor_name channels[channel_name] val_record[ -1 ]
def read_channel model channel_name monitor_name 'monitor' return getattr model monitor_name channels[channel_name] val_record[ -1 ]
def display_name_with_default_escaped block return display_name_with_default block replace '<' '&lt ' replace '>' '&gt '
def display_name_with_default_escaped block return display_name_with_default block replace '<' '&lt ' replace '>' '&gt '
def _translate_message message return {'id' message['id'] 'project_id' message['project_id'] 'request_id' message['request_id'] 'resource_type' message['resource_type'] 'resource_uuid' message get 'resource_uuid' 'event_id' message['event_id'] 'message_level' message['message_level'] 'created_at' message['created_at'] 'expires_at' message get 'expires_at' }
def cleanBlockQuotedText text joiner '' L filter truth map _lineClean split text '\n' return joiner join L
def cleanBlockQuotedText text joiner '' L filter truth map _lineClean split text '\n' return joiner join L
def last_modified_date_to_timestamp last_modified_date_str start datetime datetime strptime last_modified_date_str '%Y-%m-%dT%H %M %S %f' delta start - EPOCH return Timestamp delta total_seconds
def analyze movie_review_filename language_client language Client with open movie_review_filename 'r' as review_file document language_client document_from_html review_file read annotations document annotate_text include_sentiment True include_syntax False include_entities False print_result annotations
def analyze movie_review_filename language_client language Client with open movie_review_filename 'r' as review_file document language_client document_from_html review_file read annotations document annotate_text include_sentiment True include_syntax False include_entities False print_result annotations
def _do_for_subarray entry condition func path None if path is None path []if isinstance entry list if condition entry func entry path else for index item in enumerate entry _do_for_subarray item condition func path + [index]
def file_move session dc_ref src_file dst_file LOG debug 'Movingfilefrom% src sto% dst s ' {'src' src_file 'dst' dst_file} vim session vimmove_task session _call_method vim 'MoveDatastoreFile_Task' vim service_content fileManager sourceName str src_file sourceDatacenter dc_ref destinationName str dst_file destinationDatacenter dc_ref session _wait_for_task move_task LOG debug 'Filemoved'
def get_download_url_for_platform url_templates platform_info_dict os_ok Falsearchitecture_ok Falsefor url_template in url_templates os_name url_template get 'os' None architecture url_template get 'architecture' None if os_name if os_name lower platform_info_dict['os'] os_ok Trueelse os_ok Falseelse os_ok Trueif architecture if architecture lower platform_info_dict['architecture'] architecture_ok Trueelse architecture_ok Falseelse architecture_ok Trueif os_ok and architecture_ok return url_templatereturn None
def test_random_state_transfer class Graph def __init__ self seed 123 self rng MRG_RandomStreams seed self y self rng uniform size 1 g1 Graph seed 123 f1 theano function [] g1 y g2 Graph seed 987 f2 theano function [] g2 y g2 rng rstate g1 rng rstatefor su1 su2 in zip g1 rng state_updates g2 rng state_updates su2[0] set_value su1[0] get_value numpy testing assert_array_almost_equal f1 f2 decimal 6
def get_package_data package walk [ dirpath replace package + os sep '' 1 filenames for dirpath dirnames filenames in os walk package if not os path exists os path join dirpath '__init__ py' ]filepaths []for base filenames in walk filepaths extend [os path join base filename for filename in filenames] return {package filepaths}
def get_required_content course user required_content []if settings FEATURES get 'MILESTONES_APP' try milestone_paths get_course_milestones_fulfillment_paths unicode course id serialize_user user except InvalidMilestoneRelationshipTypeException return required_contentfor path_key in milestone_paths milestone_path milestone_paths[path_key]if milestone_path get 'content' and len milestone_path['content'] for content in milestone_path['content'] required_content append content return required_content
def batch_iter data batch_size num_epochs shuffle True data np array data data_size len data num_batches_per_epoch int len data - 1 / batch_size + 1 for epoch in range num_epochs if shuffle shuffle_indices np random permutation np arange data_size shuffled_data data[shuffle_indices]else shuffled_data datafor batch_num in range num_batches_per_epoch start_index batch_num * batch_size end_index min batch_num + 1 * batch_size data_size yield shuffled_data[start_index end_index]
def buildgraph cursor include_last_hop False include_target False only_connected True graph {}entry_nodes set for host in cursor if 'traces' not in host continuefor trace in host['traces'] hops trace['hops']hops sort key lambda hop hop['ttl'] if not hops continueentry_nodes add hops[0]['ipaddr'] if not include_last_hop and not include_target if hops[ -1 ]['ipaddr'] host['addr'] hops pop if not include_last_hop hops pop for i hop in enumerate hops[1 ] if not only_connected or hop['ttl'] - hops[i]['ttl'] 1 graph setdefault hops[i]['ipaddr'] set update [hop['ipaddr']] return graph entry_nodes
def GetPrintableStrs namespace kinds namespace_str namespace or '' if kinds kind_str 'all%sentities' % ' ' join kinds else kind_str ''return namespace_str kind_str
def resize data socket try socket tab set_viewport _get_viewport data['size'] except KeyError AttributeError pass
def resize data socket try socket tab set_viewport _get_viewport data['size'] except KeyError AttributeError pass
def top_contributors_aoa start None end None locale None count 10 page 1 query ReplyMetricsMappingType search facet 'creator_id' filtered True size BIG_NUMBER locale locale split '-' [0] if locale else None query _apply_filters query start end locale return _get_creator_counts query count page
def has_win32com if not sys platform startswith 'win32' return Falsetry mod __import__ 'win32com' except ImportError return Falsereturn True
def _ensure_dir directory try os makedirs directory except OSError as exc if exc errno errno EEXIST passelse raise
@register tagdef overextends parser token if DJANGO_VERSION > 1 9 warnings warn u"The`overextends`templatetagisdeprecatedinfavourofDjango'sbuilt-in`extends`tag whichsupportsrecursiveextensioninDjango1 9andabove " DeprecationWarning stacklevel 2 bits token split_contents if len bits 2 raise TemplateSyntaxError u"'%s'takesoneargument" % bits[0] parent_name parser compile_filter bits[1] nodelist parser parse if nodelist get_nodes_by_type ExtendsNode raise TemplateSyntaxError u"'%s'cannotappearmorethanonceinthesametemplate" % bits[0] return OverExtendsNode nodelist parent_name None
@register tagdef overextends parser token if DJANGO_VERSION > 1 9 warnings warn u"The`overextends`templatetagisdeprecatedinfavourofDjango'sbuilt-in`extends`tag whichsupportsrecursiveextensioninDjango1 9andabove " DeprecationWarning stacklevel 2 bits token split_contents if len bits 2 raise TemplateSyntaxError u"'%s'takesoneargument" % bits[0] parent_name parser compile_filter bits[1] nodelist parser parse if nodelist get_nodes_by_type ExtendsNode raise TemplateSyntaxError u"'%s'cannotappearmorethanonceinthesametemplate" % bits[0] return OverExtendsNode nodelist parent_name None
@register tagdef overextends parser token if DJANGO_VERSION > 1 9 warnings warn u"The`overextends`templatetagisdeprecatedinfavourofDjango'sbuilt-in`extends`tag whichsupportsrecursiveextensioninDjango1 9andabove " DeprecationWarning stacklevel 2 bits token split_contents if len bits 2 raise TemplateSyntaxError u"'%s'takesoneargument" % bits[0] parent_name parser compile_filter bits[1] nodelist parser parse if nodelist get_nodes_by_type ExtendsNode raise TemplateSyntaxError u"'%s'cannotappearmorethanonceinthesametemplate" % bits[0] return OverExtendsNode nodelist parent_name None
@taskdef win_install_deps options download_dir path 'downloaded' abspath if not download_dir exists download_dir makedirs win_packages {'Py2exe' dev_config['WINDOWS']['py2exe'] 'Nose' dev_config['WINDOWS']['nose'] 'PyProj' dev_config['WINDOWS']['pyproj'] 'lXML' dev_config['WINDOWS']['lxml']}failed Falsefor package url in win_packages iteritems tempfile download_dir / os path basename url print 'Installingfile ' + tempfile grab_winfiles url tempfile package try easy_install main [tempfile] except Exception as e failed Trueprint 'installfailedwitherror ' eos remove tempfile if failed and sys maxsize > 2 ** 32 print '64bitarchitectureisnotcurrentlysupported'print 'tryfindingthe64binariesforpy2exe nose andpyproj'elif failed print 'installfailedforpy2exe nose and/orpyproj'else print 'Windowsdependenciesnowcomplete Runpipinstall-egeonode--use-mirrors'
@taskdef win_install_deps options download_dir path 'downloaded' abspath if not download_dir exists download_dir makedirs win_packages {'Py2exe' dev_config['WINDOWS']['py2exe'] 'Nose' dev_config['WINDOWS']['nose'] 'PyProj' dev_config['WINDOWS']['pyproj'] 'lXML' dev_config['WINDOWS']['lxml']}failed Falsefor package url in win_packages iteritems tempfile download_dir / os path basename url print 'Installingfile ' + tempfile grab_winfiles url tempfile package try easy_install main [tempfile] except Exception as e failed Trueprint 'installfailedwitherror ' eos remove tempfile if failed and sys maxsize > 2 ** 32 print '64bitarchitectureisnotcurrentlysupported'print 'tryfindingthe64binariesforpy2exe nose andpyproj'elif failed print 'installfailedforpy2exe nose and/orpyproj'else print 'Windowsdependenciesnowcomplete Runpipinstall-egeonode--use-mirrors'
def loadImageSeries filelist None if filelist is None or len filelist < 1 returnimglist []for img in filelist if not os path exists img print 'unabletofind%s' % img continuetry im Image open img convert2byte except if not isSpiderImage img print img + 'isnotaSpiderimagefile' continueim info['filename'] imgimglist append im return imglist
def remove_metadata module_data start_line start_col end_line end_col lines module_data split '\n' new_lines lines[ start_line]if start_col 0 new_lines append lines[start_line][ start_col] next_line lines[end_line]if len next_line - 1 end_col new_lines append next_line[end_col ] if len lines > end_line new_lines extend lines[ end_line + 1 ] return '\n' join new_lines
@check_event_permissionsdef delete_event request event_id next None login_required True event get_object_or_404 Event id event_id next next or reverse 'day_calendar' args [event calendar slug] next get_next_url request next return delete_object request model Event object_id event_id post_delete_redirect next template_name 'schedule/delete_event html' extra_context dict next next login_required login_required
@_docstring 'instrument' def get_instrument_by_id id includes [] release_status [] release_type [] params _check_filter_and_make_params 'instrument' includes release_status release_type return _do_mb_query 'instrument' id includes params
@_docstring 'instrument' def get_instrument_by_id id includes [] release_status [] release_type [] params _check_filter_and_make_params 'instrument' includes release_status release_type return _do_mb_query 'instrument' id includes params
def present name maintenance_db user None db_password None db_host None db_port None db_user None ret {'name' name 'changes' {} 'result' True 'comment' 'Language{0}isalreadyinstalled' format name }dbargs {'runas' user 'host' db_host 'user' db_user 'port' db_port 'password' db_password}languages __salt__['postgres language_list'] maintenance_db **dbargs if name not in languages if __opts__['test'] ret['result'] Noneret['comment'] 'Language{0}issettobeinstalled' format name return retif __salt__['postgres language_create'] name maintenance_db **dbargs ret['comment'] 'Language{0}hasbeeninstalled' format name ret['changes'][name] 'Present'else ret['comment'] 'Failedtoinstalllanguage{0}' format name ret['result'] Falsereturn ret
def _sqlite_bytelower bytestring if not six PY2 return bytestring lower return buffer bytes bytestring lower
def _sqlite_bytelower bytestring if not six PY2 return bytestring lower return buffer bytes bytestring lower
def count_sprintf_parameters string return len _sprintf_placeholder_re findall string
def test_write assert not getattr django_conf settings 'FOOBAR' None 1234 assets_conf settings FOOBAR 1234assert django_conf settings FOOBAR 1234
def test_write assert not getattr django_conf settings 'FOOBAR' None 1234 assets_conf settings FOOBAR 1234assert django_conf settings FOOBAR 1234
def random_password_generator characters string letters + string digits pwd_size constants PASSWORD_SIZEreturn '' join random choice characters for x in range pwd_size
def _can_support_reuse_db connection return not connection creation _get_test_db_name ' memory '
def _can_support_reuse_db connection return not connection creation _get_test_db_name ' memory '
def _can_support_reuse_db connection return not connection creation _get_test_db_name ' memory '
def _expected_output_args f inspect currentframe f_back f_backi f f_lasti + 3 bytecode f f_code co_codeinstruction ordornot bytecode[i] while True if instruction dis opmap['DUP_TOP'] if ordornot bytecode[ i + 1 ] dis opmap['UNPACK_SEQUENCE'] return ordornot bytecode[ i + 2 ] i + 4instruction ordornot bytecode[i] continueif instruction dis opmap['STORE_NAME'] return 1if instruction dis opmap['UNPACK_SEQUENCE'] return ordornot bytecode[ i + 1 ] if instruction dis opmap get 'UNPACK_EX' -1 return ordornot bytecode[ i + 1 ] + ordornot bytecode[ i + 2 ] + 0 1 return 0
def _firstResult gen return list gen [0]
def get_compile_mode node if not isinstance node mod raise TypeError 'expectedmodnode got%r' % node __class__ __name__ return {Expression 'eval' Interactive 'single'} get node __class__ 'expr'
def generate_sha1 string salt None if not isinstance string str text_type string str string if not salt salt sha1 str random random encode 'utf-8' hexdigest [ 5]salted_bytes smart_bytes salt + smart_bytes string hash_ sha1 salted_bytes hexdigest return salt hash_
def load_scores_ba_dir dir return FileBinnedArrayDir dir
def load_scores_ba_dir dir return FileBinnedArrayDir dir
def get_oauth_token_from_body body if six PY3 body body decode 'utf-8' credentials urlparse parse_qs body key credentials['oauth_token'][0]secret credentials['oauth_token_secret'][0]token {'key' key 'id' key 'secret' secret}expires_at credentials get 'oauth_expires_at' if expires_at token['expires'] expires_at[0]return token
def urivalue uri uri uri[ uri find ' ' + 1 -1 ] strip if uri and uri[0] in '\'"' and uri[0] uri[ -1 ] return stringvalue uri else return uri
def urivalue uri uri uri[ uri find ' ' + 1 -1 ] strip if uri and uri[0] in '\'"' and uri[0] uri[ -1 ] return stringvalue uri else return uri
def qc_results params alpha score qc_tol qc_verbose False assert not np isnan params max assert params params ravel 'F' min 'paramsshouldhavealreadybeen1-d'fprime score params k_params len params passed_array np array [True] * k_params for i in range k_params if alpha[i] > 0 if abs fprime[i] - alpha[i] / alpha[i] > qc_tol passed_array[i] Falseqc_dict dict fprime fprime alpha alpha params params passed_array passed_array passed passed_array min if not passed num_failed passed_array False sum message 'QCcheckdidnotpassfor%doutof%dparameters' % num_failed k_params message + '\nTryincreasingsolveraccuracyornumberofiterations decreasingalpha orswitchsolvers'if qc_verbose message + _get_verbose_addon qc_dict print message return passed
def qc_results params alpha score qc_tol qc_verbose False assert not np isnan params max assert params params ravel 'F' min 'paramsshouldhavealreadybeen1-d'fprime score params k_params len params passed_array np array [True] * k_params for i in range k_params if alpha[i] > 0 if abs fprime[i] - alpha[i] / alpha[i] > qc_tol passed_array[i] Falseqc_dict dict fprime fprime alpha alpha params params passed_array passed_array passed passed_array min if not passed num_failed passed_array False sum message 'QCcheckdidnotpassfor%doutof%dparameters' % num_failed k_params message + '\nTryincreasingsolveraccuracyornumberofiterations decreasingalpha orswitchsolvers'if qc_verbose message + _get_verbose_addon qc_dict print message return passed
def fork_exec cmd exec_env None logfile None pass_fds None env os environ copy if exec_env is not None for env_name env_val in exec_env items if callable env_val env[env_name] env_val env get env_name else env[env_name] env_valpid os fork if pid 0 if logfile fds [1 2]with open logfile 'r+b' as fptr for desc in fds try os dup2 fptr fileno desc except OSError passif pass_fds and hasattr os 'set_inheritable' for fd in pass_fds os set_inheritable fd True args shlex split cmd os execvpe args[0] args env else return pid
def _calc_julian_from_U_or_W year week_of_year day_of_week week_starts_Mon first_weekday datetime_date year 1 1 weekday if not week_starts_Mon first_weekday first_weekday + 1 % 7 day_of_week day_of_week + 1 % 7 week_0_length 7 - first_weekday % 7 if week_of_year 0 return 1 + day_of_week - first_weekday else days_to_week week_0_length + 7 * week_of_year - 1 return 1 + days_to_week + day_of_week
def _calc_julian_from_U_or_W year week_of_year day_of_week week_starts_Mon first_weekday datetime_date year 1 1 weekday if not week_starts_Mon first_weekday first_weekday + 1 % 7 day_of_week day_of_week + 1 % 7 week_0_length 7 - first_weekday % 7 if week_of_year 0 return 1 + day_of_week - first_weekday else days_to_week week_0_length + 7 * week_of_year - 1 return 1 + days_to_week + day_of_week
def delete name region None key None keyid None profile None conn _get_conn region region key key keyid keyid profile profile if not exists name region key keyid profile return Truetry conn delete_load_balancer name msg 'DeletedELB{0} ' format name log info msg return Trueexcept boto exception BotoServerError as error log debug error msg 'FailedtodeleteELB{0}' format name log error msg return False
def query_series api_key user_token member_name None params {}if member_name member_id query_member_id api_key user_token member_name if member_id params {u'id' member_id}else log error u'member%rnotfound' % member_name return []r requests get API_URL_PREFIX + u'members/infos' params params headers {u'Accept' u'application/json' u'X-BetaSeries-Version' u'2 1' u'X-BetaSeries-Key' api_key u'X-BetaSeries-Token' user_token} assert r status_code 200 u'BadHTTPstatuscode %s' % r status_code j r json error_list j[u'errors']for err in error_list log error str err if not error_list return [x[u'title'] for x in j[u'member'][u'shows'] if x[u'user'][u'archived'] is False ]else return []
def func_namespace func kls Noneif hasattr func 'im_func' kls func im_classfunc func im_funcif kls return '%s %s' % kls __module__ kls __name__ else return '%s %s' % func __module__ func __name__
def get_casava_version fastq1 if isinstance fastq1 list fastq_read_f_line1 fastq1[0]else fastq_read_f_line1 fastq1 readline fastq1 seek 0 post_casava_v180 is_casava_v180_or_later fastq_read_f_line1 if post_casava_v180 check_header_match_f check_header_match_180_or_laterelse check_header_match_f check_header_match_pre180return check_header_match_f
def get_casava_version fastq1 if isinstance fastq1 list fastq_read_f_line1 fastq1[0]else fastq_read_f_line1 fastq1 readline fastq1 seek 0 post_casava_v180 is_casava_v180_or_later fastq_read_f_line1 if post_casava_v180 check_header_match_f check_header_match_180_or_laterelse check_header_match_f check_header_match_pre180return check_header_match_f
def get_casava_version fastq1 if isinstance fastq1 list fastq_read_f_line1 fastq1[0]else fastq_read_f_line1 fastq1 readline fastq1 seek 0 post_casava_v180 is_casava_v180_or_later fastq_read_f_line1 if post_casava_v180 check_header_match_f check_header_match_180_or_laterelse check_header_match_f check_header_match_pre180return check_header_match_f
def nova_to_osvif_vif vif LOG debug 'ConvertingVIF%s' vif funcname '_nova_to_osvif_vif_' + vif['type'] replace ' ' '_' func getattr sys modules[__name__] funcname None if not func raise exception NovaException "UnsupportedVIFtype% type sconvert'% func s'" % {'type' vif['type'] 'func' funcname} try vifobj func vif LOG debug 'Convertedobject%s' vifobj return vifobjexcept NotImplementedError LOG debug 'NoconversionforVIFtype%syet' vif['type'] return None
def upgrade migrate_engine meta MetaData bind migrate_engine instances Table 'instances' meta autoload True shadow_instances Table 'shadow_instances' meta autoload True ephemeral_key_uuid Column 'ephemeral_key_uuid' String 36 instances create_column ephemeral_key_uuid shadow_instances create_column ephemeral_key_uuid copy migrate_engine execute instances update values ephemeral_key_uuid None migrate_engine execute shadow_instances update values ephemeral_key_uuid None
def get_client env eget env getg regex_client search eget 'http_x_forwarded_for' '' client g group or '' split ' ' [0] if g else None if client in None '' 'unknown' g regex_client search eget 'remote_addr' '' if g client g group elif env http_host startswith '[' client ' 1'else client '127 0 0 1'if not is_valid_ip_address client raise HTTP 400 'BadRequest request client %s ' % client return client
def custom command user None conf_file None bin_env None ret __salt__['cmd run_all'] _ctl_cmd command None conf_file bin_env runas user python_shell False return _get_return ret
def custom command user None conf_file None bin_env None ret __salt__['cmd run_all'] _ctl_cmd command None conf_file bin_env runas user python_shell False return _get_return ret
@webob dec wsgify@util check_accept 'application/json' def get_resource_provider req uuid util wsgi_path_item req environ 'uuid' context req environ['placement context']resource_provider objects ResourceProvider get_by_uuid context uuid req response body encodeutils to_utf8 jsonutils dumps _serialize_provider req environ resource_provider req response content_type 'application/json'return req response
def defoveate_channel img rings dense_input start_idx ring_w numpy sum rings inner_h img shape[1] - 2 * ring_w inner_w img shape[2] - 2 * ring_w end_idx start_idx + inner_h * inner_w inner_img dense_input[ start_idx end_idx] reshape -1 inner_h inner_w img[ ring_w ring_w + inner_h ring_w ring_w + inner_w ] inner_imgidx 0start_idx end_idxfor rd in rings start_idx restore_ring img idx rd dense_input start_idx idx + rdreturn start_idx
def s3_location_constraint_for_region region region _fix_region region if not region or region _S3_REGION_WITH_NO_LOCATION_CONSTRAINT return ''else return region
def s3_location_constraint_for_region region region _fix_region region if not region or region _S3_REGION_WITH_NO_LOCATION_CONSTRAINT return ''else return region
def s3_location_constraint_for_region region region _fix_region region if not region or region _S3_REGION_WITH_NO_LOCATION_CONSTRAINT return ''else return region
@click command u'publish-realtime' @click argument u'event' @click option u'--message' @click option u'--room' @click option u'--user' @click option u'--doctype' @click option u'--docname' @click option u'--after-commit' @pass_contextdef publish_realtime context event message room user doctype docname after_commit from frappe import publish_realtimefor site in context sites try frappe init site site frappe connect publish_realtime event message message room room user user doctype doctype docname docname after_commit after_commit frappe db commit finally frappe destroy
@loader_option def contains_eager loadopt attr alias None if alias is not None if not isinstance alias str info inspect alias alias info selectablecloned loadopt set_relationship_strategy attr {'lazy' 'joined'} propagate_to_loaders False cloned local_opts['eager_from_alias'] aliasreturn cloned
@loader_option def contains_eager loadopt attr alias None if alias is not None if not isinstance alias str info inspect alias alias info selectablecloned loadopt set_relationship_strategy attr {'lazy' 'joined'} propagate_to_loaders False cloned local_opts['eager_from_alias'] aliasreturn cloned
def _get_index_videos course return list {attr video[attr] for attr in ['edx_video_id' 'client_video_id' 'created' 'duration' 'status']} for video in _get_videos course
def assert_has_text output text assert output find text > 0 "Outputfiledidnotcontainexpectedtext'%s' output'%s' " % text output
def assert_has_text output text assert output find text > 0 "Outputfiledidnotcontainexpectedtext'%s' output'%s' " % text output
def call args try return command_output args except subprocess CalledProcessError as e raise ReplayGainError u'{0}exitedwithstatus{1}' format args[0] e returncode except UnicodeEncodeError raise ReplayGainError u'argumentencodingfailed'
def _get_date data position dummy0 opts dummy1 end position + 8 millis _UNPACK_LONG data[position end] [0]return _millis_to_datetime millis opts end